[
  {
    "objectID": "normes_identite/summary.html",
    "href": "normes_identite/summary.html",
    "title": "Summary",
    "section": "",
    "text": "Summary\nIn summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "normes_identite/references.html",
    "href": "normes_identite/references.html",
    "title": "Bibliographie",
    "section": "",
    "text": "References\n\nAkerlof, George A. 1997. “Social Distance and Social Decisions.” Econometrica 65: 1005–28. https://doi.org/10.2307/2171877.\n\n\nAkerlof, George A., and R. Kranton. 2000a. “Economics and Identity.” Quarterly Journal of Economics 115: 715–53. https://doi.org/10.1162/003355300554881.\n\n\n———. 2002. “Identity and Schooling: Some Lessons for the Economics of Education.” Journal of Economic Literature 40: 1167–1201. https://doi.org/10.1257/002205102762203585.\n\n\n———. 2005. “Identity and the Economics of Organizations.” Journal of Economic Perspectives 19: 9–32. https://doi.org/10.1257/0895330053147930.\n\n\nAkerlof, George A., and Rachel E. Kranton. 2000b. “Economics and Identity.” The Quarterly Journal of Economics 115 (3): 715–53. https://www.jstor.org/stable/2586894.\n\n\nAkerlof, George A, and Rachel E Kranton. n.d.b. “Identity and Schooling: Some Lessons for the Economics of Education,” 36.\n\n\n———. n.d.a. “Identity and Schooling: Some Lessons for the Economics of Education,” 36.\n\n\n“Analyse bibliométrique de la littérature croisant genre et communs.” n.d. Accessed November 8, 2023. https://www.afd.fr/fr/ressources/analyse-bibliometrique-de-la-litterature-croisant-genre-et-communs.\n\n\nAusten-Smith, D., and Roland G. Fryer. 2005. “An Economic Analysis of ‘Acting White’.” Quarterly Journal of Economics 120: 551–83. https://doi.org/10.1093/QJE/120.2.551.\n\n\nBem, Sandra L. 1974. “The Measurement of Psychological Androgyny.” Journal of Consulting and Clinical Psychology 42 (2): 155–62. https://doi.org/10.1037/h0036215.\n\n\nBénabou, R., and J. Tirole. 2004. “Incentives and Prosocial Behavior.” IZA Institute of Labor Economics Discussion Paper Series null: null. https://doi.org/10.2139/ssrn.639043.\n\n\n———. 2011. “Identity, Morals, and Taboos: Beliefs as Assets.” The Quarterly Journal of Economics 126 2: 805–55. https://doi.org/10.1093/QJE/QJR002.\n\n\nBernhard, Helen, E. Fehr, and U. Fischbacher. 2006. “Group Affiliation and Altruistic Norm Enforcement.” The American Economic Review 96: 217–21. https://doi.org/10.1257/000282806777212594.\n\n\nBernheim, Douglas. 1994. “A Theory of Conformity.” Journal of Political Economy 102: 841–77. https://doi.org/10.1086/261957.\n\n\nBertrand, Marianne. 2011. “New Perspectives on Gender.” Handbook of Labor Economics 4: 1543–90. https://doi.org/10.1016/S0169-7218(11)02415-4.\n\n\nBertrand, Marianne, Emir Kamenica, and Jessica Pan. 2013. “Gender Identity and Relative Income Within Households.” Development Economics: Women null: null. https://doi.org/10.1093/QJE/QJV001.\n\n\nBrenøe, Anne Ardila, Lea Heursen, Eva Ranehill, and Roberto A. Weber. 2022. “Continuous Gender Identity and Economics.” AEA Papers and Proceedings 112 (May): 573–77. https://doi.org/10.1257/pandp.20221083.\n\n\nBrock, W. 2001. “Discrete Choice with Social Interactions.” IEEE Transactions on Information Theory, null. https://doi.org/10.1111/1467-937X.00168.\n\n\nBuscatto, Marie. 2014. “La Culture, c’est (Aussi) Une Question de Genre.” In Questions de Genre, Questions de Culture, 125–43. Questions de Culture. Paris: Ministère de la Culture - DEPS. https://doi.org/10.3917/deps.octob.2014.02.0125.\n\n\nBuscattO, Marie. n.d. “La culture, c’est (aussi) une question de genre.”\n\n\nChakravarty, Surajeet, Miguel A. Fonseca, S. Ghosh, and S. Marjit. 2015. “Religious Fragmentation , Social Identity and Cooperation : Evidence from an Artefactual Field Experiment in India ∗.” https://doi.org/10.1016/j.euroecorev.2015.12.006.\n\n\n———. 2016. “Religious Fragmentation, Social Identity and Conflict: Evidence from an Artefactual Field Experiment in India.” PLoS ONE 11: null. https://doi.org/10.1371/journal.pone.0164708.\n\n\nCharness, G., Ramón Cobo-Reyes, and Natalia Jiménez. 2014. “Identities, Selection, and Contributions in a Public-Goods Game.” Games Econ. Behav. 87: 322–38. https://doi.org/10.1016/J.GEB.2014.05.002.\n\n\nCharness, G., Luca Rigotti, and A. Rustichini. 2005. “Individual Behavior and Group Membership * First Draft : December 24 , 2004 This Draft : March 12 , 2005.” https://www.semanticscholar.org/paper/f621d3b2b9b51166b06b96f4ab66dfd0de41de89.\n\n\nChen, Yan, and S. Li. 2009. “Group Identity and Social Preferences.” The American Economic Review 99: 431–57. https://doi.org/10.1257/AER.99.1.431.\n\n\nChowdhury, Subhasish M., J. Jeon, and Abhijit Ramalingam. 2016. “Identity and Group Conflict.” European Economic Review 90: 107–21. https://doi.org/10.1016/J.EUROECOREV.2016.02.003.\n\n\nCipriani, Enzo, Charles-Edouard Giguère, Eugénie Samson, Ioana Cotocea, and Robert-Paul Juster. n.d.b. “Comment mesurer indirectement le genre en recherche sur les humains?” 21.\n\n\n———. n.d.a. “Comment mesurer indirectement le genre en recherche sur les humains?” 21.\n\n\nCosta-Font, Joan, and F. Cowell. 2013. “Social Identity and Redistributive Preferences: A Survey.” Econometrics: Econometric & Statistical Methods - Special Topics eJournal null: null. https://doi.org/10.1111/joes.12061.\n\n\nCosta-Font, Joan, and Frank Cowell. 2015. “Social Identity and Redistributive Preferences: A Survey.” Journal of Economic Surveys 29 (2): 357–74. https://doi.org/10.1111/joes.12061.\n\n\nDickinson, D., David Masclet, and Emmanuel Peterlé. 2018. “Discrimination as Favoritism: The Private Benefits and Social Costs of in-Group Favoritism in an Experimental Labor Market.” Behavioral & Experimental Economics eJournal null: null. https://doi.org/10.1016/J.EUROECOREV.2018.03.004.\n\n\nDrouvelis, Michalis, and Daniele Nosenzo. 2013. “Group Identity and Leading-by-Example.” Journal of Economic Psychology 39: 414–25. https://doi.org/10.1016/J.JOEP.2013.06.005.\n\n\nDugar, Subhasish, and Quazi Shahriar. 2012. “Group Identity and the Moral Hazard Problem: Experimental Evidence.” O&M: Personnel Management eJournal null: null. https://doi.org/10.1111/j.1530-9134.2012.00350.x.\n\n\nFalk, A., and Christian Zehnder. 2013. “A City-Wide Experiment on Trust Discrimination.” Journal of Public Economics 100: 15–27. https://doi.org/10.1016/J.JPUBECO.2013.01.005.\n\n\nFernández, Raquel, A. Fogli, and Claudia Olivetti. 2004. “Mothers and Sons: Preference Formation and Female Labor Force Dynamics.” Quarterly Journal of Economics 119: 1249–99. https://doi.org/10.1162/0033553042476224.\n\n\nFilmer, Deon, and Lant H Pritchett. 2023. “Estimating Wealth Effects Without Expenditure Data-or Tears: An Application to Educational Enrollments in States of India.”\n\n\nFryer, Roland G., Roland G. Fryer, and Paul Torelli. 2010. “An Empirical Analysis of ‘Acting White’.” Journal of Public Economics 94: 380–96. https://doi.org/10.1016/J.JPUBECO.2009.10.011.\n\n\nGoette, L., David Huffman, and Stephan Meier. 2012. “The Impact of Social Ties on Group Interactions: Evidence from Minimal Groups and Randomly Assigned Real Groups.” ERN: Behavioral Economics (Topic) null: null. https://doi.org/10.1257/MIC.4.1.101.\n\n\nGoldin, Claudia, and Lawrence F. Katz. 2016. “A Most Egalitarian Profession: Pharmacy and the Evolution of a Family-Friendly Occupation.” Journal of Labor Economics 34 (3): 705–46. https://doi.org/10.1086/685505.\n\n\nHeap, Shaun P. Hargreaves, and D. Zizzo. 2006. “The Value of Groups.” New Institutional Economics null: null. https://doi.org/10.2139/ssrn.951619.\n\n\nHett, Florian, Markus Kröll, and Mario Mechtel. 2017. “Choosing Who You Are: The Structure and Behavioral Effects of Revealed Identification Preferences.” https://doi.org/10.2139/ssrn.2837519.\n\n\nIoannou, Christos A., Shi Qi, and A. Rustichini. 2015. “Group Payoffs as Public Signals.” Journal of Economic Psychology 48: 89–105. https://doi.org/10.1016/J.JOEP.2015.03.003.\n\n\nJeon, J. 2014. “Essays on Social Preference.” https://www.semanticscholar.org/paper/704538b5d30d29329348bf71e9d8e6c9c04ea317.\n\n\nKlor, Esteban F., and Moses Shayo. 2007. “Social Identity and Preferences over Redistribution.” Behavioral & Experimental Economics null: null. https://doi.org/10.1016/J.JPUBECO.2009.12.003.\n\n\nKranton, R., M. Pease, Seth Sanders, and S. Huettel. 2013a. “Identity, Group Conflict, and Social Preferences.” https://www.semanticscholar.org/paper/9fb14901b7e9ce906667219254b49edc10f7aca8.\n\n\n———. 2013b. “Identity, Groups, and Social Preferences.” https://www.semanticscholar.org/paper/52c43f7403316f8989157d00f43d4d7a5ba4c06b.\n\n\nLanda, Dimitri, and Dominik Duell. 2015. “Social Identity and Electoral Accountability.” American Journal of Political Science 59: 671–89. https://doi.org/10.1111/AJPS.12128.\n\n\nLi, S. 2020. “Group Identity, Ingroup Favoritism, and Discrimination.” https://doi.org/10.1007/978-3-319-57365-6_123-1.\n\n\nLi, S., Kutsal Dogan, and E. Haruvy. 2011. “Group Identity in Markets.” International Journal of Industrial Organization 29: 104–15. https://doi.org/10.1016/J.IJINDORG.2010.04.001.\n\n\nMagliozzi, Devon, Aliya Saperstein, and Laurel Westbrook. 2016. “Scaling up: Representing Gender Diversity in Survey Research.” Socius 2 (January): 2378023116664352. https://doi.org/10.1177/2378023116664352.\n\n\nMechtel, Mario, Florian Hett, and Markus Kröll. 2014. “Endogenous Social Identity and Group Choice.” https://www.semanticscholar.org/paper/edf248303c840d8c243a513d47b113d6da469481.\n\n\nMorita, H., and Maroš Servátka. 2011. “Group Identity and Relation-Specific Investment: An Experimental Investigation.” Law & Prosociality eJournal null: null. https://doi.org/10.2139/ssrn.1743882.\n\n\nNelson, Julie A. 2015. “Are Women Really More Risk-Averse Than Men? A Re-Analysis of the Literature Using Expanded Methods.” Journal of Economic Surveys 29 (3): 566–85. https://doi.org/10.1111/joes.12069.\n\n\nOckenfels, Axel, and Peter Werner. 2014. “Beliefs and Ingroup Favoritism.” Journal of Economic Behavior and Organization 108: 453–62. https://doi.org/10.1016/J.JEBO.2013.12.003.\n\n\nOctobre, Sylvie. 2008. “Loisirs culturels et construction du genre au sein de la famille:” Agora débats/jeunesses N° 47 (1): 98–110. https://doi.org/10.3917/agora.047.0098.\n\n\nPelletier, Roxanne, Blaine Ditto, and Louise Pilote. 2015. “A Composite Measure of Gender and Its Association with Risk Factors in Patients with Premature Acute Coronary Syndrome.” Psychosomatic Medicine 77 (5): 517–26. https://doi.org/10.1097/PSY.0000000000000186.\n\n\nPerivier, Hélène. 2020. L’économie féministe. Presses de Sciences Po.\n\n\n“Rapport sur les LGBTIphobies 2024 \\textbar DILCRAH.” n.d. Accessed December 15, 2024. https://www.dilcrah.gouv.fr/ressources/rapport-sur-les-lgbtiphobies-2024.\n\n\nRoszak, Joanna. n.d.a. “6. Culture as a Factor Influencing Expression of One’s Own Identity: Measuring Gender Identity.”\n\n\n———. n.d.b. “Culture as a Factor Influencing Expression of One&#39;s Own Identity: Measuring Gender Identity.” Accessed August 1, 2023. https://www.academia.edu/20917945/Culture_as_a_factor_influencing_expression_of_ones_own_identity_Measuring_gender_identity.\n\n\nShih, Margaret, Todd L. Pittinsky, and Amy Trahan. 2006. “Domain-Specific Effects of Stereotypes on Performance.” Self and Identity 5 (1): 1–14. https://doi.org/10.1080/15298860500338534.\n\n\nTajfel, H., M. Billig, R. Bundy, and C. Flament. 1971. “Social Categorization and Intergroup Behaviour.” European Journal of Social Psychology 1: 149–78. https://doi.org/10.1002/EJSP.2420010202.\n\n\nTrachman, Mathieu. 2022b. “Très masculin, pas très féminine. Les variations sociales du genre:” Population & Sociétés N° 605 (10): 1–4. https://doi.org/10.3917/popsoc.605.0001.\n\n\n———. 2022a. “Très masculin, pas très féminine. Les variations sociales du genre:” Population & Sociétés N° 605 (10): 14. https://doi.org/10.3917/popsoc.605.0001.\n\n\nTsutsui, Kei, and D. Zizzo. 2010. “Group Status, Minorities and Trust.” Experimental Economics 17: 215–44. https://doi.org/10.1007/s10683-013-9364-x."
  },
  {
    "objectID": "normes_identite/intro.html",
    "href": "normes_identite/intro.html",
    "title": "Economie et Identité: quelles intéractions?",
    "section": "",
    "text": "Introduction\nAvec ses cheveux courts, lors de son élection, miss France 2024 a défrayé la chronique.\nAu vue des réactions épidermiques, la dunkerquoise Eve Gilles semblait transgresser là une norme de genre instituée.\nAvec cet exemple, qui peut sembler trivial, nous souhaitons aborder la question fondamentale de l’identité, et plus spécifiquement, de l’identité de genre.\nL’identité peut être définie comme le sentiment que l’on a de soi (“A person’ sense of self”) , c’est une notion multiple, protéiforme, difficile à appréhender et plus encore: à mesurer.\nMais pourquoi les économistes devraient-ils s’intéresser à cette variable identité?\nComment et pourquoi intègrent-ils cette notion dans leurs modèles?\nSi la nécessité de proposer des modèles intégrant cette variable nous semble pertinente, vient alors la question de la difficile mesure de ce concept fondamental.\nEnfin, quelles répercussions socio-économiques peut-on observer à travers la mise en lien de cette mesure de l’identité et des variables économiques?\nL’économie de l’identité est un courant récent de la discipline.\nLes travaux fondateurs d’ Akerlof et Kranton (George A. Akerlof and Kranton (2000b) ) ont mis en lumière la nécessité d’intégrer dans les modèles économiques traditionnels cette notion fondamentale qu’est l’identité."
  },
  {
    "objectID": "normes_identite/intro.html#utilité-et-identité",
    "href": "normes_identite/intro.html#utilité-et-identité",
    "title": "Economie et Identité: quelles intéractions?",
    "section": "Utilité et Identité",
    "text": "Utilité et Identité\nPour un économiste, le concept d’utilité est central. Il s’agit d’une mesure de la satisfaction individuelle.\nUn individu, par exemple un consommateur, réalise ses choix en fonction du niveau de satisfaction qu’il peut retirer. C’est son objectif, modélisé sous forme de fonction.\nDans les modèles traditionnels, l’utilité dépend de quelques variables objectives, qui ont l’intérêt d’être mesurables.\nPar exemple, pour un consommateur, \\(U=F(x,y)\\) , où \\(x\\) et \\(y\\) sont les quantités de biens consommées.\nL’apport d’Akerlof et Kranton, est d’indiquer que les choix des individus sont influencés par le sentiment qu’ils ont d’eux même, leur identité.\nEnrichir les modèles traditionnels de cette nouvelle variable permettrait de mieux comprendre ce qui parfois échappe à la théorie classique."
  },
  {
    "objectID": "normes_identite/intro.html#modèle-avec-identité",
    "href": "normes_identite/intro.html#modèle-avec-identité",
    "title": "Economie et Identité: quelles intéractions?",
    "section": "Modèle avec Identité",
    "text": "Modèle avec Identité\nReprenons ici le modèle proposé par Akerlof et Kranton,\nla fonction d’utilité d’un individu est la suivante:\n\\(U_j = U_j(a_j, a_j I_j)\\)\noù :\n\n\\(a_j\\) représente les actions de l’individu \\(j\\)\n\\(a_j\\) \\(I_j\\) capture les intéractions entre les actions de \\(j\\) et son identité \\(I_j\\)\n\nCette fonction d’identite \\(I_j\\) dépend elle même de plusieurs facteurs:\n\\(I_j = I_j(a_j, a_{-j}, c_j, E_j, P)\\)\noù :\n\n\\(a_j\\) représente les actions de l’individu \\(j\\),\n\\(a_{-j}\\) repésente les actions des autres individus,\n\\(c_j\\) est la catégorie sociale à laquelle appartien \\(j\\),\n\\(E_j\\) sont les caractéristiques données de \\(j\\),\n\\(P\\) sont les prescriptions (ou normes sociales) associées à la catégorie \\(c_j\\).\n\nCe modèle formalise cette tension qui peut exister pour les individus entre se conformer ou non aux normes de sa catégorie sociale assignée, en fonction de la distance qui peut exister entre ses propres caractéristiques et les prescriptions assignées.\nIl suppose aussi l’existence possible de sanctions de la part des pairs si les normes ne sont pas suivies (moqueries, mise à l’écart ou même violence)\nPar exemple, dans leur papier (George A. Akerlof and Kranton, n.d.) complètent les théories traditionnelles de l’économie de l’éducation en expliquant le plus ou moins grand investissement scolaire des étudiants en fonction de leurs caractéristiques identitaires (les sportifs, les intellos et les rebelles)"
  },
  {
    "objectID": "normes_identite/intro.html#identité-et-choix-des-individus",
    "href": "normes_identite/intro.html#identité-et-choix-des-individus",
    "title": "Economie et Identité: quelles intéractions?",
    "section": "Identité et choix des individus",
    "text": "Identité et choix des individus\nL’économie étudie comment les agents font leur choix (de consommation, de production…), ces choix dépendent de l’identité des individus.\nEn effet, le sens que l’on a de soi, influence nos décisions, et ces décisions influencent notre identité en retour.\nDans un premier temps, la catégorie sociale à laquelle j’appartiens peut influencer mes préférences (Chen and Li (2009)) ,mes comportements pro-sociaux (Charness, Cobo-Reyes, and Jiménez (2014)) et donc mes décisions.\nDans un second temps, l’individu arbitre entre ses propres caractéristiques et les prescriptions de sa catégorie sociale (ou les prescriptions supposées).\nVais-je me conformer à ce qui est attendu? Mes propres caractéristiques sont-elles plus ou moins proches des normes en vigueur? Si je ne me conforme pas, quelle sera la réaction de mes pairs?\nCet arbitrage et cette possibilité pour autrui de répondre à mes actions a été représenté sous forme d’arbre de décision par George A. Akerlof and Kranton (2000a)\n\n\n\n\n\nCette friction entre adhérer ou non aux normes de ma catégorie sociale a conduit la recherche des économistes de l’identité vers les questions de conflits inter-groupes (Austen-Smith and Fryer (2005), Chakravarty et al. (2015), Fryer, Fryer, and Torelli (2010), Bénabou and Tirole (2004).)\nOn s’interroge sur les normes, l’adhésion ou non à ces dernières et le rôle que peuvent jouer les politiques publiques sur ces prescriptions.\nMais l’identité joue également un rôle fondamental sur les performances individuelles."
  },
  {
    "objectID": "normes_identite/intro.html#identité-et-performances",
    "href": "normes_identite/intro.html#identité-et-performances",
    "title": "Economie et Identité: quelles intéractions?",
    "section": "Identité et Performances",
    "text": "Identité et Performances\nDans une étude particulièrement intéressante, Shih, Pittinsky, and Trahan (2006) ont montré comment l’activation d’une identité particulière, ou tout du moins comment les stéréotypes associés à cette identité, pouvaient avoir un impact sur les performances individuelles.\nEn réalisant une étude auprès d’étudiantes asiatiques aux Etats Unis, les chercheurs ont proposé l’expérience suivante:\nUn questionnaire était fourni aux participantes avant de réaliser un test de mathématiques.\nUne partie des participantes répondaient à un questionnaire dont les questions portaient sur leur identité asiatique, pour les autres participantes le questionnaire activait leur identité féminine, un groupe de contrôle était également implémanté.\nCe simple questionnaire en préambule a eu des effets notables sur les performances aux tests de mathématiques réalisés ensuite, puisque en moyenne, les étudiantes dont l’identité asiatique avait été mise en évidence performaient significativement mieux aux tests de mathématiques que leurs homologues dont l’identité féminine avait été activée.\nCette étude plaide donc pour la nécessité de s’interroger sur la notion d’identité, dès lors que cette variable peut significativement avoir des répercussions sur les résultats socio-économiques des individus.\nCependant, les critiques apportées à ce nouveau courant sont notamment que ce concept fondamental d’identité est trop flou, comment intégrer dans les modèles ou bien encore dans les études empiriques cette dimension si polymorphe?\nLa question de la mesure de l’identité se pose alors…"
  },
  {
    "objectID": "normes_identite/construction_indice.html",
    "href": "normes_identite/construction_indice.html",
    "title": "Notre Mesure: Le Cultural Gender Normativity Index (CGNI)",
    "section": "",
    "text": "code R\nlibrary(foreign)\nlibrary(questionr) \nlibrary(ggplot2) \nlibrary(tidyverse) \nlibrary(ggmosaic)\nlibrary(GGally) \nlibrary(dataMaid)\nlibrary(dplyr) \nlibrary(GDAtools)\nlibrary(FactoMineR)\nlibrary(gtsummary) \nlibrary(factoextra)\nlibrary(gtsummary) \nlibrary(kableExtra)\nlibrary(RColorBrewer) \nlibrary(FactoMineR) \nlibrary(xtable) \nlibrary(explor)\ncode R\ndata&lt;-read.csv2(\"pc18_quetelet_octobre2023.csv\")\ncode R\ndata$Sex &lt;- factor(data$SEXE, \n                            levels = c(1, 2), \n                            labels = c(\"Men\", \"Women\"))\nmy_data_frame &lt;- data |&gt; dplyr::rename( \n  Knitting = A1001 , \n  Cards_games = A1002,  \n  Gambling = A1003 , \n  Cooking = A1004 , \n  DIY = A1005  ,\n  Vegetable_garden = A1006 , \n  Ornamental_garden = A1007,  \n  Fishing_hunting = A1008 , \n  Collection = A1009  ,\n  Vehicle_custom = A1010 , \n  No_Amateur=A1011,\n  Making_music = A1901  ,\n  Diary = A1902  ,\n  Writing = A1903,  \n  Painting = A1904,  \n  Montage = A1905 , \n  Circus = A1906  ,\n  Pottery = A1907 , \n  Theater = A1908 , \n  Drawing = A1909 , \n  Dancing = A1910,  \n  Photography = A1911  ,\n  Genealogy = A1912 , \n  Science = A1913  ,\n  None = A1914  ,\n  Video_games = B1  ,\n  TV = C1  ,\n  Radio = E1  ,\n  Library = F1  ,\n  Museums = H112,  \n  Internet = I4 , \n  Concert = G2413 )\n\n\nmy_data_frame$Video_games &lt;- ifelse(my_data_frame$Video_games == 1, 1, 0)\nmy_data_frame$TV &lt;- ifelse(my_data_frame$TV == 5, 0, 1)\nmy_data_frame$Radio &lt;- ifelse(my_data_frame$Radio == 5, 0, 1)\nmy_data_frame$Library&lt;- ifelse(my_data_frame$Radio == 1, 1, 0)\nmy_data_frame$Museums&lt;- ifelse(my_data_frame$Museums == 1, 0, 1)\nmy_data_frame$Internet&lt;- ifelse(my_data_frame$Internet == 5, 0, 1)\nmy_data_frame$Concert&lt;- ifelse(my_data_frame$Concert == 1, 0, 1)\n\n\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(satisfaction = case_when(\n    A2 %in% 1 ~ \"Low\",      # 1 à 4 -&gt; Low\n    A2 %in% 2 ~ \"Medium\",   # 5 à 7 -&gt; Medium\n    A2 %in% 3 ~ \"High\",    # 8 à 10 -&gt; High\n    TRUE ~ NA_character_              \n  ))  \nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(Income = case_when(\n    CRITREVENU %in% 1:4 ~ \"Low\",      # 1 à 4 -&gt; Low\n    CRITREVENU %in% 5:7 ~ \"Medium\",   # 5 à 7 -&gt; Medium\n    CRITREVENU %in% 8:10 ~ \"High\",    # 8 à 10 -&gt; High\n    TRUE ~ NA_character_              \n  ))\n\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(Health = case_when(\n    A15 %in% 1:2 ~ \"Good\",      # 1 à 4 -&gt; Low\n    A15 %in% 3 ~ \"Medium\",   # 5 à 7 -&gt; Medium\n    A15 %in% 4:5 ~ \"Bad\",    # 8 à 10 -&gt; High\n    TRUE ~ NA_character_              \n  ))\n\n\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(Couple = case_when(\n    VITENCOUPLE %in% 1:2 ~ \"Yes\",     \n    VITENCOUPLE %in% 3~ \"No\",  \n    \n    TRUE ~ NA_character_              \n  ))\n\nquartiles &lt;- quantile(data$AGE, probs = c(0.25, 0.5, 0.75), na.rm = TRUE)\n\nmy_data_frame$age_group &lt;- cut(\n  my_data_frame$AGE,\n  breaks = 4,  # Automatically divide into 4 slices\n  labels = c(\"[15-38[\", \"[38-54[\", \"[54-67[\", \"[67-97[\"),  # Labels optionnels\n  include.lowest = TRUE \n)\ncode R\ntable &lt;- my_data_frame |&gt;\n  tbl_summary(\n    include = c(  \"Knitting\" , \n                  \"Cards_games\",  \n                  \"Gambling\" , \n                  \"Cooking\" , \n                  \"DIY\"  ,\n                  \"Vegetable_garden\" , \n                  \"Ornamental_garden\",  \n                  \"Fishing_hunting\" , \n                  \"Collection\"  ,\n                  \"Vehicle_custom\", \n                  \"Making_music\"   ,\n                  \"Diary\" ,\n                  \"Writing\" ,  \n                  \"Painting\",  \n                  \"Montage\"  , \n                  \"Circus\"   ,\n                  \"Pottery\" , \n                  \"Theater\" , \n                  \"Drawing\" , \n                  \"Dancing\",  \n                  \"Photography\"  ,\n                  \"Genealogy\" , \n                  \"Science\"  ,\n                  \"None\"  ,\n                  \"No_Amateur\",\n                  \"Video_games\"  ,\n                  \"TV\" ,\n                  \"Radio\"  ,\n                  \"Library\"  ,\n                  \"Museums\",  \n                  \"Internet\", \n                  \"Concert\"),\n    by = \"Sex\"\n  ) |&gt;\n  add_overall(last = TRUE) |&gt;\n  add_p()\n\ntable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\nOverall N = 9,2341\np-value2\n\n\n\n\nKnitting\n73 (1.8%)\n1,370 (27%)\n1,443 (16%)\n&lt;0.001\n\n\nCards_games\n1,899 (46%)\n2,764 (54%)\n4,663 (50%)\n&lt;0.001\n\n\nGambling\n990 (24%)\n970 (19%)\n1,960 (21%)\n&lt;0.001\n\n\nCooking\n1,685 (40%)\n3,473 (68%)\n5,158 (56%)\n&lt;0.001\n\n\nDIY\n2,667 (64%)\n2,283 (45%)\n4,950 (54%)\n&lt;0.001\n\n\nVegetable_garden\n1,335 (32%)\n1,245 (25%)\n2,580 (28%)\n&lt;0.001\n\n\nOrnamental_garden\n1,793 (43%)\n2,198 (43%)\n3,991 (43%)\n0.8\n\n\nFishing_hunting\n722 (17%)\n212 (4.2%)\n934 (10%)\n&lt;0.001\n\n\nCollection\n395 (9.5%)\n281 (5.5%)\n676 (7.3%)\n&lt;0.001\n\n\nVehicle_custom\n264 (6.3%)\n60 (1.2%)\n324 (3.5%)\n&lt;0.001\n\n\nMaking_music\n1,312 (32%)\n1,830 (36%)\n3,142 (34%)\n&lt;0.001\n\n\nDiary\n285 (6.8%)\n1,206 (24%)\n1,491 (16%)\n&lt;0.001\n\n\nWriting\n410 (9.9%)\n746 (15%)\n1,156 (13%)\n&lt;0.001\n\n\nPainting\n667 (16%)\n1,303 (26%)\n1,970 (21%)\n&lt;0.001\n\n\nMontage\n843 (20%)\n586 (12%)\n1,429 (15%)\n&lt;0.001\n\n\nCircus\n116 (2.8%)\n179 (3.5%)\n295 (3.2%)\n0.044\n\n\nPottery\n264 (6.3%)\n705 (14%)\n969 (10%)\n&lt;0.001\n\n\nTheater\n483 (12%)\n800 (16%)\n1,283 (14%)\n&lt;0.001\n\n\nDrawing\n864 (21%)\n1,285 (25%)\n2,149 (23%)\n&lt;0.001\n\n\nDancing\n410 (9.9%)\n1,782 (35%)\n2,192 (24%)\n&lt;0.001\n\n\nPhotography\n1,175 (28%)\n1,176 (23%)\n2,351 (25%)\n&lt;0.001\n\n\nGenealogy\n513 (12%)\n575 (11%)\n1,088 (12%)\n0.14\n\n\nScience\n611 (15%)\n469 (9.2%)\n1,080 (12%)\n&lt;0.001\n\n\nNone\n1,394 (33%)\n1,261 (25%)\n2,655 (29%)\n&lt;0.001\n\n\nNo_Amateur\n276 (6.6%)\n359 (7.1%)\n635 (6.9%)\n0.4\n\n\nVideo_games\n1,760 (42%)\n1,827 (36%)\n3,587 (39%)\n&lt;0.001\n\n\nTV\n3,878 (93%)\n4,806 (95%)\n8,684 (94%)\n0.001\n\n\nRadio\n3,522 (85%)\n4,186 (83%)\n7,708 (83%)\n0.007\n\n\nLibrary\n3,522 (85%)\n4,186 (83%)\n7,708 (83%)\n0.007\n\n\nMuseums\n4,101 (99%)\n5,009 (99%)\n9,110 (99%)\n0.4\n\n\nInternet\n3,459 (83%)\n4,185 (83%)\n7,644 (83%)\n0.4\n\n\nConcert\n3,344 (80%)\n4,234 (83%)\n7,578 (82%)\n&lt;0.001\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\ncode R\npratiques_cols_1 &lt;- c( \"Knitting\" , \n                     \"Cards_games\",  \n                     \"Gambling\" , \n                     \"Cooking\" , \n                     \"DIY\"  ,\n                     \"Vegetable_garden\" , \n                     \"Fishing_hunting\" , \n                     \"Collection\"  ,\n                     \"Vehicle_custom\",\n                     \"Making_music\"   ,\n                     \"Diary\" ,\n                     \"Writing\" ,  \n                     \"Painting\",  \n                     \"Montage\"  , \n                     \"Pottery\" , \n                     \"Theater\" , \n                     \"Drawing\" , \n                     \"Dancing\",  \n                     \"Photography\"  ,\n                     \"Genealogy\" , \n                     \"Science\"  ,\n                     \"None\" ,\n                     \"Video_games\"  ,\n                     \"Library\"  ,\n                     \"Concert\"\n                            )\n\n\n#MCA\n\n# Add Sex Column to the selection\ncols_of_interest_1 &lt;- c(\"Sex\", \"AGE\", pratiques_cols_1)\n\n# Build a new dataframe with these columns\ndata_pratiques &lt;- my_data_frame[, cols_of_interest_1]\ndata_pratiques$AGE &lt;- cut(data_pratiques$AGE, \n                          breaks = quantile(data_pratiques$AGE, probs = seq(0, 1, 0.25), na.rm = TRUE), \n                          include.lowest = TRUE)\nra_data &lt;- na.omit(data_pratiques)\n\ncols_to_factor &lt;- c(  \"Knitting\" , \n                      \"Cards_games\",  \n                      \"Gambling\" , \n                      \"Cooking\" , \n                      \"DIY\"  ,\n                      \"Vegetable_garden\" , \n                      \"Fishing_hunting\" , \n                      \"Collection\"  ,\n                      \"Vehicle_custom\",\n                      \"Making_music\"   ,\n                      \"Diary\" ,\n                      \"Writing\" ,  \n                      \"Painting\",  \n                      \"Montage\"  , \n                      \"Pottery\" , \n                      \"Theater\" , \n                      \"Drawing\" , \n                      \"Dancing\",  \n                      \"Photography\"  ,\n                      \"Genealogy\" , \n                      \"Science\"  ,\n                      \"None\"  ,\n                      \"Video_games\"  ,\n                      \"Library\"  ,\n                      \"Concert\")\n\n# apply as.factor to these columnns\nra_data[cols_to_factor] &lt;- lapply(ra_data[cols_to_factor], as.factor)\n\n# running MCA with FactoMiner\nacm2_fm &lt;- ra_data |&gt; \n  FactoMineR::MCA(\n    ncp = Inf,\n    graph = TRUE,\n    quali.sup = 1:2\n  )\ncode R\n# Extract modality names\nmodalites_names &lt;- rownames(acm2_fm$var$coord)\n\n# Check modality names\nhead(modalites_names)\n\n\n[1] \"Knitting_0\"    \"Knitting_1\"    \"Cards_games_0\" \"Cards_games_1\"\n[5] \"Gambling_0\"    \"Gambling_1\"   \n\n\ncode R\n# Extract coordinates for dimension 2\ncoord_dim2_modalites &lt;- acm2_fm$var$coord[, 2]\n\n# Create a table associating the modalities and their coordinates in dimension 2\nmodalites_coord &lt;- data.frame(Modalite = modalites_names, Coord_Dim2 = coord_dim2_modalites)\n\n\n\n# Keep only the two necessary columns\nmodalites_coord_selected &lt;- modalites_coord[, c(\"Modalite\", \"Coord_Dim2\")]\n\nprint(modalites_coord_selected)\n\n\n                             Modalite  Coord_Dim2\nKnitting_0                 Knitting_0  0.04314603\nKnitting_1                 Knitting_1 -0.23295268\nCards_games_0           Cards_games_0 -0.21072530\nCards_games_1           Cards_games_1  0.20656774\nGambling_0                 Gambling_0 -0.17433328\nGambling_1                 Gambling_1  0.64698995\nCooking_0                   Cooking_0 -0.06432635\nCooking_1                   Cooking_1  0.05083253\nDIY_0                           DIY_0 -0.59097111\nDIY_1                           DIY_1  0.51145863\nVegetable_garden_0 Vegetable_garden_0 -0.29999865\nVegetable_garden_1 Vegetable_garden_1  0.77371744\nFishing_hunting_0   Fishing_hunting_0 -0.16671349\nFishing_hunting_1   Fishing_hunting_1  1.48150102\nCollection_0             Collection_0 -0.05539977\nCollection_1             Collection_1  0.70134797\nVehicle_custom_0     Vehicle_custom_0 -0.05128080\nVehicle_custom_1     Vehicle_custom_1  1.41022187\nMaking_music_0         Making_music_0  0.09403755\nMaking_music_1         Making_music_1 -0.18232870\nDiary_0                       Diary_0  0.09378209\nDiary_1                       Diary_1 -0.48702531\nWriting_0                   Writing_0  0.06770001\nWriting_1                   Writing_1 -0.47308017\nPainting_0                 Painting_0  0.04361213\nPainting_1                 Painting_1 -0.16081142\nMontage_0                   Montage_0 -0.07125251\nMontage_1                   Montage_1  0.38917132\nPottery_0                   Pottery_0  0.01201096\nPottery_1                   Pottery_1 -0.10244644\nTheater_0                   Theater_0  0.07187594\nTheater_1                   Theater_1 -0.44542916\nDrawing_0                   Drawing_0  0.04570585\nDrawing_1                   Drawing_1 -0.15068681\nDancing_0                   Dancing_0  0.14396501\nDancing_1                   Dancing_1 -0.46250072\nPhotography_0           Photography_0 -0.07539973\nPhotography_1           Photography_1  0.22074706\nGenealogy_0               Genealogy_0 -0.01967874\nGenealogy_1               Genealogy_1  0.14733732\nScience_0                   Science_0 -0.04008198\nScience_1                   Science_1  0.30261895\nNone_0                         None_0 -0.06572453\nNone_1                         None_1  0.16286315\nVideo_games_0           Video_games_0 -0.22185919\nVideo_games_1           Video_games_1  0.34927205\nLibrary_0                   Library_0 -0.65936864\nLibrary_1                   Library_1  0.13053925\nConcert_0                   Concert_0 -0.23244943\nConcert_1                   Concert_1  0.05079655\ncode R\n# Initialize a vector to store the index of each individual\nra_data$indice_culturel &lt;- 0\n\n# Browse each individual\nfor (i in 1:nrow(ra_data)) {\n  \n  # Initialize individual's index to 0\n  indice_individu &lt;- 0\n  \n  # Browse each practice column (columns 3 to 27)\n  for (pratique in 3:27) {\n    \n    # Retrieve the individual's response for this practice (0 or 1)\n    reponse &lt;- ra_data[i, pratique]\n    \n    # If the answer is 1, add the coordinate of the corresponding modality to the index.\n    if (reponse == 1) {\n      \n      # Create the modality name (e.g. “knitting_1” or “knitting_0”)\n      nom_modalite_1 &lt;- paste0(names(ra_data)[pratique], \"_1\")\n      nom_modalite_0 &lt;- paste0(names(ra_data)[pratique], \"_0\")\n      \n      # Find the coordinate associated with the corresponding modality\n      if (nom_modalite_1 %in% modalites_coord$Modalite) {\n        indice_individu &lt;- indice_individu + modalites_coord$Coord_Dim2[modalites_coord$Modalite == nom_modalite_1]\n      }\n      if (nom_modalite_0 %in% modalites_coord$Modalite) {\n        indice_individu &lt;- indice_individu + modalites_coord$Coord_Dim2[modalites_coord$Modalite == nom_modalite_0]\n      }\n    }\n  }\n  \n  # Assign the calculated index to the individual\n  ra_data$indice_culturel[i] &lt;- indice_individu\n}\n####Normalisation\n\n# Calculate minimum and maximum index values\nmin_indice &lt;- min(ra_data$indice_culturel, na.rm = TRUE)\nmax_indice &lt;- max(ra_data$indice_culturel, na.rm = TRUE)\n\n# Normalize index\nra_data$indice_culturel_normalise &lt;- (ra_data$indice_culturel - min_indice) / (max_indice - min_indice)\n\n# Check results\n\nhead(ra_data[, c(\"indice_culturel\", \"indice_culturel_normalise\")])\n\n\n  indice_culturel indice_culturel_normalise\n1       2.8024423                 0.8624142\n2       0.5427446                 0.5073268\n3      -0.4557477                 0.3504244\n4      -0.3429253                 0.3681533\n5       0.0409659                 0.4284777\n6      -0.2367887                 0.3848315\nNotre indice est donc construit de la façon suivante:\n\\[I_{1j} = \\sum_{k=1}^{Z} w_{1k} \\cdot X_{k j}\\]\nDans cette expression, \\(I_{1j}\\) désigne l’indice de l’individu \\(j\\), tandis que \\(w_{1k}\\) représente le poids associé à chaque variable culturelle \\(X_{kj}\\). La somme englobe toutes les variables culturelles \\(Z\\), ce qui nous permet de saisir l’engagement culturel global de l’individu.\ncode R\nmy_data_frame$identity&lt;-ra_data$indice_culturel_normalise\nmy_data_frame$indice&lt;-ra_data$indice_culturel\nggplot(my_data_frame, aes(x = identity, fill = Sex)) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) + \n  labs(title = \"Density of The Normalized Cultural Index by Sexe\",\n       x = \"Normalized Cultural Index\",\n       y = \"Density\",\n       fill = \"Sexe\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ncode R\nstat_des_indice&lt;-my_data_frame%&gt;%\n  tbl_summary(include=c(\"identity\"),by = \"Sex\",\n              statistic = list(\n            all_continuous() ~ \"{min} - {max}\"\n        )) %&gt;%\n  add_overall(last = TRUE) %&gt;%\n  add_p()\nstat_des_indice\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\nOverall N = 9,2341\np-value2\n\n\n\n\nidentity\n0.01 - 1.00\n0.00 - 0.91\n0.00 - 1.00\n&lt;0.001\n\n\n\n1 Min - Max\n\n\n2 Wilcoxon rank sum test\ncode R\ndata$identity&lt;- my_data_frame$identity\nmy_data_frame$identity&lt;-data$identity\n# List of cultural activities\ncultural_activities &lt;- c(\n   \"Knitting\" , \n                      \"Cards_games\",  \n                      \"Gambling\" , \n                      \"Cooking\" , \n                      \"DIY\"  ,\n                      \"Vegetable_garden\" , \n                      \"Fishing_hunting\" , \n                      \"Collection\"  ,\n                      \"Vehicle_custom\",\n                      \"Making_music\"   ,\n                      \"Diary\" ,\n                      \"Writing\" ,  \n                      \"Painting\",  \n                      \"Montage\"  , \n                      \"Pottery\" , \n                      \"Theater\" , \n                      \"Drawing\" , \n                      \"Dancing\",  \n                      \"Photography\"  ,\n                      \"Genealogy\" , \n                      \"Science\"  ,\n                      \"None\"  ,\n                      \"Video_games\"  ,\n                      \"Library\"  ,\n                      \"Concert\"\n)\n\n# Create a data frame to store the results\nresult_table &lt;- data.frame(Activity = character(0), Accuracy = numeric(0))\n\nfor (activity in cultural_activities) {\n  # Perform a Probit regression for the current cultural activity\n  model_formula &lt;- as.formula(paste(activity, \"~ identity\"))\n  model &lt;- glm(model_formula, data = my_data_frame, family = binomial(link = \"probit\"))\n \n  # Calculate predictions\n  predicted &lt;- ifelse(predict(model, type = \"response\") &gt;= 0.5, 1, 0)\n \n  # Calculate the accuracy\n  correct_predictions &lt;- sum(predicted == my_data_frame[[activity]])\n  total_predictions &lt;- nrow(my_data_frame)\n  accuracy &lt;- (correct_predictions / total_predictions) * 100\n \n  # Add the result to the data frame\n  result_table &lt;- rbind(result_table, data.frame(Activity = activity, Accuracy = accuracy))\n}\nresult_table\n\n\n           Activity Accuracy\n1          Knitting 84.37297\n2       Cards_games 51.00715\n3          Gambling 79.18562\n4           Cooking 56.55187\n5               DIY 51.25623\n6  Vegetable_garden 72.89365\n7   Fishing_hunting 93.95712\n8        Collection 92.54927\n9    Vehicle_custom 96.85943\n10     Making_music 68.16114\n11            Diary 85.85662\n12          Writing 88.16331\n13         Painting 78.76327\n14          Montage 84.52458\n15          Pottery 89.50617\n16          Theater 86.53888\n17          Drawing 76.73814\n18          Dancing 79.66212\n19      Photography 74.53974\n20        Genealogy 88.21746\n21          Science 88.30409\n22             None 70.19710\n23      Video_games 62.06411\n24          Library 83.20338\n25          Concert 81.92549\ncode R\nmy_data_frame$identity_scale &lt;- cut(\n  my_data_frame$identity,\n  breaks = 7,  # Automatically divide into 7 slices\n  labels = c(\"Very Feminine\", \"1\", \"2\", \"3\", \"4\", \"5\", \"Very Masculine\"), \n  include.lowest = TRUE  \n)\ntable1 &lt;-\n  my_data_frame |&gt; \n  tbl_summary(include = c(identity_scale),\n  by=Sex ,)|&gt; \n    add_p()\ntable1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\np-value2\n\n\n\n\nidentity_scale\n\n\n\n\n&lt;0.001\n\n\n    Very Feminine\n9 (0.2%)\n218 (4.3%)\n\n\n\n\n    1\n403 (9.7%)\n1,506 (30%)\n\n\n\n\n    2\n2,139 (51%)\n2,669 (53%)\n\n\n\n\n    3\n985 (24%)\n576 (11%)\n\n\n\n\n    4\n509 (12%)\n90 (1.8%)\n\n\n\n\n    5\n96 (2.3%)\n10 (0.2%)\n\n\n\n\n    Very Masculine\n21 (0.5%)\n3 (&lt;0.1%)\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test"
  },
  {
    "objectID": "normes_identite/construction_indice.html#indice-alternatif-méthode-de-lasso",
    "href": "normes_identite/construction_indice.html#indice-alternatif-méthode-de-lasso",
    "title": "Notre Mesure: Le Cultural Gender Normativity Index (CGNI)",
    "section": "Indice Alternatif: Méthode de LASSO",
    "text": "Indice Alternatif: Méthode de LASSO\n\n\ncode R\nsummary(my_data_frame$Library)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  1.0000  1.0000  0.8347  1.0000  1.0000 \n\n\ncode R\nmy_data_frame$SEXE&lt;-as.factor(my_data_frame$SEXE)\nreg_lm&lt;- lm(Sex~ Knitting+ \n                  Cards_games+  \n                  Gambling+ \n                  Cooking+ \n                  DIY+\n                  Vegetable_garden+ \n                  Ornamental_garden+  \n                  Fishing_hunting+ \n                  Collection+\n                  Vehicle_custom + \n                  Making_music +\n                  Diary +\n                  Writing +  \n                  Painting +  \n                  Montage + \n                  Circus +\n                  Pottery + \n                  Theater + \n                  Drawing + \n                  Dancing +  \n                  Photography +\n                  Genealogy + \n                  Science +\n                  None +\n                  No_Amateur +\n                  Video_games +\n                  TV +\n                  Radio+\n                  Library+\n                  Museums +  \n                  Internet + \n                  Concert, data=my_data_frame)\n\n\n\nn &lt;- nrow(my_data_frame)\n\n# Indices pour la division (2/3 pour l'entraînement, 1/3 pour le test)\ntrain_index &lt;- sample(1:n, size = 2 * n / 3)  # 2/3 des indices pour l'entraînement\n\n# Créer l'ensemble d'entraînement et l'ensemble de test\ntrain_data &lt;- my_data_frame[train_index, ]  # Enregistrement d'entraînement\ntest_data &lt;- my_data_frame[-train_index, ]  # Enregistrement de test\n\n# Vérifier les tailles\ncat(\"Nombre d'observations dans l'ensemble d'entraînement :\", nrow(train_data), \"\\n\")\n\n\nNombre d'observations dans l'ensemble d'entraînement : 6156 \n\n\ncode R\ncat(\"Nombre d'observations dans l'ensemble de test :\", nrow(test_data), \"\\n\")\n\n\nNombre d'observations dans l'ensemble de test : 3078 \n\n\ncode R\n# Charger les bibliothèques nécessaires\nlibrary(glmnet)\nlibrary(pROC)\n\n# Définir la matrice X pour l'entraînement\nx &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                  Vegetable_garden + Ornamental_garden + Fishing_hunting + \n                  Collection + Vehicle_custom + Making_music + Diary + Writing + \n                  Painting + Montage + Circus + Pottery + Theater + Drawing + \n                  Dancing + Photography + Genealogy + Science + None + No_Amateur +\n                  Video_games + TV + Radio + Library + Museums + Internet + Concert,\n                  train_data)[, -1]\n\n# Variable cible y pour l'entraînement\ny &lt;- train_data$SEXE\n\n# Ajuster le modèle LASSO avec validation croisée\ncv_lasso &lt;- cv.glmnet(x, y, alpha = 1, family = \"binomial\")\nbest_lambda &lt;- cv_lasso$lambda.min  # Lambda optimal\n\n# Vérifie les coefficients pour le lambda optimal\nprint(coef(cv_lasso, s = \"lambda.min\"))\n\n\n33 x 1 sparse Matrix of class \"dgCMatrix\"\n                             s1\n(Intercept)       -8.104798e-01\nKnitting           3.132407e+00\nCards_games        1.950613e-01\nGambling          -3.633046e-01\nCooking            1.218712e+00\nDIY               -1.034844e+00\nVegetable_garden  -3.228305e-01\nOrnamental_garden  3.129368e-01\nFishing_hunting   -1.484076e+00\nCollection        -6.926679e-01\nVehicle_custom    -1.607262e+00\nMaking_music      -1.069814e-01\nDiary              1.430136e+00\nWriting           -1.252247e-01\nPainting           5.410238e-01\nMontage           -1.050218e+00\nCircus             1.782524e-02\nPottery            4.777913e-01\nTheater           -2.030145e-01\nDrawing           -1.688730e-01\nDancing            1.523379e+00\nPhotography       -4.109226e-01\nGenealogy         -3.513350e-01\nScience           -8.044160e-01\nNone              -1.272694e-01\nNo_Amateur         4.565083e-01\nVideo_games       -1.574696e-01\nTV                 6.309620e-01\nRadio             -1.427390e-01\nLibrary           -2.234719e-16\nMuseums            .           \nInternet           2.249076e-01\nConcert           -5.351611e-04\n\n\ncode R\nprint(best_lambda)\n\n\n[1] 0.0009574657\n\n\ncode R\n# Préparer X_test (même traitement que pour l'entraînement)\nx_test &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                       Vegetable_garden + Ornamental_garden + Fishing_hunting + \n                       Collection + Vehicle_custom + Making_music + Diary + Writing + \n                       Painting + Montage + Circus + Pottery + Theater + Drawing + \n                       Dancing + Photography + Genealogy + Science + None + No_Amateur +\n                       Video_games + TV + Radio + Library + Museums + Internet + Concert,\n                       test_data)[, -1]\n\n# Prédire les probabilités sur les données de test avec le meilleur lambda\npreds &lt;- predict(cv_lasso, newx = x_test, s = \"lambda.min\", type = \"response\")\n\n# Variable cible y_test pour l'ensemble de test\ny_test &lt;- test_data$SEXE\n\n# Calcul de l'AUC avec pROC\nroc_curve &lt;- roc(y_test, preds)\nauc_value &lt;- auc(roc_curve)\nprint(paste(\"AUC:\", auc_value))\n\n\n[1] \"AUC: 0.864939516603264\"\n\n\ncode R\n# Calculer la courbe ROC\nroc_curve &lt;- roc(y_test, preds)\n\n# Afficher la courbe ROC\nplot(roc_curve, main = \"Courbe ROC\", col = \"blue\", lwd = 2)\n\n# Optionnel : Ajouter la ligne de base (diagonale)\nabline(a = 0, b = 1, col = \"red\", lty = 2)\n\n\n\n\n\n\n\n\n\ncode R\n# Afficher les coefficients pour le meilleur lambda\ncoefficients &lt;- coef(cv_lasso, s = \"lambda.min\")\n\n# Convertir en data.frame pour une meilleure lisibilité\ncoefficients_df &lt;- as.data.frame(as.matrix(coefficients))\ncolnames(coefficients_df) &lt;- \"Coefficient\"\ncoefficients_df$Variable &lt;- rownames(coefficients_df)\n\n# Filtrer pour ne garder que les variables avec des coefficients non nuls\ncoefficients_non_zero &lt;- coefficients_df[coefficients_df$Coefficient != 0, ]\n\n# Afficher les variables gardées et leurs coefficients\nprint(coefficients_non_zero)\n\n\n                    Coefficient          Variable\n(Intercept)       -8.104798e-01       (Intercept)\nKnitting           3.132407e+00          Knitting\nCards_games        1.950613e-01       Cards_games\nGambling          -3.633046e-01          Gambling\nCooking            1.218712e+00           Cooking\nDIY               -1.034844e+00               DIY\nVegetable_garden  -3.228305e-01  Vegetable_garden\nOrnamental_garden  3.129368e-01 Ornamental_garden\nFishing_hunting   -1.484076e+00   Fishing_hunting\nCollection        -6.926679e-01        Collection\nVehicle_custom    -1.607262e+00    Vehicle_custom\nMaking_music      -1.069814e-01      Making_music\nDiary              1.430136e+00             Diary\nWriting           -1.252247e-01           Writing\nPainting           5.410238e-01          Painting\nMontage           -1.050218e+00           Montage\nCircus             1.782524e-02            Circus\nPottery            4.777913e-01           Pottery\nTheater           -2.030145e-01           Theater\nDrawing           -1.688730e-01           Drawing\nDancing            1.523379e+00           Dancing\nPhotography       -4.109226e-01       Photography\nGenealogy         -3.513350e-01         Genealogy\nScience           -8.044160e-01           Science\nNone              -1.272694e-01              None\nNo_Amateur         4.565083e-01        No_Amateur\nVideo_games       -1.574696e-01       Video_games\nTV                 6.309620e-01                TV\nRadio             -1.427390e-01             Radio\nLibrary           -2.234719e-16           Library\nInternet           2.249076e-01          Internet\nConcert           -5.351611e-04           Concert\n\n\ncode R\n###CREATION INDICE\n\n# Récupérer les coefficients du modèle pour le meilleur lambda\ncoefficients &lt;- coef(cv_lasso, s = \"lambda.min\")\n\n# Convertir en data.frame et filtrer les variables non nulles\ncoefficients_df &lt;- as.data.frame(as.matrix(coefficients))\ncolnames(coefficients_df) &lt;- \"Coefficient\"\ncoefficients_df$Variable &lt;- rownames(coefficients_df)\ncoefficients_non_zero &lt;- coefficients_df[coefficients_df$Coefficient != 0, ]\n\n# Préparer la matrice X des pratiques pour l'ensemble de test (ou d'entraînement si nécessaire)\nx_test &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                       Vegetable_garden + Ornamental_garden + Fishing_hunting + \n                       Collection + Vehicle_custom + Making_music + Diary + Writing + \n                       Painting + Montage + Circus + Pottery + Theater + Drawing + \n                       Dancing + Photography + Genealogy + Science + None + No_Amateur +\n                       Video_games + TV + Radio + Library + Museums + Internet + Concert,\n                       test_data)[, -1]  # Assurez-vous d'enlever l'intercept avec [, -1]\n\n# Sélectionner les variables pertinentes\nmatched_vars &lt;- intersect(rownames(coefficients_non_zero), colnames(x_test))\nx_test &lt;- x_test[, matched_vars, drop = FALSE]\ncoef_vector &lt;- coefficients_non_zero$Coefficient[matched_vars]  # Associer les coefficients\n\nprint(paste(\"Dimension de x_test :\", dim(x_test)[1], \"x\", dim(x_test)[2]))\n\n\n[1] \"Dimension de x_test : 3078 x 31\"\n\n\ncode R\nprint(paste(\"Longueur de coef_vector :\", length(coef_vector)))\n\n\n[1] \"Longueur de coef_vector : 31\"\n\n\ncode R\nprint(paste(\"Nombre de valeurs NA dans x_test :\", sum(is.na(x_test))))\n\n\n[1] \"Nombre de valeurs NA dans x_test : 0\"\n\n\ncode R\nprint(paste(\"Nombre de valeurs NA dans coef_vector :\", sum(is.na(coef_vector))))\n\n\n[1] \"Nombre de valeurs NA dans coef_vector : 31\"\n\n\ncode R\nprint(\"Variables dans coefficients_non_zero :\")\n\n\n[1] \"Variables dans coefficients_non_zero :\"\n\n\ncode R\nprint(coefficients_non_zero$Variable)\n\n\n [1] \"(Intercept)\"       \"Knitting\"          \"Cards_games\"      \n [4] \"Gambling\"          \"Cooking\"           \"DIY\"              \n [7] \"Vegetable_garden\"  \"Ornamental_garden\" \"Fishing_hunting\"  \n[10] \"Collection\"        \"Vehicle_custom\"    \"Making_music\"     \n[13] \"Diary\"             \"Writing\"           \"Painting\"         \n[16] \"Montage\"           \"Circus\"            \"Pottery\"          \n[19] \"Theater\"           \"Drawing\"           \"Dancing\"          \n[22] \"Photography\"       \"Genealogy\"         \"Science\"          \n[25] \"None\"              \"No_Amateur\"        \"Video_games\"      \n[28] \"TV\"                \"Radio\"             \"Library\"          \n[31] \"Internet\"          \"Concert\"          \n\n\ncode R\nprint(\"Colonnes de x_test :\")\n\n\n[1] \"Colonnes de x_test :\"\n\n\ncode R\nprint(colnames(x_test))\n\n\n [1] \"Knitting\"          \"Cards_games\"       \"Gambling\"         \n [4] \"Cooking\"           \"DIY\"               \"Vegetable_garden\" \n [7] \"Ornamental_garden\" \"Fishing_hunting\"   \"Collection\"       \n[10] \"Vehicle_custom\"    \"Making_music\"      \"Diary\"            \n[13] \"Writing\"           \"Painting\"          \"Montage\"          \n[16] \"Circus\"            \"Pottery\"           \"Theater\"          \n[19] \"Drawing\"           \"Dancing\"           \"Photography\"      \n[22] \"Genealogy\"         \"Science\"           \"None\"             \n[25] \"No_Amateur\"        \"Video_games\"       \"TV\"               \n[28] \"Radio\"             \"Library\"           \"Internet\"         \n[31] \"Concert\"          \n\n\ncode R\n# Exclure \"(Intercept)\" des coefficients\ncoefficients_filtered &lt;- coefficients_non_zero[coefficients_non_zero$Variable != \"(Intercept)\", ]\n\n# Aligner les coefficients sur x_test\ncoef_vector &lt;- coefficients_filtered$Coefficient[match(colnames(x_test), coefficients_filtered$Variable)]\n\n\n\n# Calcul des scores\ntest_data$score &lt;- x_test %*% coef_vector\n\n# Normalisation des scores\nmin_score &lt;- min(test_data$score, na.rm = TRUE)\nmax_score &lt;- max(test_data$score, na.rm = TRUE)\n\nif (max_score &gt; min_score) {\n  test_data$score_normalise &lt;- (test_data$score - min_score) / (max_score - min_score)\n} else {\n  test_data$score_normalise &lt;- 0\n}\n\n# Visualisation avec ggplot2\nlibrary(ggplot2)\nggplot(test_data, aes(x = score_normalise, color = SEXE, fill = SEXE)) +\n  geom_density(alpha = 0.4) + \n  labs(title = \"Densité du Score Normalisé\", x = \"Score Normalisé\", y = \"Densité\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\ncode R\n# Préparer la matrice X pour l'ensemble complet (train + test)\nx_full &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                       Vegetable_garden + Ornamental_garden + Fishing_hunting + \n                       Collection + Vehicle_custom + Making_music + Diary + Writing + \n                       Painting + Montage + Circus + Pottery + Theater + Drawing + \n                       Dancing + Photography + Genealogy + Science + None + No_Amateur +\n                       Video_games + TV + Radio + Library + Museums + Internet + Concert,\n                       my_data_frame)[, -1]  # Exclure l'intercept\n\n# Sélectionner les variables pertinentes (identiques à celles du modèle LASSO)\nmatched_vars &lt;- intersect(rownames(coefficients_non_zero), colnames(x_full))\nx_full &lt;- x_full[, matched_vars, drop = FALSE]  # Garder uniquement les variables sélectionnées\n# Aligner les coefficients sur x_full\ncoef_vector_full &lt;- coefficients_filtered$Coefficient[match(colnames(x_full), coefficients_filtered$Variable)]\n\n# Calcul des scores pour l'ensemble complet\nmy_data_frame$score &lt;- x_full %*% coef_vector_full\n# Normalisation des scores\nmin_score_full &lt;- min(my_data_frame$score, na.rm = TRUE)\nmax_score_full &lt;- max(my_data_frame$score, na.rm = TRUE)\n\nif (max_score_full &gt; min_score_full) {\n  my_data_frame$score_normalise &lt;- (my_data_frame$score - min_score_full) / (max_score_full - min_score_full)\n} else {\n  my_data_frame$score_normalise &lt;- 0\n}\n# Visualisation du score normalisé pour l'ensemble complet avec ggplot2\nlibrary(ggplot2)\nggplot(my_data_frame, aes(x = score_normalise, color = SEXE, fill = SEXE)) +\n  geom_density(alpha = 0.4) + \n  labs(title = \"Densité du Score Normalisé (Ensemble Complet)\", x = \"Score Normalisé\", y = \"Densité\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()"
  },
  {
    "objectID": "normes_identite/construction_indice.html#comparaisons",
    "href": "normes_identite/construction_indice.html#comparaisons",
    "title": "Notre Mesure: Le Cultural Gender Normativity Index (CGNI)",
    "section": "Comparaisons",
    "text": "Comparaisons\n\n\ncode R\n# Calculer la corrélation entre indice_normalise et score_normalise\ncorrelation_value &lt;- cor(my_data_frame$identity, my_data_frame$score_normalise, use = \"complete.obs\")\nprint(paste(\"Corrélation entre indice_normalise et score_normalise :\", correlation_value))\n\n\n[1] \"Corrélation entre indice_normalise et score_normalise : -0.632686378340336\"\n\n\ncode R\n# Visualiser la relation entre indice_normalise et score_normalise\nlibrary(ggplot2)\nggplot(my_data_frame, aes(x = identity, y = score_normalise)) +\n  geom_point(alpha = 0.5) +\n  labs(title = \"Relation entre indice_normalise et score_normalise\", \n       x = \"Indice Normalisé\", \n       y = \"Score Normalisé\") +\n  theme_minimal() +\n  geom_smooth(method = \"lm\", col = \"red\", se = FALSE)  # Ajouter une droite de régression linéaire\n\n\n\n\n\n\n\n\n\n\n\ncode R\nn_2 &lt;- nrow(my_data_frame)\n\n# Indices pour la division (2/3 pour l'entraînement, 1/3 pour le test)\ntrain_index &lt;- sample(1:n_2, size = 2 * n_2 / 3)  # 2/3 des indices pour l'entraînement\n\n# Créer l'ensemble d'entraînement et l'ensemble de test\ntrain_data &lt;- my_data_frame[train_index, ]  # Enregistrement d'entraînement\ntest_data &lt;- my_data_frame[-train_index, ]  # Enregistrement de test\n\n# Vérifier les tailles\ncat(\"Nombre d'observations dans l'ensemble d'entraînement :\", nrow(train_data), \"\\n\")\n\n\nNombre d'observations dans l'ensemble d'entraînement : 6156 \n\n\ncode R\ncat(\"Nombre d'observations dans l'ensemble de test :\", nrow(test_data), \"\\n\")\n\n\nNombre d'observations dans l'ensemble de test : 3078 \n\n\ncode R\n# Charger les bibliothèques nécessaires\nlibrary(glmnet)\nlibrary(pROC)\n\n# Définir la matrice X pour l'entraînement\nx_2 &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                  Vegetable_garden + Fishing_hunting + \n                  Collection + Vehicle_custom + Making_music + Diary + Writing + \n                  Painting + Montage +  Pottery + Theater + Drawing + \n                  Dancing + Photography + Genealogy + Science + None + \n                  Video_games + Library +  Concert,\n                  train_data)[, -1]\n\n# Variable cible y pour l'entraînement\ny_2 &lt;- train_data$SEXE\n\n# Ajuster le modèle LASSO avec validation croisée\ncv_lasso_2 &lt;- cv.glmnet(x_2, y_2, alpha = 1, family = \"binomial\")\nbest_lambda_2 &lt;- cv_lasso_2$lambda.min  # Lambda optimal\n\n# Vérifie les coefficients pour le lambda optimal\nprint(coef(cv_lasso_2, s = \"lambda.min\"))\n\n\n26 x 1 sparse Matrix of class \"dgCMatrix\"\n                          s1\n(Intercept)       0.17494648\nKnitting          3.19937130\nCards_games       0.20088572\nGambling         -0.37127876\nCooking           1.10395855\nDIY              -1.11501160\nVegetable_garden -0.28525548\nFishing_hunting  -1.50261572\nCollection       -0.69093548\nVehicle_custom   -1.51762832\nMaking_music     -0.15891192\nDiary             1.44047776\nWriting          -0.04671198\nPainting          0.54680796\nMontage          -0.96904281\nPottery           0.66682037\nTheater          -0.19409798\nDrawing          -0.25870718\nDancing           1.65499394\nPhotography      -0.37225824\nGenealogy        -0.46304638\nScience          -0.88293227\nNone             -0.16610482\nVideo_games      -0.21283464\nLibrary          -0.09823084\nConcert           0.05395608\n\n\ncode R\nprint(best_lambda_2)\n\n\n[1] 0.0004997766\n\n\ncode R\n# Préparer X_test (même traitement que pour l'entraînement)\nx_test_2 &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                  Vegetable_garden + Fishing_hunting + \n                  Collection + Vehicle_custom + Making_music + Diary + Writing + \n                  Painting + Montage +  Pottery + Theater + Drawing + \n                  Dancing + Photography + Genealogy + Science + None + \n                  Video_games + Library +  Concert,\n                       test_data)[, -1]\n\n# Prédire les probabilités sur les données de test avec le meilleur lambda\npreds_2 &lt;- predict(cv_lasso_2, newx = x_test_2, s = \"lambda.min\", type = \"response\")\n\n# Variable cible y_test pour l'ensemble de test\ny_test_2 &lt;- test_data$SEXE\n\n# Calcul de l'AUC avec pROC\nroc_curve_2 &lt;- roc(y_test_2, preds_2)\nauc_value_2 &lt;- auc(roc_curve_2)\nprint(paste(\"AUC:\", auc_value_2))\n\n\n[1] \"AUC: 0.858224034893495\"\n\n\ncode R\n# Calculer la courbe ROC\nroc_curve_2 &lt;- roc(y_test_2, preds_2)\n\n# Afficher la courbe ROC\nplot(roc_curve_2, main = \"Courbe ROC 2\", col = \"blue\", lwd = 2)\n\n# Optionnel : Ajouter la ligne de base (diagonale)\nabline(a = 0, b = 1, col = \"red\", lty = 2)\n\n\n\n\n\n\n\n\n\ncode R\n# Afficher les coefficients pour le meilleur lambda\ncoefficients_2 &lt;- coef(cv_lasso_2, s = \"lambda.min\")\n\n# Convertir en data.frame pour une meilleure lisibilité\ncoefficients_df_2 &lt;- as.data.frame(as.matrix(coefficients_2))\ncolnames(coefficients_df_2) &lt;- \"Coefficient\"\ncoefficients_df_2$Variable &lt;- rownames(coefficients_df_2)\n\n# Filtrer pour ne garder que les variables avec des coefficients non nuls\ncoefficients_non_zero_2 &lt;- coefficients_df_2[coefficients_df_2$Coefficient != 0, ]\n\n# Afficher les variables gardées et leurs coefficients\nprint(coefficients_non_zero_2)\n\n\n                 Coefficient         Variable\n(Intercept)       0.17494648      (Intercept)\nKnitting          3.19937130         Knitting\nCards_games       0.20088572      Cards_games\nGambling         -0.37127876         Gambling\nCooking           1.10395855          Cooking\nDIY              -1.11501160              DIY\nVegetable_garden -0.28525548 Vegetable_garden\nFishing_hunting  -1.50261572  Fishing_hunting\nCollection       -0.69093548       Collection\nVehicle_custom   -1.51762832   Vehicle_custom\nMaking_music     -0.15891192     Making_music\nDiary             1.44047776            Diary\nWriting          -0.04671198          Writing\nPainting          0.54680796         Painting\nMontage          -0.96904281          Montage\nPottery           0.66682037          Pottery\nTheater          -0.19409798          Theater\nDrawing          -0.25870718          Drawing\nDancing           1.65499394          Dancing\nPhotography      -0.37225824      Photography\nGenealogy        -0.46304638        Genealogy\nScience          -0.88293227          Science\nNone             -0.16610482             None\nVideo_games      -0.21283464      Video_games\nLibrary          -0.09823084          Library\nConcert           0.05395608          Concert\n\n\ncode R\n###CREATION INDICE\n\n# Récupérer les coefficients du modèle pour le meilleur lambda\ncoefficients_2 &lt;- coef(cv_lasso_2, s = \"lambda.min\")\n\n# Convertir en data.frame et filtrer les variables non nulles\ncoefficients_df_2 &lt;- as.data.frame(as.matrix(coefficients_2))\ncolnames(coefficients_df_2) &lt;- \"Coefficient\"\ncoefficients_df_2$Variable &lt;- rownames(coefficients_df_2)\ncoefficients_non_zero_2 &lt;- coefficients_df_2[coefficients_df_2$Coefficient != 0, ]\n\n# Préparer la matrice X des pratiques pour l'ensemble de test (ou d'entraînement si nécessaire)\nx_test_2 &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                  Vegetable_garden + Fishing_hunting + \n                  Collection + Vehicle_custom + Making_music + Diary + Writing + \n                  Painting + Montage +  Pottery + Theater + Drawing + \n                  Dancing + Photography + Genealogy + Science + None + \n                  Video_games + Library +  Concert,\n                       test_data)[, -1]  # Assurez-vous d'enlever l'intercept avec [, -1]\n\n# Sélectionner les variables pertinentes\nmatched_vars_2 &lt;- intersect(rownames(coefficients_non_zero_2), colnames(x_test_2))\nx_test_2 &lt;- x_test_2[, matched_vars_2, drop = FALSE]\ncoef_vector_2 &lt;- coefficients_non_zero_2$Coefficient[matched_vars_2]  # Associer les coefficients\n\n#print(paste(\"Dimension de x_test :\", dim(x_test)[1], \"x\", dim(x_test)[2]))\n#print(paste(\"Longueur de coef_vector :\", length(coef_vector)))\n#print(paste(\"Nombre de valeurs NA dans x_test :\", sum(is.na(x_test))))\n#print(paste(\"Nombre de valeurs NA dans coef_vector :\", sum(is.na(coef_vector))))\n\n#print(\"Variables dans coefficients_non_zero :\")\n#print(coefficients_non_zero$Variable)\n\n#print(\"Colonnes de x_test :\")\n#print(colnames(x_test))\n\n\n# Exclure \"(Intercept)\" des coefficients\ncoefficients_filtered_2 &lt;- coefficients_non_zero_2[coefficients_non_zero_2$Variable != \"(Intercept)\", ]\n\n# Aligner les coefficients sur x_test\ncoef_vector_2 &lt;- coefficients_filtered_2$Coefficient[match(colnames(x_test_2), coefficients_filtered_2$Variable)]\n\n\n\n# Calcul des scores\ntest_data$score_2 &lt;- x_test_2 %*% coef_vector_2\n\n# Normalisation des scores\nmin_score_2 &lt;- min(test_data$score_2, na.rm = TRUE)\nmax_score_2 &lt;- max(test_data$score_2, na.rm = TRUE)\n\nif (max_score_2 &gt; min_score_2) {\n  test_data$score_normalise_2 &lt;- (test_data$score_2 - min_score_2) / (max_score_2 - min_score_2)\n} else {\n  test_data$score_normalise_2 &lt;- 0\n}\n\n# Visualisation avec ggplot2\nlibrary(ggplot2)\nggplot(test_data, aes(x = score_normalise_2, color = SEXE, fill = SEXE)) +\n  geom_density(alpha = 0.4) + \n  labs(title = \"Densité du Score Normalisé 2\", x = \"Score Normalisé 2\", y = \"Densité\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ncode R\n# Préparer la matrice X pour l'ensemble complet (train + test)\nx_full_2 &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                  Vegetable_garden + Fishing_hunting + \n                  Collection + Vehicle_custom + Making_music + Diary + Writing + \n                  Painting + Montage +  Pottery + Theater + Drawing + \n                  Dancing + Photography + Genealogy + Science + None + \n                  Video_games + Library +  Concert,\n                       my_data_frame)[, -1]  # Exclure l'intercept\n\n# Sélectionner les variables pertinentes (identiques à celles du modèle LASSO)\nmatched_vars_2 &lt;- intersect(rownames(coefficients_non_zero_2), colnames(x_full_2))\nx_full_2 &lt;- x_full_2[, matched_vars_2, drop = FALSE]  # Garder uniquement les variables sélectionnées\n# Aligner les coefficients sur x_full\ncoef_vector_full_2 &lt;- coefficients_filtered_2$Coefficient[match(colnames(x_full_2), coefficients_filtered_2$Variable)]\n\n# Calcul des scores pour l'ensemble complet\nmy_data_frame$score_2 &lt;- x_full_2 %*% coef_vector_full_2\n# Normalisation des scores\nmin_score_full_2 &lt;- min(my_data_frame$score_2, na.rm = TRUE)\nmax_score_full_2 &lt;- max(my_data_frame$score_2, na.rm = TRUE)\n\nif (max_score_full_2 &gt; min_score_full_2) {\n  my_data_frame$score_normalise_2 &lt;- (my_data_frame$score_2 - min_score_full_2) / (max_score_full_2 - min_score_full_2)\n} else {\n  my_data_frame$score_normalise_2 &lt;- 0\n}\n# Visualisation du score normalisé pour l'ensemble complet avec ggplot2\nlibrary(ggplot2)\nggplot(my_data_frame, aes(x = score_normalise_2, color = SEXE, fill = SEXE)) +\n  geom_density(alpha = 0.4) + \n  labs(title = \"Densité du Score Normalisé 2(Ensemble Complet)\", x = \"Score Normalisé\", y = \"Densité\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ncode R\n# Calculer la corrélation entre indice_normalise et score_normalise\ncorrelation_value_2 &lt;- cor(my_data_frame$identity, my_data_frame$score_normalise_2, use = \"complete.obs\")\nprint(paste(\"Corrélation entre indice_normalise et score_normalise 2:\", correlation_value))\n\n\n[1] \"Corrélation entre indice_normalise et score_normalise 2: -0.632686378340336\"\n\n\ncode R\n# Visualiser la relation entre indice_normalise et score_normalise\nlibrary(ggplot2)\nggplot(my_data_frame, aes(x = identity, y = score_normalise_2)) +\n  geom_point(alpha = 0.5) +\n  labs(title = \"Relation entre indice_normalise et score_normalise 2\", \n       x = \"Indice Normalisé\", \n       y = \"Score Normalisé\") +\n  theme_minimal() +\n  geom_smooth(method = \"lm\", col = \"red\", se = FALSE)  # Ajouter une droite de régression linéaire\n\n\n\n\n\n\n\n\n\ncode R\n# Créer un data frame pour stocker les résultats\nresult_table_score_2 &lt;- data.frame(Activity_2 = character(0), Accuracy_2 = numeric(0))\n\ncultural_activities_2 &lt;- c(\n   \"Knitting\", \"Cards_games\", \"Gambling\", \"Cooking\", \"DIY\",\n   \"Vegetable_garden\", \"Fishing_hunting\", \"Collection\", \"Vehicle_custom\",\n   \"Making_music\", \"Diary\", \"Writing\", \"Painting\", \"Montage\",\n   \"Pottery\", \"Theater\", \"Drawing\", \"Dancing\", \"Photography\",\n   \"Genealogy\", \"Science\", \"None\", \"Video_games\", \"Library\", \"Concert\"\n)\n\nfor (activity_2 in cultural_activities_2) {\n  # Effectuer une régression Probit pour l'activité culturelle actuelle\n  model_formula_2 &lt;- as.formula(paste(activity_2, \"~ score_normalise_2\"))\n  model_2 &lt;- glm(model_formula_2, data = my_data_frame, family = binomial(link = \"probit\"))\n \n  # Calculer les prédictions\n  predicted_2 &lt;- ifelse(predict(model_2, type = \"response\") &gt;= 0.5, 1, 0)\n \n  # Calculer la précision\n  correct_predictions_2 &lt;- sum(predicted_2 == my_data_frame[[activity_2]])\n  total_predictions_2 &lt;- nrow(my_data_frame)\n  accuracy_2 &lt;- (correct_predictions_2 / total_predictions_2) * 100\n \n  # Ajouter le résultat au data frame\n  result_table_score_2 &lt;- rbind(result_table_score_2, data.frame(Activity_2 = activity_2, Accuracy_2 = accuracy_2))\n}\n\n# Afficher le tableau des résultats\nprint(result_table_score_2)\n\n\n         Activity_2 Accuracy_2\n1          Knitting   92.96080\n2       Cards_games   56.51938\n3          Gambling   78.77410\n4           Cooking   67.68464\n5               DIY   57.82976\n6  Vegetable_garden   72.05978\n7   Fishing_hunting   90.42668\n8        Collection   92.67923\n9    Vehicle_custom   96.52372\n10     Making_music   65.97358\n11            Diary   84.39463\n12          Writing   87.48105\n13         Painting   78.66580\n14          Montage   84.52458\n15          Pottery   89.50617\n16          Theater   86.10570\n17          Drawing   76.72731\n18          Dancing   76.86810\n19      Photography   74.53974\n20        Genealogy   88.21746\n21          Science   88.30409\n22             None   71.11761\n23      Video_games   61.53346\n24          Library   83.47412\n25          Concert   82.06628\n\n\n\n\ncode R\nmy_data_frame$score_scale &lt;- cut(\n  my_data_frame$score_normalise,\n  breaks = 7,  # Automatically divide into 7 slices\n  labels = c(\"Very Masculine\", \"1\", \"2\", \"3\", \"4\", \"5\", \"Very Feminine\"), \n  include.lowest = TRUE  \n)\ntable1 &lt;-\n  my_data_frame |&gt; \n  tbl_summary(include = c(score_scale),\n  by=Sex ,)|&gt; \n    add_p()\ntable1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\np-value2\n\n\n\n\nscore_scale\n\n\n\n\n&lt;0.001\n\n\n    Very Masculine\n18 (0.4%)\n0 (0%)\n\n\n\n\n    1\n383 (9.2%)\n21 (0.4%)\n\n\n\n\n    2\n1,891 (45%)\n401 (7.9%)\n\n\n\n\n    3\n1,666 (40%)\n2,063 (41%)\n\n\n\n\n    4\n185 (4.4%)\n1,626 (32%)\n\n\n\n\n    5\n18 (0.4%)\n808 (16%)\n\n\n\n\n    Very Feminine\n1 (&lt;0.1%)\n153 (3.0%)\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\ncode R\n# Proportions de 'score_scale' par genre\ntable_score_gender &lt;- table(my_data_frame$score_scale, my_data_frame$Sex)\ntable_score_gender_percent &lt;- prop.table(table_score_gender, 2) * 100  # Calcul par genre\ntable_score_gender_percent\n\n\n                \n                         Men       Women\n  Very Masculine  0.43248438  0.00000000\n  1               9.20230658  0.41403785\n  2              45.43488707  7.90615142\n  3              40.02883229 40.67429022\n  4               4.44497838 32.05835962\n  5               0.43248438 15.93059937\n  Very Feminine   0.02402691  3.01656151\n\n\ncode R\n# Proportions de 'satisfaction' par genre\ntable_satisfaction_gender &lt;- table(my_data_frame$satisfaction, my_data_frame$Sex)\ntable_satisfaction_gender_percent &lt;- prop.table(table_satisfaction_gender, 2) * 100  # Calcul par genre\ntable_satisfaction_gender_percent\n\n\n        \n              Men    Women\n  High   35.15399 32.66917\n  Low    35.80366 39.75143\n  Medium 29.04235 27.57940\n\n\n\n\ncode R\n# Charger les bibliothèques nécessaires\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(scales)\n\n# Création du graphique avec ggplot\np &lt;- ggplot(as.data.frame(table_score_gender_percent), \n            aes(x = Var1, y = Freq, fill = Var2, text = paste0(\"Proportion: \", percent(Freq / 100)))) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  labs(title = \"Répartition des scores par genre\",\n       x = \"Score (1-7)\", y = \"Proportion (%)\") +\n  scale_y_continuous(labels = percent_format(scale = 1)) +\n  theme_minimal() +\n  theme(legend.title = element_blank())\n\n# Convertir en graphique interactif avec ggplotly\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\ncode R\ntable1 &lt;-\n  my_data_frame |&gt; \n  tbl_summary(include = c(identity_scale),\n  by=Sex ,)|&gt; \n    add_p()\ntable1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\np-value2\n\n\n\n\nidentity_scale\n\n\n\n\n&lt;0.001\n\n\n    Very Feminine\n9 (0.2%)\n218 (4.3%)\n\n\n\n\n    1\n403 (9.7%)\n1,506 (30%)\n\n\n\n\n    2\n2,139 (51%)\n2,669 (53%)\n\n\n\n\n    3\n985 (24%)\n576 (11%)\n\n\n\n\n    4\n509 (12%)\n90 (1.8%)\n\n\n\n\n    5\n96 (2.3%)\n10 (0.2%)\n\n\n\n\n    Very Masculine\n21 (0.5%)\n3 (&lt;0.1%)\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\ncode R\n# Proportions de 'score_scale' par genre\ntable_identity_gender &lt;- table(my_data_frame$identity_scale, my_data_frame$Sex)\ntable_identity_gender_percent &lt;- prop.table(table_identity_gender, 2) * 100  # Calcul par genre\ntable_identity_gender_percent\n\n\n                \n                         Men       Women\n  Very Feminine   0.21624219  4.29810726\n  1               9.68284479 29.69242902\n  2              51.39356079 52.62223975\n  3              23.66650649 11.35646688\n  4              12.22969726  1.77444795\n  5               2.30658337  0.19716088\n  Very Masculine  0.50456511  0.05914826\n\n\ncode R\n# Création du graphique avec ggplot\np &lt;- ggplot(as.data.frame(table_identity_gender_percent), \n            aes(x = Var1, y = Freq, fill = Var2, text = paste0(\"Proportion: \", percent(Freq / 100)))) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  labs(title = \"Répartition de l'identity scale par genre\",\n       x = \"Score (1-7)\", y = \"Proportion (%)\") +\n  scale_y_continuous(labels = percent_format(scale = 1)) +\n  theme_minimal() +\n  theme(legend.title = element_blank())\n\n# Convertir en graphique interactif avec ggplotly\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\nggplotly(p)\n\n\ncode R\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(plotly)\n\n# Créer un tableau de fréquence pour la heatmap\nheatmap_data &lt;- my_data_frame %&gt;%\n  count(score_scale, satisfaction)  # Compte les occurrences\n\n# Ajouter une colonne pour l'affichage interactif\nheatmap_data &lt;- heatmap_data %&gt;%\n  mutate(info_text = paste0(\"Score: \", score_scale, \n                            \"\\nSatisfaction: \", satisfaction, \n                            \"\\nNombre d'observations: \", n))\n\n# Créer la heatmap avec ggplot\np &lt;- ggplot(heatmap_data, aes(x = as.factor(score_scale), \n                              y = as.factor(satisfaction), \n                              fill = n, text = info_text)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"white\", high = \"blue\") +\n  labs(title = \"Heatmap de la relation entre satisfaction et score\",\n       x = \"Score Scale\", y = \"Satisfaction\", fill = \"Fréquence\") +\n  theme_minimal()\n\n# Rendre le graphique interactif avec des infobulles personnalisées\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\ncode R\n# Créer un tableau de fréquence pour la heatmap\nheatmap_data &lt;- my_data_frame %&gt;%\n  count(identity_scale, satisfaction)  # Compte les occurrences\n\n# Ajouter une colonne pour l'affichage interactif\nheatmap_data &lt;- heatmap_data %&gt;%\n  mutate(info_text = paste0(\"Identity: \", identity_scale, \n                            \"\\nSatisfaction: \", satisfaction, \n                            \"\\nNombre d'observations: \", n))\n\n# Créer la heatmap avec ggplot\np &lt;- ggplot(heatmap_data, aes(x = as.factor(identity_scale), \n                              y = as.factor(satisfaction), \n                              fill = n, text = info_text)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"white\", high = \"blue\") +\n  labs(title = \"Heatmap de la relation entre satisfaction et identity scale\",\n       x = \"Score Scale\", y = \"Satisfaction\", fill = \"Fréquence\") +\n  theme_minimal()\n\n# Rendre le graphique interactif avec des infobulles personnalisées\nggplotly(p, tooltip = \"text\")"
  },
  {
    "objectID": "normes_identite/construction_indice.html#ecarts-aux-normes-et-satisfaction",
    "href": "normes_identite/construction_indice.html#ecarts-aux-normes-et-satisfaction",
    "title": "Notre Mesure: Le Cultural Gender Normativity Index (CGNI)",
    "section": "Ecarts aux normes et satisfaction",
    "text": "Ecarts aux normes et satisfaction\n\n\ncode R\nmean_gender &lt;- tapply(my_data_frame$identity, my_data_frame$Sex, mean)\nsd_gender &lt;- tapply(my_data_frame$identity, my_data_frame$Sex, sd)\n\nmy_data_frame$distance_abs&lt;- abs((my_data_frame$identity - mean_gender[my_data_frame$Sex]) / sd_gender[my_data_frame$Sex])\n\nggplot(my_data_frame, aes(x = distance_abs, color = Sex, fill = Sex)) +\n  geom_density(alpha = 0.4) +\n  labs(title = \"Density of Distance to the Norm, by Sex\", \n       x = \"Distance to the Norm (Z-score)\", y = \"Density\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\ncode R\n# Charger dplyr\nlibrary(dplyr)\n\n# Assurer que Sex est un facteur avec les niveaux appropriés\nmy_data_frame$Sex &lt;- factor(my_data_frame$Sex, levels = c(\"Men\", \"Women\"))\n\n# Calculer les moyennes et écarts-types par sexe avec dplyr\nmean_sd_by_sex &lt;- my_data_frame %&gt;%\n  group_by(Sex) %&gt;%\n  summarise(\n    mean_gender = mean(score_normalise, na.rm = TRUE),\n    sd_gender = sd(score_normalise, na.rm = TRUE)\n  )\n\n# Joindre les moyennes et écarts-types au dataframe original\nmy_data_frame &lt;- my_data_frame %&gt;%\n  left_join(mean_sd_by_sex, by = \"Sex\")\n\n# Calculer la distance absolue à la moyenne (Z-score)\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(distance_abs_2 = abs((score_normalise - mean_gender) / sd_gender))\n\n# Visualisation\nggplot(my_data_frame, aes(x = distance_abs_2, color = Sex, fill = Sex)) +\n  geom_density(alpha = 0.4) +\n  labs(title = \"Density of Distance to the Norm (Score), by Sex\", \n       x = \"Distance to the Norm (Z-score)\", y = \"Density\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal() +\n  geom_vline(data = my_data_frame, aes(xintercept = mean(distance_abs_2[Sex == \"Men\"]), color = \"Men\"), linetype = \"dashed\") +\n  geom_vline(data = my_data_frame, aes(xintercept = mean(distance_abs_2[Sex == \"Women\"]), color = \"Women\"), linetype = \"dashed\") +\n  theme(legend.title = element_blank())  # Enlever le titre de la légende\n\n\n\n\n\n\n\n\n\n\n\ncode R\n# Charger le package MASS pour polr\nlibrary(MASS)\n\n# Modèle de régression ordinale (polr)\nmodel &lt;- polr(as.factor(satisfaction) ~ distance_abs_2, data = my_data_frame, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model)\n\n\nCall:\npolr(formula = as.factor(satisfaction) ~ distance_abs_2, data = my_data_frame, \n    method = \"logistic\")\n\nCoefficients:\n                  Value Std. Error t value\ndistance_abs_2 0.006466    0.03186  0.2029\n\nIntercepts:\n           Value    Std. Error t value \nHigh|Low    -0.6675   0.0339   -19.6997\nLow|Medium   0.9379   0.0346    27.0688\n\nResidual Deviance: 20135.99 \nAIC: 20141.99 \n(9 observations effacées parce que manquantes)\n\n\ncode R\n# Modèle de régression ordinale avec interaction entre sexe et distance aux normes\nmodel_interaction &lt;- polr(as.factor(satisfaction) ~ Sex * distance_abs_2, data = my_data_frame, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model_interaction)\n\n\nCall:\npolr(formula = as.factor(satisfaction) ~ Sex * distance_abs_2, \n    data = my_data_frame, method = \"logistic\")\n\nCoefficients:\n                          Value Std. Error t value\nSexWomen                 0.1157    0.06433   1.798\ndistance_abs_2           0.0622    0.04580   1.358\nSexWomen:distance_abs_2 -0.1093    0.06379  -1.713\n\nIntercepts:\n           Value    Std. Error t value \nHigh|Low    -0.6084   0.0474   -12.8372\nLow|Medium   0.9975   0.0482    20.7042\n\nResidual Deviance: 20132.55 \nAIC: 20142.55 \n(9 observations effacées parce que manquantes)\n\n\n\n\ncode R\n# Charger la bibliothèque Plotly\nlibrary(plotly)\n\n# Regroupement de distance_abs_2 en catégories (bins)\nmy_data_frame$distance_abs_2_bins &lt;- cut(my_data_frame$distance_abs_2, \n                                          breaks = 10,  # Divise en 10 intervalles\n                                          labels = FALSE, include.lowest = TRUE)\n\n# Comptage des occurrences pour chaque combinaison de Sexe, Satisfaction et Distance\nlibrary(dplyr)\ncount_data &lt;- my_data_frame %&gt;%\n  count(Sex, satisfaction, distance_abs_2_bins)\n\n# Création de la heatmap interactive avec Plotly\nfig &lt;- plot_ly(count_data, \n               x = ~distance_abs_2_bins, \n               y = ~as.factor(satisfaction), \n               z = ~n, \n               type = \"heatmap\", \n               colors = colorRamp(c(\"white\", \"blue\")), \n               colorbar = list(title = \"Nombre d'individus\"))\n\n# Ajouter des titres\nfig &lt;- fig %&gt;%\n  layout(title = \"Heatmap de Satisfaction par Sexe et Distance aux Normes\",\n         xaxis = list(title = \"Distance aux Normes (Binned)\"),\n         yaxis = list(title = \"Satisfaction\"))\n\n# Afficher la heatmap interactive\nfig\n\n\n\n\n\n\n\n\ncode R\nggplot(my_data_frame, aes(x = distance_abs_2, y = as.factor(satisfaction), color = Sex)) +\n  geom_point(alpha = 0.7) +\n  labs(title = \"Interaction entre Sexe et Distance aux Normes sur Satisfaction\",\n       x = \"Distance aux Normes (Z-score)\", y = \"Satisfaction\") +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal() +\n  facet_wrap(~Sex)\n\n\n\n\n\n\n\n\n\n\n\ncode R\n# 1. Charger les librairies nécessaires\nlibrary(MASS)\nlibrary(ggplot2)\n\n# 2. Vérifier les valeurs manquantes dans le dataframe\n#summary(my_data_frame)\n\n# 3. Supprimer les lignes contenant des valeurs manquantes dans les colonnes pertinentes\nmy_data_frame_clean &lt;- my_data_frame[complete.cases(my_data_frame[c(\"satisfaction\", \"Sex\", \"distance_abs_2\")]), ]\n\n# Vérification de la taille du dataframe nettoyé\nnrow(my_data_frame_clean)  # Assure-toi que la taille est correcte\n\n\n[1] 9225\n\n\ncode R\n# 4. Convertir les variables catégoriques en facteurs avec les niveaux appropriés\nmy_data_frame_clean$satisfaction &lt;- factor(my_data_frame_clean$satisfaction, levels = c(\"Low\", \"Medium\", \"High\"))\nmy_data_frame_clean$Sex &lt;- factor(my_data_frame_clean$Sex, levels = c(\"Men\", \"Women\"))\n\n# 5. Ajuster le modèle de régression logistique ordinale\nmodel_clean &lt;- polr(as.factor(satisfaction) ~ distance_abs_2, data = my_data_frame_clean, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model_clean)\n\n\nCall:\npolr(formula = as.factor(satisfaction) ~ distance_abs_2, data = my_data_frame_clean, \n    method = \"logistic\")\n\nCoefficients:\n                  Value Std. Error t value\ndistance_abs_2 -0.07781    0.03216   -2.42\n\nIntercepts:\n            Value    Std. Error t value \nLow|Medium   -0.5532   0.0336   -16.4602\nMedium|High   0.6108   0.0337    18.1097\n\nResidual Deviance: 20130.17 \nAIC: 20136.17 \n\n\ncode R\n# 6. Calculer les probabilités pour chaque niveau de satisfaction\npred_prob_clean &lt;- predict(model_clean, type = \"probs\")\n\n# Ajouter les probabilités au dataframe nettoyé\nmy_data_frame_clean$prob_high &lt;- pred_prob_clean[, \"High\"]\nmy_data_frame_clean$prob_medium &lt;- pred_prob_clean[, \"Medium\"]\nmy_data_frame_clean$prob_low &lt;- pred_prob_clean[, \"Low\"]\n\n# 7. Visualiser les résultats\nggplot(my_data_frame_clean, aes(x = distance_abs_2)) +\n  geom_line(aes(y = prob_high, color = \"High\"), size = 1) +\n  geom_line(aes(y = prob_medium, color = \"Medium\"), size = 1) +\n  geom_line(aes(y = prob_low, color = \"Low\"), size = 1) +\n  labs(title = \"Probabilité d'être satisfait selon l'écart aux normes\",\n       x = \"Distance aux Normes (Z-score)\",\n       y = \"Probabilité\") +\n  scale_color_manual(values = c(\"High\" = \"blue\", \"Medium\" = \"orange\", \"Low\" = \"red\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\ncode R\n# 1. Charger les librairies nécessaires\nlibrary(MASS)\nlibrary(ggplot2)\n\n# 2. Vérifier les valeurs manquantes dans le dataframe\n#summary(my_data_frame)\n\n# 3. Supprimer les lignes contenant des valeurs manquantes dans les colonnes pertinentes\nmy_data_frame_clean &lt;- my_data_frame[complete.cases(my_data_frame[c(\"satisfaction\", \"Sex\", \"distance_abs_2\")]), ]\n\n# Vérification de la taille du dataframe nettoyé\nnrow(my_data_frame_clean)  # Assure-toi que la taille est correcte\n\n\n[1] 9225\n\n\ncode R\n# 4. Convertir les variables catégoriques en facteurs avec les niveaux appropriés\nmy_data_frame_clean$satisfaction &lt;- factor(my_data_frame_clean$satisfaction, levels = c(\"Low\", \"Medium\", \"High\"))\nmy_data_frame_clean$Sex &lt;- factor(my_data_frame_clean$Sex, levels = c(\"Men\", \"Women\"))\n\n# 5. Ajuster le modèle de régression logistique ordinale avec interaction entre Sex et distance_abs_2\nmodel_clean_sex &lt;- polr(as.factor(satisfaction) ~ distance_abs_2 * Sex, data = my_data_frame_clean, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model_clean_sex)\n\n\nCall:\npolr(formula = as.factor(satisfaction) ~ distance_abs_2 * Sex, \n    data = my_data_frame_clean, method = \"logistic\")\n\nCoefficients:\n                          Value Std. Error t value\ndistance_abs_2          -0.1148    0.04583  -2.505\nSexWomen                -0.2017    0.06424  -3.139\ndistance_abs_2:SexWomen  0.0791    0.06436   1.229\n\nIntercepts:\n            Value    Std. Error t value \nLow|Medium   -0.6585   0.0470   -14.0070\nMedium|High   0.5070   0.0468    10.8335\n\nResidual Deviance: 20115.75 \nAIC: 20125.75 \n\n\ncode R\n# 6. Calculer les probabilités pour chaque niveau de satisfaction par sexe\npred_prob_clean_sex &lt;- predict(model_clean_sex, type = \"probs\")\n\n# Ajouter les probabilités au dataframe nettoyé\nmy_data_frame_clean$prob_high &lt;- pred_prob_clean_sex[, \"High\"]\nmy_data_frame_clean$prob_medium &lt;- pred_prob_clean_sex[, \"Medium\"]\nmy_data_frame_clean$prob_low &lt;- pred_prob_clean_sex[, \"Low\"]\n\n# 7. Visualiser les résultats en fonction de l'écart aux normes et du sexe (avec facet)\nggplot(my_data_frame_clean, aes(x = distance_abs_2)) +\n  geom_line(aes(y = prob_high, color = \"High\"), size = 1) +\n  geom_line(aes(y = prob_medium, color = \"Medium\"), size = 1) +\n  geom_line(aes(y = prob_low, color = \"Low\"), size = 1) +\n  labs(title = \"Probabilité d'être satisfait selon l'écart aux normes et par sexe\",\n       x = \"Distance aux Normes (Z-score)\",\n       y = \"Probabilité\") +\n  scale_color_manual(values = c(\"High\" = \"blue\", \"Medium\" = \"orange\", \"Low\" = \"red\")) +\n  theme_minimal() +\n  facet_wrap(~ Sex) +  # Facette par Sexe\n  theme(legend.title = element_blank())  # Enlever le titre de la légende\n\n\n\n\n\n\n\n\n\n\n\ncode R\n# 1. Charger les librairies nécessaires\nlibrary(MASS)\nlibrary(ggplot2)\nlibrary(plotly)\n\n# 2. Vérifier les valeurs manquantes dans le dataframe\n#summary(my_data_frame)\n\n# 3. Supprimer les lignes contenant des valeurs manquantes dans les colonnes pertinentes\nmy_data_frame_clean &lt;- my_data_frame[complete.cases(my_data_frame[c(\"satisfaction\", \"Sex\", \"distance_abs_2\")]), ]\n\n# Vérification de la taille du dataframe nettoyé\nnrow(my_data_frame_clean)  # Assure-toi que la taille est correcte\n\n\n[1] 9225\n\n\ncode R\n# 4. Convertir les variables catégoriques en facteurs avec les niveaux appropriés\nmy_data_frame_clean$satisfaction &lt;- factor(my_data_frame_clean$satisfaction, levels = c(\"Low\", \"Medium\", \"High\"))\nmy_data_frame_clean$Sex &lt;- factor(my_data_frame_clean$Sex, levels = c(\"Men\", \"Women\"))\n\n# 5. Ajuster le modèle de régression logistique ordinale avec interaction entre Sex et distance_abs_2\nmodel_clean_sex &lt;- polr(as.factor(satisfaction) ~ distance_abs_2 * Sex, data = my_data_frame_clean, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model_clean_sex)\n\n\nCall:\npolr(formula = as.factor(satisfaction) ~ distance_abs_2 * Sex, \n    data = my_data_frame_clean, method = \"logistic\")\n\nCoefficients:\n                          Value Std. Error t value\ndistance_abs_2          -0.1148    0.04583  -2.505\nSexWomen                -0.2017    0.06424  -3.139\ndistance_abs_2:SexWomen  0.0791    0.06436   1.229\n\nIntercepts:\n            Value    Std. Error t value \nLow|Medium   -0.6585   0.0470   -14.0070\nMedium|High   0.5070   0.0468    10.8335\n\nResidual Deviance: 20115.75 \nAIC: 20125.75 \n\n\ncode R\n# 6. Calculer les probabilités pour chaque niveau de satisfaction par sexe\npred_prob_clean_sex &lt;- predict(model_clean_sex, type = \"probs\")\n\n# Ajouter les probabilités au dataframe nettoyé\nmy_data_frame_clean$prob_high &lt;- pred_prob_clean_sex[, \"High\"]\nmy_data_frame_clean$prob_medium &lt;- pred_prob_clean_sex[, \"Medium\"]\nmy_data_frame_clean$prob_low &lt;- pred_prob_clean_sex[, \"Low\"]\n\n# 7. Visualisation avec ggplot et ajout de commentaires pour les courbes\np &lt;- ggplot(my_data_frame_clean, aes(x = distance_abs_2)) +\n  geom_line(aes(y = prob_high, color = \"High\"), size = 1) +\n  geom_line(aes(y = prob_medium, color = \"Medium\"), size = 1) +\n  geom_line(aes(y = prob_low, color = \"Low\"), size = 1) +\n  labs(title = \"Probabilité d'être satisfait selon l'écart aux normes et par sexe\",\n       x = \"Distance aux Normes (Z-score)\",\n       y = \"Probabilité\") +\n  scale_color_manual(values = c(\"High\" = \"blue\", \"Medium\" = \"orange\", \"Low\" = \"red\")) +\n  theme_minimal() +\n  facet_wrap(~ Sex) +  # Facette par Sexe\n  theme(legend.title = element_blank())  # Enlever le titre de la légende\n\n# 8. Rendre le graphique interactif avec plotly et ajouter des annotations\np_interactive &lt;- ggplotly(p)\n\n# Ajouter des annotations pour chaque courbe\np_interactive &lt;- p_interactive %&gt;%\n  layout(\n    annotations = list(\n      list(\n        x = 0.5, y = 0.8, \n        text = \"Probabilité High\", \n        showarrow = TRUE, \n        arrowhead = 2,\n        ax = -50, ay = -50\n      ),\n      list(\n        x = 0.5, y = 0.6, \n        text = \"Probabilité Medium\", \n        showarrow = TRUE, \n        arrowhead = 2,\n        ax = -50, ay = -50\n      ),\n      list(\n        x = 0.5, y = 0.4, \n        text = \"Probabilité Low\", \n        showarrow = TRUE, \n        arrowhead = 2,\n        ax = -50, ay = -50\n      )\n    )\n  )\n\n# Afficher le graphique interactif\np_interactive\n\n\n\n\n\n\n\n\ncode R\n# 1. Charger les librairies nécessaires\nlibrary(MASS)\nlibrary(ggplot2)\nlibrary(plotly)\n\n# 2. Convertir la colonne de réponses A15 en une variable Santé catégorique (3 niveaux)\n# Supposons que ta variable santé est dans la colonne 'A15' de 'my_data_frame'\n\n# Remplacer les valeurs de A15 par les niveaux correspondants pour Santé\nmy_data_frame$Santé &lt;- factor(my_data_frame$A15,\n                              levels = c(1, 2, 3, 4, 5),\n                              labels = c(\"Very Good\", \"Good\", \"Fair\", \"Poor\", \"Very Poor\"))\n\n# Convertir en 3 niveaux: \"Good\", \"Fair\", \"Poor\"\nmy_data_frame$Santé &lt;- factor(my_data_frame$Santé,\n                              levels = c(\"Very Good\", \"Good\", \"Fair\", \"Poor\", \"Very Poor\"),\n                              labels = c(\"Good\", \"Good\", \"Fair\", \"Poor\", \"Poor\"))\n\n# Exclure les réponses \"Ne sait pas\" (6) et \"Refus\" (7)\nmy_data_frame_clean &lt;- my_data_frame[!(my_data_frame$A15 %in% c(6, 7)), ]\n\n# 3. Vérifier que la variable Santé est correctement créée\ntable(my_data_frame_clean$Santé)\n\n\n\nGood Fair Poor \n6410 1998  783 \n\n\ncode R\n# 4. Convertir 'Sex' en facteur\nmy_data_frame_clean$Sex &lt;- factor(my_data_frame_clean$Sex, levels = c(\"Men\", \"Women\"))\n\n# 5. Ajuster le modèle de régression logistique ordinale avec interaction entre Sex et distance_abs_2\nmodel_clean_sex_health &lt;- polr(Santé ~ distance_abs_2 * Sex, data = my_data_frame_clean, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model_clean_sex_health)\n\n\nCall:\npolr(formula = Santé ~ distance_abs_2 * Sex, data = my_data_frame_clean, \n    method = \"logistic\")\n\nCoefficients:\n                           Value Std. Error t value\ndistance_abs_2          -0.18516    0.05723 -3.2354\nSexWomen                 0.01082    0.07548  0.1433\ndistance_abs_2:SexWomen  0.23130    0.07692  3.0071\n\nIntercepts:\n          Value   Std. Error t value\nGood|Fair  0.7996  0.0549    14.5549\nFair|Poor  2.3414  0.0624    37.5084\n\nResidual Deviance: 14545.54 \nAIC: 14555.54 \n\n\ncode R\n# 6. Calculer les probabilités pour chaque niveau de Santé par sexe\npred_prob_clean_sex_health &lt;- predict(model_clean_sex_health, type = \"probs\")\n\n# Ajouter les probabilités au dataframe nettoyé\nmy_data_frame_clean$prob_poor &lt;- pred_prob_clean_sex_health[, \"Poor\"]\nmy_data_frame_clean$prob_fair &lt;- pred_prob_clean_sex_health[, \"Fair\"]\nmy_data_frame_clean$prob_good &lt;- pred_prob_clean_sex_health[, \"Good\"]\n\n# 7. Visualisation avec ggplot et ajout de commentaires pour les courbes\np_health &lt;- ggplot(my_data_frame_clean, aes(x = distance_abs_2)) +\n  geom_line(aes(y = prob_poor, color = \"Poor\"), size = 1) +\n  geom_line(aes(y = prob_fair, color = \"Fair\"), size = 1) +\n  geom_line(aes(y = prob_good, color = \"Good\"), size = 1) +\n  labs(title = \"Probabilité d'être en bonne santé selon l'écart aux normes et par sexe\",\n       x = \"Distance aux Normes (Z-score)\",\n       y = \"Probabilité\") +\n  scale_color_manual(values = c(\"Poor\" = \"red\", \n                                \"Fair\" = \"orange\", \n                                \"Good\" = \"green\")) +\n  theme_minimal() +\n  facet_wrap(~ Sex) +  # Facette par Sexe\n  theme(legend.title = element_blank())  # Enlever le titre de la légende\n\n# 8. Rendre le graphique interactif avec plotly et ajouter des annotations\np_interactive_health &lt;- ggplotly(p_health)\n\n# Ajouter des annotations pour chaque courbe\np_interactive_health &lt;- p_interactive_health %&gt;%\n  layout(\n    annotations = list(\n      list(\n        x = 0.5, y = 0.8, \n        text = \"Probabilité Poor\", \n        showarrow = TRUE, \n        arrowhead = 2,\n        ax = -50, ay = -50\n      ),\n      list(\n        x = 0.5, y = 0.6, \n        text = \"Probabilité Fair\", \n        showarrow = TRUE, \n        arrowhead = 2,\n        ax = -50, ay = -50\n      ),\n      list(\n        x = 0.5, y = 0.4, \n        text = \"Probabilité Good\", \n        showarrow = TRUE, \n        arrowhead = 2,\n        ax = -50, ay = -50\n      )\n    )\n  )\n\n# Afficher le graphique interactif\np_interactive_health\n\n\n\n\n\n\n\n\ncode R\n# Créer la variable revenu en fonction de CRITREVENU\nmy_data_frame$revenu &lt;- NA  # Initialisation de la variable\n\n# Assignation des tranches de revenu\nmy_data_frame$revenu[my_data_frame$CRITREVENU %in% c(1, 2)] &lt;- \"Moins de 1000 euros\"\nmy_data_frame$revenu[my_data_frame$CRITREVENU %in% c(3, 4)] &lt;- \"1000 à 1499 euros\"\nmy_data_frame$revenu[my_data_frame$CRITREVENU %in% c(5, 6)] &lt;- \"1500 à 2499 euros\"\nmy_data_frame$revenu[my_data_frame$CRITREVENU %in% c(7, 8, 9, 10)] &lt;- \"2500 euros et plus\"\n\n# Convertir la variable revenu en facteur\nmy_data_frame$revenu &lt;- factor(my_data_frame$revenu, \n                               levels = c(\"Moins de 1000 euros\", \"1000 à 1499 euros\", \"1500 à 2499 euros\", \"2500 euros et plus\"))\n\n# Vérifier les niveaux de la nouvelle variable revenu\nsummary(my_data_frame$revenu)\n\n\nMoins de 1000 euros   1000 à 1499 euros   1500 à 2499 euros  2500 euros et plus \n                766                1280                2241                3775 \n               NA's \n               1172 \n\n\n\n\ncode R\n# Charger les librairies nécessaires\nlibrary(MASS)\nlibrary(ggplot2)\nlibrary(plotly)\n\n# 2. Vérifier les valeurs manquantes dans le dataframe\n#summary(my_data_frame)\n\n# 3. Supprimer les lignes contenant des valeurs manquantes dans les colonnes pertinentes\nmy_data_frame_clean &lt;- my_data_frame[complete.cases(my_data_frame[c(\"satisfaction\", \"Sex\", \"distance_abs_2\", \"revenu\")]), ]\n\n# Vérification de la taille du dataframe nettoyé\nnrow(my_data_frame_clean)  # Assure-toi que la taille est correcte\n\n\n[1] 8057\n\n\ncode R\n# 4. Convertir les variables catégoriques en facteurs avec les niveaux appropriés\nmy_data_frame_clean$satisfaction &lt;- factor(my_data_frame_clean$satisfaction, levels = c(\"Low\", \"Medium\", \"High\"))\nmy_data_frame_clean$Sex &lt;- factor(my_data_frame_clean$Sex, levels = c(\"Men\", \"Women\"))\n\n\nmy_data_frame_clean$revenu &lt;- factor(my_data_frame_clean$revenu, \n                                     levels = c(\"Moins de 1000 euros\", \"1000 à 1499 euros\", \n                                                \"1500 à 2499 euros\", \"2500 euros et plus\"),\n                                     labels = c(\"&lt;1000\", \"[1000-1499]\", \"[1500-2499]\", \"≥2500\"))\n\n# 5. Ajuster le modèle de régression logistique ordinale avec interaction entre Sexe, revenu et distance_abs_2\nmodel_clean_sex_revenu &lt;- polr(as.factor(satisfaction) ~ distance_abs_2 * Sex * revenu, \n                               data = my_data_frame_clean, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model_clean_sex_revenu)\n\n\nCall:\npolr(formula = as.factor(satisfaction) ~ distance_abs_2 * Sex * \n    revenu, data = my_data_frame_clean, method = \"logistic\")\n\nCoefficients:\n                                             Value Std. Error t value\ndistance_abs_2                            -0.09979     0.1619 -0.6162\nSexWomen                                  -0.31623     0.2334 -1.3551\nrevenu[1000-1499]                         -0.04255     0.2232 -0.1906\nrevenu[1500-2499]                         -0.35836     0.1967 -1.8216\nrevenu≥2500                               -1.03159     0.1857 -5.5564\ndistance_abs_2:SexWomen                    0.21809     0.2278  0.9574\ndistance_abs_2:revenu[1000-1499]          -0.04684     0.2164 -0.2164\ndistance_abs_2:revenu[1500-2499]          -0.19435     0.1892 -1.0273\ndistance_abs_2:revenu≥2500                 0.07973     0.1751  0.4553\nSexWomen:revenu[1000-1499]                 0.04296     0.2975  0.1444\nSexWomen:revenu[1500-2499]                -0.09766     0.2684 -0.3639\nSexWomen:revenu≥2500                       0.04588     0.2538  0.1808\ndistance_abs_2:SexWomen:revenu[1000-1499] -0.08680     0.2937 -0.2955\ndistance_abs_2:SexWomen:revenu[1500-2499]  0.08247     0.2648  0.3114\ndistance_abs_2:SexWomen:revenu≥2500       -0.28512     0.2482 -1.1490\n\nIntercepts:\n            Value   Std. Error t value\nLow|Medium  -1.3039  0.1733    -7.5242\nMedium|High -0.0848  0.1727    -0.4914\n\nResidual Deviance: 17141.50 \nAIC: 17175.50 \n\n\ncode R\n# 6. Calculer les probabilités pour chaque niveau de satisfaction par sexe et revenu\npred_prob_clean_sex_revenu &lt;- predict(model_clean_sex_revenu, type = \"probs\")\n\n# Ajouter les probabilités au dataframe nettoyé\nmy_data_frame_clean$prob_high &lt;- pred_prob_clean_sex_revenu[, \"High\"]\nmy_data_frame_clean$prob_medium &lt;- pred_prob_clean_sex_revenu[, \"Medium\"]\nmy_data_frame_clean$prob_low &lt;- pred_prob_clean_sex_revenu[, \"Low\"]\n\np &lt;- ggplot(my_data_frame_clean, aes(x = distance_abs_2)) +\n  geom_line(aes(y = prob_high, color = \"High\"), size = 1) +\n  geom_line(aes(y = prob_medium, color = \"Medium\"), size = 1) +\n  geom_line(aes(y = prob_low, color = \"Low\"), size = 1) +\n  labs(title = \"Probabilité d'être satisfait selon l'écart aux normes, par Sexe et Revenu\",\n       x = \"Distance aux Normes (Z-score)\",\n       y = \"Probabilité\") +\n  scale_color_manual(values = c(\"High\" = \"blue\", \"Medium\" = \"orange\", \"Low\" = \"red\")) +\n  theme_minimal() +\n  facet_grid(revenu ~ Sex) +  # Facet verticalement par revenu et horizontalement par sexe\n  theme(\n    legend.title = element_blank(),\n    strip.text.y = element_text(size = 10),  # Réduire la taille des labels des facettes\n    panel.spacing = unit(2, \"lines\")  # Augmenter l'espacement vertical entre facettes\n  )\n\n# Rendre interactif\np_interactive &lt;- ggplotly(p)\n\n# Afficher le graphique\np_interactive\n\n\n\n\n\n\n\n\ncode R\n# Charger les librairies nécessaires\nlibrary(MASS)\nlibrary(ggplot2)\nlibrary(plotly)\n\n\n\n# Supprimer les lignes contenant des valeurs manquantes dans les colonnes pertinentes\nmy_data_frame_clean &lt;- my_data_frame[complete.cases(my_data_frame[c(\"Santé\", \"Sex\", \"distance_abs_2\", \"revenu\")]), ]\n\n# Convertir les variables catégoriques en facteurs avec les niveaux appropriés\nmy_data_frame_clean$Sex &lt;- factor(my_data_frame_clean$Sex, levels = c(\"Men\", \"Women\"))\n\nmy_data_frame_clean$revenu &lt;- factor(my_data_frame_clean$revenu, \n                                     levels = c(\"Moins de 1000 euros\", \"1000 à 1499 euros\", \n                                                \"1500 à 2499 euros\", \"2500 euros et plus\"),\n                                     labels = c(\"&lt;1000\", \"[1000-1499]\", \"[1500-2499]\", \"≥2500\"))\n\n# Ajuster le modèle de régression logistique ordinale avec interaction entre Sexe, revenu et distance_abs_2\nmodel_clean_sex_revenu &lt;- polr(Santé ~ distance_abs_2 * Sex * revenu, \n                               data = my_data_frame_clean, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model_clean_sex_revenu)\n\n\nCall:\npolr(formula = Santé ~ distance_abs_2 * Sex * revenu, data = my_data_frame_clean, \n    method = \"logistic\")\n\nCoefficients:\n                                             Value Std. Error  t value\ndistance_abs_2                            -0.04726     0.1752 -0.26972\nSexWomen                                  -0.00787     0.2395 -0.03286\nrevenu[1000-1499]                         -0.17953     0.2311 -0.77699\nrevenu[1500-2499]                         -0.58712     0.2077 -2.82662\nrevenu≥2500                               -1.35152     0.2012 -6.71747\ndistance_abs_2:SexWomen                    0.14027     0.2374  0.59078\ndistance_abs_2:revenu[1000-1499]          -0.08297     0.2318 -0.35795\ndistance_abs_2:revenu[1500-2499]          -0.24211     0.2106 -1.14967\ndistance_abs_2:revenu≥2500                -0.12468     0.1999 -0.62381\nSexWomen:revenu[1000-1499]                 0.13125     0.3072  0.42727\nSexWomen:revenu[1500-2499]                -0.29009     0.2836 -1.02271\nSexWomen:revenu≥2500                      -0.03496     0.2736 -0.12778\ndistance_abs_2:SexWomen:revenu[1000-1499] -0.15748     0.3073 -0.51252\ndistance_abs_2:SexWomen:revenu[1500-2499]  0.26764     0.2853  0.93797\ndistance_abs_2:SexWomen:revenu≥2500        0.10373     0.2716  0.38191\n\nIntercepts:\n          Value   Std. Error t value\nGood|Fair -0.0268  0.1782    -0.1503\nFair|Poor  1.5826  0.1801     8.7888\n\nResidual Deviance: 12216.87 \nAIC: 12250.87 \n\n\ncode R\n# Calculer les probabilités pour chaque niveau de santé par sexe et revenu\npred_prob_clean_sex_revenu &lt;- predict(model_clean_sex_revenu, type = \"probs\")\n\n# Ajouter les probabilités au dataframe nettoyé\nmy_data_frame_clean$prob_high &lt;- pred_prob_clean_sex_revenu[, \"Good\"]\nmy_data_frame_clean$prob_medium &lt;- pred_prob_clean_sex_revenu[, \"Fair\"]\nmy_data_frame_clean$prob_low &lt;- pred_prob_clean_sex_revenu[, \"Poor\"]\n\n# Visualisation avec ggplot\np &lt;- ggplot(my_data_frame_clean, aes(x = distance_abs_2)) +\n  geom_line(aes(y = prob_high, color = \"High\"), size = 1) +\n  geom_line(aes(y = prob_medium, color = \"Medium\"), size = 1) +\n  geom_line(aes(y = prob_low, color = \"Low\"), size = 1) +\n  labs(title = \"Probabilité d'avoir un bon état de santé selon l'écart aux normes, par Sexe et Revenu\",\n       x = \"Distance aux Normes (Z-score)\",\n       y = \"Probabilité\") +\n  scale_color_manual(values = c(\"High\" = \"blue\", \"Medium\" = \"orange\", \"Low\" = \"red\")) +\n  theme_minimal() +\n  facet_grid(revenu ~ Sex) +  # Facet verticalement par revenu et horizontalement par sexe\n  theme(\n    legend.title = element_blank(),\n    strip.text.y = element_text(size = 10),  # Réduire la taille des labels des facettes\n    panel.spacing = unit(2, \"lines\")  # Augmenter l'espacement vertical entre facettes\n  )\n\n# Rendre interactif\np_interactive &lt;- ggplotly(p)\n\n# Afficher le graphique\np_interactive\n\n\n\n\n\n\n\n\ncode R\nmy_data_frame$distance_abs_2_bins&lt;-as.factor(my_data_frame$distance_abs_2_bins)\nmy_data_frame$satisfaction&lt;-as.factor(my_data_frame$satisfaction)\nrego &lt;- MASS::polr(\n  satisfaction ~ Sex + revenu + age_group + distance_abs_2_bins,\n  data = my_data_frame\n)\n\ntheme_gtsummary_language(\"en\", decimal.mark = \",\")\nrego |&gt; \n  tbl_regression(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  ) |&gt; \n  bold_labels() |&gt; \n  add_global_p(keep = TRUE) |&gt; \n  as_kable_extra(format = \"latex\", booktabs = TRUE) |&gt; \n  kable_styling(latex_options = c(\"hold_position\", \"scale_down\"), full_width = FALSE)\n\n\n\n\n\ncode R\nrego |&gt; \n  ggstats::ggcoef_table(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  )\n\n\n\n\n\n\n\n\n\ncode R\nrego |&gt; \n  broom.helpers::plot_marginal_predictions() |&gt; \n  patchwork::wrap_plots(ncol = 1) &\n  scale_y_continuous(labels = scales::percent) &\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\ncode R\nlibrary(dplyr)\n\n# Vérifier et nettoyer la colonne Sex\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(\n    Sex = trimws(as.character(Sex)),  # Supprime les espaces autour des valeurs\n    Sex = case_when(\n      tolower(Sex) == \"men\" ~ \"Men\",   # Uniformise \"men\" en \"Men\"\n      tolower(Sex) == \"women\" ~ \"Women\",  # Uniformise \"women\" en \"Women\"\n      TRUE ~ NA_character_  # Remplace toutes les autres valeurs par NA\n    )\n  ) %&gt;%\n  drop_na(Sex)  # Supprime les lignes où Sex est NA\n\n# Séparer les données\ndf_men &lt;- my_data_frame %&gt;% filter(Sex == \"Men\")\ndf_women &lt;- my_data_frame %&gt;% filter(Sex == \"Women\")\n\n# Vérifier la séparation\nprint(dim(df_men))   # Nombre de lignes et colonnes pour les hommes\n\n\n[1] 4162 1593\n\n\ncode R\nprint(dim(df_women)) # Nombre de lignes et colonnes pour les femmes\n\n\n[1] 5072 1593\n\n\ncode R\n# Modèles de régression\nrego_men &lt;- polr(\n  satisfaction ~ revenu + age_group + score_scale,\n  data = df_men\n)\n\n\n\n# Fonction pour générer le tableau\ngenerate_table &lt;- function(rego_model) {\n  rego_model |&gt; \n    tbl_regression(\n      exponentiate = TRUE,\n      tidy_fun = broom.helpers::tidy_parameters\n    ) |&gt; \n    bold_labels() |&gt; \n    add_global_p(keep = TRUE) |&gt; \n    as_kable_extra(format = \"latex\", booktabs = TRUE) |&gt; \n    kable_styling(latex_options = c(\"hold_position\", \"scale_down\"), full_width = FALSE)\n}\n\np1&lt;- rego_men |&gt; \n  ggstats::ggcoef_table(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  )\n\np1\n\n\n\n\n\n\n\n\n\ncode R\np2&lt;-rego_men |&gt; \n  broom.helpers::plot_marginal_predictions() |&gt; \n  patchwork::wrap_plots(ncol = 1) &\n  scale_y_continuous(labels = scales::percent) &\n  coord_flip()\np2\n\n\n\n\n\n\n\n\n\ncode R\ndf_women &lt;- df_women %&gt;%\n  mutate(across(where(is.factor), droplevels))\nrego_women &lt;- polr(\n  satisfaction ~ revenu + age_group + score_scale,\n  data = df_women\n)\n\nsummary(rego_women)\n\n\nCall:\npolr(formula = satisfaction ~ revenu + age_group + score_scale, \n    data = df_women)\n\nCoefficients:\n                            Value Std. Error   t value\nrevenu1000 à 1499 euros   0.26039    0.11541   2.25631\nrevenu1500 à 2499 euros   0.44209    0.10790   4.09730\nrevenu2500 euros et plus  0.53988    0.10225   5.27977\nage_group[38-54[         -0.24242    0.07518  -3.22476\nage_group[54-67[         -0.85674    0.07848 -10.91669\nage_group[67-97[         -1.82061    0.11712 -15.54511\nscore_scale2             -0.09855    0.42182  -0.23363\nscore_scale3             -0.12071    0.41244  -0.29268\nscore_scale4             -0.02359    0.41278  -0.05715\nscore_scale5             -0.05236    0.41616  -0.12581\nscore_scaleVery Feminine -0.02693    0.43886  -0.06137\n\nIntercepts:\n           Value    Std. Error t value \nHigh|Low    -0.9986   0.4212    -2.3706\nLow|Medium   0.8594   0.4211     2.0407\n\nResidual Deviance: 9115.381 \nAIC: 9141.381 \n(682 observations effacées parce que manquantes)\n\n\ncode R\np3&lt;-rego_women |&gt; \n  ggstats::ggcoef_table(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  )\np3\n\n\n\n\n\n\n\n\n\ncode R\np4&lt;-rego_women |&gt; \n  broom.helpers::plot_marginal_predictions() |&gt; \n  patchwork::wrap_plots(ncol = 1) &\n  scale_y_continuous(labels = scales::percent) &\n  coord_flip()\n\np4"
  },
  {
    "objectID": "normes_identite/CGNI.html",
    "href": "normes_identite/CGNI.html",
    "title": "Vers une Mesure Continue de l’identité de Genre",
    "section": "",
    "text": "Avec ses cheveux courts, lors de son élection, miss France 2024 a défrayé la chronique.\nAu vue des réactions épidermiques, la dunkerquoise Eve Gilles semblait transgresser là une norme de genre instituée.\nAvec cet exemple, qui peut sembler trivial, nous souhaitons aborder la question fondamentale de l’identité, et plus spécifiquement, de l’identité de genre.\nL’identité peut être définie comme le sentiment que l’on a de soi (“A person’ sense of self”) , c’est une notion multiple, protéiforme, difficile à appréhender et plus encore: à mesurer.\nMais pourquoi les économistes devraient-ils s’intéresser à cette variable identité?\nComment et pourquoi intègrent-ils cette notion dans leurs modèles?\nSi la nécessité de proposer des modèles intégrant cette variable nous semble pertinente, vient alors la question de la difficile mesure de ce concept fondamental.\nEnfin, quelles répercussions socio-économiques peut-on observer à travers la mise en lien de cette mesure de l’identité et des variables économiques?\nL’économie de l’identité est un courant récent de la discipline.\nLes travaux fondateurs d’ Akerlof et Kranton (George A. Akerlof and Kranton (2000b) ) ont mis en lumière la nécessité d’intégrer dans les modèles économiques traditionnels cette notion fondamentale qu’est l’identité.\n\n\nPour un économiste, le concept d’utilité est central. Il s’agit d’une mesure de la satisfaction individuelle.\nUn individu, par exemple un consommateur, réalise ses choix en fonction du niveau de satisfaction qu’il peut retirer. C’est son objectif, modélisé sous forme de fonction.\nDans les modèles traditionnels, l’utilité dépend de quelques variables objectives, qui ont l’intérêt d’être mesurables.\nPar exemple, pour un consommateur, \\(U=F(x,y)\\) , où \\(x\\) et \\(y\\) sont les quantités de biens consommées.\nL’apport d’Akerlof et Kranton, est d’indiquer que les choix des individus sont influencés par le sentiment qu’ils ont d’eux même, leur identité.\nEnrichir les modèles traditionnels de cette nouvelle variable permettrait de mieux comprendre ce qui parfois échappe à la théorie classique.\n\n\n\nReprenons ici le modèle proposé par Akerlof et Kranton,\nla fonction d’utilité d’un individu est la suivante:\n\\(U_j = U_j(a_j, a_j I_j)\\)\noù :\n\n\\(a_j\\) représente les actions de l’individu \\(j\\)\n\\(a_j\\) \\(I_j\\) capture les intéractions entre les actions de \\(j\\) et son identité \\(I_j\\)\n\nCette fonction d’identite \\(I_j\\) dépend elle même de plusieurs facteurs:\n\\(I_j = I_j(a_j, a_{-j}, c_j, E_j, P)\\)\noù :\n\n\\(a_j\\) représente les actions de l’individu \\(j\\),\n\\(a_{-j}\\) repésente les actions des autres individus,\n\\(c_j\\) est la catégorie sociale à laquelle appartien \\(j\\),\n\\(E_j\\) sont les caractéristiques données de \\(j\\),\n\\(P\\) sont les prescriptions (ou normes sociales) associées à la catégorie \\(c_j\\).\n\nCe modèle formalise cette tension qui peut exister pour les individus entre se conformer ou non aux normes de sa catégorie sociale assignée, en fonction de la distance qui peut exister entre ses propres caractéristiques et les prescriptions assignées.\nIl suppose aussi l’existence possible de sanctions de la part des pairs si les normes ne sont pas suivies (moqueries, mise à l’écart ou même violence)\nPar exemple, dans leur papier (George A. Akerlof and Kranton, n.d.) complètent les théories traditionnelles de l’économie de l’éducation en expliquant le plus ou moins grand investissement scolaire des étudiants en fonction de leurs caractéristiques identitaires (les sportifs, les intellos et les rebelles)\n\n\n\nL’économie étudie comment les agents font leur choix (de consommation, de production…), ces choix dépendent de l’identité des individus.\nEn effet, le sens que l’on a de soi, influence nos décisions, et ces décisions influencent notre identité en retour.\nDans un premier temps, la catégorie sociale à laquelle j’appartiens peut influencer mes préférences (Chen and Li (2009)) ,mes comportements pro-sociaux (Charness, Cobo-Reyes, and Jiménez (2014)) et donc mes décisions.\nDans un second temps, l’individu arbitre entre ses propres caractéristiques et les prescriptions de sa catégorie sociale (ou les prescriptions supposées).\nVais-je me conformer à ce qui est attendu? Mes propres caractéristiques sont-elles plus ou moins proches des normes en vigueur? Si je ne me conforme pas, quelle sera la réaction de mes pairs?\nCet arbitrage et cette possibilité pour autrui de répondre à mes actions a été représenté sous forme d’arbre de décision par George A. Akerlof and Kranton (2000a)\n\n\n\n\n\nCette friction entre adhérer ou non aux normes de ma catégorie sociale a conduit la recherche des économistes de l’identité vers les questions de conflits inter-groupes (Austen-Smith and Fryer (2005), Chakravarty et al. (2015), Fryer, Fryer, and Torelli (2010), Bénabou and Tirole (2004).)\nOn s’interroge sur les normes, l’adhésion ou non à ces dernières et le rôle que peuvent jouer les politiques publiques sur ces prescriptions.\nMais l’identité joue également un rôle fondamental sur les performances individuelles.\n\n\n\nDans une étude particulièrement intéressante, Shih, Pittinsky, and Trahan (2006) ont montré comment l’activation d’une identité particulière, ou tout du moins comment les stéréotypes associés à cette identité, pouvaient avoir un impact sur les performances individuelles.\nEn réalisant une étude auprès d’étudiantes asiatiques aux Etats Unis, les chercheurs ont proposé l’expérience suivante:\nUn questionnaire était fourni aux participantes avant de réaliser un test de mathématiques.\nUne partie des participantes répondaient à un questionnaire dont les questions portaient sur leur identité asiatique, pour les autres participantes le questionnaire activait leur identité féminine, un groupe de contrôle était également implémanté.\nCe simple questionnaire en préambule a eu des effets notables sur les performances aux tests de mathématiques réalisés ensuite, puisque en moyenne, les étudiantes dont l’identité asiatique avait été mise en évidence performaient significativement mieux aux tests de mathématiques que leurs homologues dont l’identité féminine avait été activée.\nCette étude plaide donc pour la nécessité de s’interroger sur la notion d’identité, dès lors que cette variable peut significativement avoir des répercussions sur les résultats socio-économiques des individus.\nCependant, les critiques apportées à ce nouveau courant sont notamment que ce concept fondamental d’identité est trop flou, comment intégrer dans les modèles ou bien encore dans les études empiriques cette dimension si polymorphe?\nLa question de la mesure de l’identité se pose alors… ## Construction de l’indice\nL’indice que nous proposons repose donc sur la dernière approche présentée:\nUn indice de mesure continue de l’identité de genre, construit comme un indice composite à partir de dimensions non définies a priori comme genrées.\nMais alors, quelles variables choisir pour représenter ces dimensions du genre?\nNotre choix s’est porté sur les pratiques culturelles des français (leurs loisirs culturels) car ces pratiques sont en effet particulièrement genrées (différenciées selon les sexes biologiques), il nous paraissait pertinent de s’appuyer sur ces dernières pour construire notre indice.\n\n\nEn sociologie, la question de la culture et du Genre fait l’objet de travaux ayant montré combien les pratiques culturelles sont différenciées chez les hommes et les femmes (Octobre (2008)) , et ce, dès l’enfance.\nCette différenciation nous permet d’envisager qu’il y ait des pratiques plus ou moins féminines ou masculines, dans la mesure où en moyenne elles sont plus pratiquées par des hommes ou par des femmes.\nCela signifie qu’il existe des normes genrées dans la pratique ou non d’une activité culturelle: le tricot est essentiellement féminin, la chasse est une activité plutôt pratiquée par les hommes.\nCes exemples sont tirés de l’analyse de nos données, en effet, nous avons utilisé la base de données Enquête sur les pratiques culturelles des Français, 2018.\nCette base de données comprend des informations sur les pratiques culturelles des français (9234 individus interrogés) , ainsi que des données socio-démographiques et porte également une question qui va nous intéresser sur le degré de satisfaction en termes de temps libre.\nCette dernière variable (“Vous arrive-t-il d’avoir le sentiment de manquer de temps libre pour faire tout ce dont vous avez envie?”) a retenu notre attention car elle pourrait être une mesure de l’utilité (satisfaction) de l’individu.\n\n\n\n\nShow the code\nlibrary(foreign)\nlibrary(questionr) \nlibrary(ggplot2) \nlibrary(tidyverse) \nlibrary(ggmosaic)\nlibrary(GGally) \nlibrary(dataMaid)\nlibrary(dplyr) \nlibrary(GDAtools)\nlibrary(FactoMineR)\nlibrary(gtsummary) \nlibrary(factoextra)\nlibrary(gtsummary) \nlibrary(kableExtra)\nlibrary(RColorBrewer) \nlibrary(FactoMineR) \nlibrary(xtable) \nlibrary(explor)\n\n\n\n\nShow the code\ndata&lt;-read.csv2(\"pc18_quetelet_octobre2023.csv\")\n\n\n\n\nShow the code\ndata$Sex &lt;- factor(data$SEXE, \n                            levels = c(1, 2), \n                            labels = c(\"Men\", \"Women\"))\nmy_data_frame &lt;- data |&gt; dplyr::rename( \n  Knitting = A1001 , \n  Cards_games = A1002,  \n  Gambling = A1003 , \n  Cooking = A1004 , \n  DIY = A1005  ,\n  Vegetable_garden = A1006 , \n  Ornamental_garden = A1007,  \n  Fishing_hunting = A1008 , \n  Collection = A1009  ,\n  Vehicle_custom = A1010 , \n  No_Amateur=A1011,\n  Making_music = A1901  ,\n  Diary = A1902  ,\n  Writing = A1903,  \n  Painting = A1904,  \n  Montage = A1905 , \n  Circus = A1906  ,\n  Pottery = A1907 , \n  Theater = A1908 , \n  Drawing = A1909 , \n  Dancing = A1910,  \n  Photography = A1911  ,\n  Genealogy = A1912 , \n  Science = A1913  ,\n  None = A1914  ,\n  Video_games = B1  ,\n  TV = C1  ,\n  Radio = E1  ,\n  Library = F1  ,\n  Museums = H112,  \n  Internet = I4 , \n  Concert = G2413 )\n\n\nmy_data_frame$Video_games &lt;- ifelse(my_data_frame$Video_games == 1, 1, 0)\nmy_data_frame$TV &lt;- ifelse(my_data_frame$TV == 5, 0, 1)\nmy_data_frame$Radio &lt;- ifelse(my_data_frame$Radio == 5, 0, 1)\nmy_data_frame$Library&lt;- ifelse(my_data_frame$Radio == 1, 1, 0)\nmy_data_frame$Museums&lt;- ifelse(my_data_frame$Museums == 1, 0, 1)\nmy_data_frame$Internet&lt;- ifelse(my_data_frame$Internet == 5, 0, 1)\nmy_data_frame$Concert&lt;- ifelse(my_data_frame$Concert == 1, 0, 1)\n\n\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(satisfaction = case_when(\n    A2 %in% 1 ~ \"Low\",      # 1 à 4 -&gt; Low\n    A2 %in% 2 ~ \"Medium\",   # 5 à 7 -&gt; Medium\n    A2 %in% 3 ~ \"High\",    # 8 à 10 -&gt; High\n    TRUE ~ NA_character_              \n  ))  \nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(Income = case_when(\n    CRITREVENU %in% 1:4 ~ \"Low\",      # 1 à 4 -&gt; Low\n    CRITREVENU %in% 5:7 ~ \"Medium\",   # 5 à 7 -&gt; Medium\n    CRITREVENU %in% 8:10 ~ \"High\",    # 8 à 10 -&gt; High\n    TRUE ~ NA_character_              \n  ))\n\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(Health = case_when(\n    A15 %in% 1:2 ~ \"Good\",      # 1 à 4 -&gt; Low\n    A15 %in% 3 ~ \"Medium\",   # 5 à 7 -&gt; Medium\n    A15 %in% 4:5 ~ \"Bad\",    # 8 à 10 -&gt; High\n    TRUE ~ NA_character_              \n  ))\n\n\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(Couple = case_when(\n    VITENCOUPLE %in% 1:2 ~ \"Yes\",     \n    VITENCOUPLE %in% 3~ \"No\",  \n    \n    TRUE ~ NA_character_              \n  ))\n\nquartiles &lt;- quantile(data$AGE, probs = c(0.25, 0.5, 0.75), na.rm = TRUE)\n\nmy_data_frame$age_group &lt;- cut(\n  my_data_frame$AGE,\n  breaks = 4,  # Automatically divide into 4 slices\n  labels = c(\"[15-38[\", \"[38-54[\", \"[54-67[\", \"[67-97[\"),  # Labels optionnels\n  include.lowest = TRUE \n)\n\n\n\n\nShow the code\nstat_des_1 &lt;- my_data_frame |&gt;\n    tbl_summary(\n        include = c(\"AGE\", \"Income\", \"Couple\", \"CLASSIF\", \"satisfaction\", \"Health\"),\n        by = \"Sex\",\n        statistic = list(\n            all_continuous() ~ \"{min} - {max}\"\n        )\n    ) |&gt;\n    add_overall(last = TRUE) |&gt;\n    add_p(\n        test.args = list(\n            all_continuous() ~ list(simulate.p.value = TRUE),\n            all_categorical() ~ list(simulate.p.value = TRUE)\n        )\n    )\n\nstat_des_1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\nOverall N = 9,2341\np-value2\n\n\n\n\nAGE\n15 - 95\n15 - 97\n15 - 97\n0.042\n\n\nIncome\n\n\n\n\n\n\n&lt;0.001\n\n\n    High\n1,432 (39%)\n1,464 (33%)\n2,896 (36%)\n\n\n\n\n    Low\n762 (21%)\n1,284 (29%)\n2,046 (25%)\n\n\n\n\n    Medium\n1,476 (40%)\n1,644 (37%)\n3,120 (39%)\n\n\n\n\n    Unknown\n492\n680\n1,172\n\n\n\n\nCouple\n2,444 (59%)\n2,567 (51%)\n5,011 (54%)\n&lt;0.001\n\n\n    Unknown\n4\n9\n13\n\n\n\n\nCLASSIF\n\n\n\n\n\n\n&lt;0.001\n\n\n    1\n123 (8.7%)\n63 (4.5%)\n186 (6.6%)\n\n\n\n\n    2\n454 (32%)\n143 (10%)\n597 (21%)\n\n\n\n\n    3\n190 (13%)\n92 (6.6%)\n282 (10%)\n\n\n\n\n    4\n157 (11%)\n126 (9.1%)\n283 (10%)\n\n\n\n\n    5\n278 (20%)\n236 (17%)\n514 (18%)\n\n\n\n\n    6\n194 (14%)\n703 (51%)\n897 (32%)\n\n\n\n\n    7\n13 (0.9%)\n7 (0.5%)\n20 (0.7%)\n\n\n\n\n    8\n11 (0.8%)\n18 (1.3%)\n29 (1.0%)\n\n\n\n\n    9\n1 (&lt;0.1%)\n1 (&lt;0.1%)\n2 (&lt;0.1%)\n\n\n\n\n    Unknown\n2,741\n3,683\n6,424\n\n\n\n\nsatisfaction\n\n\n\n\n\n\n&lt;0.001\n\n\n    High\n1,461 (35%)\n1,656 (33%)\n3,117 (34%)\n\n\n\n\n    Low\n1,488 (36%)\n2,015 (40%)\n3,503 (38%)\n\n\n\n\n    Medium\n1,207 (29%)\n1,398 (28%)\n2,605 (28%)\n\n\n\n\n    Unknown\n6\n3\n9\n\n\n\n\nHealth\n\n\n\n\n\n\n&lt;0.001\n\n\n    Bad\n322 (7.8%)\n461 (9.1%)\n783 (8.5%)\n\n\n\n\n    Good\n2,984 (72%)\n3,426 (68%)\n6,410 (70%)\n\n\n\n\n    Medium\n841 (20%)\n1,157 (23%)\n1,998 (22%)\n\n\n\n\n    Unknown\n15\n28\n43\n\n\n\n\n\n1 Min - Max; n (%)\n\n\n2 Wilcoxon rank sum test; Pearson’s Chi-squared test with simulated p-value (based on 2000 replicates); Fisher’s Exact Test for Count Data with simulated p-value (based on 2000 replicates)\n\n\n\n\n\n\n\n\nLecture: Parmi les individus de sexe masculin, 59% sont en couple. La différence avec les femmes est significative (p&lt;0,001)\n\n\nShow the code\ntable &lt;- my_data_frame |&gt;\n  tbl_summary(\n    include = c(  \"Knitting\" , \n                  \"Cards_games\",  \n                  \"Gambling\" , \n                  \"Cooking\" , \n                  \"DIY\"  ,\n                  \"Vegetable_garden\" , \n                  \"Ornamental_garden\",  \n                  \"Fishing_hunting\" , \n                  \"Collection\"  ,\n                  \"Vehicle_custom\", \n                  \"Making_music\"   ,\n                  \"Diary\" ,\n                  \"Writing\" ,  \n                  \"Painting\",  \n                  \"Montage\"  , \n                  \"Circus\"   ,\n                  \"Pottery\" , \n                  \"Theater\" , \n                  \"Drawing\" , \n                  \"Dancing\",  \n                  \"Photography\"  ,\n                  \"Genealogy\" , \n                  \"Science\"  ,\n                  \"None\"  ,\n                  \"No_Amateur\",\n                  \"Video_games\"  ,\n                  \"TV\" ,\n                  \"Radio\"  ,\n                  \"Library\"  ,\n                  \"Museums\",  \n                  \"Internet\", \n                  \"Concert\"),\n    by = \"Sex\"\n  ) |&gt;\n  add_overall(last = TRUE) |&gt;\n  add_p()\n\ntable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\nOverall N = 9,2341\np-value2\n\n\n\n\nKnitting\n73 (1.8%)\n1,370 (27%)\n1,443 (16%)\n&lt;0.001\n\n\nCards_games\n1,899 (46%)\n2,764 (54%)\n4,663 (50%)\n&lt;0.001\n\n\nGambling\n990 (24%)\n970 (19%)\n1,960 (21%)\n&lt;0.001\n\n\nCooking\n1,685 (40%)\n3,473 (68%)\n5,158 (56%)\n&lt;0.001\n\n\nDIY\n2,667 (64%)\n2,283 (45%)\n4,950 (54%)\n&lt;0.001\n\n\nVegetable_garden\n1,335 (32%)\n1,245 (25%)\n2,580 (28%)\n&lt;0.001\n\n\nOrnamental_garden\n1,793 (43%)\n2,198 (43%)\n3,991 (43%)\n0.8\n\n\nFishing_hunting\n722 (17%)\n212 (4.2%)\n934 (10%)\n&lt;0.001\n\n\nCollection\n395 (9.5%)\n281 (5.5%)\n676 (7.3%)\n&lt;0.001\n\n\nVehicle_custom\n264 (6.3%)\n60 (1.2%)\n324 (3.5%)\n&lt;0.001\n\n\nMaking_music\n1,312 (32%)\n1,830 (36%)\n3,142 (34%)\n&lt;0.001\n\n\nDiary\n285 (6.8%)\n1,206 (24%)\n1,491 (16%)\n&lt;0.001\n\n\nWriting\n410 (9.9%)\n746 (15%)\n1,156 (13%)\n&lt;0.001\n\n\nPainting\n667 (16%)\n1,303 (26%)\n1,970 (21%)\n&lt;0.001\n\n\nMontage\n843 (20%)\n586 (12%)\n1,429 (15%)\n&lt;0.001\n\n\nCircus\n116 (2.8%)\n179 (3.5%)\n295 (3.2%)\n0.044\n\n\nPottery\n264 (6.3%)\n705 (14%)\n969 (10%)\n&lt;0.001\n\n\nTheater\n483 (12%)\n800 (16%)\n1,283 (14%)\n&lt;0.001\n\n\nDrawing\n864 (21%)\n1,285 (25%)\n2,149 (23%)\n&lt;0.001\n\n\nDancing\n410 (9.9%)\n1,782 (35%)\n2,192 (24%)\n&lt;0.001\n\n\nPhotography\n1,175 (28%)\n1,176 (23%)\n2,351 (25%)\n&lt;0.001\n\n\nGenealogy\n513 (12%)\n575 (11%)\n1,088 (12%)\n0.14\n\n\nScience\n611 (15%)\n469 (9.2%)\n1,080 (12%)\n&lt;0.001\n\n\nNone\n1,394 (33%)\n1,261 (25%)\n2,655 (29%)\n&lt;0.001\n\n\nNo_Amateur\n276 (6.6%)\n359 (7.1%)\n635 (6.9%)\n0.4\n\n\nVideo_games\n1,760 (42%)\n1,827 (36%)\n3,587 (39%)\n&lt;0.001\n\n\nTV\n3,878 (93%)\n4,806 (95%)\n8,684 (94%)\n0.001\n\n\nRadio\n3,522 (85%)\n4,186 (83%)\n7,708 (83%)\n0.007\n\n\nLibrary\n3,522 (85%)\n4,186 (83%)\n7,708 (83%)\n0.007\n\n\nMuseums\n4,101 (99%)\n5,009 (99%)\n9,110 (99%)\n0.4\n\n\nInternet\n3,459 (83%)\n4,185 (83%)\n7,644 (83%)\n0.4\n\n\nConcert\n3,344 (80%)\n4,234 (83%)\n7,578 (82%)\n&lt;0.001\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\nLecture: Parmi les hommes, 1.8% déclarent pratiquer le tricot, contre 27% des femmes. Cette activité est pratiquée par 16% des répondants.\nLes p-value &lt;10% indiquent que les différences de participation aux pratiques culturelles sont significativement différentes selon le sexe biologique du répondant.\n\n\n\n\n\n\nNote\n\n\n\nNous retiendrons pour la construction de notre indice les pratiques culturelles suivantes:\n“Knitting” , “Cards_games”,“Gambling” , “Cooking” , “DIY” , “Vegetable_garden” , “Fishing_hunting” , “Collection” , “Vehicle_custom”, “Making_music” , “Diary” , “Writing” ,“Painting”,“Montage” , “Pottery” , “Theater” , “Drawing” , “Dancing”,\n“Photography” , “Genealogy” , “Science” , “None” , “Video_games” , “Library” , “Concert”\n\n\n\n\n\n\nAfin de construire notre indice d’identité de genre, nous suivons la méthodologie proposée par Cipriani et al. (n.d.) et réalisons une Analyse des Correspondances Multiples (ACM) sur nos variables “pratiques culturelles”.\n\n\n\n\n\n\nEncadré Technique 1: Détails de la méthode ACM\n\n\n\nL’**ACM** est une extension de l’**Analyse des Correspondances Simples (ACS)** qui permet d’explorer les relations entre plusieurs variables qualitatives en projetant les individus et les modalités dans un espace de faible dimension. Elle est souvent utilisée pour analyser des **questionnaires** et des **tableaux de contingence** complexes.\n### Principaux résultats d’une ACM\n1. **Inertie totale**\nMesure la dispersion des données et est donnée par :\n\\(I_{\\text{total}} = \\frac{q}{q-1} \\sum_{k} \\lambda_k\\)\noù \\(\\lambda_k\\) sont les valeurs propres et \\(q\\) est le nombre total de modalités.\n2. **Valeurs propres \\(\\lambda_k\\)**\nElles indiquent la variance expliquée par chaque axe factoriel. Plus une valeur propre est élevée, plus l’axe correspondant est important dans l’analyse.\n3. **Rapports de corrélation \\(\\eta^2\\)**\nLe **rapport de corrélation** \\(\\eta^2\\) mesure la liaison entre une variable et un axe factoriel :\n\\(\\eta^2 = \\frac{\\sum_{i} f_i d_{i,k}^2}{\\sum_{i} f_i d_{i}^2}\\)\noù $ f_i $ est la fréquence de l’individu/modalité $i $, et $d_{i,k} $ est sa distance à l’axe \\(k\\) .\n4. **Coordonnées des individus et modalités**\nElles sont obtenues à partir des vecteurs propres et permettent la représentation graphique des données :\n\\(C_{i,k} = \\frac{v_{i,k}}{\\sqrt{\\lambda_k}}\\)\noù \\(v_{i,k}\\) est le vecteur propre associé à l’axe \\(k\\).\n5. **Cos² (Qualité de représentation)**\nIndique dans quelle mesure un point est bien représenté sur un axe donné. Une valeur proche de **1** signifie que la projection sur cet axe est pertinente.\n6. **Contributions **\nElles mesurent l’importance d’une modalité ou d’un individu dans la construction d’un axe. Plus une contribution est élevée, plus l’élément joue un rôle important dans l’interprétation de l’axe.\n\n\n\n\nShow the code\npratiques_cols_1 &lt;- c( \"Knitting\" , \n                     \"Cards_games\",  \n                     \"Gambling\" , \n                     \"Cooking\" , \n                     \"DIY\"  ,\n                     \"Vegetable_garden\" , \n                     \"Fishing_hunting\" , \n                     \"Collection\"  ,\n                     \"Vehicle_custom\",\n                     \"Making_music\"   ,\n                     \"Diary\" ,\n                     \"Writing\" ,  \n                     \"Painting\",  \n                     \"Montage\"  , \n                     \"Pottery\" , \n                     \"Theater\" , \n                     \"Drawing\" , \n                     \"Dancing\",  \n                     \"Photography\"  ,\n                     \"Genealogy\" , \n                     \"Science\"  ,\n                     \"None\" ,\n                     \"Video_games\"  ,\n                     \"Library\"  ,\n                     \"Concert\"\n                            )\n\n\n#MCA\n\n# Add Sex Column to the selection\ncols_of_interest_1 &lt;- c(\"Sex\", \"AGE\", pratiques_cols_1)\n\n# Build a new dataframe with these columns\ndata_pratiques &lt;- my_data_frame[, cols_of_interest_1]\ndata_pratiques$AGE &lt;- cut(data_pratiques$AGE, \n                          breaks = quantile(data_pratiques$AGE, probs = seq(0, 1, 0.25), na.rm = TRUE), \n                          include.lowest = TRUE)\nra_data &lt;- na.omit(data_pratiques)\n\ncols_to_factor &lt;- c(  \"Knitting\" , \n                      \"Cards_games\",  \n                      \"Gambling\" , \n                      \"Cooking\" , \n                      \"DIY\"  ,\n                      \"Vegetable_garden\" , \n                      \"Fishing_hunting\" , \n                      \"Collection\"  ,\n                      \"Vehicle_custom\",\n                      \"Making_music\"   ,\n                      \"Diary\" ,\n                      \"Writing\" ,  \n                      \"Painting\",  \n                      \"Montage\"  , \n                      \"Pottery\" , \n                      \"Theater\" , \n                      \"Drawing\" , \n                      \"Dancing\",  \n                      \"Photography\"  ,\n                      \"Genealogy\" , \n                      \"Science\"  ,\n                      \"None\"  ,\n                      \"Video_games\"  ,\n                      \"Library\"  ,\n                      \"Concert\")\n\n# apply as.factor to these columnns\nra_data[cols_to_factor] &lt;- lapply(ra_data[cols_to_factor], as.factor)\n\n# running MCA with FactoMiner\nacm2_fm &lt;- ra_data |&gt; \n  FactoMineR::MCA(\n    ncp = Inf,\n    graph = TRUE,\n    quali.sup = 1:2\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn remarque que la variable supplémentaire “Sexe” correspond à la dimension 2 de notre ACM. Cette dimension explique 6,06% de la variance totale.\nUne analyse plus poussée avec le package Explor nous permet de mesurer l’association de la variable supplémentaire Sexe avec cette dimension (dim2), en effet, l’ \\(𝞰^2\\) est de 0,14 , ce qui peut sembler peu mais indique bien que notre variable supplémentaire est liée à cet axe.\nPour construire notre indice, nous utiliserons donc les coordonnées des variables pratiques culturelles le long de cet axe 2.\n\n\nShow the code\n# Extract modality names\nmodalites_names &lt;- rownames(acm2_fm$var$coord)\n\n# Check modality names\nhead(modalites_names)\n\n\n[1] \"Knitting_0\"    \"Knitting_1\"    \"Cards_games_0\" \"Cards_games_1\"\n[5] \"Gambling_0\"    \"Gambling_1\"   \n\n\nShow the code\n# Extract coordinates for dimension 2\ncoord_dim2_modalites &lt;- acm2_fm$var$coord[, 2]\n\n# Create a table associating the modalities and their coordinates in dimension 2\nmodalites_coord &lt;- data.frame(Modalite = modalites_names, Coord_Dim2 = coord_dim2_modalites)\n\n\n\n# Keep only the two necessary columns\nmodalites_coord_selected &lt;- modalites_coord[, c(\"Modalite\", \"Coord_Dim2\")]\n\nprint(modalites_coord_selected)\n\n\n                             Modalite  Coord_Dim2\nKnitting_0                 Knitting_0  0.04314603\nKnitting_1                 Knitting_1 -0.23295268\nCards_games_0           Cards_games_0 -0.21072530\nCards_games_1           Cards_games_1  0.20656774\nGambling_0                 Gambling_0 -0.17433328\nGambling_1                 Gambling_1  0.64698995\nCooking_0                   Cooking_0 -0.06432635\nCooking_1                   Cooking_1  0.05083253\nDIY_0                           DIY_0 -0.59097111\nDIY_1                           DIY_1  0.51145863\nVegetable_garden_0 Vegetable_garden_0 -0.29999865\nVegetable_garden_1 Vegetable_garden_1  0.77371744\nFishing_hunting_0   Fishing_hunting_0 -0.16671349\nFishing_hunting_1   Fishing_hunting_1  1.48150102\nCollection_0             Collection_0 -0.05539977\nCollection_1             Collection_1  0.70134797\nVehicle_custom_0     Vehicle_custom_0 -0.05128080\nVehicle_custom_1     Vehicle_custom_1  1.41022187\nMaking_music_0         Making_music_0  0.09403755\nMaking_music_1         Making_music_1 -0.18232870\nDiary_0                       Diary_0  0.09378209\nDiary_1                       Diary_1 -0.48702531\nWriting_0                   Writing_0  0.06770001\nWriting_1                   Writing_1 -0.47308017\nPainting_0                 Painting_0  0.04361213\nPainting_1                 Painting_1 -0.16081142\nMontage_0                   Montage_0 -0.07125251\nMontage_1                   Montage_1  0.38917132\nPottery_0                   Pottery_0  0.01201096\nPottery_1                   Pottery_1 -0.10244644\nTheater_0                   Theater_0  0.07187594\nTheater_1                   Theater_1 -0.44542916\nDrawing_0                   Drawing_0  0.04570585\nDrawing_1                   Drawing_1 -0.15068681\nDancing_0                   Dancing_0  0.14396501\nDancing_1                   Dancing_1 -0.46250072\nPhotography_0           Photography_0 -0.07539973\nPhotography_1           Photography_1  0.22074706\nGenealogy_0               Genealogy_0 -0.01967874\nGenealogy_1               Genealogy_1  0.14733732\nScience_0                   Science_0 -0.04008198\nScience_1                   Science_1  0.30261895\nNone_0                         None_0 -0.06572453\nNone_1                         None_1  0.16286315\nVideo_games_0           Video_games_0 -0.22185919\nVideo_games_1           Video_games_1  0.34927205\nLibrary_0                   Library_0 -0.65936864\nLibrary_1                   Library_1  0.13053925\nConcert_0                   Concert_0 -0.23244943\nConcert_1                   Concert_1  0.05079655\n\n\nCe tableau indique les poids utilisés pour la construction de notre indice.\n\n\nShow the code\n# Initialize a vector to store the index of each individual\nra_data$indice_culturel &lt;- 0\n\n# Browse each individual\nfor (i in 1:nrow(ra_data)) {\n  \n  # Initialize individual's index to 0\n  indice_individu &lt;- 0\n  \n  # Browse each practice column (columns 3 to 27)\n  for (pratique in 3:27) {\n    \n    # Retrieve the individual's response for this practice (0 or 1)\n    reponse &lt;- ra_data[i, pratique]\n    \n    # If the answer is 1, add the coordinate of the corresponding modality to the index.\n    if (reponse == 1) {\n      \n      # Create the modality name (e.g. “knitting_1” or “knitting_0”)\n      nom_modalite_1 &lt;- paste0(names(ra_data)[pratique], \"_1\")\n      nom_modalite_0 &lt;- paste0(names(ra_data)[pratique], \"_0\")\n      \n      # Find the coordinate associated with the corresponding modality\n      if (nom_modalite_1 %in% modalites_coord$Modalite) {\n        indice_individu &lt;- indice_individu + modalites_coord$Coord_Dim2[modalites_coord$Modalite == nom_modalite_1]\n      }\n      if (nom_modalite_0 %in% modalites_coord$Modalite) {\n        indice_individu &lt;- indice_individu + modalites_coord$Coord_Dim2[modalites_coord$Modalite == nom_modalite_0]\n      }\n    }\n  }\n  \n  # Assign the calculated index to the individual\n  ra_data$indice_culturel[i] &lt;- indice_individu\n}\n####Normalisation\n\n# Calculate minimum and maximum index values\nmin_indice &lt;- min(ra_data$indice_culturel, na.rm = TRUE)\nmax_indice &lt;- max(ra_data$indice_culturel, na.rm = TRUE)\n\n# Normalize index\nra_data$indice_culturel_normalise &lt;- (ra_data$indice_culturel - min_indice) / (max_indice - min_indice)\n\n# Check results\n\nhead(ra_data[, c(\"indice_culturel\", \"indice_culturel_normalise\")])\n\n\n  indice_culturel indice_culturel_normalise\n1       2.8024423                 0.8624142\n2       0.5427446                 0.5073268\n3      -0.4557477                 0.3504244\n4      -0.3429253                 0.3681533\n5       0.0409659                 0.4284777\n6      -0.2367887                 0.3848315\n\n\nNotre indice est donc construit de la façon suivante:\n\\[I_{1j} = \\sum_{k=1}^{Z} w_{1k} \\cdot X_{k j}\\]\nDans cette expression, \\(I_{1j}\\) désigne l’indice de l’individu \\(j\\), tandis que \\(w_{1k}\\) représente le poids associé à chaque variable culturelle \\(X_{kj}\\). La somme englobe toutes les variables culturelles \\(Z\\), ce qui nous permet de saisir l’engagement culturel global de l’individu.\n\n\n\n\n\nShow the code\nmy_data_frame$identity&lt;-ra_data$indice_culturel_normalise\nmy_data_frame$indice&lt;-ra_data$indice_culturel\nggplot(my_data_frame, aes(x = identity, fill = Sex)) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) + \n  labs(title = \"Density of The Normalized Cultural Index by Sexe\",\n       x = \"Normalized Cultural Index\",\n       y = \"Density\",\n       fill = \"Sexe\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\nstat_des_indice&lt;-my_data_frame%&gt;%\n  tbl_summary(include=c(\"identity\"),by = \"Sex\",\n              statistic = list(\n            all_continuous() ~ \"{min} - {max}\"\n        )) %&gt;%\n  add_overall(last = TRUE) %&gt;%\n  add_p()\nstat_des_indice\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\nOverall N = 9,2341\np-value2\n\n\n\n\nidentity\n0.01 - 1.00\n0.00 - 0.91\n0.00 - 1.00\n&lt;0.001\n\n\n\n1 Min - Max\n\n\n2 Wilcoxon rank sum test\n\n\n\n\n\n\n\n\nL’indice normalisé est compris entre 0 et 1. Plus il est proche de zéro plus les individus sont proches de la norme féminine (en termes de pratiques culturelles).\nL’indice est significativement différent selon le sexe biologique des interrogés.\n\n\nShow the code\nreg&lt;- lm(identity~Sex, my_data_frame)\nsummary(reg)\n\n\n\nCall:\nlm(formula = identity ~ Sex, data = my_data_frame)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.41933 -0.07875 -0.01093  0.06694  0.58782 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.424436   0.001815  233.79   &lt;2e-16 ***\nSexWomen    -0.099669   0.002450  -40.69   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1171 on 9232 degrees of freedom\nMultiple R-squared:  0.1521,    Adjusted R-squared:  0.152 \nF-statistic:  1656 on 1 and 9232 DF,  p-value: &lt; 2.2e-16\n\n\nLe sexe biologique est très significatif, les valeurs plus faibles de l’indice sont associées au sexe féminin.\n\n\n\n\n\nShow the code\ndata$identity&lt;- my_data_frame$identity\nmy_data_frame$identity&lt;-data$identity\n# List of cultural activities\ncultural_activities &lt;- c(\n   \"Knitting\" , \n                      \"Cards_games\",  \n                      \"Gambling\" , \n                      \"Cooking\" , \n                      \"DIY\"  ,\n                      \"Vegetable_garden\" , \n                      \"Fishing_hunting\" , \n                      \"Collection\"  ,\n                      \"Vehicle_custom\",\n                      \"Making_music\"   ,\n                      \"Diary\" ,\n                      \"Writing\" ,  \n                      \"Painting\",  \n                      \"Montage\"  , \n                      \"Pottery\" , \n                      \"Theater\" , \n                      \"Drawing\" , \n                      \"Dancing\",  \n                      \"Photography\"  ,\n                      \"Genealogy\" , \n                      \"Science\"  ,\n                      \"None\"  ,\n                      \"Video_games\"  ,\n                      \"Library\"  ,\n                      \"Concert\"\n)\n\n# Create a data frame to store the results\nresult_table &lt;- data.frame(Activity = character(0), Accuracy = numeric(0))\n\nfor (activity in cultural_activities) {\n  # Perform a Probit regression for the current cultural activity\n  model_formula &lt;- as.formula(paste(activity, \"~ identity\"))\n  model &lt;- glm(model_formula, data = my_data_frame, family = binomial(link = \"probit\"))\n \n  # Calculate predictions\n  predicted &lt;- ifelse(predict(model, type = \"response\") &gt;= 0.5, 1, 0)\n \n  # Calculate the accuracy\n  correct_predictions &lt;- sum(predicted == my_data_frame[[activity]])\n  total_predictions &lt;- nrow(my_data_frame)\n  accuracy &lt;- (correct_predictions / total_predictions) * 100\n \n  # Add the result to the data frame\n  result_table &lt;- rbind(result_table, data.frame(Activity = activity, Accuracy = accuracy))\n}\nresult_table\n\n\n           Activity Accuracy\n1          Knitting 84.37297\n2       Cards_games 51.00715\n3          Gambling 79.18562\n4           Cooking 56.55187\n5               DIY 51.25623\n6  Vegetable_garden 72.89365\n7   Fishing_hunting 93.95712\n8        Collection 92.54927\n9    Vehicle_custom 96.85943\n10     Making_music 68.16114\n11            Diary 85.85662\n12          Writing 88.16331\n13         Painting 78.76327\n14          Montage 84.52458\n15          Pottery 89.50617\n16          Theater 86.53888\n17          Drawing 76.73814\n18          Dancing 79.66212\n19      Photography 74.53974\n20        Genealogy 88.21746\n21          Science 88.30409\n22             None 70.19710\n23      Video_games 62.06411\n24          Library 83.20338\n25          Concert 81.92549\n\n\nNous réalisons une série de régressions Probit sur les différentes pratiques culturelles, avec pour unique régresseur notre indice d’identité, afin de mesurer le pouvoir prédictif (ou accuracy) de ce dernier.\n\n\n\nComparons l’indice obtenu avec d’autres mesures, et plus particulièrement avec les indices échelle d’identité.\nPour cela, nous allons diviser notre indice en 7 catégories, allant du plus féminin au plus masculin.\n\n\nShow the code\nmy_data_frame$identity_scale &lt;- cut(\n  my_data_frame$identity,\n  breaks = 7,  # Automatically divide into 7 slices\n  labels = c(\"Very Feminine\", \"1\", \"2\", \"3\", \"4\", \"5\", \"Very Masculine\"), \n  include.lowest = TRUE  \n)\ntable1 &lt;-\n  my_data_frame |&gt; \n  tbl_summary(include = c(identity_scale),\n  by=Sex ,)|&gt; \n    add_p()\ntable1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\np-value2\n\n\n\n\nidentity_scale\n\n\n\n\n&lt;0.001\n\n\n    Very Feminine\n9 (0.2%)\n218 (4.3%)\n\n\n\n\n    1\n403 (9.7%)\n1,506 (30%)\n\n\n\n\n    2\n2,139 (51%)\n2,669 (53%)\n\n\n\n\n    3\n985 (24%)\n576 (11%)\n\n\n\n\n    4\n509 (12%)\n90 (1.8%)\n\n\n\n\n    5\n96 (2.3%)\n10 (0.2%)\n\n\n\n\n    Very Masculine\n21 (0.5%)\n3 (&lt;0.1%)\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\nCe tableau est à mettre en perspective avec les données de Trachman (2022a).\nTout d’abord non remarquons que, comme dans l’enquête de Trachman (2022a), les individus “hors norme” sont peu nombreux (d’après notre indice, moins de 0,1% des femmes ont des pratiques culturelles très masculines; 0,2% des hommes ont des pratiques très féminines) , de même que les individus dont les pratiques culturelles seraient complètement conformes à leur sexe biologique ne sont pas la majorité (4,3% des femmes sont classées comme très féminines, 0,5% des hommes comme très masculins.)\nCela plaide encore une fois pour l’intérêt d’une mesure continue.\nNous allons ensuite explorer plus en détails les variables socio-démographiques qui peuvent influencer notre indice (revenu, âge, catégorie socio-professionnelle …)\n\n\n\n\nDans cette partie, nous allons analyser les implications socio-économiques de l’identité de genre.\nPour commencer, nous allons regarder les différents profils des individus selon leur indice d’identité.\nPuis nous analyserons les liens entre distance à la norme et l’utilité des individus (leur degré de satisfaction.)\n\n\nShow the code\nstat_des_2 &lt;- my_data_frame |&gt;  \n  tbl_summary(        \n    include = c(\"AGE\", \"Income\", \"Couple\", \"CLASSIF\"),         by = \"identity_scale\") |&gt;  \n  \n  add_overall(last = TRUE) |&gt; \n  add_p(       \n    test.args = list(           \n      all_continuous() ~ list(simulate.p.value = TRUE),             all_categorical() ~ list(simulate.p.value = TRUE)      \n      )    \n    )  \n\n\nstat_des_2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nVery Feminine N = 2271\n1 N = 1,9091\n2 N = 4,8081\n3 N = 1,5611\n4 N = 5991\n5 N = 1061\nVery Masculine N = 241\nOverall N = 9,2341\np-value2\n\n\n\n\nAGE\n44 (32, 57)\n50 (35, 65)\n56 (40, 69)\n55 (37, 68)\n51 (35, 65)\n43 (30, 59)\n37 (30, 57)\n54 (38, 67)\n\n\n\n\nIncome\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\n    High\n88 (44%)\n710 (42%)\n1,428 (34%)\n452 (33%)\n175 (33%)\n34 (36%)\n9 (43%)\n2,896 (36%)\n\n\n\n\n    Low\n48 (24%)\n382 (23%)\n1,118 (27%)\n369 (27%)\n108 (20%)\n17 (18%)\n4 (19%)\n2,046 (25%)\n\n\n\n\n    Medium\n65 (32%)\n592 (35%)\n1,631 (39%)\n536 (39%)\n245 (46%)\n43 (46%)\n8 (38%)\n3,120 (39%)\n\n\n\n\n    Unknown\n26\n225\n631\n204\n71\n12\n3\n1,172\n\n\n\n\nCouple\n109 (48%)\n1,013 (53%)\n2,594 (54%)\n842 (54%)\n373 (62%)\n68 (64%)\n12 (50%)\n5,011 (54%)\n&lt;0.001\n\n\n    Unknown\n2\n4\n5\n1\n1\n0\n0\n13\n\n\n\n\nCLASSIF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\n    1\n0 (0%)\n18 (3.2%)\n95 (6.8%)\n48 (10%)\n16 (6.6%)\n7 (17%)\n2 (18%)\n186 (6.6%)\n\n\n\n\n    2\n6 (8.0%)\n61 (11%)\n278 (20%)\n132 (28%)\n98 (40%)\n19 (46%)\n3 (27%)\n597 (21%)\n\n\n\n\n    3\n3 (4.0%)\n36 (6.4%)\n148 (11%)\n56 (12%)\n33 (14%)\n6 (15%)\n0 (0%)\n282 (10%)\n\n\n\n\n    4\n8 (11%)\n59 (11%)\n140 (10.0%)\n47 (9.8%)\n22 (9.1%)\n4 (9.8%)\n3 (27%)\n283 (10%)\n\n\n\n\n    5\n26 (35%)\n149 (27%)\n229 (16%)\n80 (17%)\n26 (11%)\n3 (7.3%)\n1 (9.1%)\n514 (18%)\n\n\n\n\n    6\n29 (39%)\n224 (40%)\n484 (34%)\n110 (23%)\n47 (19%)\n2 (4.9%)\n1 (9.1%)\n897 (32%)\n\n\n\n\n    7\n1 (1.3%)\n6 (1.1%)\n11 (0.8%)\n1 (0.2%)\n1 (0.4%)\n0 (0%)\n0 (0%)\n20 (0.7%)\n\n\n\n\n    8\n2 (2.7%)\n6 (1.1%)\n16 (1.1%)\n4 (0.8%)\n0 (0%)\n0 (0%)\n1 (9.1%)\n29 (1.0%)\n\n\n\n\n    9\n0 (0%)\n0 (0%)\n2 (0.1%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n2 (&lt;0.1%)\n\n\n\n\n    Unknown\n152\n1,350\n3,405\n1,083\n356\n65\n13\n6,424\n\n\n\n\n\n1 Median (Q1, Q3); n (%)\n\n\n2 Pearson’s Chi-squared test with simulated p-value (based on 2000 replicates); Fisher’s Exact Test for Count Data with simulated p-value (based on 2000 replicates)\n\n\n\n\n\n\n\n\nLecture: Parmi les individus catégorisés comme très féminins selon notre indice, 44% ont des revenus élevés. Les variables étudiées sont significativement différentes selon les degrés d’identité.\nIl semble, d’après cette première table descriptive, que l’âge, les niveaux de revenus ainsi que les professions (CLASSIF) jouent un rôle dans l’identité de genre. Tout comme dans l’étude de Trachman (2022b), les facteurs socio-économiques influencent les variations du genre.\n\n\n\n\n\n\n\nCLASSIF\n\n\n\n\n\n1\nManoeuvre ou ouvrier spécialisé\n\n\n2\nOuvrier qualifié ou hautement qualifié/ technicien(ne) d’atelier\n\n\n3\nTechnicien(ne)\n\n\n4\nAgent de maîtrise, maîtrise administrative ou commerciale, VRP (non cadre)\n\n\n5\nIngénieur, Cadre\n\n\n6\nEmployé(e) de bureau, Employé(e) de commerce, Personnel de services\n\n\n7\nDirecteur général, Adjoint direct\n\n\n8\nNSP\n\n\n9\nREF\n\n\n\nOn peut regarder si les effets sont différents selon le sexe biologique:\n\n\nShow the code\nstat_des &lt;- my_data_frame |&gt;\n    tbl_strata(\n        strata = Sex,  # Stratification par sexe\n        .tbl_fun = ~ .x |&gt;\n            tbl_summary(\n                include = c(\"AGE\", \"Income\", \"Couple\", \"CLASSIF\"),\n                by = \"identity_scale\"  # Stratification supplémentaire par 'identity_scale'\n            ) |&gt;\n            add_overall(last = TRUE) |&gt;\n            add_p(\n                test.args = list(\n                    all_continuous() ~ list(simulate.p.value = TRUE),\n                    all_categorical() ~ list(simulate.p.value = TRUE)\n                )\n            )\n    )\n\nstat_des\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nMen\n\n\nWomen\n\n\n\nVery Feminine N = 91\n1 N = 4031\n2 N = 2,1391\n3 N = 9851\n4 N = 5091\n5 N = 961\nVery Masculine N = 211\nOverall N = 4,1621\np-value2\nVery Feminine N = 2181\n1 N = 1,5061\n2 N = 2,6691\n3 N = 5761\n4 N = 901\n5 N = 101\nVery Masculine N = 31\nOverall N = 5,0721\np-value2\n\n\n\n\nAGE\n50 (36, 59)\n54 (39, 66)\n54 (40, 68)\n52 (35, 66)\n52 (36, 65)\n44 (30, 59)\n37 (28, 56)\n53 (38, 66)\n\n\n44 (32, 56)\n49 (34, 64)\n58 (40, 70)\n57 (39, 71)\n44 (33, 60)\n37 (33, 68)\n34 (33, 57)\n54 (37, 68)\n\n\n\n\nIncome\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.035\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\n    High\n4 (44%)\n160 (44%)\n762 (40%)\n316 (36%)\n153 (34%)\n28 (33%)\n9 (50%)\n1,432 (39%)\n\n\n84 (44%)\n550 (42%)\n666 (29%)\n136 (28%)\n22 (26%)\n6 (60%)\n0 (0%)\n1,464 (33%)\n\n\n\n\n    Low\n4 (44%)\n66 (18%)\n393 (21%)\n192 (22%)\n88 (20%)\n16 (19%)\n3 (17%)\n762 (21%)\n\n\n44 (23%)\n316 (24%)\n725 (32%)\n177 (36%)\n20 (24%)\n1 (10%)\n1 (33%)\n1,284 (29%)\n\n\n\n\n    Medium\n1 (11%)\n134 (37%)\n733 (39%)\n359 (41%)\n203 (46%)\n40 (48%)\n6 (33%)\n1,476 (40%)\n\n\n64 (33%)\n458 (35%)\n898 (39%)\n177 (36%)\n42 (50%)\n3 (30%)\n2 (67%)\n1,644 (37%)\n\n\n\n\n    Unknown\n0\n43\n251\n118\n65\n12\n3\n492\n\n\n26\n182\n380\n86\n6\n0\n0\n680\n\n\n\n\nCouple\n4 (44%)\n224 (56%)\n1,271 (59%)\n561 (57%)\n314 (62%)\n59 (61%)\n11 (52%)\n2,444 (59%)\n0.3\n105 (49%)\n789 (52%)\n1,323 (50%)\n281 (49%)\n59 (66%)\n9 (90%)\n1 (33%)\n2,567 (51%)\n&lt;0.001\n\n\n    Unknown\n0\n1\n2\n0\n1\n0\n0\n4\n\n\n2\n3\n3\n1\n0\n0\n0\n9\n\n\n\n\nCLASSIF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\n    1\n0 (0%)\n6 (5.2%)\n57 (7.9%)\n37 (11%)\n16 (7.7%)\n6 (16%)\n1 (11%)\n123 (8.7%)\n\n\n0 (0%)\n12 (2.7%)\n38 (5.5%)\n11 (7.7%)\n0 (0%)\n1 (25%)\n1 (50%)\n63 (4.5%)\n\n\n\n\n    2\n0 (0%)\n24 (21%)\n214 (30%)\n109 (33%)\n87 (42%)\n17 (46%)\n3 (33%)\n454 (32%)\n\n\n6 (8.1%)\n37 (8.3%)\n64 (9.3%)\n23 (16%)\n11 (31%)\n2 (50%)\n0 (0%)\n143 (10%)\n\n\n\n\n    3\n0 (0%)\n15 (13%)\n98 (14%)\n42 (13%)\n30 (14%)\n5 (14%)\n0 (0%)\n190 (13%)\n\n\n3 (4.1%)\n21 (4.7%)\n50 (7.3%)\n14 (9.8%)\n3 (8.3%)\n1 (25%)\n0 (0%)\n92 (6.6%)\n\n\n\n\n    4\n0 (0%)\n15 (13%)\n76 (11%)\n37 (11%)\n22 (11%)\n4 (11%)\n3 (33%)\n157 (11%)\n\n\n8 (11%)\n44 (9.9%)\n64 (9.3%)\n10 (7.0%)\n0 (0%)\n0 (0%)\n0 (0%)\n126 (9.1%)\n\n\n\n\n    5\n1 (100%)\n31 (27%)\n151 (21%)\n66 (20%)\n25 (12%)\n3 (8.1%)\n1 (11%)\n278 (20%)\n\n\n25 (34%)\n118 (27%)\n78 (11%)\n14 (9.8%)\n1 (2.8%)\n0 (0%)\n0 (0%)\n236 (17%)\n\n\n\n\n    6\n0 (0%)\n21 (18%)\n104 (15%)\n41 (12%)\n26 (13%)\n2 (5.4%)\n0 (0%)\n194 (14%)\n\n\n29 (39%)\n203 (46%)\n380 (55%)\n69 (48%)\n21 (58%)\n0 (0%)\n1 (50%)\n703 (51%)\n\n\n\n\n    7\n0 (0%)\n2 (1.7%)\n9 (1.3%)\n1 (0.3%)\n1 (0.5%)\n0 (0%)\n0 (0%)\n13 (0.9%)\n\n\n1 (1.4%)\n4 (0.9%)\n2 (0.3%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n7 (0.5%)\n\n\n\n\n    8\n0 (0%)\n1 (0.9%)\n7 (1.0%)\n2 (0.6%)\n0 (0%)\n0 (0%)\n1 (11%)\n11 (0.8%)\n\n\n2 (2.7%)\n5 (1.1%)\n9 (1.3%)\n2 (1.4%)\n0 (0%)\n0 (0%)\n0 (0%)\n18 (1.3%)\n\n\n\n\n    9\n0 (0%)\n0 (0%)\n1 (0.1%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (&lt;0.1%)\n\n\n0 (0%)\n0 (0%)\n1 (0.1%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (&lt;0.1%)\n\n\n\n\n    Unknown\n8\n288\n1,422\n650\n302\n59\n12\n2,741\n\n\n144\n1,062\n1,983\n433\n54\n6\n1\n3,683\n\n\n\n\n\n1 Median (Q1, Q3); n (%)\n\n\n2 Fisher’s Exact Test for Count Data with simulated p-value (based on 2000 replicates)\n\n\n\n\n\n\n\n\nLecture: Parmi les hommes classés comme très féminins, 27% appartiennent à la catégorie socio-professionnelle 5 (ingénieur, cadre)\n\n\nNous l’évoquions au début de ce document, ce qui nous intéresse en proposant une mesure continue des variations du genre c’est de pouvoir analyser les distances prises avec les normes de son groupe de référence.\nPour cela, nous allons construire la variable “Distance à la norme”\n\n\nShow the code\nmean_gender &lt;- tapply(my_data_frame$identity, my_data_frame$Sex, mean)\nsd_gender &lt;- tapply(my_data_frame$identity, my_data_frame$Sex, sd)\n\nmy_data_frame$distance&lt;- (my_data_frame$identity - mean_gender[my_data_frame$Sex]) / sd_gender[my_data_frame$Sex]\n\nggplot(my_data_frame, aes(x = distance, color = Sex, fill = Sex)) +\n  geom_density(alpha = 0.4) +\n  labs(title = \"Density of Distance to the Norm, by Sex\", \n       x = \"Distance to the Norm (Z-score)\", y = \"Density\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n#Ou en valeur absolue: \nmean_gender &lt;- tapply(my_data_frame$identity, my_data_frame$Sex, mean)\nsd_gender &lt;- tapply(my_data_frame$identity, my_data_frame$Sex, sd)\n\nmy_data_frame$distance_abs&lt;- abs((my_data_frame$identity - mean_gender[my_data_frame$Sex]) / sd_gender[my_data_frame$Sex])\n\nggplot(my_data_frame, aes(x = distance_abs, color = Sex, fill = Sex)) +\n  geom_density(alpha = 0.4) +\n  labs(title = \"Density of Distance to the Norm, by Sex\", \n       x = \"Distance to the Norm (Z-score)\", y = \"Density\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Catégorisation par quartiles\nmy_data_frame$categories &lt;- cut(my_data_frame$distance, breaks = 4, include.lowest = TRUE,labels = c(\"very Feminine\",\"Feminine\", \"Masculine\", \"very masculine\" ))\n\n#my_data_frame$categories &lt;- cut(my_data_frame$distance,                         breaks = quantile(my_data_frame$distance, probs = c(0, 0.25, 0.75, 1), na.rm = TRUE),                         labels = c(\"Feminine Norms\", \"Medium\", \"Masculine Norms\"),                         include.lowest = TRUE)\n\n\n\n\n\n\n\nShow the code\nlibrary(MASS)\nmy_data_frame$satisfaction&lt;-as.factor((my_data_frame$satisfaction))\n# Ordinal logistic regression model fitting\nordinal_model &lt;- polr(satisfaction ~ distance, data = my_data_frame, Hess = TRUE)\n\n\n# 1. Predict the probabilities for each category\ndistance_vals &lt;- seq(min(my_data_frame$distance), max(my_data_frame$distance))\nnew_data &lt;- data.frame(distance = distance_vals)\n\npredicted_probs &lt;- predict(ordinal_model, newdata = new_data, type = \"probs\")\n\n# 3. Convert results to dataframe\npredicted_probs_df &lt;- as.data.frame(predicted_probs)\npredicted_probs_df$distance &lt;- distance_vals\n\n# 4. Transform data into long format for ggplot2\npredicted_probs_long &lt;- pivot_longer(predicted_probs_df, \n                                     cols = -distance, \n                                     names_to = \"satisfaction\", \n                                     values_to = \"probabilite\")\n\n# 5. Visualize predicted probabilities\nggplot(predicted_probs_long, aes(x = distance, y = probabilite, color = satisfaction)) +\n  geom_line(size = 1.2) +\n  labs(title = \"Probability of satisfaction as a function of deviation from Norms\",\n       x = \"Distance to the Norm\",\n       y = \"Probability\") +\n  \n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n    axis.title.x = element_text(size = 12),\n    axis.title.y = element_text(size = 12)\n  )\n\n\n\n\n\n\n\n\n\nLa satisfaction est mesurée comme étant la réponse à la question “Vous arrive-t-il d’avoir le sentiment de manquer de temps libre pour faire tout ce dont vous avez envie ?”\nCe graphique semble indiquer que la satisfaction en termes de temps libre croît avec la distance à sa norme de genre.\nCet effet est-il vérifié pour les différents niveaux de revenus et le sexe biologique?\n\n\nShow the code\n# Graph with only lines and no scatter points\nggplot(my_data_frame, aes(x = distance, y = as.numeric(satisfaction), color = as.factor(Income))) +\n  geom_smooth(method = \"lm\", aes(linetype = as.factor(Income)), se = FALSE) + # Regression curves without confidence intervals and different line types                              # Gray scale palette\n  scale_linetype_manual(values = c(\"Low\" = \"solid\", \"Medium\" = \"dashed\", \"High\" = \"twodash\")) +  # Line types: solid, dashed, and twodash for the 3rd\n  labs(\n    title = \"Interaction between Distance to the Norm and Income Groups\",\n    x = \"Distance to the Norm (z-score)\",\n    y = \"Satisfaction (ordinal)\",\n    color = \"Income (grouped)\",\n    linetype = \"Line Type\"\n  ) +\n  theme_minimal() +                                                      # Minimalist theme\n  theme(\n    text = element_text(size = 12),                                       # Text size\n    panel.grid = element_blank(),                                          # Remove gridlines\n    panel.border = element_blank(),                                        # Remove borders around the plot\n    plot.background = element_blank(),                                     # Remove gray background\n    legend.position = \"top\",                                              # Place legend at the top\n    axis.title = element_text(color = \"black\"),                            # Axis titles in black\n    axis.text = element_text(color = \"black\")                              # Axis text in black\n  )\n\n\n\n\n\n\n\n\n\nL’effet semble s’inverser pour les bas revenus, s’écarter de la norme s’accompagne d’une baisse de la satisfaction ressentie.\nQu’en est-il si on regarde ces effets par sexe?\n\n\nShow the code\nbase_femmes &lt;- my_data_frame %&gt;%\n  filter(Sex == \"Women\")\n\n# Creating a table without NA\nfemmes_categories &lt;- base_femmes %&gt;%\n  tbl_summary(\n    include = c(Income, LNAIS, Couple,satisfaction, Health, age_group),\n    by = categories,\n    statistic = ~ \"{p}%\",\n    percent = \"row\",\n    missing = \"no\"  \n  ) %&gt;%\n  add_p()\nfemmes_categories\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nvery Feminine N = 7131\nFeminine N = 3,8711\nMasculine N = 4671\nvery masculine N = 211\np-value2\n\n\n\n\nIncome\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\n    High\n20%\n72%\n8.2%\n0.6%\n\n\n\n\n    Low\n11%\n79%\n9.1%\n0.3%\n\n\n\n\n    Medium\n12%\n77%\n10.0%\n0.5%\n\n\n\n\nLNAIS\n\n\n\n\n\n\n\n\n&gt;0.9\n\n\n    1\n14%\n76%\n9.3%\n0.4%\n\n\n\n\n    2\n14%\n77%\n8.6%\n0.4%\n\n\n\n\nCouple\n14%\n76%\n9.8%\n0.6%\n0.041\n\n\nsatisfaction\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\n    High\n8.5%\n81%\n10.0%\n0.2%\n\n\n\n\n    Low\n18%\n73%\n8.8%\n0.5%\n\n\n\n\n    Medium\n15%\n76%\n8.9%\n0.5%\n\n\n\n\nHealth\n\n\n\n\n\n\n\n\n\n\n\n\n    Bad\n8.5%\n82%\n9.1%\n0.2%\n\n\n\n\n    Good\n16%\n75%\n8.8%\n0.4%\n\n\n\n\n    Medium\n11%\n78%\n10%\n0.5%\n\n\n\n\nage_group\n\n\n\n\n\n\n\n\n\n\n\n\n    [15-38[\n20%\n69%\n10%\n1.0%\n\n\n\n\n    [38-54[\n17%\n73%\n9.4%\n0.3%\n\n\n\n\n    [54-67[\n9.7%\n81%\n9.0%\n0.2%\n\n\n\n\n    [67-97[\n6.1%\n86%\n7.7%\n0.2%\n\n\n\n\n\n1 \n\n\n2 Pearson’s Chi-squared test; Fisher’s exact test\n\n\n\n\n\n\n\n\nShow the code\nbase_hommes &lt;- my_data_frame %&gt;%\n  filter(Sex == \"Men\")\n\n\nhommes_categories &lt;- base_hommes %&gt;%\n  tbl_summary(\n    include = c(Income, LNAIS, Couple, satisfaction, Health, age_group),\n    by = categories,\n    statistic = ~ \"{p}%\",\n    percent = \"row\",\n    missing = \"no\"  \n  ) %&gt;%\n  add_p()\nhommes_categories\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nvery Feminine N = 4551\nFeminine N = 3,1121\nMasculine N = 5751\nvery masculine N = 201\np-value2\n\n\n\n\nIncome\n\n\n\n\n\n\n\n\n\n\n\n\n    High\n13%\n74%\n12%\n0.6%\n\n\n\n\n    Low\n10%\n76%\n13%\n0.4%\n\n\n\n\n    Medium\n9.8%\n75%\n15%\n0.3%\n\n\n\n\nLNAIS\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\n    1\n11%\n74%\n15%\n0.5%\n\n\n\n\n    2\n14%\n79%\n6.1%\n0.2%\n\n\n\n\nCouple\n10%\n75%\n15%\n0.5%\n0.3\n\n\nsatisfaction\n\n\n\n\n\n\n\n\n0.5\n\n\n    High\n11%\n76%\n13%\n0.3%\n\n\n\n\n    Low\n11%\n73%\n15%\n0.5%\n\n\n\n\n    Medium\n11%\n75%\n13%\n0.7%\n\n\n\n\nHealth\n\n\n\n\n\n\n\n\n\n\n\n\n    Bad\n8.1%\n80%\n12%\n0%\n\n\n\n\n    Good\n11%\n74%\n14%\n0.6%\n\n\n\n\n    Medium\n10%\n76%\n14%\n0.1%\n\n\n\n\nage_group\n\n\n\n\n\n\n\n\n\n\n\n\n    [15-38[\n10%\n72%\n17%\n1.0%\n\n\n\n\n    [38-54[\n11%\n75%\n13%\n0.5%\n\n\n\n\n    [54-67[\n11%\n75%\n14%\n0.3%\n\n\n\n\n    [67-97[\n12%\n79%\n8.8%\n0%\n\n\n\n\n\n1 \n\n\n2 Fisher’s exact test; Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\nShow the code\n# Fit ordinal logistic regression model including SEX\nordinal_model2 &lt;- polr(satisfaction ~ distance * Sex, data = my_data_frame, Hess = TRUE)\n\n# Create a sequence of values for conformity\nconformity_vals &lt;- seq(min(my_data_frame$distance), max(my_data_frame$distance))\n\n# Create a new dataset with all combinations of conformity and SEX\nnew_data &lt;- expand.grid(distance = distance_vals, Sex = c(\"Men\", \"Women\"))\n\n# Predict probabilities for each combination of conformity and SEXE\npredicted_probs &lt;- predict(ordinal_model2, newdata = new_data, type = \"probs\")\n\n# Convert results to dataframe\npredicted_probs_df &lt;- as.data.frame(predicted_probs)\npredicted_probs_df$distance &lt;- new_data$distance\npredicted_probs_df$Sex &lt;- new_data$Sex\n\n# Correctly name probability columns for satisfaction levels 1, 2 and 3\ncolnames(predicted_probs_df)[1:3] &lt;- c(\"satisfaction_1\", \"satisfaction_2\", \"satisfaction_3\")\n\n# Transformation to long format for easier viewing with ggplot2\npredicted_probs_long &lt;- pivot_longer(predicted_probs_df, \n                                     cols = starts_with(\"satisfaction\"),  # Selects columns satisfaction_1, 2 and 3\n                                     names_to = \"satisfaction\", \n                                     values_to = \"probabilite\")\n\n# Modify names for simple labels\npredicted_probs_long$satisfaction &lt;- factor(predicted_probs_long$satisfaction, \n                                            levels = c(\"satisfaction_1\", \"satisfaction_2\", \"satisfaction_3\"),\n                                            labels = c(\"Low\", \"Medium\", \"High\"))\n\n# Visualize predicted probabilities for each gender\nggplot(predicted_probs_long, aes(x = distance, y = probabilite, color = satisfaction, linetype = Sex)) +\n  geom_line(size = 1.2) +\n  labs(title = \"Predicted Probabilities of Satisfaction Based on Distance to the Norm\",\n       x = \"Distance to the Norm\",\n       y = \"Probability\") +\n  scale_color_manual(values = c(\"#87CEEB\", \"#4682B4\", \"#1E90FF\")) +  # \n  scale_linetype_manual(values = c(\"solid\", \"dashed\")) +  # Differentiates between men and women\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n    axis.title.x = element_text(size = 12),\n    axis.title.y = element_text(size = 12)\n  )\n\n\n\n\n\n\n\n\n\nCe graphique montre des différences significatives entre hommes et femmes, chez les femmes l’éloignement aux normes semble augmenter l’insatisfaction, cet effet n’est pas aussi net chez les hommes.\n\n\nShow the code\nrego &lt;- MASS::polr(\n  satisfaction ~ Sex + Income + age_group + categories,\n  data = my_data_frame\n)\n\ntheme_gtsummary_language(\"en\", decimal.mark = \",\")\nrego |&gt; \n  tbl_regression(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  ) |&gt; \n  bold_labels() |&gt; \n  add_global_p(keep = TRUE) |&gt; \n  as_kable_extra(format = \"latex\", booktabs = TRUE) |&gt; \n  kable_styling(latex_options = c(\"hold_position\", \"scale_down\"), full_width = FALSE)\n\n\n\n\n\nShow the code\nrego |&gt; \n  ggstats::ggcoef_table(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  )\n\n\n\n\n\n\n\n\n\nShow the code\nrego |&gt; \n  broom.helpers::plot_marginal_predictions() |&gt; \n  patchwork::wrap_plots(ncol = 1) &\n  scale_y_continuous(labels = scales::percent) &\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n#Contrôle par le temps passé au travail et distance absolue\n\n# Catégorisation par quartiles\nmy_data_frame$categories_abs &lt;- cut(my_data_frame$distance_abs,                         breaks = 4, na.rm = TRUE ,                         labels = c(\"Low Distance\", \"Medium_low\", \"Medium_high\", \"High Distance\"),                         include.lowest = TRUE)\nrego3 &lt;- MASS::polr(\n  satisfaction ~ Sex + Income + age_group + categories_abs,\n  data = my_data_frame\n)\n\ntheme_gtsummary_language(\"en\", decimal.mark = \",\")\nrego3 |&gt; \n  tbl_regression(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  ) |&gt; \n  bold_labels() |&gt; \n  add_global_p(keep = TRUE) |&gt; \n  as_kable_extra(format = \"latex\", booktabs = TRUE) |&gt; \n  kable_styling(latex_options = c(\"hold_position\", \"scale_down\"), full_width = FALSE)\n\n\n\n\n\nShow the code\nrego3 |&gt; \n  ggstats::ggcoef_table(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  )\n\n\n\n\n\n\n\n\n\nShow the code\nrego3 |&gt; \n  broom.helpers::plot_marginal_predictions() |&gt; \n  patchwork::wrap_plots(ncol = 1) &\n  scale_y_continuous(labels = scales::percent) &\n  coord_flip()\n\n\n\n\n\n\n\n\n\nEn utilisant une autre variable proxy de l’utilité: l’état de santé déclaré.\n\n\nShow the code\n#Une autre mesure de l'utilité: l'état de santé déclaré\n\nmy_data_frame$Health&lt;-as.factor(my_data_frame$Health)\nrego4 &lt;- MASS::polr(\n  Health ~ Sex + Income + age_group + categories_abs,\n  data = my_data_frame\n)\n\ntheme_gtsummary_language(\"en\", decimal.mark = \",\")\nrego4 |&gt; \n  tbl_regression(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  ) |&gt; \n  bold_labels() |&gt; \n  add_global_p(keep = TRUE) |&gt; \n  as_kable_extra(format = \"latex\", booktabs = TRUE) |&gt; \n  kable_styling(latex_options = c(\"hold_position\", \"scale_down\"), full_width = FALSE)\n\n\n\n\n\nShow the code\nrego4 |&gt; \n  ggstats::ggcoef_table(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  )\n\n\n\n\n\n\n\n\n\nShow the code\nrego4 |&gt; \n  broom.helpers::plot_marginal_predictions() |&gt; \n  patchwork::wrap_plots(ncol = 1) &\n  scale_y_continuous(labels = scales::percent) &\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nsummary(my_data_frame$Library)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  1.0000  1.0000  0.8347  1.0000  1.0000 \n\n\nShow the code\nmy_data_frame$SEXE&lt;-as.factor(my_data_frame$SEXE)\nreg_lm&lt;- lm(Sex~ Knitting+ \n                  Cards_games+  \n                  Gambling+ \n                  Cooking+ \n                  DIY+\n                  Vegetable_garden+ \n                  Ornamental_garden+  \n                  Fishing_hunting+ \n                  Collection+\n                  Vehicle_custom + \n                  Making_music +\n                  Diary +\n                  Writing +  \n                  Painting +  \n                  Montage + \n                  Circus +\n                  Pottery + \n                  Theater + \n                  Drawing + \n                  Dancing +  \n                  Photography +\n                  Genealogy + \n                  Science +\n                  None +\n                  No_Amateur +\n                  Video_games +\n                  TV +\n                  Radio+\n                  Library+\n                  Museums +  \n                  Internet + \n                  Concert, data=my_data_frame)\n\n\n\nn &lt;- nrow(my_data_frame)\n\n# Indices pour la division (2/3 pour l'entraînement, 1/3 pour le test)\ntrain_index &lt;- sample(1:n, size = 2 * n / 3)  # 2/3 des indices pour l'entraînement\n\n# Créer l'ensemble d'entraînement et l'ensemble de test\ntrain_data &lt;- my_data_frame[train_index, ]  # Enregistrement d'entraînement\ntest_data &lt;- my_data_frame[-train_index, ]  # Enregistrement de test\n\n# Vérifier les tailles\ncat(\"Nombre d'observations dans l'ensemble d'entraînement :\", nrow(train_data), \"\\n\")\n\n\nNombre d'observations dans l'ensemble d'entraînement : 6156 \n\n\nShow the code\ncat(\"Nombre d'observations dans l'ensemble de test :\", nrow(test_data), \"\\n\")\n\n\nNombre d'observations dans l'ensemble de test : 3078 \n\n\nShow the code\n# Charger les bibliothèques nécessaires\nlibrary(glmnet)\nlibrary(pROC)\n\n# Définir la matrice X pour l'entraînement\nx &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                  Vegetable_garden + Ornamental_garden + Fishing_hunting + \n                  Collection + Vehicle_custom + Making_music + Diary + Writing + \n                  Painting + Montage + Circus + Pottery + Theater + Drawing + \n                  Dancing + Photography + Genealogy + Science + None + No_Amateur +\n                  Video_games + TV + Radio + Library + Museums + Internet + Concert,\n                  train_data)[, -1]\n\n# Variable cible y pour l'entraînement\ny &lt;- train_data$SEXE\n\n# Ajuster le modèle LASSO avec validation croisée\ncv_lasso &lt;- cv.glmnet(x, y, alpha = 1, family = \"binomial\")\nbest_lambda &lt;- cv_lasso$lambda.min  # Lambda optimal\n\n# Vérifie les coefficients pour le lambda optimal\nprint(coef(cv_lasso, s = \"lambda.min\"))\n\n\n33 x 1 sparse Matrix of class \"dgCMatrix\"\n                             s1\n(Intercept)       -6.594268e-01\nKnitting           2.897789e+00\nCards_games        2.442634e-01\nGambling          -4.166131e-01\nCooking            1.178967e+00\nDIY               -1.041022e+00\nVegetable_garden  -3.655189e-01\nOrnamental_garden  2.772988e-01\nFishing_hunting   -1.289056e+00\nCollection        -6.543257e-01\nVehicle_custom    -1.748330e+00\nMaking_music      -2.121348e-01\nDiary              1.466762e+00\nWriting           -9.833754e-02\nPainting           4.373124e-01\nMontage           -9.239000e-01\nCircus             .           \nPottery            5.402698e-01\nTheater           -2.806501e-02\nDrawing           -1.061173e-01\nDancing            1.639313e+00\nPhotography       -4.795022e-01\nGenealogy         -2.433708e-01\nScience           -8.540327e-01\nNone              -2.186679e-01\nNo_Amateur         4.344182e-01\nVideo_games       -1.824566e-01\nTV                 8.141467e-01\nRadio             -2.640448e-01\nLibrary           -8.467656e-16\nMuseums           -8.953888e-02\nInternet           1.465727e-01\nConcert            4.438503e-02\n\n\nShow the code\nprint(best_lambda)\n\n\n[1] 0.0008359059\n\n\nShow the code\n# Préparer X_test (même traitement que pour l'entraînement)\nx_test &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                       Vegetable_garden + Ornamental_garden + Fishing_hunting + \n                       Collection + Vehicle_custom + Making_music + Diary + Writing + \n                       Painting + Montage + Circus + Pottery + Theater + Drawing + \n                       Dancing + Photography + Genealogy + Science + None + No_Amateur +\n                       Video_games + TV + Radio + Library + Museums + Internet + Concert,\n                       test_data)[, -1]\n\n# Prédire les probabilités sur les données de test avec le meilleur lambda\npreds &lt;- predict(cv_lasso, newx = x_test, s = \"lambda.min\", type = \"response\")\n\n# Variable cible y_test pour l'ensemble de test\ny_test &lt;- test_data$SEXE\n\n# Calcul de l'AUC avec pROC\nroc_curve &lt;- roc(y_test, preds)\nauc_value &lt;- auc(roc_curve)\nprint(paste(\"AUC:\", auc_value))\n\n\n[1] \"AUC: 0.865934928476251\"\n\n\nShow the code\n# Calculer la courbe ROC\nroc_curve &lt;- roc(y_test, preds)\n\n# Afficher la courbe ROC\nplot(roc_curve, main = \"Courbe ROC\", col = \"blue\", lwd = 2)\n\n# Optionnel : Ajouter la ligne de base (diagonale)\nabline(a = 0, b = 1, col = \"red\", lty = 2)\n\n\n\n\n\n\n\n\n\nShow the code\n# Afficher les coefficients pour le meilleur lambda\ncoefficients &lt;- coef(cv_lasso, s = \"lambda.min\")\n\n# Convertir en data.frame pour une meilleure lisibilité\ncoefficients_df &lt;- as.data.frame(as.matrix(coefficients))\ncolnames(coefficients_df) &lt;- \"Coefficient\"\ncoefficients_df$Variable &lt;- rownames(coefficients_df)\n\n# Filtrer pour ne garder que les variables avec des coefficients non nuls\ncoefficients_non_zero &lt;- coefficients_df[coefficients_df$Coefficient != 0, ]\n\n# Afficher les variables gardées et leurs coefficients\nprint(coefficients_non_zero)\n\n\n                    Coefficient          Variable\n(Intercept)       -6.594268e-01       (Intercept)\nKnitting           2.897789e+00          Knitting\nCards_games        2.442634e-01       Cards_games\nGambling          -4.166131e-01          Gambling\nCooking            1.178967e+00           Cooking\nDIY               -1.041022e+00               DIY\nVegetable_garden  -3.655189e-01  Vegetable_garden\nOrnamental_garden  2.772988e-01 Ornamental_garden\nFishing_hunting   -1.289056e+00   Fishing_hunting\nCollection        -6.543257e-01        Collection\nVehicle_custom    -1.748330e+00    Vehicle_custom\nMaking_music      -2.121348e-01      Making_music\nDiary              1.466762e+00             Diary\nWriting           -9.833754e-02           Writing\nPainting           4.373124e-01          Painting\nMontage           -9.239000e-01           Montage\nPottery            5.402698e-01           Pottery\nTheater           -2.806501e-02           Theater\nDrawing           -1.061173e-01           Drawing\nDancing            1.639313e+00           Dancing\nPhotography       -4.795022e-01       Photography\nGenealogy         -2.433708e-01         Genealogy\nScience           -8.540327e-01           Science\nNone              -2.186679e-01              None\nNo_Amateur         4.344182e-01        No_Amateur\nVideo_games       -1.824566e-01       Video_games\nTV                 8.141467e-01                TV\nRadio             -2.640448e-01             Radio\nLibrary           -8.467656e-16           Library\nMuseums           -8.953888e-02           Museums\nInternet           1.465727e-01          Internet\nConcert            4.438503e-02           Concert\n\n\nShow the code\n###CREATION INDICE\n\n# Récupérer les coefficients du modèle pour le meilleur lambda\ncoefficients &lt;- coef(cv_lasso, s = \"lambda.min\")\n\n# Convertir en data.frame et filtrer les variables non nulles\ncoefficients_df &lt;- as.data.frame(as.matrix(coefficients))\ncolnames(coefficients_df) &lt;- \"Coefficient\"\ncoefficients_df$Variable &lt;- rownames(coefficients_df)\ncoefficients_non_zero &lt;- coefficients_df[coefficients_df$Coefficient != 0, ]\n\n# Préparer la matrice X des pratiques pour l'ensemble de test (ou d'entraînement si nécessaire)\nx_test &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                       Vegetable_garden + Ornamental_garden + Fishing_hunting + \n                       Collection + Vehicle_custom + Making_music + Diary + Writing + \n                       Painting + Montage + Circus + Pottery + Theater + Drawing + \n                       Dancing + Photography + Genealogy + Science + None + No_Amateur +\n                       Video_games + TV + Radio + Library + Museums + Internet + Concert,\n                       test_data)[, -1]  # Assurez-vous d'enlever l'intercept avec [, -1]\n\n# Sélectionner les variables pertinentes\nmatched_vars &lt;- intersect(rownames(coefficients_non_zero), colnames(x_test))\nx_test &lt;- x_test[, matched_vars, drop = FALSE]\ncoef_vector &lt;- coefficients_non_zero$Coefficient[matched_vars]  # Associer les coefficients\n\nprint(paste(\"Dimension de x_test :\", dim(x_test)[1], \"x\", dim(x_test)[2]))\n\n\n[1] \"Dimension de x_test : 3078 x 31\"\n\n\nShow the code\nprint(paste(\"Longueur de coef_vector :\", length(coef_vector)))\n\n\n[1] \"Longueur de coef_vector : 31\"\n\n\nShow the code\nprint(paste(\"Nombre de valeurs NA dans x_test :\", sum(is.na(x_test))))\n\n\n[1] \"Nombre de valeurs NA dans x_test : 0\"\n\n\nShow the code\nprint(paste(\"Nombre de valeurs NA dans coef_vector :\", sum(is.na(coef_vector))))\n\n\n[1] \"Nombre de valeurs NA dans coef_vector : 31\"\n\n\nShow the code\nprint(\"Variables dans coefficients_non_zero :\")\n\n\n[1] \"Variables dans coefficients_non_zero :\"\n\n\nShow the code\nprint(coefficients_non_zero$Variable)\n\n\n [1] \"(Intercept)\"       \"Knitting\"          \"Cards_games\"      \n [4] \"Gambling\"          \"Cooking\"           \"DIY\"              \n [7] \"Vegetable_garden\"  \"Ornamental_garden\" \"Fishing_hunting\"  \n[10] \"Collection\"        \"Vehicle_custom\"    \"Making_music\"     \n[13] \"Diary\"             \"Writing\"           \"Painting\"         \n[16] \"Montage\"           \"Pottery\"           \"Theater\"          \n[19] \"Drawing\"           \"Dancing\"           \"Photography\"      \n[22] \"Genealogy\"         \"Science\"           \"None\"             \n[25] \"No_Amateur\"        \"Video_games\"       \"TV\"               \n[28] \"Radio\"             \"Library\"           \"Museums\"          \n[31] \"Internet\"          \"Concert\"          \n\n\nShow the code\nprint(\"Colonnes de x_test :\")\n\n\n[1] \"Colonnes de x_test :\"\n\n\nShow the code\nprint(colnames(x_test))\n\n\n [1] \"Knitting\"          \"Cards_games\"       \"Gambling\"         \n [4] \"Cooking\"           \"DIY\"               \"Vegetable_garden\" \n [7] \"Ornamental_garden\" \"Fishing_hunting\"   \"Collection\"       \n[10] \"Vehicle_custom\"    \"Making_music\"      \"Diary\"            \n[13] \"Writing\"           \"Painting\"          \"Montage\"          \n[16] \"Pottery\"           \"Theater\"           \"Drawing\"          \n[19] \"Dancing\"           \"Photography\"       \"Genealogy\"        \n[22] \"Science\"           \"None\"              \"No_Amateur\"       \n[25] \"Video_games\"       \"TV\"                \"Radio\"            \n[28] \"Library\"           \"Museums\"           \"Internet\"         \n[31] \"Concert\"          \n\n\nShow the code\n# Exclure \"(Intercept)\" des coefficients\ncoefficients_filtered &lt;- coefficients_non_zero[coefficients_non_zero$Variable != \"(Intercept)\", ]\n\n# Aligner les coefficients sur x_test\ncoef_vector &lt;- coefficients_filtered$Coefficient[match(colnames(x_test), coefficients_filtered$Variable)]\n\n\n\n# Calcul des scores\ntest_data$score &lt;- x_test %*% coef_vector\n\n# Normalisation des scores\nmin_score &lt;- min(test_data$score, na.rm = TRUE)\nmax_score &lt;- max(test_data$score, na.rm = TRUE)\n\nif (max_score &gt; min_score) {\n  test_data$score_normalise &lt;- (test_data$score - min_score) / (max_score - min_score)\n} else {\n  test_data$score_normalise &lt;- 0\n}\n\n# Visualisation avec ggplot2\nlibrary(ggplot2)\nggplot(test_data, aes(x = score_normalise, color = SEXE, fill = SEXE)) +\n  geom_density(alpha = 0.4) + \n  labs(title = \"Densité du Score Normalisé\", x = \"Score Normalisé\", y = \"Densité\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Préparer la matrice X pour l'ensemble complet (train + test)\nx_full &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                       Vegetable_garden + Ornamental_garden + Fishing_hunting + \n                       Collection + Vehicle_custom + Making_music + Diary + Writing + \n                       Painting + Montage + Circus + Pottery + Theater + Drawing + \n                       Dancing + Photography + Genealogy + Science + None + No_Amateur +\n                       Video_games + TV + Radio + Library + Museums + Internet + Concert,\n                       my_data_frame)[, -1]  # Exclure l'intercept\n\n# Sélectionner les variables pertinentes (identiques à celles du modèle LASSO)\nmatched_vars &lt;- intersect(rownames(coefficients_non_zero), colnames(x_full))\nx_full &lt;- x_full[, matched_vars, drop = FALSE]  # Garder uniquement les variables sélectionnées\n# Aligner les coefficients sur x_full\ncoef_vector_full &lt;- coefficients_filtered$Coefficient[match(colnames(x_full), coefficients_filtered$Variable)]\n\n# Calcul des scores pour l'ensemble complet\nmy_data_frame$score &lt;- x_full %*% coef_vector_full\n# Normalisation des scores\nmin_score_full &lt;- min(my_data_frame$score, na.rm = TRUE)\nmax_score_full &lt;- max(my_data_frame$score, na.rm = TRUE)\n\nif (max_score_full &gt; min_score_full) {\n  my_data_frame$score_normalise &lt;- (my_data_frame$score - min_score_full) / (max_score_full - min_score_full)\n} else {\n  my_data_frame$score_normalise &lt;- 0\n}\n# Visualisation du score normalisé pour l'ensemble complet avec ggplot2\nlibrary(ggplot2)\nggplot(my_data_frame, aes(x = score_normalise, color = SEXE, fill = SEXE)) +\n  geom_density(alpha = 0.4) + \n  labs(title = \"Densité du Score Normalisé (Ensemble Complet)\", x = \"Score Normalisé\", y = \"Densité\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Calculer la corrélation entre indice_normalise et score_normalise\ncorrelation_value &lt;- cor(my_data_frame$identity, my_data_frame$score_normalise, use = \"complete.obs\")\nprint(paste(\"Corrélation entre indice_normalise et score_normalise :\", correlation_value))\n\n\n[1] \"Corrélation entre indice_normalise et score_normalise : -0.64021199798235\"\n\n\nShow the code\n# Visualiser la relation entre indice_normalise et score_normalise\nlibrary(ggplot2)\nggplot(my_data_frame, aes(x = identity, y = score_normalise)) +\n  geom_point(alpha = 0.5) +\n  labs(title = \"Relation entre indice_normalise et score_normalise\", \n       x = \"Indice Normalisé\", \n       y = \"Score Normalisé\") +\n  theme_minimal() +\n  geom_smooth(method = \"lm\", col = \"red\", se = FALSE)  # Ajouter une droite de régression linéaire\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Create a data frame to store the results\nresult_table_score &lt;- data.frame(Activity = character(0), Accuracy = numeric(0))\n\nfor (activity in cultural_activities) {\n  # Perform a Probit regression for the current cultural activity\n  model_formula &lt;- as.formula(paste(activity, \"~ score_normalise\"))\n  model &lt;- glm(model_formula, data = my_data_frame, family = binomial(link = \"probit\"))\n \n  # Calculate predictions\n  predicted &lt;- ifelse(predict(model, type = \"response\") &gt;= 0.5, 1, 0)\n \n  # Calculate the accuracy\n  correct_predictions &lt;- sum(predicted == my_data_frame[[activity]])\n  total_predictions &lt;- nrow(my_data_frame)\n  accuracy &lt;- (correct_predictions / total_predictions) * 100\n \n  # Add the result to the data frame\n  result_table_score &lt;- rbind(result_table, data.frame(Activity = activity, Accuracy = accuracy))\n}\nresult_table_score\n\n\n           Activity Accuracy\n1          Knitting 84.37297\n2       Cards_games 51.00715\n3          Gambling 79.18562\n4           Cooking 56.55187\n5               DIY 51.25623\n6  Vegetable_garden 72.89365\n7   Fishing_hunting 93.95712\n8        Collection 92.54927\n9    Vehicle_custom 96.85943\n10     Making_music 68.16114\n11            Diary 85.85662\n12          Writing 88.16331\n13         Painting 78.76327\n14          Montage 84.52458\n15          Pottery 89.50617\n16          Theater 86.53888\n17          Drawing 76.73814\n18          Dancing 79.66212\n19      Photography 74.53974\n20        Genealogy 88.21746\n21          Science 88.30409\n22             None 70.19710\n23      Video_games 62.06411\n24          Library 83.20338\n25          Concert 81.92549\n26          Concert 82.06628\n\n\n\n\nShow the code\nmy_data_frame$score_scale &lt;- cut(\n  my_data_frame$score_normalise,\n  breaks = 7,  # Automatically divide into 7 slices\n  labels = c(\"Very Masculine\", \"1\", \"2\", \"3\", \"4\", \"5\", \"Very Feminine\"), \n  include.lowest = TRUE  \n)\ntable1 &lt;-\n  my_data_frame |&gt; \n  tbl_summary(include = c(score_scale),\n  by=Sex ,)|&gt; \n    add_p()\ntable1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4 1621\nWomen N = 5 0721\np-value2\n\n\n\n\nscore_scale\n\n\n\n\n&lt;0,001\n\n\n    Very Masculine\n18 (0,4%)\n0 (0%)\n\n\n\n\n    1\n322 (7,7%)\n18 (0,4%)\n\n\n\n\n    2\n1 905 (46%)\n392 (7,7%)\n\n\n\n\n    3\n1 695 (41%)\n2 014 (40%)\n\n\n\n\n    4\n205 (4,9%)\n1 699 (33%)\n\n\n\n\n    5\n16 (0,4%)\n814 (16%)\n\n\n\n\n    Very Feminine\n1 (&lt;0,1%)\n135 (2,7%)\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\nrappel des données de Trachman:\nLa majorité des femmes se disent plutôt féminines et la majorité des hommes plutôt masculins. Ceci suggère un sentiment de “normalité” du point de vue du genre\nCependant, l’intensité de ces positionnements diffère selon le sexe. Un tiers des hommes se disent très masculins, tandis que moins d’un quart des femmes se disent très féminines\nDe plus, un peu plus de 9 % des femmes se considèrent « pas très féminines », contre seulement 2 % des hommes qui se disent « pas très masculins »\n\n\n\n\n\nShow the code\n# Calculer la moyenne des scores normalisés pour chaque genre\nmean_scores_by_gender &lt;- my_data_frame %&gt;%\n  group_by(SEXE) %&gt;%\n  summarise(mean_score_by_gender = mean(score_normalise, na.rm = TRUE))\n\n# Afficher les moyennes par genre\nprint(mean_scores_by_gender)\n\n\n# A tibble: 2 × 2\n  SEXE  mean_score_by_gender\n  &lt;fct&gt;                &lt;dbl&gt;\n1 1                    0.419\n2 2                    0.595\n\n\nShow the code\n# Fusionner les données avec la moyenne par genre\nmy_data_frame &lt;- my_data_frame %&gt;%\n  left_join(mean_scores_by_gender, by = \"SEXE\")\n\n# Calculer la distance entre le score normalisé de chaque individu et la moyenne de son genre\nmy_data_frame$distance_to_mean_gender &lt;- abs(my_data_frame$score_normalise - my_data_frame$mean_score_by_gender)\n\n\nggplot(my_data_frame, aes(x = distance_to_mean_gender, color = Sex, fill = Sex)) +\n  geom_density(alpha = 0.4) +\n  labs(title = \"Density of Distance to the Norm, by Sex\", \n       x = \"Distance to the Norm (Z-score)\", y = \"Density\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nlibrary(MASS)\nlibrary(tidyr)\nlibrary(ggplot2)\n\n# Assurez-vous que 'distance_to_mean_gender' est bien numérique\nmy_data_frame$distance_to_mean_gender &lt;- as.numeric(my_data_frame$distance_to_mean_gender)\n\n# Vérification du type de la variable\nprint(paste(\"Type de distance_to_mean_gender :\", class(my_data_frame$distance_to_mean_gender)))\n\n\n[1] \"Type de distance_to_mean_gender : numeric\"\n\n\nShow the code\n# Ordinal logistic regression model fitting\nmy_data_frame$satisfaction &lt;- as.factor(my_data_frame$satisfaction)  # Assurez-vous que satisfaction est bien un facteur ordinal\n\n# Ajuster le modèle\nordinal_model &lt;- polr(satisfaction ~ distance_to_mean_gender, data = my_data_frame, Hess = TRUE)\n\n# 1. Créer les valeurs de distance pour la prédiction\ndistance_vals &lt;- seq(min(my_data_frame$distance_to_mean_gender, na.rm = TRUE), \n                     max(my_data_frame$distance_to_mean_gender, na.rm = TRUE), length.out = 100)\n\n# 2. Créer un nouveau data frame pour les prédictions\nnew_data &lt;- data.frame(distance_to_mean_gender = distance_vals)\n\n# 3. Prédire les probabilités pour chaque catégorie\npredicted_probs &lt;- predict(ordinal_model, newdata = new_data, type = \"probs\")\n\n# 4. Convertir les résultats en data frame\npredicted_probs_df &lt;- as.data.frame(predicted_probs)\npredicted_probs_df$distance_to_mean_gender &lt;- distance_vals\n\n# 5. Transformer les données en format long pour ggplot2\npredicted_probs_long &lt;- pivot_longer(predicted_probs_df, \n                                     cols = -distance_to_mean_gender, \n                                     names_to = \"satisfaction\", \n                                     values_to = \"probabilite\")\n\n# 6. Visualiser les probabilités prédites\nggplot(predicted_probs_long, aes(x = distance_to_mean_gender, y = probabilite, color = satisfaction)) +\n  geom_line(size = 1.2) +\n  labs(title = \"Probability of satisfaction as a function of deviation from Norms\",\n       x = \"Distance to the Norm\",\n       y = \"Probability\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n    axis.title.x = element_text(size = 12),\n    axis.title.y = element_text(size = 12)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nn_2 &lt;- nrow(my_data_frame)\n\n# Indices pour la division (2/3 pour l'entraînement, 1/3 pour le test)\ntrain_index &lt;- sample(1:n_2, size = 2 * n_2 / 3)  # 2/3 des indices pour l'entraînement\n\n# Créer l'ensemble d'entraînement et l'ensemble de test\ntrain_data &lt;- my_data_frame[train_index, ]  # Enregistrement d'entraînement\ntest_data &lt;- my_data_frame[-train_index, ]  # Enregistrement de test\n\n# Vérifier les tailles\ncat(\"Nombre d'observations dans l'ensemble d'entraînement :\", nrow(train_data), \"\\n\")\n\n\nNombre d'observations dans l'ensemble d'entraînement : 6156 \n\n\nShow the code\ncat(\"Nombre d'observations dans l'ensemble de test :\", nrow(test_data), \"\\n\")\n\n\nNombre d'observations dans l'ensemble de test : 3078 \n\n\nShow the code\n# Charger les bibliothèques nécessaires\nlibrary(glmnet)\nlibrary(pROC)\n\n# Définir la matrice X pour l'entraînement\nx_2 &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                  Vegetable_garden + Fishing_hunting + \n                  Collection + Vehicle_custom + Making_music + Diary + Writing + \n                  Painting + Montage +  Pottery + Theater + Drawing + \n                  Dancing + Photography + Genealogy + Science + None + \n                  Video_games + Library +  Concert,\n                  train_data)[, -1]\n\n# Variable cible y pour l'entraînement\ny_2 &lt;- train_data$SEXE\n\n# Ajuster le modèle LASSO avec validation croisée\ncv_lasso_2 &lt;- cv.glmnet(x_2, y_2, alpha = 1, family = \"binomial\")\nbest_lambda_2 &lt;- cv_lasso_2$lambda.min  # Lambda optimal\n\n# Vérifie les coefficients pour le lambda optimal\nprint(coef(cv_lasso_2, s = \"lambda.min\"))\n\n\n26 x 1 sparse Matrix of class \"dgCMatrix\"\n                           s1\n(Intercept)       0.241278327\nKnitting          3.292132453\nCards_games       0.210011234\nGambling         -0.440924009\nCooking           1.121404608\nDIY              -1.056417444\nVegetable_garden -0.257143930\nFishing_hunting  -1.469151636\nCollection       -0.719078970\nVehicle_custom   -1.538434788\nMaking_music     -0.100324107\nDiary             1.450903260\nWriting          -0.195681167\nPainting          0.601249644\nMontage          -0.946011138\nPottery           0.425091964\nTheater          -0.146702323\nDrawing          -0.243913677\nDancing           1.583552273\nPhotography      -0.372015708\nGenealogy        -0.290551260\nScience          -0.839985429\nNone             -0.208211076\nVideo_games      -0.161655611\nLibrary          -0.190150904\nConcert           0.002970803\n\n\nShow the code\nprint(best_lambda_2)\n\n\n[1] 0.0004980784\n\n\nShow the code\n# Préparer X_test (même traitement que pour l'entraînement)\nx_test_2 &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                  Vegetable_garden + Fishing_hunting + \n                  Collection + Vehicle_custom + Making_music + Diary + Writing + \n                  Painting + Montage +  Pottery + Theater + Drawing + \n                  Dancing + Photography + Genealogy + Science + None + \n                  Video_games + Library +  Concert,\n                       test_data)[, -1]\n\n# Prédire les probabilités sur les données de test avec le meilleur lambda\npreds_2 &lt;- predict(cv_lasso_2, newx = x_test_2, s = \"lambda.min\", type = \"response\")\n\n# Variable cible y_test pour l'ensemble de test\ny_test_2 &lt;- test_data$SEXE\n\n# Calcul de l'AUC avec pROC\nroc_curve_2 &lt;- roc(y_test_2, preds_2)\nauc_value_2 &lt;- auc(roc_curve_2)\nprint(paste(\"AUC:\", auc_value_2))\n\n\n[1] \"AUC: 0.861803379874\"\n\n\nShow the code\n# Calculer la courbe ROC\nroc_curve_2 &lt;- roc(y_test_2, preds_2)\n\n# Afficher la courbe ROC\nplot(roc_curve_2, main = \"Courbe ROC 2\", col = \"blue\", lwd = 2)\n\n# Optionnel : Ajouter la ligne de base (diagonale)\nabline(a = 0, b = 1, col = \"red\", lty = 2)\n\n\n\n\n\n\n\n\n\nShow the code\n# Afficher les coefficients pour le meilleur lambda\ncoefficients_2 &lt;- coef(cv_lasso_2, s = \"lambda.min\")\n\n# Convertir en data.frame pour une meilleure lisibilité\ncoefficients_df_2 &lt;- as.data.frame(as.matrix(coefficients_2))\ncolnames(coefficients_df_2) &lt;- \"Coefficient\"\ncoefficients_df_2$Variable &lt;- rownames(coefficients_df_2)\n\n# Filtrer pour ne garder que les variables avec des coefficients non nuls\ncoefficients_non_zero_2 &lt;- coefficients_df_2[coefficients_df_2$Coefficient != 0, ]\n\n# Afficher les variables gardées et leurs coefficients\nprint(coefficients_non_zero_2)\n\n\n                  Coefficient         Variable\n(Intercept)       0.241278327      (Intercept)\nKnitting          3.292132453         Knitting\nCards_games       0.210011234      Cards_games\nGambling         -0.440924009         Gambling\nCooking           1.121404608          Cooking\nDIY              -1.056417444              DIY\nVegetable_garden -0.257143930 Vegetable_garden\nFishing_hunting  -1.469151636  Fishing_hunting\nCollection       -0.719078970       Collection\nVehicle_custom   -1.538434788   Vehicle_custom\nMaking_music     -0.100324107     Making_music\nDiary             1.450903260            Diary\nWriting          -0.195681167          Writing\nPainting          0.601249644         Painting\nMontage          -0.946011138          Montage\nPottery           0.425091964          Pottery\nTheater          -0.146702323          Theater\nDrawing          -0.243913677          Drawing\nDancing           1.583552273          Dancing\nPhotography      -0.372015708      Photography\nGenealogy        -0.290551260        Genealogy\nScience          -0.839985429          Science\nNone             -0.208211076             None\nVideo_games      -0.161655611      Video_games\nLibrary          -0.190150904          Library\nConcert           0.002970803          Concert\n\n\nShow the code\n###CREATION INDICE\n\n# Récupérer les coefficients du modèle pour le meilleur lambda\ncoefficients_2 &lt;- coef(cv_lasso_2, s = \"lambda.min\")\n\n# Convertir en data.frame et filtrer les variables non nulles\ncoefficients_df_2 &lt;- as.data.frame(as.matrix(coefficients_2))\ncolnames(coefficients_df_2) &lt;- \"Coefficient\"\ncoefficients_df_2$Variable &lt;- rownames(coefficients_df_2)\ncoefficients_non_zero_2 &lt;- coefficients_df_2[coefficients_df_2$Coefficient != 0, ]\n\n# Préparer la matrice X des pratiques pour l'ensemble de test (ou d'entraînement si nécessaire)\nx_test_2 &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                  Vegetable_garden + Fishing_hunting + \n                  Collection + Vehicle_custom + Making_music + Diary + Writing + \n                  Painting + Montage +  Pottery + Theater + Drawing + \n                  Dancing + Photography + Genealogy + Science + None + \n                  Video_games + Library +  Concert,\n                       test_data)[, -1]  # Assurez-vous d'enlever l'intercept avec [, -1]\n\n# Sélectionner les variables pertinentes\nmatched_vars_2 &lt;- intersect(rownames(coefficients_non_zero_2), colnames(x_test_2))\nx_test_2 &lt;- x_test_2[, matched_vars_2, drop = FALSE]\ncoef_vector_2 &lt;- coefficients_non_zero_2$Coefficient[matched_vars_2]  # Associer les coefficients\n\n#print(paste(\"Dimension de x_test :\", dim(x_test)[1], \"x\", dim(x_test)[2]))\n#print(paste(\"Longueur de coef_vector :\", length(coef_vector)))\n#print(paste(\"Nombre de valeurs NA dans x_test :\", sum(is.na(x_test))))\n#print(paste(\"Nombre de valeurs NA dans coef_vector :\", sum(is.na(coef_vector))))\n\n#print(\"Variables dans coefficients_non_zero :\")\n#print(coefficients_non_zero$Variable)\n\n#print(\"Colonnes de x_test :\")\n#print(colnames(x_test))\n\n\n# Exclure \"(Intercept)\" des coefficients\ncoefficients_filtered_2 &lt;- coefficients_non_zero_2[coefficients_non_zero_2$Variable != \"(Intercept)\", ]\n\n# Aligner les coefficients sur x_test\ncoef_vector_2 &lt;- coefficients_filtered_2$Coefficient[match(colnames(x_test_2), coefficients_filtered_2$Variable)]\n\n\n\n# Calcul des scores\ntest_data$score_2 &lt;- x_test_2 %*% coef_vector_2\n\n# Normalisation des scores\nmin_score_2 &lt;- min(test_data$score_2, na.rm = TRUE)\nmax_score_2 &lt;- max(test_data$score_2, na.rm = TRUE)\n\nif (max_score_2 &gt; min_score_2) {\n  test_data$score_normalise_2 &lt;- (test_data$score_2 - min_score_2) / (max_score_2 - min_score_2)\n} else {\n  test_data$score_normalise_2 &lt;- 0\n}\n\n# Visualisation avec ggplot2\nlibrary(ggplot2)\nggplot(test_data, aes(x = score_normalise_2, color = SEXE, fill = SEXE)) +\n  geom_density(alpha = 0.4) + \n  labs(title = \"Densité du Score Normalisé 2\", x = \"Score Normalisé 2\", y = \"Densité\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\n# Préparer la matrice X pour l'ensemble complet (train + test)\nx_full_2 &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                  Vegetable_garden + Fishing_hunting + \n                  Collection + Vehicle_custom + Making_music + Diary + Writing + \n                  Painting + Montage +  Pottery + Theater + Drawing + \n                  Dancing + Photography + Genealogy + Science + None + \n                  Video_games + Library +  Concert,\n                       my_data_frame)[, -1]  # Exclure l'intercept\n\n# Sélectionner les variables pertinentes (identiques à celles du modèle LASSO)\nmatched_vars_2 &lt;- intersect(rownames(coefficients_non_zero_2), colnames(x_full_2))\nx_full_2 &lt;- x_full_2[, matched_vars_2, drop = FALSE]  # Garder uniquement les variables sélectionnées\n# Aligner les coefficients sur x_full\ncoef_vector_full_2 &lt;- coefficients_filtered_2$Coefficient[match(colnames(x_full_2), coefficients_filtered_2$Variable)]\n\n# Calcul des scores pour l'ensemble complet\nmy_data_frame$score_2 &lt;- x_full_2 %*% coef_vector_full_2\n# Normalisation des scores\nmin_score_full_2 &lt;- min(my_data_frame$score_2, na.rm = TRUE)\nmax_score_full_2 &lt;- max(my_data_frame$score_2, na.rm = TRUE)\n\nif (max_score_full_2 &gt; min_score_full_2) {\n  my_data_frame$score_normalise_2 &lt;- (my_data_frame$score_2 - min_score_full_2) / (max_score_full_2 - min_score_full_2)\n} else {\n  my_data_frame$score_normalise_2 &lt;- 0\n}\n# Visualisation du score normalisé pour l'ensemble complet avec ggplot2\nlibrary(ggplot2)\nggplot(my_data_frame, aes(x = score_normalise_2, color = SEXE, fill = SEXE)) +\n  geom_density(alpha = 0.4) + \n  labs(title = \"Densité du Score Normalisé 2(Ensemble Complet)\", x = \"Score Normalisé\", y = \"Densité\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\n# Calculer la corrélation entre indice_normalise et score_normalise\ncorrelation_value_2 &lt;- cor(my_data_frame$identity, my_data_frame$score_normalise_2, use = \"complete.obs\")\nprint(paste(\"Corrélation entre indice_normalise et score_normalise 2:\", correlation_value))\n\n\n[1] \"Corrélation entre indice_normalise et score_normalise 2: -0.64021199798235\"\n\n\nShow the code\n# Visualiser la relation entre indice_normalise et score_normalise\nlibrary(ggplot2)\nggplot(my_data_frame, aes(x = identity, y = score_normalise_2)) +\n  geom_point(alpha = 0.5) +\n  labs(title = \"Relation entre indice_normalise et score_normalise 2\", \n       x = \"Indice Normalisé\", \n       y = \"Score Normalisé\") +\n  theme_minimal() +\n  geom_smooth(method = \"lm\", col = \"red\", se = FALSE)  # Ajouter une droite de régression linéaire\n\n\n\n\n\n\n\n\n\nShow the code\n# Créer un data frame pour stocker les résultats\nresult_table_score_2 &lt;- data.frame(Activity_2 = character(0), Accuracy_2 = numeric(0))\n\ncultural_activities_2 &lt;- c(\n   \"Knitting\", \"Cards_games\", \"Gambling\", \"Cooking\", \"DIY\",\n   \"Vegetable_garden\", \"Fishing_hunting\", \"Collection\", \"Vehicle_custom\",\n   \"Making_music\", \"Diary\", \"Writing\", \"Painting\", \"Montage\",\n   \"Pottery\", \"Theater\", \"Drawing\", \"Dancing\", \"Photography\",\n   \"Genealogy\", \"Science\", \"None\", \"Video_games\", \"Library\", \"Concert\"\n)\n\nfor (activity_2 in cultural_activities_2) {\n  # Effectuer une régression Probit pour l'activité culturelle actuelle\n  model_formula_2 &lt;- as.formula(paste(activity_2, \"~ score_normalise_2\"))\n  model_2 &lt;- glm(model_formula_2, data = my_data_frame, family = binomial(link = \"probit\"))\n \n  # Calculer les prédictions\n  predicted_2 &lt;- ifelse(predict(model_2, type = \"response\") &gt;= 0.5, 1, 0)\n \n  # Calculer la précision\n  correct_predictions_2 &lt;- sum(predicted_2 == my_data_frame[[activity_2]])\n  total_predictions_2 &lt;- nrow(my_data_frame)\n  accuracy_2 &lt;- (correct_predictions_2 / total_predictions_2) * 100\n \n  # Ajouter le résultat au data frame\n  result_table_score_2 &lt;- rbind(result_table_score_2, data.frame(Activity_2 = activity_2, Accuracy_2 = accuracy_2))\n}\n\n# Afficher le tableau des résultats\nprint(result_table_score_2)\n\n\n         Activity_2 Accuracy_2\n1          Knitting   93.63223\n2       Cards_games   56.69266\n3          Gambling   78.77410\n4           Cooking   70.69526\n5               DIY   57.79727\n6  Vegetable_garden   72.05978\n7   Fishing_hunting   90.35088\n8        Collection   92.67923\n9    Vehicle_custom   96.52372\n10     Making_music   65.97358\n11            Diary   84.30799\n12          Writing   87.48105\n13         Painting   78.68746\n14          Montage   84.52458\n15          Pottery   89.50617\n16          Theater   86.10570\n17          Drawing   76.72731\n18          Dancing   76.38077\n19      Photography   74.53974\n20        Genealogy   88.21746\n21          Science   88.30409\n22             None   71.10678\n23      Video_games   61.29521\n24          Library   83.47412\n25          Concert   82.06628\n\n\n\n\nShow the code\noptions(repos = c(CRAN = \"https://cran.rstudio.com/\"))\n# Charger les bibliothèques\nlibrary(MASS)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(ggeffects)\n\n# Vérifier et convertir la variable dépendante en facteur ordonné\nmy_data_frame$satisfaction &lt;- as.ordered(my_data_frame$satisfaction)\n\n# Ajuster le modèle avec la méthode logistique\nmodel_ordinal &lt;- polr(satisfaction ~ distance_to_mean_gender, \n                       data = my_data_frame, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model_ordinal)\n\n\nCall:\npolr(formula = satisfaction ~ distance_to_mean_gender, data = my_data_frame, \n    method = \"logistic\")\n\nCoefficients:\n                         Value Std. Error t value\ndistance_to_mean_gender 0.1989     0.2735  0.7272\n\nIntercepts:\n           Value    Std. Error t value \nHigh|Low    -0.6542   0.0336   -19.4644\nLow|Medium   0.9512   0.0345    27.6055\n\nResidual Deviance: 20135.51 \nAIC: 20141.51 \n(9 observations effacées parce que manquantes)\n\n\nShow the code\nlibrary(lmtest)\n\n# Calculer les p-values\ncoeftest(model_ordinal)\n\n\n\nt test of coefficients:\n\n                        Estimate Std. Error t value Pr(&gt;|t|)\ndistance_to_mean_gender  0.19889    0.27350  0.7272   0.4671\n\n\nShow the code\n# Calculer les odds ratios\nexp(coef(model_ordinal))\n\n\ndistance_to_mean_gender \n               1.220052 \n\n\nShow the code\n# Générer une séquence de valeurs pour distance_to_mean_gender_2\nnew_data &lt;- data.frame(distance_to_mean_gender = seq(\n  min(my_data_frame$distance_to_mean_gender, na.rm = TRUE),\n  max(my_data_frame$distance_to_mean_gender, na.rm = TRUE),\n  length.out = 100\n))\n\n# Vérifier que les types sont corrects\nstr(new_data)\n\n\n'data.frame':   100 obs. of  1 variable:\n $ distance_to_mean_gender: num  1.87e-05 4.78e-03 9.54e-03 1.43e-02 1.91e-02 ...\n\n\nShow the code\n# Prédictions des probabilités\npred_probs &lt;- predict(model_ordinal, newdata = new_data, type = \"probs\")\n\n# Transformer les probabilités en data.frame\npred_probs_df &lt;- as.data.frame(pred_probs)\n\n# Ajouter la variable explicative\npred_probs_df$distance_to_mean_gender &lt;- new_data$distance_to_mean_gender\n\n# Restructurer les données pour ggplot\npred_probs_long &lt;- pivot_longer(pred_probs_df, cols = -distance_to_mean_gender, \n                                names_to = \"Satisfaction\", values_to = \"Probability\")\n\n# Visualiser les effets\nggplot(pred_probs_long, aes(x = distance_to_mean_gender, y = Probability, color = Satisfaction)) +\n  geom_line(size = 1) +\n  labs(title = \"Probabilités prédites de satisfaction en fonction de la distance au score moyen\",\n       x = \"Distance au score moyen de genre\",\n       y = \"Probabilité prédite\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\n# Calcul des effets marginaux\neffects_plot &lt;- ggpredict(model_ordinal, terms = \"distance_to_mean_gender\")\n\n# Visualisation des effets marginaux\nplot(effects_plot) + \n  ggtitle(\"Effet marginal de distance_to_mean_gender sur la satisfaction\")\n\n\n\n\n\n\n\n\n\nShow the code\n# Vérifier et forcer la variable explicative à être numérique\nmy_data_frame$distance_to_mean_gender &lt;- as.numeric(my_data_frame$distance_to_mean_gender) \n\n\n\n\nShow the code\n# Charger les bibliothèques nécessaires\nlibrary(MASS)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(ggeffects)\nlibrary(lmtest)\n\n# Vérifier et convertir la variable dépendante en facteur ordonné\nmy_data_frame$satisfaction &lt;- as.ordered(my_data_frame$satisfaction)\n\n# Vérifier et forcer la variable explicative à être numérique\nmy_data_frame$distance_to_mean_gender &lt;- as.numeric(my_data_frame$distance_to_mean_gender)\n\n# Ajuster le modèle avec la méthode logistique, incluant l'interaction avec Sex\nmodel_ordinal_sex &lt;- polr(satisfaction ~ distance_to_mean_gender * Sex, \n                          data = my_data_frame, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model_ordinal_sex)\n\n\nCall:\npolr(formula = satisfaction ~ distance_to_mean_gender * Sex, \n    data = my_data_frame, method = \"logistic\")\n\nCoefficients:\n                                    Value Std. Error t value\ndistance_to_mean_gender           0.66137    0.46790   1.413\nSexWomen                          0.09023    0.06443   1.400\ndistance_to_mean_gender:SexWomen -0.77024    0.58331  -1.320\n\nIntercepts:\n           Value    Std. Error t value \nHigh|Low    -0.6065   0.0473   -12.8234\nLow|Medium   0.9993   0.0481    20.7786\n\nResidual Deviance: 20133.42 \nAIC: 20143.42 \n(9 observations effacées parce que manquantes)\n\n\nShow the code\n# Calculer les p-values\ncoeftest(model_ordinal_sex)\n\n\n\nt test of coefficients:\n\n                                  Estimate Std. Error t value Pr(&gt;|t|)\ndistance_to_mean_gender           0.661372   0.467899  1.4135   0.1575\nSexWomen                          0.090232   0.064432  1.4004   0.1614\ndistance_to_mean_gender:SexWomen -0.770243   0.583306 -1.3205   0.1867\n\n\nShow the code\n# Calculer les odds ratios\nexp(coef(model_ordinal_sex))\n\n\n         distance_to_mean_gender                         SexWomen \n                       1.9374481                        1.0944276 \ndistance_to_mean_gender:SexWomen \n                       0.4629006 \n\n\nShow the code\n# Générer une séquence de valeurs pour distance_to_mean_gender\nnew_data_sex_men &lt;- data.frame(distance_to_mean_gender = seq(\n  min(my_data_frame$distance_to_mean_gender, na.rm = TRUE),\n  max(my_data_frame$distance_to_mean_gender, na.rm = TRUE),\n  length.out = 100\n))\nnew_data_sex_men$Sex &lt;- \"Men\"  # Spécifier que c'est pour les hommes\n\nnew_data_sex_women &lt;- data.frame(distance_to_mean_gender = seq(\n  min(my_data_frame$distance_to_mean_gender, na.rm = TRUE),\n  max(my_data_frame$distance_to_mean_gender, na.rm = TRUE),\n  length.out = 100\n))\nnew_data_sex_women$Sex &lt;- \"Women\"  # Spécifier que c'est pour les femmes\n\n# Combiner les données pour hommes et femmes\nnew_data_sex &lt;- rbind(new_data_sex_men, new_data_sex_women)\n\n# Prédictions des probabilités pour chaque catégorie de satisfaction\npred_probs_sex &lt;- predict(model_ordinal_sex, newdata = new_data_sex, type = \"probs\")\n\n# Transformer les probabilités en data.frame\npred_probs_df_sex &lt;- as.data.frame(pred_probs_sex)\n\n# Ajouter la variable explicative (distance_to_mean_gender) et Sex\npred_probs_df_sex$distance_to_mean_gender &lt;- new_data_sex$distance_to_mean_gender\npred_probs_df_sex$Sex &lt;- new_data_sex$Sex\n\n# Restructurer les données pour ggplot\npred_probs_long_sex &lt;- pivot_longer(pred_probs_df_sex, cols = -c(distance_to_mean_gender, Sex), \n                                    names_to = \"Satisfaction\", values_to = \"Probability\")\n\n# Visualiser les effets selon le sexe\nggplot(pred_probs_long_sex, aes(x = distance_to_mean_gender, y = Probability, color = Satisfaction, linetype = Sex)) +\n  geom_line(size = 1) +\n  labs(title = \"Probabilités prédites de satisfaction en fonction de la distance au score moyen, par sexe\",\n       x = \"Distance au score moyen de genre\",\n       y = \"Probabilité prédite\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\n# Calcul des effets marginaux pour chaque sexe\neffects_plot_sex &lt;- ggpredict(model_ordinal_sex, terms = c(\"distance_to_mean_gender\", \"Sex\"))\n\n# Visualisation des effets marginaux par sexe\nplot(effects_plot_sex) + \n  ggtitle(\"Effet marginal de distance_to_mean_gender sur la satisfaction, par sexe\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Charger les bibliothèques nécessaires\nlibrary(MASS)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(ggeffects)\nlibrary(lmtest)\n\n# Vérifier et convertir la variable dépendante en facteur ordonné\nmy_data_frame$satisfaction &lt;- as.ordered(my_data_frame$satisfaction)\n\n# Vérifier et forcer la variable explicative à être numérique\nmy_data_frame$distance_abs &lt;- as.numeric(my_data_frame$distance_abs)\n\n# Ajuster le modèle avec la méthode logistique, incluant l'interaction avec Sex\nmodel_ordinal_sex_abs &lt;- polr(satisfaction ~ distance_abs * Sex, \n                              data = my_data_frame, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model_ordinal_sex_abs)\n\n\nCall:\npolr(formula = satisfaction ~ distance_abs * Sex, data = my_data_frame, \n    method = \"logistic\")\n\nCoefficients:\n                         Value Std. Error t value\ndistance_abs           0.03373    0.04550  0.7413\nSexWomen              -0.02619    0.06039 -0.4336\ndistance_abs:SexWomen  0.07107    0.05949  1.1946\n\nIntercepts:\n           Value    Std. Error t value \nHigh|Low    -0.6312   0.0472   -13.3727\nLow|Medium   0.9754   0.0479    20.3602\n\nResidual Deviance: 20127.49 \nAIC: 20137.49 \n(9 observations effacées parce que manquantes)\n\n\nShow the code\n# Calculer les p-values\ncoeftest(model_ordinal_sex_abs)\n\n\n\nt test of coefficients:\n\n                       Estimate Std. Error t value Pr(&gt;|t|)\ndistance_abs           0.033732   0.045504  0.7413   0.4585\nSexWomen              -0.026185   0.060393 -0.4336   0.6646\ndistance_abs:SexWomen  0.071069   0.059493  1.1946   0.2323\n\n\nShow the code\n# Calculer les odds ratios\nexp(coef(model_ordinal_sex_abs))\n\n\n         distance_abs              SexWomen distance_abs:SexWomen \n            1.0343070             0.9741547             1.0736553 \n\n\nShow the code\n# Générer une séquence de valeurs pour distance_abs\nnew_data_sex_men_abs &lt;- data.frame(distance_abs = seq(\n  min(my_data_frame$distance_abs, na.rm = TRUE),\n  max(my_data_frame$distance_abs, na.rm = TRUE),\n  length.out = 100\n))\nnew_data_sex_men_abs$Sex &lt;- \"Men\"  # Spécifier que c'est pour les hommes\n\nnew_data_sex_women_abs &lt;- data.frame(distance_abs = seq(\n  min(my_data_frame$distance_abs, na.rm = TRUE),\n  max(my_data_frame$distance_abs, na.rm = TRUE),\n  length.out = 100\n))\nnew_data_sex_women_abs$Sex &lt;- \"Women\"  # Spécifier que c'est pour les femmes\n\n# Combiner les données pour hommes et femmes\nnew_data_sex_abs &lt;- rbind(new_data_sex_men_abs, new_data_sex_women_abs)\n\n# Prédictions des probabilités pour chaque catégorie de satisfaction\npred_probs_sex_abs &lt;- predict(model_ordinal_sex_abs, newdata = new_data_sex_abs, type = \"probs\")\n\n# Transformer les probabilités en data.frame\npred_probs_df_sex_abs &lt;- as.data.frame(pred_probs_sex_abs)\n\n# Ajouter la variable explicative (distance_abs) et Sex\npred_probs_df_sex_abs$distance_abs &lt;- new_data_sex_abs$distance_abs\npred_probs_df_sex_abs$Sex &lt;- new_data_sex_abs$Sex\n\n# Restructurer les données pour ggplot\npred_probs_long_sex_abs &lt;- pivot_longer(pred_probs_df_sex_abs, cols = -c(distance_abs, Sex), \n                                         names_to = \"Satisfaction\", values_to = \"Probability\")\n\n# Visualiser les effets selon le sexe\nggplot(pred_probs_long_sex_abs, aes(x = distance_abs, y = Probability, color = Satisfaction, linetype = Sex)) +\n  geom_line(size = 1) +\n  labs(title = \"Probabilités prédites de satisfaction en fonction de la distance absolue au score moyen, par sexe\",\n       x = \"Distance absolue au score moyen de genre\",\n       y = \"Probabilité prédite\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\n# Calcul des effets marginaux pour chaque sexe\neffects_plot_sex_abs &lt;- ggpredict(model_ordinal_sex_abs, terms = c(\"distance_abs\", \"Sex\"))\n\n# Visualisation des effets marginaux par sexe\nplot(effects_plot_sex_abs) + \n  ggtitle(\"Effet marginal de distance_abs sur la satisfaction, par sexe\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Charger les bibliothèques nécessaires\nlibrary(MASS)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(ggeffects)\nlibrary(lmtest)\n\n# Vérifier et convertir la variable dépendante en facteur ordonné\nmy_data_frame$Health &lt;- as.ordered(my_data_frame$Health)\n\n# Vérifier et forcer la variable explicative à être numérique\nmy_data_frame$distance_to_mean_gender &lt;- as.numeric(my_data_frame$distance_to_mean_gender)\n\n# Ajuster le modèle avec la méthode logistique, incluant l'interaction avec Sex\nmodel_ordinal_sex &lt;- polr(Health ~ distance_to_mean_gender * Sex, \n                          data = my_data_frame, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model_ordinal_sex)\n\n\nCall:\npolr(formula = Health ~ distance_to_mean_gender * Sex, data = my_data_frame, \n    method = \"logistic\")\n\nCoefficients:\n                                    Value Std. Error t value\ndistance_to_mean_gender          -0.67943    0.54325 -1.2507\nSexWomen                         -0.04176    0.07519 -0.5554\ndistance_to_mean_gender:SexWomen  1.17361    0.68187  1.7212\n\nIntercepts:\n            Value    Std. Error t value \nBad|Good     -2.3932   0.0613   -39.0681\nGood|Medium   1.2633   0.0545    23.1766\n\nResidual Deviance: 14569.98 \nAIC: 14579.98 \n(43 observations effacées parce que manquantes)\n\n\nShow the code\n# Calculer les p-values\ncoeftest(model_ordinal_sex)\n\n\n\nt test of coefficients:\n\n                                  Estimate Std. Error t value Pr(&gt;|t|)  \ndistance_to_mean_gender          -0.679434   0.543253 -1.2507  0.21108  \nSexWomen                         -0.041757   0.075186 -0.5554  0.57865  \ndistance_to_mean_gender:SexWomen  1.173612   0.681866  1.7212  0.08525 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nShow the code\n# Calculer les odds ratios\nexp(coef(model_ordinal_sex))\n\n\n         distance_to_mean_gender                         SexWomen \n                       0.5069037                        0.9591026 \ndistance_to_mean_gender:SexWomen \n                       3.2336507 \n\n\nShow the code\n# Générer une séquence de valeurs pour distance_to_mean_gender\nnew_data_sex_men &lt;- data.frame(distance_to_mean_gender = seq(\n  min(my_data_frame$distance_to_mean_gender, na.rm = TRUE),\n  max(my_data_frame$distance_to_mean_gender, na.rm = TRUE),\n  length.out = 100\n))\nnew_data_sex_men$Sex &lt;- \"Men\"  # Spécifier que c'est pour les hommes\n\nnew_data_sex_women &lt;- data.frame(distance_to_mean_gender = seq(\n  min(my_data_frame$distance_to_mean_gender, na.rm = TRUE),\n  max(my_data_frame$distance_to_mean_gender, na.rm = TRUE),\n  length.out = 100\n))\nnew_data_sex_women$Sex &lt;- \"Women\"  # Spécifier que c'est pour les femmes\n\n# Combiner les données pour hommes et femmes\nnew_data_sex &lt;- rbind(new_data_sex_men, new_data_sex_women)\n\n# Prédictions des probabilités pour chaque catégorie de satisfaction\npred_probs_sex &lt;- predict(model_ordinal_sex, newdata = new_data_sex, type = \"probs\")\n\n# Transformer les probabilités en data.frame\npred_probs_df_sex &lt;- as.data.frame(pred_probs_sex)\n\n# Ajouter la variable explicative (distance_to_mean_gender) et Sex\npred_probs_df_sex$distance_to_mean_gender &lt;- new_data_sex$distance_to_mean_gender\npred_probs_df_sex$Sex &lt;- new_data_sex$Sex\n\n# Restructurer les données pour ggplot\npred_probs_long_sex &lt;- pivot_longer(pred_probs_df_sex, cols = -c(distance_to_mean_gender, Sex), \n                                    names_to = \"Health\", values_to = \"Probability\")\n\n# Visualiser les effets selon le sexe\nggplot(pred_probs_long_sex, aes(x = distance_to_mean_gender, y = Probability, color = Health, linetype = Sex)) +\n  geom_line(size = 1) +\n  labs(title = \"Probabilités prédites de santé en fonction de la distance au score moyen, par sexe\",\n       x = \"Distance au score moyen de genre\",\n       y = \"Probabilité prédite\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\n# Calcul des effets marginaux pour chaque sexe\neffects_plot_sex &lt;- ggpredict(model_ordinal_sex, terms = c(\"distance_to_mean_gender\", \"Sex\"))\n\n# Visualisation des effets marginaux par sexe\nplot(effects_plot_sex) + \n  ggtitle(\"Effet marginal de distance_to_mean_gender sur la satisfaction, par sexe\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(my_data_frame, aes(x = distance_to_mean_gender, fill = satisfaction)) +\n  geom_bar(position = \"fill\") +\n  labs(title = \"Répartition de la satisfaction par distance_to_mean_gender\",\n       x = \"Distance au score moyen de genre\",\n       y = \"Proportion\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set3\")\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(my_data_frame, aes(x = satisfaction, y = distance_to_mean_gender, fill = satisfaction)) +\n  geom_violin(trim = FALSE) +\n  labs(title = \"Distribution de distance_to_mean_gender par satisfaction\",\n       x = \"Satisfaction\",\n       y = \"Distance au score moyen de genre\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set3\")\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Calculer la distance absolue par rapport à la moyenne et à l'écart-type pour chaque sexe\nmean_gender_score &lt;- tapply(my_data_frame$distance_to_mean_gender, my_data_frame$Sex, mean)\nsd_gender &lt;- tapply(my_data_frame$distance_to_mean_gender, my_data_frame$Sex, sd)\n\n# Calculer la distance absolue par rapport à la moyenne et l'écart-type\nmy_data_frame$distance_abs_score &lt;- abs((my_data_frame$distance_to_mean_gender - mean_gender_score[my_data_frame$Sex]) / sd_gender[my_data_frame$Sex])\n\n# Créer une colonne norm_status pour identifier les individus \"hors normes\" (distance_abs_score &gt; 2 par exemple)\nmy_data_frame$norm_status &lt;- ifelse(my_data_frame$distance_abs_score &gt; 2, \"Hors normes\", \"Normaux\")\n\n# Vérifier que la colonne a bien été ajoutée\nhead(my_data_frame)\n\n\n         IDENT18    POND_INIT         POND TYPMEN NHAB TUU2016 REG SEXE AGE\n1 Z01202A00002V2 0.9702619959 5205.7105547      1    1       2  84    1  59\n2   Z01202A00004 0.9702619959 13909.706241      4    3       2  84    1  16\n3 Z01202A00006V2 0.9702619959  6949.074595      4    3       2  84    1  47\n4   Z01202A00007 0.9702619959 4162.1183557      3    2       2  84    2  74\n5   Z01202A00008 0.9702619959 2823.6286989      1    1       2  84    1  71\n6   Z01202A00010 0.9702619959 4602.0810455      4    3       2  84    1  52\n  CRITAGE AUTRENF PETITENF LNAIS REVENU TRANREV CRITREVENU CLASS_univprat\n1       3       2       NA     1      1      NA          6              2\n2       1       2       NA     1      1      NA          8              3\n3       3       2       NA     1      1      NA          9              4\n4       4       1        2     2      1      NA          4              1\n5       4       2       NA     1      2       3          3              1\n6       3      NA        2     1      1      NA          9              4\n  CLASS_univprat_name A15 A16 A17 A18_SQ1 A18_SQ2 A18_SQ3 A18_SQ4 VITENCOUPLE\n1          Bain audio   2   2   3      NA      NA      NA      NA           3\n2            Tout-num   1   2   3      NA      NA      NA      NA           3\n3        Culture patr   4   1   2       1       1       1       1           1\n4         Petit ecran   3   2   3      NA      NA      NA      NA           1\n5         Petit ecran   3   2   3      NA      NA      NA      NA           3\n6        Culture patr   2   2   3      NA      NA      NA      NA           1\n  NOIKISH NOICONJ CSTOT CSTOT_conj G_PCS_MENAGE_ SG_PCS_MENAGE_ I_PCS_MENAGE\n1       1      NA    48         NA           III          III B            0\n2       3      NA    NA         NA           III          III C            1\n3       2       1    33         42             I          I   B            0\n4       2       1    56         68             V          V   A            0\n5       1      NA    64         NA            VI          VI  B            0\n6       1       2    37         37             I          I   A            0\n  SEXE_pers1 ANAIS_pers1 AGE_pers1 AGEJANV_pers1 LNAIS_pers1 DEPNAIS_pers1\n1          1        1959        59            58           1            69\n2          1        1978        39            39           1            39\n3          2        1975        43            42           1             1\n4          1        1934        83            83           2              \n5          1        1946        71            71           1             1\n6          1        1966        52            51           1             1\n  ANARRIV_pers1 ANARRIV_pers1_C_1 AGARRIV_pers1 AGARRIV_pers1_C_1 COUPLE_pers1\n1            NA                NA            NA                NA            3\n2            NA                NA            NA                NA            1\n3            NA                NA            NA                NA            1\n4             1              1971            NA                NA            1\n5            NA                NA            NA                NA            3\n6            NA                NA            NA                NA            1\n  NOI_99_pers1 CONJOINT_pers1 ETAMATRI_pers1 MER1E_pers1 MERELOG_pers1\n1           NA             NA              1           3            NA\n2           NA              2              2           2            NA\n3           NA              2              1           2            22\n4           NA              2              2           3            NA\n5           NA             NA              1           3            NA\n6           NA              2              2           2            NA\n  PERELOG_pers1 PER1E_pers1 LIENTYP_pers1 LIENPERS_pers1 SEXE_pers2 ANAIS_pers2\n1            NA           3            NA             NA         NA          NA\n2            22           1            NA             NA          2        1979\n3            NA           2            NA             NA          1        1971\n4            NA           3            NA             NA          2        1943\n5            NA           3            NA             NA         NA          NA\n6            22           3            NA             NA          2        1963\n  AGE_pers2 AGEJANV_pers2 LNAIS_pers2 DEPNAIS_pers2 ANARRIV_pers2\n1        NA            NA          NA                          NA\n2        39            38           1            38            NA\n3        47            46           1             1            NA\n4        74            74           2                           1\n5        NA            NA          NA                          NA\n6        55            54           1             1            NA\n  ANARRIV_pers2_C_1 AGARRIV_pers2 AGARRIV_pers2_C_1 COUPLE_pers2 NOI_99_pers2\n1                NA            NA                NA           NA           NA\n2                NA            NA                NA            1           NA\n3                NA            NA                NA            1           NA\n4              1973            NA                NA            1           NA\n5                NA            NA                NA           NA           NA\n6                NA            NA                NA            1           NA\n  CONJOINT_pers2 ETAMATRI_pers2 MER1E_pers2 MERELOG_pers2 PERELOG_pers2\n1             NA             NA          NA            NA            NA\n2              1              2           2            22            NA\n3              1              1           2            NA            NA\n4              1              2           3            NA            NA\n5             NA             NA          NA            NA            NA\n6              1              2           2            22            NA\n  PER1E_pers2 LIENTYP_pers2 LIENPERS_pers2 SEXE_pers3 ANAIS_pers3 AGE_pers3\n1          NA            NA             NA         NA          NA        NA\n2           2            NA             NA          1        2001        16\n3           3            NA             NA          1        2002        16\n4           3            NA             NA         NA          NA        NA\n5          NA            NA             NA         NA          NA        NA\n6           2            NA             NA          1        1995        22\n  AGEJANV_pers3 LNAIS_pers3 DEPNAIS_pers3 ANARRIV_pers3 ANARRIV_pers3_C_1\n1            NA          NA                          NA                NA\n2            16           1            84            NA                NA\n3            15           1            69            NA                NA\n4            NA          NA                          NA                NA\n5            NA          NA                          NA                NA\n6            22           1             1            NA                NA\n  AGARRIV_pers3 AGARRIV_pers3_C_1 COUPLE_pers3 NOI_99_pers3 CONJOINT_pers3\n1            NA                NA           NA           NA             NA\n2            NA                NA            3           NA             NA\n3            NA                NA            3           NA             NA\n4            NA                NA           NA           NA             NA\n5            NA                NA           NA           NA             NA\n6            NA                NA            3           NA             NA\n  ETAMATRI_pers3 MER1E_pers3 MERELOG_pers3 PERELOG_pers3 PER1E_pers3\n1             NA          NA            NA            NA          NA\n2              1           1             2             1           1\n3              1           1             1            21           2\n4             NA          NA            NA            NA          NA\n5             NA          NA            NA            NA          NA\n6              1           1             2             1           1\n  LIENTYP_pers3 LIENPERS_pers3 SEXE_pers4 ANAIS_pers4 AGE_pers4 AGEJANV_pers4\n1            NA             NA         NA          NA        NA            NA\n2            NA             NA         NA          NA        NA            NA\n3            NA             NA         NA          NA        NA            NA\n4            NA             NA         NA          NA        NA            NA\n5            NA             NA         NA          NA        NA            NA\n6            NA             NA         NA          NA        NA            NA\n  LNAIS_pers4 DEPNAIS_pers4 ANARRIV_pers4 ANARRIV_pers4_C_1 AGARRIV_pers4\n1          NA                          NA                NA            NA\n2          NA                          NA                NA            NA\n3          NA                          NA                NA            NA\n4          NA                          NA                NA            NA\n5          NA                          NA                NA            NA\n6          NA                          NA                NA            NA\n  AGARRIV_pers4_C_1 COUPLE_pers4 NOI_99_pers4 CONJOINT_pers4 ETAMATRI_pers4\n1                NA           NA           NA             NA             NA\n2                NA           NA           NA             NA             NA\n3                NA           NA           NA             NA             NA\n4                NA           NA           NA             NA             NA\n5                NA           NA           NA             NA             NA\n6                NA           NA           NA             NA             NA\n  MER1E_pers4 MERELOG_pers4 PERELOG_pers4 PER1E_pers4 LIENTYP_pers4\n1          NA            NA            NA          NA            NA\n2          NA            NA            NA          NA            NA\n3          NA            NA            NA          NA            NA\n4          NA            NA            NA          NA            NA\n5          NA            NA            NA          NA            NA\n6          NA            NA            NA          NA            NA\n  LIENPERS_pers4 SEXE_pers5 ANAIS_pers5 AGE_pers5 AGEJANV_pers5 LNAIS_pers5\n1             NA         NA          NA        NA            NA          NA\n2             NA         NA          NA        NA            NA          NA\n3             NA         NA          NA        NA            NA          NA\n4             NA         NA          NA        NA            NA          NA\n5             NA         NA          NA        NA            NA          NA\n6             NA         NA          NA        NA            NA          NA\n  DEPNAIS_pers5 ANARRIV_pers5 ANARRIV_pers5_C_1 AGARRIV_pers5 AGARRIV_pers5_C_1\n1            NA            NA                NA            NA                NA\n2            NA            NA                NA            NA                NA\n3            NA            NA                NA            NA                NA\n4            NA            NA                NA            NA                NA\n5            NA            NA                NA            NA                NA\n6            NA            NA                NA            NA                NA\n  COUPLE_pers5 NOI_99_pers5 CONJOINT_pers5 ETAMATRI_pers5 MER1E_pers5\n1           NA           NA             NA             NA          NA\n2           NA           NA             NA             NA          NA\n3           NA           NA             NA             NA          NA\n4           NA           NA             NA             NA          NA\n5           NA           NA             NA             NA          NA\n6           NA           NA             NA             NA          NA\n  MERELOG_pers5 PERELOG_pers5 PER1E_pers5 LIENTYP_pers5 LIENPERS_pers5\n1            NA            NA          NA            NA             NA\n2            NA            NA          NA            NA             NA\n3            NA            NA          NA            NA             NA\n4            NA            NA          NA            NA             NA\n5            NA            NA          NA            NA             NA\n6            NA            NA          NA            NA             NA\n  SEXE_pers6 ANAIS_pers6 AGE_pers6 AGEJANV_pers6 LNAIS_pers6 DEPNAIS_pers6\n1         NA          NA        NA            NA          NA            NA\n2         NA          NA        NA            NA          NA            NA\n3         NA          NA        NA            NA          NA            NA\n4         NA          NA        NA            NA          NA            NA\n5         NA          NA        NA            NA          NA            NA\n6         NA          NA        NA            NA          NA            NA\n  ANARRIV_pers6 ANARRIV_pers6_C_1 AGARRIV_pers6 AGARRIV_pers6_C_1 COUPLE_pers6\n1            NA                NA            NA                NA           NA\n2            NA                NA            NA                NA           NA\n3            NA                NA            NA                NA           NA\n4            NA                NA            NA                NA           NA\n5            NA                NA            NA                NA           NA\n6            NA                NA            NA                NA           NA\n  NOI_99_pers6 CONJOINT_pers6 ETAMATRI_pers6 MER1E_pers6 MERELOG_pers6\n1           NA             NA             NA          NA            NA\n2           NA             NA             NA          NA            NA\n3           NA             NA             NA          NA            NA\n4           NA             NA             NA          NA            NA\n5           NA             NA             NA          NA            NA\n6           NA             NA             NA          NA            NA\n  PERELOG_pers6 PER1E_pers6 LIENTYP_pers6 LIENPERS_pers6 SEXE_pers7 ANAIS_pers7\n1            NA          NA            NA             NA         NA          NA\n2            NA          NA            NA             NA         NA          NA\n3            NA          NA            NA             NA         NA          NA\n4            NA          NA            NA             NA         NA          NA\n5            NA          NA            NA             NA         NA          NA\n6            NA          NA            NA             NA         NA          NA\n  AGE_pers7 AGEJANV_pers7 LNAIS_pers7 DEPNAIS_pers7 ANARRIV_pers7\n1        NA            NA          NA            NA            NA\n2        NA            NA          NA            NA            NA\n3        NA            NA          NA            NA            NA\n4        NA            NA          NA            NA            NA\n5        NA            NA          NA            NA            NA\n6        NA            NA          NA            NA            NA\n  ANARRIV_pers7_C_1 AGARRIV_pers7 AGARRIV_pers7_C_1 COUPLE_pers7 NOI_99_pers7\n1                NA            NA                NA           NA           NA\n2                NA            NA                NA           NA           NA\n3                NA            NA                NA           NA           NA\n4                NA            NA                NA           NA           NA\n5                NA            NA                NA           NA           NA\n6                NA            NA                NA           NA           NA\n  CONJOINT_pers7 ETAMATRI_pers7 MER1E_pers7 MERELOG_pers7 PERELOG_pers7\n1             NA             NA          NA            NA            NA\n2             NA             NA          NA            NA            NA\n3             NA             NA          NA            NA            NA\n4             NA             NA          NA            NA            NA\n5             NA             NA          NA            NA            NA\n6             NA             NA          NA            NA            NA\n  PER1E_pers7 LIENTYP_pers7 LIENPERS_pers7 SEXE_pers8 ANAIS_pers8 AGE_pers8\n1          NA            NA             NA         NA          NA        NA\n2          NA            NA             NA         NA          NA        NA\n3          NA            NA             NA         NA          NA        NA\n4          NA            NA             NA         NA          NA        NA\n5          NA            NA             NA         NA          NA        NA\n6          NA            NA             NA         NA          NA        NA\n  AGEJANV_pers8 LNAIS_pers8 DEPNAIS_pers8 ANARRIV_pers8 ANARRIV_pers8_C_1\n1            NA          NA            NA            NA                NA\n2            NA          NA            NA            NA                NA\n3            NA          NA            NA            NA                NA\n4            NA          NA            NA            NA                NA\n5            NA          NA            NA            NA                NA\n6            NA          NA            NA            NA                NA\n  AGARRIV_pers8 AGARRIV_pers8_C_1 COUPLE_pers8 NOI_99_pers8 CONJOINT_pers8\n1            NA                NA           NA           NA             NA\n2            NA                NA           NA           NA             NA\n3            NA                NA           NA           NA             NA\n4            NA                NA           NA           NA             NA\n5            NA                NA           NA           NA             NA\n6            NA                NA           NA           NA             NA\n  ETAMATRI_pers8 MER1E_pers8 MERELOG_pers8 PERELOG_pers8 PER1E_pers8\n1             NA          NA            NA            NA          NA\n2             NA          NA            NA            NA          NA\n3             NA          NA            NA            NA          NA\n4             NA          NA            NA            NA          NA\n5             NA          NA            NA            NA          NA\n6             NA          NA            NA            NA          NA\n  LIENTYP_pers8 LIENPERS_pers8 A1 A2 A3 A4 A5 A6 A71 A72 A73 A74 A75 A8 A9\n1            NA             NA  1  1  1  2  1  1   0   0   1   0   0  5  4\n2            NA             NA  1  2  1  4  1  3   1   0   0   0   0  1  5\n3            NA             NA  1  3  1  1  1  1   0   0   1   0   0  2  3\n4            NA             NA  2  3  2 NA  1  1   1   0   0   0   0  5  2\n5            NA             NA  2  3  2 NA  2 NA  NA  NA  NA  NA  NA  4  5\n6            NA             NA  1  1  1  2  1  1   1   0   0   0   0  5  3\n  Knitting Cards_games Gambling Cooking DIY Vegetable_garden Ornamental_garden\n1        0           0        0       0   1                0                 0\n2        0           0        0       0   0                0                 0\n3        0           0        0       1   0                1                 0\n4        1           0        0       1   0                1                 0\n5        0           0        1       0   0                0                 0\n6        0           1        0       1   1                1                 1\n  Fishing_hunting Collection Vehicle_custom No_Amateur A1012 A1013 A1101 A1102\n1               1          1              1          0     0     0    NA    NA\n2               0          0              0          1     0     0    NA    NA\n3               0          0              0          0     0     0    NA    NA\n4               0          0              0          0     0     0    NA    NA\n5               0          0              0          0     0     0     1     0\n6               0          0              0          0     0     0     1     0\n  A1103 A1104 A1105 A1106 A1107 A1108 A1109 A1110 A1111 A1112 A1113 A12 A13\n1    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   1   1\n2    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   1   1\n3    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   2  NA\n4    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   2  NA\n5     0     0     0     0     0     0     0     0     0     0     0   2  NA\n6     0     0     0     0     0     1     0     0     0     0     0   1   3\n  Making_music Diary Writing Painting Montage Circus Pottery Theater Drawing\n1            0     0       0        0       0      0       0       0       0\n2            1     0       0        1       1      0       0       0       1\n3            1     0       0        1       0      0       0       0       0\n4            0     0       0        0       0      0       0       0       0\n5            0     0       0        0       0      0       0       0       0\n6            0     0       0        0       0      0       0       0       0\n  Dancing Photography Genealogy Science None A1915 A1916 RECODE_A21 A20_musique\n1       0           1         0       0    0     0     0          1          NA\n2       0           1         0       1    0     0     0          4           8\n3       0           0         0       0    0     0     0          2          44\n4       0           0         0       0    1     0     0         NA          NA\n5       0           0         0       0    1     0     0         NA          NA\n6       0           0         0       0    1     0     0         NA          NA\n  A21_musique A22_musique A23_musique A241_musique A242_musique A243_musique\n1          NA          NA          NA           NA           NA           NA\n2           2          15          NA           NA           NA           NA\n3           1          NA           1            1            0            0\n4          NA          NA          NA           NA           NA           NA\n5          NA          NA          NA           NA           NA           NA\n6          NA          NA          NA           NA           NA           NA\n  A244_musique A245_musique A246_musique A25_musique A261_musique A262_musique\n1           NA           NA           NA          NA           NA           NA\n2           NA           NA           NA          NA            0            0\n3            0            0            0          NA            1            0\n4           NA           NA           NA          NA           NA           NA\n5           NA           NA           NA          NA           NA           NA\n6           NA           NA           NA          NA           NA           NA\n  A263_musique A264_musique A265_musique A266_musique A267_musique A27_musique\n1           NA           NA           NA           NA           NA            \n2            1            0            0            0            0            \n3            0            0            0            0            0         268\n4           NA           NA           NA           NA           NA            \n5           NA           NA           NA           NA           NA            \n6           NA           NA           NA           NA           NA            \n  A28_musique A2901_musique A2902_musique A2903_musique A2904_musique\n1                        NA            NA            NA            NA\n2                         1             1             0             0\n3                         0             0             0             0\n4                        NA            NA            NA            NA\n5                        NA            NA            NA            NA\n6                        NA            NA            NA            NA\n  A2905_musique A2906_musique A2907_musique A2908_musique A2909_musique\n1            NA            NA            NA            NA            NA\n2             0             0             0             0             0\n3             0             0             0             0             1\n4            NA            NA            NA            NA            NA\n5            NA            NA            NA            NA            NA\n6            NA            NA            NA            NA            NA\n  A2910_musique A2911_musique A2912_musique A2913_musique A20_journal\n1            NA            NA            NA            NA          NA\n2             0             0             0             0          NA\n3             0             0             0             0          NA\n4            NA            NA            NA            NA          NA\n5            NA            NA            NA            NA          NA\n6            NA            NA            NA            NA          NA\n  A21_journal A22_journal A23_journal A241_journal A242_journal A243_journal\n1          NA          NA          NA           NA           NA           NA\n2          NA          NA          NA           NA           NA           NA\n3          NA          NA          NA           NA           NA           NA\n4          NA          NA          NA           NA           NA           NA\n5          NA          NA          NA           NA           NA           NA\n6          NA          NA          NA           NA           NA           NA\n  A244_journal A245_journal A246_journal A25_journal A20_romans A21_romans\n1           NA           NA           NA          NA         NA         NA\n2           NA           NA           NA          NA         NA         NA\n3           NA           NA           NA          NA         NA         NA\n4           NA           NA           NA          NA         NA         NA\n5           NA           NA           NA          NA         NA         NA\n6           NA           NA           NA          NA         NA         NA\n  A22_romans A23_romans A241_romans A242_romans A243_romans A244_romans\n1         NA         NA          NA          NA          NA          NA\n2         NA         NA          NA          NA          NA          NA\n3         NA         NA          NA          NA          NA          NA\n4         NA         NA          NA          NA          NA          NA\n5         NA         NA          NA          NA          NA          NA\n6         NA         NA          NA          NA          NA          NA\n  A245_romans A246_romans A25_romans A20_peinture A21_peinture A22_peinture\n1          NA          NA         NA           NA           NA           NA\n2          NA          NA         NA            5            2           15\n3          NA          NA         NA           39            1           NA\n4          NA          NA         NA           NA           NA           NA\n5          NA          NA         NA           NA           NA           NA\n6          NA          NA         NA           NA           NA           NA\n  A23_peinture A241_peinture A242_peinture A243_peinture A244_peinture\n1           NA            NA            NA            NA            NA\n2           NA            NA            NA            NA            NA\n3            2            NA            NA            NA            NA\n4           NA            NA            NA            NA            NA\n5           NA            NA            NA            NA            NA\n6           NA            NA            NA            NA            NA\n  A245_peinture A246_peinture A25_peinture A20_montages A21_montages\n1            NA            NA           NA           NA           NA\n2            NA            NA           NA           15            1\n3            NA            NA            2           NA           NA\n4            NA            NA           NA           NA           NA\n5            NA            NA           NA           NA           NA\n6            NA            NA           NA           NA           NA\n  A22_montages A23_montages A241_montages A242_montages A243_montages\n1           NA           NA            NA            NA            NA\n2           NA            2            NA            NA            NA\n3           NA           NA            NA            NA            NA\n4           NA           NA            NA            NA            NA\n5           NA           NA            NA            NA            NA\n6           NA           NA            NA            NA            NA\n  A244_montages A245_montages A246_montages A25_montages A20_cirque A21_cirque\n1            NA            NA            NA           NA         NA         NA\n2            NA            NA            NA            2         NA         NA\n3            NA            NA            NA           NA         NA         NA\n4            NA            NA            NA           NA         NA         NA\n5            NA            NA            NA           NA         NA         NA\n6            NA            NA            NA           NA         NA         NA\n  A22_cirque A23_cirque A241_cirque A242_cirque A243_cirque A244_cirque\n1         NA         NA          NA          NA          NA          NA\n2         NA         NA          NA          NA          NA          NA\n3         NA         NA          NA          NA          NA          NA\n4         NA         NA          NA          NA          NA          NA\n5         NA         NA          NA          NA          NA          NA\n6         NA         NA          NA          NA          NA          NA\n  A245_cirque A246_cirque A25_cirque A20_poterie A21_poterie A22_poterie\n1          NA          NA         NA          NA          NA          NA\n2          NA          NA         NA          NA          NA          NA\n3          NA          NA         NA          NA          NA          NA\n4          NA          NA         NA          NA          NA          NA\n5          NA          NA         NA          NA          NA          NA\n6          NA          NA         NA          NA          NA          NA\n  A23_poterie A241_poterie A242_poterie A243_poterie A244_poterie A245_poterie\n1          NA           NA           NA           NA           NA           NA\n2          NA           NA           NA           NA           NA           NA\n3          NA           NA           NA           NA           NA           NA\n4          NA           NA           NA           NA           NA           NA\n5          NA           NA           NA           NA           NA           NA\n6          NA           NA           NA           NA           NA           NA\n  A246_poterie A25_poterie A20_theatre A21_theatre A22_theatre A23_theatre\n1           NA          NA          NA          NA          NA          NA\n2           NA          NA          NA          NA          NA          NA\n3           NA          NA          NA          NA          NA          NA\n4           NA          NA          NA          NA          NA          NA\n5           NA          NA          NA          NA          NA          NA\n6           NA          NA          NA          NA          NA          NA\n  A241_theatre A242_theatre A243_theatre A244_theatre A245_theatre A246_theatre\n1           NA           NA           NA           NA           NA           NA\n2           NA           NA           NA           NA           NA           NA\n3           NA           NA           NA           NA           NA           NA\n4           NA           NA           NA           NA           NA           NA\n5           NA           NA           NA           NA           NA           NA\n6           NA           NA           NA           NA           NA           NA\n  A25_theatre A20_dessin A21_dessin A22_dessin A23_dessin A241_dessin\n1          NA         NA         NA         NA         NA          NA\n2          NA          5          1         NA          1           0\n3          NA         NA         NA         NA         NA          NA\n4          NA         NA         NA         NA         NA          NA\n5          NA         NA         NA         NA         NA          NA\n6          NA         NA         NA         NA         NA          NA\n  A242_dessin A243_dessin A244_dessin A245_dessin A246_dessin A25_dessin\n1          NA          NA          NA          NA          NA         NA\n2           0           0           1           0           0         NA\n3          NA          NA          NA          NA          NA         NA\n4          NA          NA          NA          NA          NA         NA\n5          NA          NA          NA          NA          NA         NA\n6          NA          NA          NA          NA          NA         NA\n  A20_danse A21_danse A22_danse A23_danse A241_danse A242_danse A243_danse\n1        NA        NA        NA        NA         NA         NA         NA\n2        NA        NA        NA        NA         NA         NA         NA\n3        NA        NA        NA        NA         NA         NA         NA\n4        NA        NA        NA        NA         NA         NA         NA\n5        NA        NA        NA        NA         NA         NA         NA\n6        NA        NA        NA        NA         NA         NA         NA\n  A244_danse A245_danse A246_danse A25_danse A3001_danse A3002_danse\n1         NA         NA         NA        NA          NA          NA\n2         NA         NA         NA        NA          NA          NA\n3         NA         NA         NA        NA          NA          NA\n4         NA         NA         NA        NA          NA          NA\n5         NA         NA         NA        NA          NA          NA\n6         NA         NA         NA        NA          NA          NA\n  A3003_danse A3004_danse A3005_danse A3006_danse A3007_danse A3008_danse\n1          NA          NA          NA          NA          NA          NA\n2          NA          NA          NA          NA          NA          NA\n3          NA          NA          NA          NA          NA          NA\n4          NA          NA          NA          NA          NA          NA\n5          NA          NA          NA          NA          NA          NA\n6          NA          NA          NA          NA          NA          NA\n  A3009_danse A3010_danse A20_photo A21_photo A22_photo A23_photo A241_photo\n1          NA          NA        30         1        NA         2         NA\n2          NA          NA        13         1        NA         2         NA\n3          NA          NA        NA        NA        NA        NA         NA\n4          NA          NA        NA        NA        NA        NA         NA\n5          NA          NA        NA        NA        NA        NA         NA\n6          NA          NA        NA        NA        NA        NA         NA\n  A242_photo A243_photo A244_photo A245_photo A246_photo A25_photo\n1         NA         NA         NA         NA         NA         2\n2         NA         NA         NA         NA         NA         2\n3         NA         NA         NA         NA         NA        NA\n4         NA         NA         NA         NA         NA        NA\n5         NA         NA         NA         NA         NA        NA\n6         NA         NA         NA         NA         NA        NA\n  A20_genealogie A21_genealogie A22_genealogie A23_genealogie A241_genealogie\n1             NA             NA             NA             NA              NA\n2             NA             NA             NA             NA              NA\n3             NA             NA             NA             NA              NA\n4             NA             NA             NA             NA              NA\n5             NA             NA             NA             NA              NA\n6             NA             NA             NA             NA              NA\n  A242_genealogie A243_genealogie A244_genealogie A245_genealogie\n1              NA              NA              NA              NA\n2              NA              NA              NA              NA\n3              NA              NA              NA              NA\n4              NA              NA              NA              NA\n5              NA              NA              NA              NA\n6              NA              NA              NA              NA\n  A246_genealogie A25_genealogie A20_activite_scientifique\n1              NA             NA                        NA\n2              NA             NA                        15\n3              NA             NA                        NA\n4              NA             NA                        NA\n5              NA             NA                        NA\n6              NA             NA                        NA\n  A21_activite_scientifique A22_activite_scientifique A23_activite_scientifique\n1                        NA                        NA                        NA\n2                         1                        NA                         1\n3                        NA                        NA                        NA\n4                        NA                        NA                        NA\n5                        NA                        NA                        NA\n6                        NA                        NA                        NA\n  A241_activite_scientifique A242_activite_scientifique\n1                         NA                         NA\n2                          0                          0\n3                         NA                         NA\n4                         NA                         NA\n5                         NA                         NA\n6                         NA                         NA\n  A243_activite_scientifique A244_activite_scientifique\n1                         NA                         NA\n2                          0                          1\n3                         NA                         NA\n4                         NA                         NA\n5                         NA                         NA\n6                         NA                         NA\n  A245_activite_scientifique A246_activite_scientifique\n1                         NA                         NA\n2                          0                          0\n3                         NA                         NA\n4                         NA                         NA\n5                         NA                         NA\n6                         NA                         NA\n  A25_activite_scientifique A311 A312 A313 A314 A315 A316 A32 A32BIS A33\n1                        NA    0    0    1    0    0    0   2     NA   1\n2                        NA    1    1    1    0    0    0   2     14   2\n3                        NA    1    0    0    0    0    0  NA     14   2\n4                        NA   NA   NA   NA   NA   NA   NA  NA     NA  NA\n5                        NA   NA   NA   NA   NA   NA   NA  NA     NA  NA\n6                        NA   NA   NA   NA   NA   NA   NA  NA     NA  NA\n  Video_games B2 B3 B401 B402 B403 B404 B405 B406 B407 B408 B409 B410 B5 B601\n1           1  4  4    1    0    0    0    0    0    0    0    0    0  2    1\n2           1  3  2    1    0    0    0    0    1    0    0    0    0  1    0\n3           0 NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA   NA\n4           0 NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA   NA\n5           0 NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA   NA\n6           0 NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA   NA\n  B602 B603 B604 B605 B606 B607 B608 B609 B610 B611 B612 B613 B614 B7 TV C2\n1    0    1    0    0    0    0    0    0    0    0    0    0    0  4  1  1\n2    0    0    1    0    1    1    0    0    1    0    0    0    0  2  1  4\n3   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA  1  2\n4   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA  1  4\n5   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA  1  1\n6   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA  1  1\n  C301 C302 C303 C304 C305 C306 C307 C308 C309 C310 C4 C5 C61 C62 C63 C64 C65\n1    1    1    0    0    0    1    0    0    0    0 NA NA   1   0   0   0   0\n2    1    0    0    0    0    0    0    0    0    0 28 30   1   0   0   1   0\n3    1    1    0    0    0    0    0    0    0    0 NA NA   1   0   0   0   0\n4    1    1    1    0    0    1    0    0    0    0 28 29   1   0   0   0   0\n5    1    0    0    0    0    0    0    0    0    0 29 29   1   0   0   0   0\n6    1    1    1    0    0    0    0    0    0    0  7 24   1   0   0   0   0\n  C66 C67 C701 C702 C703 C704 C705 C706 C707 C708 C709 C710 C711 C712 C713 C8\n1   0   0    1    0    0    0    0    1    1    0    1    0    0    0    0  2\n2   0   0    1    1    0    0    0    0    1    0    1    0    0    0    0  4\n3   0   0    0    0    0    0    0    0    1    0    1    0    0    0    0  4\n4   0   0    1    1    1    1    0    0    0    0    1    1    0    0    0  1\n5   0   0    1    1    0    1    0    0    0    0    0    0    0    0    0  4\n6   0   0    1    0    0    0    0    0    1    0    1    0    0    0    0  4\n  C10 C10_C_1 C11 C12 C12_C_1 C13 C14 C15 C161 C162 C163 C164 C165 C166 C167\n1   1       3   1   1       4   2   4   3    1    0    0    0    0    0    0\n2   1       0   2   1       3   2   3   1    0    1    1    1    0    0    0\n3   1       1   1   1       3   2   3   5   NA   NA   NA   NA   NA   NA   NA\n4   1       5   2   1       7   2   2   5   NA   NA   NA   NA   NA   NA   NA\n5   1      24   2   1       5   1   3   5   NA   NA   NA   NA   NA   NA   NA\n6   1       2   1   1       2   2   2   5   NA   NA   NA   NA   NA   NA   NA\n  C1701 C1702 C1703 C1704 C1705 C1706 C1707 C1708 C1709 C1710 C1711 C1712 C1713\n1     1     0     0     0     0     0     0     0     1     0     0     0     0\n2     1     1     1     1     1     1     1     0     1     1     0     0     0\n3    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n4    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n5    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n6    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n  C18 C19 C2001 C2002 C2003 C2004 C2005 C2006 C2007 C2008 C2009 C2010 C211 C212\n1   4   1     1     0     0     0     0     0     0     0     0     0    1    0\n2   1   2     1     0     0     0     0     1     0     0     0     0    0    1\n3  NA   2     1     1     0     0     0     0     0     0     0     0    1    0\n4  NA   4     0     0     1     0     0     0     0     0     0     0    1    0\n5  NA   1     1     0     0     0     0     0     0     0     0     0    1    0\n6  NA   1     1     1     0     0     0     0     0     0     0     0    1    0\n  C213 C214 C215 C216 C217 C221 C222 C223 C224 C225 C226 C227 C228 C23 C24\n1    0    0    0    0    0    1    0    1    1    0    0    0    0   3   2\n2    0    0    0    0    0    0    1    0    0    1    0    0    0   1   1\n3    0    0    0    0    0    0    0    1    0    0    0    0    0   3   1\n4    0    0    0    0    0    0    0    1    0    0    0    0    0   3   2\n5    0    0    0    0    0    0    0    1    0    0    0    0    0   3   2\n6    0    0    0    0    0    0    0    1    0    0    0    0    0   3   2\n  C2601 C2602 C2603 C2604 C2605 C2606 C2607 C2608 C2609 C2610 C2611 C2612 C2613\n1     1     0     0     1     0     0     0     1     0     1     0     0     0\n2     1     1     0     1     1     0     1     1     0     1     0     0     1\n3     1     0     0     0     0     1     0     0     1     1     0     0     0\n4     0     0     1     0     0     0     0     0     0     0     0     0     0\n5     0     1     0     0     0     0     0     0     0     0     1     0     0\n6     1     1     0     1     0     0     0     0     0     1     0     0     0\n  C2614 C2615 C2616 C2617 C2618 C2701 C2702 C2703 C2704 C2705 C2706 C2707 C2708\n1     0     0     0     0     0     1     0     0     1     0     0     0     0\n2     0     0     0     0     0     1     1     0     0     1     0     0     1\n3     0     0     0     0     0     0     0     0     0     0     0     0     0\n4     0     0     0     0     0     0     0     1     0     0     0     1     0\n5     0     0     0     0     0     0     1     0     0     0     0     0     0\n6     0     0     0     0     0     0     1     0     1     0     0     0     0\n  C2709 C2710 C2711 C2712 C2713 C2714 C2715 C2716 C2717 C2718 C2801 C2802 C2803\n1     0     0     0     0     0     0     0     0     0     0     0     0     0\n2     0     0     0     0     0     0     0     0     0     0     0     0     0\n3     0     0     0     0     0     0     0     0     0     1     0     0     0\n4     0     0     0     0     0     0     0     0     0     0     0     0     0\n5     0     0     1     0     0     0     0     0     0     0     0     0     0\n6     0     0     0     0     0     0     0     0     0     0     0     0     0\n  C2804 C2805 C2806 C2807 C2808 C2809 C2810 C2811 C2812 C2813 C2814 C2815 C2816\n1     0     0     0     0     0     0     0     0     0     0     0     1     1\n2     0     0     1     0     0     0     0     0     0     0     0     0     0\n3     0     0     0     0     0     0     0     0     0     0     0     0     1\n4     0     0     0     0     1     0     0     0     1     0     0     0     0\n5     0     0     0     0     1     0     0     0     0     0     0     0     0\n6     0     0     0     0     1     0     0     0     0     0     0     1     0\n  C2817 C2818 C2901 C2902 C2903 C2904 C2905 C2906 C2907 C2908 C2909 C2910 C2911\n1     0     0     0     0     0     0     0     1     0     0     0     1     0\n2     0     0     1     0     0     1     0     1     0     1     1     1     1\n3     0     0     0     0     1     0     0     1     1     0     0     1     1\n4     0     0     0     0     0     0     0     0     0     0     0     1     1\n5     0     0     0     0     0     0     0     0     0     0     0     0     0\n6     0     0     0     0     0     0     0     1     0     0     0     1     0\n  C2912 C2913 C2914 C2915 C2916 C2917 C30 C31 C3201 C3202 C3203 C3204 C3205\n1     1     0     1     0     0     0   2   2     1     0     0     0     0\n2     0     0     1     0     0     0   1   2     1     0     0     0     0\n3     1     0     0     0     0     0   1   5    NA    NA    NA    NA    NA\n4     0     0     0     0     0     0   2   5    NA    NA    NA    NA    NA\n5     0     0     1     0     0     0   3   5    NA    NA    NA    NA    NA\n6     0     0     1     0     0     0   1   4     0     1     0     0     0\n  C3206 C3207 C3208 C3209 C3210 C331 C332 C333 C334 C335 C336 C337 C341 C342\n1     0     0     0     0     0    1    0    0    0    0    0    0    0    0\n2     1     0     0     0     0    0    1    0    1    0    0    0    0    1\n3    NA    NA    NA    NA    NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n4    NA    NA    NA    NA    NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n5    NA    NA    NA    NA    NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n6     0     0     0     0     0    1    0    0    0    0    0    0    0    0\n  C343 C344 C345 C346 C347 C348 C35 C36 C3801 C3802 C3803 C3804 C3805 C3806\n1    1    0    0    0    0    0   3   2     0     0     0     1     0     0\n2    0    0    1    0    0    0   2   1     0     1     0     1     1     0\n3   NA   NA   NA   NA   NA   NA  NA  NA    NA    NA    NA    NA    NA    NA\n4   NA   NA   NA   NA   NA   NA  NA  NA    NA    NA    NA    NA    NA    NA\n5   NA   NA   NA   NA   NA   NA  NA  NA    NA    NA    NA    NA    NA    NA\n6    1    0    0    0    0    0   3   2     0     0     0     0     0     0\n  C3807 C3808 C3809 C3810 C3811 C3812 C3813 C3814 C3815 C3816 C3817 C3818 C3901\n1     0     0     0     1     0     0     0     0     0     0     0     0     0\n2     1     1     0     1     0     0     1     0     0     0     0     0     0\n3    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n4    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n5    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n6     0     0     0     1     0     1     0     0     0     0     0     0     0\n  C3902 C3903 C3904 C3905 C3906 C3907 C3908 C3909 C3910 C3911 C3912 C3913 C3914\n1     0     0     1     0     0     0     0     0     1     0     0     0     0\n2     1     0     1     1     0     0     0     0     0     0     0     1     0\n3    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n4    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n5    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n6     0     0     0     0     0     0     0     0     0     0     0     0     0\n  C3915 C3916 C3917 C3918 C4001 C4002 C4003 C4004 C4005 C4006 C4007 C4008 C4009\n1     0     0     0     0     0     0     0     0     0     0     0     0     0\n2     0     0     0     0     0     0     0     0     0     0     0     0     0\n3    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n4    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n5    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n6     0     0     0     1     0     0     0     0     0     0     0     0     0\n  C4010 C4011 C4012 C4013 C4014 C4015 C4016 C4017 C4018 C4101 C4102 C4103 C4104\n1     0     0     0     0     0     1     1     0     0     0     0     0     0\n2     0     0     0     0     0     0     1     0     0     1     1     0     1\n3    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n4    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n5    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n6     0     0     0     0     0     1     0     0     0     0     1     0     1\n  C4105 C4106 C4107 C4108 C4109 C4110 C4111 C4112 C4113 C4114 C4115 C4116 C4117\n1     0     0     0     0     0     0     0     0     0     1     0     0     0\n2     0     0     0     0     1     0     0     0     0     0     0     0     0\n3    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n4    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n5    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n6     0     0     0     0     0     0     0     0     1     1     0     0     0\n  C42 D101 D102 D103 D104 D105 D106 D107 D108 D109 D110 D111 D112 D113 D114\n1   4    0    0    0    0    0    0    0    0    1    1    0    0    0    0\n2   1    1    1    1    1    1    1    1    1    1    1    1    0    1    1\n3  NA    0    1    1    0    1    0    0    0    0    0    1    0    1    0\n4  NA    0    0    0    0    0    0    0    0    0    0    0    1    1    0\n5  NA    0    0    0    0    0    0    0    0    0    1    0    0    0    0\n6   4    1    0    0    0    1    0    0    0    0    1    0    0    1    0\n  D115 D116 D117 D2 D31 D32 D33 D34 D35 D36 D37 D38 D39 D41 D42 D43 D44 D5 D6\n1    0    0    0  1   0   1   0   1   0   0   0   0   0   0   1   0   0  3  2\n2    0    0    0  2   0   0   0   0   1   0   0   0   0  NA  NA  NA  NA  2  2\n3    0    0    0  1   1   1   1   0   0   0   0   0   0  NA  NA  NA  NA  1  2\n4    0    0    0  1   1   0   0   0   0   0   0   0   0  NA  NA  NA  NA  3  1\n5    0    0    0  3   1   1   0   0   0   0   0   0   0  NA  NA  NA  NA  3  2\n6    0    0    0  1   1   1   1   0   0   0   0   0   0  NA  NA  NA  NA  2  2\n  D8 Radio E2 E2_C_1 E3      E4 E501 E502 E503 E504 E505 E506 E507 E508 E509\n1  4     1  1      1  1 109.000    0    0    1    1    0    0    0    0    1\n2  2     0 NA        NA      NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n3  1     1  1      2  1 182.718    0    0    0    1    0    0    0    0    0\n4  1     1  1      2  3   5.000    0    0    0    0    0    0    0    0    0\n5  4     1  2        NA 294.000    0    0    0    0    0    0    0    0    0\n6  1     1  1      1  1 181.719    0    0    0    1    0    0    1    0    1\n  E510 E511 E512 E513 E514 E6 E7 E81 E82 E83 E84 E85 E86 E87 E88 E89 E8BIS\n1    0    0    0    0    0  2  1   1   0   0   0   0   1   0   0   0     1\n2   NA   NA   NA   NA   NA NA  1   0   0   1   0   0   0   0   0   0     1\n3    1    0    0    0    0  1  1   1   0   1   0   0   1   0   0   0     1\n4    0    1    0    0    0  2  5   1   0   0   0   0   1   1   0   0     3\n5    0    1    0    0    0  2  3   0   0   0   0   0   0   1   0   0     3\n6    0    0    0    0    0  2  1   0   0   0   0   0   1   0   0   0     1\n  E1001 E1002 E1003 E1004 E1005 E1006 E1007 E1008 E1009 E1010 E1011 E1012 E1013\n1     0     0     0     1     0     0     0     0     1     0     0     0     0\n2     0     0     0     0     0     0     1     0     0     0     0     0     0\n3     1     0     0     1     0     0     0     0     1     1     1     0     0\n4     1     0     0     0     0     0     0     0     0     0     1     0     1\n5     1     0     0     0     0     0     0     0     0     1     0     0     0\n6     1     0     1     0     0     0     0     0     1     1     0     0     0\n  E1014 E1015 E1201 E1202 E1203 E1204 E1205 E1206 E1207 E1208 E1209 E1210 E1211\n1     0     0     0     0     0     1     0     0     0     0     1     0     0\n2     0     0     0     0     0     0     0     0     1     0     0     0     0\n3     0     0     0     0     0     0     0     0     0     0     1     0     0\n4     0     0     1     0     1     0     0     0     0     0     0     0     1\n5     0     0     0     0     0     0     0     0     0     0     0     0     0\n6     0     0     0     0     0     1     0     0     0     0     0     0     0\n  E1212 E1213 E1214 E1215 E1301 E1302 E1303 E1304 E1305 E1306 E1307 E1308 E1309\n1     0     0     0     0     0     0     0     0     0     1     1     0     0\n2     0     0     0     0     0     0     0     0     0     0     0     0     0\n3     0     0     0     0     0     0     0     0     0     0     1     0     0\n4     0     0     0     0     0     0     0     0     0     0     0     1     0\n5     0     0     1     0     0     0     0     0     0     0     0     0     0\n6     0     0     0     0     0     0     0     0     0     0     1     1     0\n  E1310 E1311 E1312 E1313 E1314 E1315 E1401 E1402 E1403 E1404 E1405 E1406 E1407\n1     0     1     1     0     0     0     1     0     0     0     0     0     0\n2     0     1     1     0     0     0     1     0     1     1     0     1     1\n3     0     0     0     0     0     0     1     1     0     0     0     0     0\n4     1     0     0     0     0     0     0     0     0     0     0     0     0\n5     0     0     0     1     0     0     0     0     0     0     0     0     0\n6     0     1     0     0     0     0     0     0     1     1     0     0     0\n  E1408 E1409 E1410 E1411 E1412 E1413 E1414 E1415 E1416 E1417 E15 E17 E18 E19\n1     0     0     1     1     0     0     0     0     0     0   1   2   4   1\n2     0     0     0     0     1     0     1     1     0     0   1   1   2   1\n3     0     0     1     1     0     0     0     1     0     0   1   2   3   1\n4     0     0     1     1     0     0     1     1     0     0   1  NA  NA   1\n5     0     0     1     0     0     0     0     0     0     0   1   4   4   4\n6     0     0     0     1     0     0     1     0     0     0   1   3   4   1\n  Library F21 F22 F23 F24 F25 F3 F3BIS01 F3BIS02 F3BIS03 F3BIS04 F3BIS05\n1       1  NA  NA  NA  NA  NA  5      NA      NA      NA      NA      NA\n2       0  NA  NA  NA  NA  NA  4       0       0       0       0       0\n3       1  NA  NA  NA  NA  NA  5      NA      NA      NA      NA      NA\n4       1  NA  NA  NA  NA  NA  5      NA      NA      NA      NA      NA\n5       1  NA  NA  NA  NA  NA  5      NA      NA      NA      NA      NA\n6       1  NA  NA  NA  NA  NA  5      NA      NA      NA      NA      NA\n  F3BIS06 F3BIS07 F3BIS08 F3BIS09 F3BIS10 F4 F5 F601 F602 F603 F604 F605 F606\n1      NA      NA      NA      NA      NA NA  2    0    1    1    0    0    0\n2       0       1       0       0       0  4  4   NA   NA   NA   NA   NA   NA\n3      NA      NA      NA      NA      NA NA  3    0    0    0    0    0    0\n4      NA      NA      NA      NA      NA NA  3    0    0    0    0    0    0\n5      NA      NA      NA      NA      NA NA  4   NA   NA   NA   NA   NA   NA\n6      NA      NA      NA      NA      NA NA  4   NA   NA   NA   NA   NA   NA\n  F607 F608 F609 F610 F611 F612 F613 F614 F615 F616 F617 F618 F619 F620 F701\n1    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0\n2   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n3    0    1    1    0    0    0    0    1    0    1    0    0    0    0    0\n4    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0\n5   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n6   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n  F702 F703 F704 F705 F706 F707 F708 F709 F710 F711 F712 F713 F714 F715 F716\n1    1    1    0    0    0    0    0    0    0    0    0    0    0    1    0\n2   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n3    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0\n4    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1\n5   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n6   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n  F717 F718 F719 F720 F801 F802 F803 F804 F805 F806 F807 F808 F809 F810 F811\n1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1\n2   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n3    0    0    0    0    0    0    1    0    0    0    0    0    0    0    1\n4    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n5   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n6   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n  F812 F813 F814 F815 F816 F817 F818 F819 F820 F9 F11 F11BIS F11TER F121 F122\n1    0    0    0    0    0    0    0    0    0  2   2      2      3    1    0\n2   NA   NA   NA   NA   NA   NA   NA   NA   NA NA  NA     NA     NA   NA   NA\n3    0    0    0    0    0    0    0    0    0  2   3      2      2    1    0\n4    0    0    0    0    0    0    0    1    0  1   4      3      3    1    0\n5   NA   NA   NA   NA   NA   NA   NA   NA   NA NA  NA     NA     NA   NA   NA\n6   NA   NA   NA   NA   NA   NA   NA   NA   NA NA  NA     NA     NA   NA   NA\n  F123 F124 F125 F126 F12BIS F13 F13_C_1 F14 F15 F15_C_1 F1601 F1602 F1603\n1    0    0    0    0     NA   1      10  NA  NA       0     0     0     0\n2   NA   NA   NA   NA     NA  NA       0  NA  NA       0    NA    NA    NA\n3    0    0    0    0     NA   1      12   1   1       9     1     1     1\n4    0    0    0    0     NA   1       3  NA  NA       0     0     0     0\n5   NA   NA   NA   NA     NA  NA       0  NA  NA       0    NA    NA    NA\n6   NA   NA   NA   NA     NA  NA       0  NA  NA       0    NA    NA    NA\n  F1604 F1605 F1606 F1607 F1608 F1609 F1610 F1611 F1612 F1613 F1614 F1615 F1616\n1     1     0     0     0     0     0     0     0     0     0     0     0     0\n2    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n3     0     0     0     0     0     0     0     0     0     0     0     0     0\n4     0     0     0     0     0     0     0     0     0     0     0     0     1\n5    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n6    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n  F1617 F1618 F17 G2401 G2402 G2403 G2404 G2405 G2406 G2407 G2408 G2409 G2410\n1     0     0   1     1     0     0     0     0     0     0     0     1     0\n2    NA    NA  NA     0     0     0     0     0     0     0     0     0     0\n3     0     0   1     1     0     1     1     0     0     0     0     1     1\n4     0     0   4     1     0     0     0     0     0     0     0     0     0\n5    NA    NA  NA     0     0     0     0     0     0     0     0     0     0\n6    NA    NA  NA     1     0     0     1     0     0     0     0     0     0\n  G2411 G2412 Concert G2414 G2415 G2501 G2502 G2503 G2504 G2505 G2506 G2507\n1     0     0       1     0     0     0     0     0     0     0     0     0\n2     0     0       0     0     0    NA    NA    NA    NA    NA    NA    NA\n3     1     1       1     0     0     1     0     0     0     0     0     0\n4     0     0       1     0     0     0     0     0     0     0     0     0\n5     0     0       0     0     0    NA    NA    NA    NA    NA    NA    NA\n6     0     0       1     0     0     0     0     0     1     0     0     0\n  G2508 G2509 G2510 G2511 G2512 G2513 G2514 G2515 G26val_variet_francaise\n1     0     0     0     0     0     1     0     0                      NA\n2    NA    NA    NA    NA    NA    NA    NA    NA                      NA\n3     0     0     0     0     1     0     0     0                       1\n4     0     0     0     0     0     1     0     0                      NA\n5    NA    NA    NA    NA    NA    NA    NA    NA                      NA\n6     0     0     0     0     0     0     0     0                      NA\n  G26val_musiques_monde G26val_musiques_tradi G26val_variet_internationale\n1                    NA                    NA                           NA\n2                    NA                    NA                           NA\n3                    NA                    NA                           NA\n4                    NA                    NA                           NA\n5                    NA                    NA                           NA\n6                    NA                    NA                            1\n  G26val_rnb G26val_electro_techno G26val_hip_hop_rap G26val_metal_hard\n1         NA                    NA                 NA                NA\n2         NA                    NA                 NA                NA\n3         NA                    NA                 NA                NA\n4         NA                    NA                 NA                NA\n5         NA                    NA                 NA                NA\n6         NA                    NA                 NA                NA\n  G26val_pop_rock G26val_jazz G26val_opera G26val_musique_classique\n1              NA          NA           NA                       NA\n2              NA          NA           NA                       NA\n3              NA          NA           NA                        1\n4              NA          NA           NA                       NA\n5              NA          NA           NA                       NA\n6              NA          NA           NA                       NA\n  G26unit_variet_francaise G26unit_musiques_monde G26unit_musiques_tradi\n1                       NA                     NA                     NA\n2                       NA                     NA                     NA\n3                        3                     NA                     NA\n4                       NA                     NA                     NA\n5                       NA                     NA                     NA\n6                       NA                     NA                     NA\n  G26unit_variet_internationale G26unit_rnb G26unit_electro_techno\n1                            NA          NA                     NA\n2                            NA          NA                     NA\n3                            NA          NA                     NA\n4                            NA          NA                     NA\n5                            NA          NA                     NA\n6                             3          NA                     NA\n  G26unit_hip_hop_rap G26unit_metal_hard G26unit_pop_rock G26unit_jazz\n1                  NA                 NA               NA           NA\n2                  NA                 NA               NA           NA\n3                  NA                 NA               NA           NA\n4                  NA                 NA               NA           NA\n5                  NA                 NA               NA           NA\n6                  NA                 NA               NA           NA\n  G26unit_opera G26unit_musique_classique G271 G272 G273 G274 G275 G276 G277\n1            NA                        NA   NA   NA   NA   NA   NA   NA   NA\n2            NA                        NA   NA   NA   NA   NA   NA   NA   NA\n3            NA                         3    1    0    0    0    0    0    0\n4            NA                        NA   NA   NA   NA   NA   NA   NA   NA\n5            NA                        NA   NA   NA   NA   NA   NA   NA   NA\n6            NA                        NA    1    0    0    0    0    0    0\n  G278 G28 G29 G3001 G3002 G3003 G3004 G3005 G3006 G3007 G3008 G3009 G3010 G31\n1   NA  NA  NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA  NA\n2   NA  NA  NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA  NA\n3    0   2   2     0     1     0     0     1     0     0     0     0     0   1\n4   NA  NA  NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA  NA\n5   NA  NA  NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA  NA\n6    0   2   2     0     1     1     0     0     1     0     0     0     0   1\n  G11 G12 G13 G14 G15 G16 G17 G18 G211 G212 G213 G214 G215 G216 G217 G218 G3A\n1   0   0   1   1   1   0   0   0    0    0    1    0    0    0    0    0   2\n2   0   0   0   1   0   0   0   0    0    0    0    0    0    1    0    0   1\n3   0   1   1   1   1   0   0   0    0    0    1    1    0    0    0    0   1\n4   0   0   1   0   0   0   0   0    0    0    0    0    0    1    0    0   2\n5   0   0   0   0   0   1   0   0   NA   NA   NA   NA   NA   NA   NA   NA   2\n6   0   0   1   1   1   0   0   0    0    0    0    1    0    0    0    0   1\n  G3B G6BIS G4 G4_C_1 G5 G6 G701 G702 G703 G704 G705 G706 G707 G708 G709 G710\n1   1     2 NA     NA NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n2  NA     2  1      6  3  2    1    1    0    0    1    0    1    0    0    0\n3  NA     2  1      2  3  2    0    0    0    0    0    1    0    0    0    0\n4   2     2 NA     NA NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n5   1     2 NA     NA NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n6  NA     2  1      6  3  2    1    1    0    1    1    0    0    0    0    0\n  G711 G712 G713 G714 G715 G716 G717 G718 G8 G9 G1001 G1002 G1003 G1004 G1005\n1   NA   NA   NA   NA   NA   NA   NA   NA NA NA    NA    NA    NA    NA    NA\n2    0    0    1    0    0    0    0    0  1 NA     0     0     0     0     0\n3    0    0    0    0    0    0    0    0  2  2     0     1     0     0     1\n4   NA   NA   NA   NA   NA   NA   NA   NA NA NA    NA    NA    NA    NA    NA\n5   NA   NA   NA   NA   NA   NA   NA   NA NA NA    NA    NA    NA    NA    NA\n6    0    0    0    0    0    0    0    0  2  2     0     1     0     0     0\n  G1006 G1007 G1008 G1009 G1010 G111 G121 G122 G123 G124 G125 G126 G127 G131\n1    NA    NA    NA    NA    NA   NA    1    1    1    1    0    0    0    0\n2     1     0     0     0     0    2    0    1    1    1    0    0    0    0\n3     0     0     0     0     0    1    1    1    1    1    0    0    0    0\n4    NA    NA    NA    NA    NA   NA    0    0    1    0    0    0    0    0\n5    NA    NA    NA    NA    NA   NA    0    0    1    0    0    0    0    0\n6     0     0     0     0     0    1    0    0    1    1    0    0    0    0\n  G132 G133 G134 G135 G136 G137 G14val_danse G14val_cirque G14val_spectacle_rue\n1    0    1    0    0    0    0           NA            NA                    2\n2    0    0    0    1    0    0           NA            NA                   NA\n3    0    0    0    1    0    0           NA            NA                   NA\n4    0    1    0    0    0    0           NA            NA                    1\n5    0    0    0    1    0    0           NA            NA                   NA\n6    0    1    1    0    0    0           NA            NA                    1\n  G14val_theatre G14unit_danse G14unit_cirque G14unit_spectacle_rue\n1             NA            NA             NA                     3\n2             NA            NA             NA                    NA\n3             NA            NA             NA                    NA\n4             NA            NA             NA                     3\n5             NA            NA             NA                    NA\n6              4            NA             NA                     3\n  G14unit_theatre G161 G162 G163 G164 G165 G166 G167 G171 G172 G173 G174 G175\n1              NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n2              NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n3              NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n4              NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n5              NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n6               3   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n  G176 G17B01 G17B02 G17B03 G17B04 G17B05 G17B06 G17B07 G17B08 G17B09 G17B10\n1   NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA\n2   NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA\n3   NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA\n4   NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA\n5   NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA\n6   NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA\n  G181 G182 G183 G184 G185 G186 G187 G188 G189 G20A1 G20A2 G20A3 G20A4 G20A5\n1    1    0    1    0    0    0    0    0    0    NA    NA    NA    NA    NA\n2   NA   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA    NA    NA    NA\n3   NA   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA    NA    NA    NA\n4    1    0    0    0    0    0    0    0    0    NA    NA    NA    NA    NA\n5   NA   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA    NA    NA    NA\n6    1    0    1    0    0    0    0    0    0     0     0     1     1     0\n  G20A6 G20A7 G20B G21 G2201 G2202 G2203 G2204 G2205 G2206 G2207 G2208 G2209\n1    NA    NA   NA  NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n2    NA    NA   NA  NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n3    NA    NA   NA  NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n4    NA    NA   NA  NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n5    NA    NA   NA  NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n6     0     0    2   2     0     1     0     0     0     1     0     0     0\n  G2210 G23 G32 G331 G332 G333 G334 G335 G336 G337 G338 G339 G351 G352 G353\n1    NA   3   2   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n2    NA  NA   2   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n3    NA  NA   1    1    0    0    0    0    0    0    0    0    1    0    0\n4    NA   4   2   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n5    NA  NA   2   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n6     0   1   2   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n  G354 G355 G356 G357 G36 G37 G3801 G3802 G3803 G3804 G3805 G3806 G3807 G3808\n1   NA   NA   NA   NA  NA  NA    NA    NA    NA    NA    NA    NA    NA    NA\n2   NA   NA   NA   NA  NA  NA    NA    NA    NA    NA    NA    NA    NA    NA\n3    0    0    0    0   2   2     0     1     0     0     0     0     0     0\n4   NA   NA   NA   NA  NA  NA    NA    NA    NA    NA    NA    NA    NA    NA\n5   NA   NA   NA   NA  NA  NA    NA    NA    NA    NA    NA    NA    NA    NA\n6   NA   NA   NA   NA  NA  NA    NA    NA    NA    NA    NA    NA    NA    NA\n  G3809 G3810 G39 H101 H102 H103 H104 H105 H106 H107 H108 H109 H110 H111\n1    NA    NA  NA    0    1    0    1    0    0    0    0    1    1    0\n2    NA    NA  NA    1    1    1    1    0    1    1    1    1    1    1\n3     0     0   2    0    0    1    1    0    1    1    0    1    1    0\n4    NA    NA  NA    0    0    1    1    0    0    1    0    1    0    0\n5    NA    NA  NA    0    0    1    1    0    0    0    0    0    0    0\n6    NA    NA  NA    1    1    1    1    0    1    1    1    1    1    0\n  Museums H113 H114 H201 H202 H203 H204 H205 H206 H207 H208 H209 H210 H211 H212\n1       1    0    0    0    0    0    0    0    0    0    0    1    0    0    0\n2       1    0    0    1    1    1    0    0    1    1    0    1    1    1    0\n3       1    0    0    0    0    0    0    0    0    0    0    0    1    0    0\n4       1    0    0    0    0    1    0    0    0    0    0    0    0    0    0\n5       1    0    0    0    0    0    0    0    0    0    0    0    0    0    1\n6       1    0    0    0    0    0    0    0    1    0    0    1    0    0    0\n  H214 H215 H301 H302 H303 H304 H305 H306 H307 H308 H309 H310 H4 H4_C_1 H4F H51\n1    0    0   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA     NA  NA  NA\n2    0    0    1    1    1    0    1    0    0    0    0    0  1      5   3   1\n3    0    0    0    0    0    0    1    0    0    0    0    0  1      1   3   1\n4    0    0   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA     NA  NA  NA\n5    0    0   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA     NA  NA  NA\n6    0    0   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA     NA  NA  NA\n  H52 H53 H54 H55 H56 H57 H6 H7 H801 H802 H803 H804 H805 H806 H807 H808 H809\n1  NA  NA  NA  NA  NA  NA NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n2   0   1   1   0   0   0  3  3    0    0    0    0    1    0    1    0    0\n3   0   0   0   0   0   0  2  1    0    1    0    0    1    0    0    0    0\n4  NA  NA  NA  NA  NA  NA NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n5  NA  NA  NA  NA  NA  NA NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n6  NA  NA  NA  NA  NA  NA NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n  H810 H9 H1001 H1002 H1003 H1004 H1005 H1006 H1007 H1008 H1009 H1010 H11\n1   NA NA     1     1     1     1     1     1     0     0     0     0   1\n2    0  3     1     1     1     1     1     0     0     0     0     0   1\n3    0  2     0     0     0     0     0     0     0     1     0     0  NA\n4   NA NA     0     0     0     0     0     0     0     1     0     0  NA\n5   NA NA     0     0     0     0     0     0     0     1     0     0  NA\n6   NA NA     1     1     1     1     0     0     0     0     0     0   1\n  H11_C_1 H11F H121 H122 H123 H124 H125 H126 H127 H13 H14 H1501 H1502 H1503\n1      10    3    1    0    0    0    0    0    0   2   1     1     1     0\n2      10    3    1    0    1    1    0    0    0   3   3     0     0     0\n3      NA   NA   NA   NA   NA   NA   NA   NA   NA  NA  NA    NA    NA    NA\n4      NA   NA   NA   NA   NA   NA   NA   NA   NA  NA  NA    NA    NA    NA\n5      NA   NA   NA   NA   NA   NA   NA   NA   NA  NA  NA    NA    NA    NA\n6       3    3    1    0    1    1    0    0    0   1  NA     0     1     0\n  H1504 H1505 H1506 H1507 H1508 H1509 H1510 H16 I101 I102 I103 I104 I105 I106\n1     0     1     1     0     0     0     0   1    1    1    1    1    0    0\n2     0     1     0     1     0     0     0   2    0    1    0    1    1    1\n3    NA    NA    NA    NA    NA    NA    NA  NA    1    1    0    1    1    0\n4    NA    NA    NA    NA    NA    NA    NA  NA    1    1    0    1    0    0\n5    NA    NA    NA    NA    NA    NA    NA  NA    1    1    0    0    0    0\n6     0     0     1     0     0     0     0   1    0    1    1    1    0    0\n  I107 I108 I109 I110 I111 I112 I113 I114 I115 I2 I3 Internet I5 I6 I71 I72 I73\n1    1    1    0    0    1    1    0    0    0  1  3        1  2 NA   0   0   0\n2    1    0    1    1    1    1    0    0    0  3  3        1  1  1   0   0   0\n3    1    0    1    1    1    1    0    0    0  1  3        1  1  1   1   0   0\n4    1    0    0    0    1    0    0    0    0  1 NA        0  2 NA  NA  NA  NA\n5    0    0    0    0    1    0    0    0    0  1 NA        0  2 NA  NA  NA  NA\n6    1    1    1    1    1    1    0    0    0  3  3        1  2 NA   1   0   0\n  I74 I75 I76 I77 I78 I79 SITUA TRAVAIL ACTIVANTE STATUTECL STATUT CS2D\n1   0   0   0   1   0   0     1      NA        NA         3      3   48\n2   0   0   0   1   0   0     3       2         2        NA     NA   NA\n3   0   0   0   0   0   0     1      NA        NA         8      2   33\n4  NA  NA  NA  NA  NA  NA     5       2         1        NA     NA   NA\n5  NA  NA  NA  NA  NA  NA     5       2         1        NA     NA   NA\n6   0   0   0   0   0   0     1      NA        NA         6      6   37\n  TYPEMPLOI TEMPTRAV SUPERVISION CLASSIF CLASSIF2 SALARIES\n1         6       NA           1       4       NA       NA\n2        NA       NA          NA      NA       NA       NA\n3         6        1           3      NA        5       NA\n4        NA       NA          NA      NA       NA       NA\n5        NA       NA          NA      NA       NA       NA\n6         6       NA           1      NA       NA        3\n                ACTIVLIB STATUTECLANTE STATUTANTE CS2D_ante SUPERVISIONANTE\n1  Transport automobiles            NA         NA        NA              NA\n2                                   NA         NA        NA              NA\n3 Bailleur public social            NA         NA        NA              NA\n4                                    3          3        56               3\n5                                    3          3        64               3\n6             Restaurant            NA         NA        NA              NA\n  CLASSIFANTE CLASSIFANTE2 RECHEMPLOI S10 S10_C_1 S11 S11_C_1 S12 S12_C_1\n1          NA           NA          3   1       5   1      35   1      30\n2          NA           NA         NA  NA      NA  NA          NA        \n3          NA           NA          3   1       5   1      38   1     110\n4           6           NA          3  NA      NA  NA          NA        \n5           2           NA          3  NA      NA  NA          NA        \n6          NA           NA          3   1       7   1      45   1       3\n  SITUA_conj TRAVAIL_conj ACTIVANTE_conj STATUTECL_conj STATUT_conj CS2D_conj\n1         NA           NA             NA             NA          NA        NA\n2         NA           NA             NA             NA          NA        NA\n3          1           NA             NA              1           1        42\n4          5            2              1             NA          NA        NA\n5         NA           NA             NA             NA          NA        NA\n6          1           NA             NA              3           3        37\n  TYPEMPLOI_conj TEMPTRAV_conj SUPERVISION_conj CLASSIF_conj CLASSIF2_conj\n1             NA            NA               NA           NA            NA\n2             NA            NA               NA           NA            NA\n3              6             1                3           NA             5\n4             NA            NA               NA           NA            NA\n5             NA            NA               NA           NA            NA\n6              6            NA                3            5            NA\n  SALARIES_conj     ACTIVLIB_conj STATUTECLANTE_conj STATUTANTE_conj\n1            NA                                   NA              NA\n2            NA                                   NA              NA\n3            NA        Coll\\xe8ge                 NA              NA\n4            NA                                    3               3\n5            NA                                   NA              NA\n6            NA Assurance maladie                 NA              NA\n  CS2D_ante_conj SUPERVISIONANTE_conj CLASSIFANTE_conj CLASSIFANTE2_conj\n1             NA                   NA               NA                NA\n2             NA                   NA               NA                NA\n3             NA                   NA               NA                NA\n4             68                    3                1                NA\n5             NA                   NA               NA                NA\n6             NA                   NA               NA                NA\n  RECHEMPLOI_conj AGDIP DATDIP DATDIP_C_1 DIPLOM DIPLOMACT FORMEL NAIM NAIP\n1              NA    NA      1       1976      6        NA      2    1    1\n2              NA    NA      1       2017      5         4      1   NA   NA\n3               3    NA      1       1993     10        NA      2    1    1\n4               3    NA     NA         NA      2        NA      2    2    2\n5              NA    NA      1       1966      4        NA      2    1    1\n6               3    NA      1       1983      6        NA      2    1    1\n  NATIO1N1 NATIO1N2 NATIO1N3 NATIO1N4 NATIO1N5 NATIO1N6 NATIOM NATIOP SPECIAL\n1        1        0        0        0        0        0      1      1      NA\n2        1        0        0        0        0        0      1      1      NA\n3        1        0        0        0        0        0      1      1     315\n4        0        0        1        0        0        0      2      2      NA\n5        1        0        0        0        0        0      1      1      NA\n6        1        0        0        0        0        0      1      1      NA\n  SPECIAL_CODE_CITE_13 SPECIALACT SPECIALACT_CODE_CITE_13 AGDIP_conj\n1                   NA         NA                      NA         NA\n2                   NA        708                     732         NA\n3                  421         NA                      NA         NA\n4                   NA         NA                      NA         NA\n5                   NA         NA                      NA         NA\n6                   NA         NA                      NA         NA\n  DATDIP_conj DATDIP_C_1_conj DIPLOM_conj DIPLOMACT_conj FORMEL_conj NAIM_conj\n1          NA              NA          NA             NA          NA        NA\n2          NA              NA          NA             NA          NA        NA\n3           1            1997          12             NA           2         1\n4          NA              NA           1             NA           2         2\n5          NA              NA          NA             NA          NA        NA\n6           1            1981           7             NA           2         1\n  NAIP_conj NATIO1N1_conj NATIO1N2_conj NATIO1N3_conj NATIO1N4_conj\n1        NA            NA            NA            NA            NA\n2        NA            NA            NA            NA            NA\n3         1             1             0             0             0\n4         2             0             0             1             0\n5        NA            NA            NA            NA            NA\n6         1             1             0             0             0\n  NATIO1N5_conj NATIO1N6_conj NATIOM_conj NATIOP_conj SPECIAL_conj\n1            NA            NA          NA          NA           NA\n2            NA            NA          NA          NA           NA\n3             0             0           1           1          805\n4             0             0           2           2           NA\n5            NA            NA          NA          NA           NA\n6             0             0           1           1           NA\n  SPECIAL_CODE_CITE_13_conj SPECIALACT_conj SPECIALACT_CODE_CITE_13_conj M1_SQ1\n1                        NA              NA                           NA      3\n2                        NA              NA                           NA      1\n3                      1014              NA                           NA      1\n4                        NA              NA                           NA      4\n5                        NA              NA                           NA      4\n6                        NA              NA                           NA      1\n  M1_SQ2 M1_SQ3 M1_SQ4 M1_SQ5 M1_SQ7 M1_SQ8 M1_SQ9 M1_SQ10 M1_SQ11 M1_SQ12 M201\n1      1      1      1      4      4      2      4       2       2       4    1\n2      2      3      1      1      1      1      4       3       1       2    0\n3      1      1      1      3      4      4      4       4       4       3    1\n4      4      4      4      4      4      4      4       4       4       4    0\n5      4      4      5      4      4      4      4       4       4       4    0\n6      1      3      2      1      4      4      4       4       4       4    1\n  M202 M203 M204 M205 M206 M207 M208 M209 M210 M211 M212 M213 M214 M215 M216\n1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n2    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0\n3    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n4    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0\n5    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0\n6    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n  M301 M302 M303 M304 M305 M306 M307 M308 M309 M310 M311 M312 M313 M314 M315\n1    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n2    1    1    0    1    0    0    0    0    0    0    0    0    0    0    0\n3    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n4    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0\n5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1\n6    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n  M316 M401 M402 M403 M404 M405 M406 M407 M408 M409 M410 M7_1 M7_2 M7_3 M81 M82\n1    0    1    1    0    0    0    0    0    0    0    0   NA   NA   NA  NA  NA\n2    0    1    1    0    0    0    0    0    0    0    0   NA   NA   NA  NA  NA\n3    0    1    1    0    0    0    0    0    0    0    0   NA   NA   NA  NA  NA\n4    0    1    1    0    0    0    0    0    0    0    0   NA   NA   NA  NA  NA\n5    0    1    1    0    0    0    0    0    0    0    0   NA   NA   NA  NA  NA\n6    0    1    1    0    0    0    0    0    0    0    0   NA   NA   NA  NA  NA\n  adulte_enfance1 adulte_enfance2 adultes_enfance M9_adulte1 M9_BIS1_adulte1\n1              NA              NA              12         NA              NA\n2               1               2              12          1              NA\n3              NA              NA              12         NA              NA\n4               1               2              12          6              NA\n5               1               2              12          1              NA\n6               1               2              12          1              NA\n  M9_BIS2_adulte1 M9_adulte2 M9_BIS1_adulte2 M9_BIS2_adulte2 M121 M122 M123\n1              NA         NA              NA              NA    1    0    0\n2              NA          1              NA              NA    0    1    0\n3              NA         NA              NA              NA    1    0    0\n4              NA          6              NA              NA    0    1    0\n5              NA          1              NA              NA    1    0    0\n6              NA          1              NA              NA    0    1    0\n  M124 M125 M14 M16 M17 M18 STATUTECLCD_PER STATUTCD_PER CSTOT_PER\n1    0    0   2   1   1   1               3            3        65\n2    0    0   2   2  NA   1               1            1        53\n3    0    0   1   2  NA   1               1            1        52\n4    0    0   1   1   4   1               7            7        21\n5    0    0   2   1   1   1               3            3        67\n6    0    0   1   1   2   1               7            7        21\n  CLASSIFCD_PER1 CLASSIFCD_PER2 M19 M20 STATUTECLCD_MER STATUTCD_MER CSTOT_MER\n1              2             NA   6   1               4            4        56\n2             NA              4   7   1               2            2        52\n3             NA              6   4   1               3            3        55\n4             NA             NA   1   2              NA           NA        99\n5              8             NA  14   1               3            3        54\n6             NA             NA   6   1               5            5        21\n  CLASSIFCD_MER1 CLASSIFCD_MER2 M21 CATLOGAC EMMENAG EMMENAG_C_1 STOC ACC\n1              6             NA  14        1       1        1959    2   2\n2             NA              6   3        1       1        2012    5   2\n3              6             NA   4        1       1        2002    2   2\n4             NA             NA   1        1       1        1991    2   2\n5              6             NA  14        1       1        2003    2   2\n6             NA             NA   2        1       1        1991    2   2\n  C9_anglais C9_espagnol C9_portugais C9_italien C9_allemand C9_arabe\n1        Non         Non          Non        Non         Non      Non\n2                                                                    \n3                                                                    \n4        Non         Non          Oui        Non         Non      Non\n5                                                                    \n6                                                                    \n  C9_autreslangues C25_anglais C25_espagnol C25_portugais C25_italien\n1              Oui                                                   \n2                          Oui          Oui           Non         Oui\n3                          Oui          Non           Non         Non\n4              Non                                                   \n5                                                                    \n6                                                                    \n  C25_allemand C25_arabe C25_coreen C25_japonais C25_autreslangues C37_anglais\n1                                                                             \n2          Non       Non        Non          Non               Non         Non\n3          Non       Non        Non          Non               Non            \n4                                                                             \n5                                                                             \n6                                                                             \n  C37_espagnol C37_italien C37_allemand C37_arabe C37_japonais\n1                                                             \n2          Oui         Non          Non       Non          Non\n3                                                             \n4                                                             \n5                                                             \n6                                                             \n  C37_autreslangues D7_anglais D7_espagnol D7_italien D7_allemand D7_portugais\n1                                                                             \n2               Non                                                           \n3                                                                             \n4                          Non         Non        Non         Non          Oui\n5                                                                             \n6                                                                             \n  D7_arabe D7_autreslangues E16_anglais E16_espagnol E16_italien E16_allemand\n1                                   Oui          Non         Non          Non\n2                                   Oui          Non         Non          Non\n3                                   Oui          Non         Non          Non\n4      Non              Non         Non          Non         Non          Non\n5                                   Non          Non         Non          Non\n6                                   Oui          Non         Non          Non\n  E16_portugais E16_arabe E16_turc E16_chinois E16_coreen E16_japonais\n1           Non       Non      Non         Non        Non          Non\n2           Non       Non      Non         Non        Non          Non\n3           Non       Non      Non         Non        Non          Non\n4           Oui       Non      Non         Non        Non          Non\n5           Non       Non      Non         Non        Non          Non\n6           Non       Non      Non         Non        Non          Non\n  E16_russe E16_autreslangues F10_anglais F10_espagnol F10_italien F10_allemand\n1       Non               Non                                                  \n2       Non               Non                                                  \n3       Non               Non                                                  \n4       Non               Non         Non          Non         Non          Non\n5       Non               Non                                                  \n6       Non               Non                                                  \n  F10_portugais F10_arabe F10_autreslangues M13_anglais M13_espagnol\n1                                                                   \n2                                                   Oui          Non\n3                                                                   \n4           Oui       Non               Non         Non          Non\n5                                                                   \n6                                                   Oui          Non\n  M13_italien M13_allemand M13_portugais M13_arabe M13_autreslangues\n1                                                                   \n2         Oui          Non           Non       Non               Non\n3                                                                   \n4         Non          Non           Oui       Non               Non\n5                                                                   \n6         Non          Non           Non       Non               Non\n  M15_anglais M15_espagnol M15_italien M15_allemand M15_portugais M15_arabe\n1                                                                          \n2                                                                          \n3         Oui          Non         Non          Oui           Non       Non\n4         Non          Non         Non          Non           Oui       Non\n5                                                                          \n6         Oui          Non         Non          Non           Non       Non\n  M15_autreslangues   Sex satisfaction Income Health Couple age_group  identity\n1                     Men          Low Medium   Good     No   [54-67[ 0.8624142\n2                     Men       Medium   High   Good     No   [15-38[ 0.5073268\n3               Non   Men         High   High    Bad    Yes   [38-54[ 0.3504244\n4               Non Women         High    Low Medium    Yes   [54-67[ 0.3681533\n5                     Men         High    Low Medium     No   [54-67[ 0.4284777\n6               Non   Men          Low   High   Good    Yes   [38-54[ 0.3848315\n      indice identity_scale    distance distance_abs categories categories_abs\n1  2.8024423 Very Masculine  3.36401698   3.36401698  Masculine    Medium_high\n2  0.5427446              3  0.63666730   0.63666730   Feminine   Low Distance\n3 -0.4557477              2 -0.56846635   0.56846635   Feminine   Low Distance\n4 -0.3429253              2  0.41247337   0.41247337   Feminine   Low Distance\n5  0.0409659              2  0.03104383   0.03104383   Feminine   Low Distance\n6 -0.2367887              2 -0.30419303   0.30419303   Feminine   Low Distance\n       score score_normalise    score_scale mean_score_by_gender\n1 -4.7431719       0.1076284 Very Masculine            0.4189343\n2 -1.0152326       0.3660092              2            0.4189343\n3  1.6901460       0.5535170              3            0.4189343\n4  3.9975170       0.7134392              4            0.5953428\n5 -0.1747180       0.4242646              2            0.4189343\n6  0.7268407       0.4867510              3            0.4189343\n  distance_to_mean_gender    score_2 score_normalise_2 distance_abs_score\n1             0.311305867 -5.5039343         0.1089070          3.8565094\n2             0.052925125 -2.0626560         0.3443974          0.3842434\n3             0.134582688  1.1780061         0.5661594          0.9559863\n4             0.118096370  3.7610020         0.7429166          0.1789834\n5             0.005330327 -0.8392860         0.4281139          1.1654076\n6             0.067816700 -0.3775367         0.4597119          0.1398309\n  norm_status\n1 Hors normes\n2     Normaux\n3     Normaux\n4     Normaux\n5     Normaux\n6     Normaux\n\n\nShow the code\n# Calculer la proportion de \"hors normes\"\ntotal_individuals &lt;- nrow(my_data_frame)\nhors_normes &lt;- sum(my_data_frame$norm_status == \"Hors normes\")\n\nproportion_hors_normes &lt;- hors_normes / total_individuals\nproportion_hors_normes\n\n\n[1] 0.04700022\n\n\nShow the code\n# Calculer la répartition des individus \"hors normes\" par niveau de satisfaction\ntable_satisfaction_hors_normes &lt;- table(my_data_frame$norm_status, my_data_frame$satisfaction)\n\n# Convertir en pourcentage\ntable_satisfaction_hors_normes_percent &lt;- prop.table(table_satisfaction_hors_normes, 1) * 100\ntable_satisfaction_hors_normes_percent\n\n\n             \n                  High      Low   Medium\n  Hors normes 27.64977 47.23502 25.11521\n  Normaux     34.09168 37.51564 28.39267\n\n\nShow the code\n# Visualisation de la proportion d'individus \"hors normes\"\nggplot(data = data.frame(Status = c(\"Normaux\", \"Hors normes\"), \n                         Proportion = c(1 - proportion_hors_normes, proportion_hors_normes)),\n       aes(x = Status, y = Proportion, fill = Status)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE) +\n  geom_text(aes(label = scales::percent(Proportion)), vjust = -0.5, size = 5) +\n  scale_fill_manual(values = c(\"blue\", \"red\")) +\n  labs(title = \"Proportion d'individus Hors Normes vs Normaux\",\n       x = \"Statut\", y = \"Proportion\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Visualisation avec boxplot pour la distance à la moyenne par niveau de satisfaction\nggplot(my_data_frame, aes(x = satisfaction, y = distance_abs_score, fill = norm_status)) +\n  geom_boxplot(outlier.colour = \"red\", outlier.size = 3, alpha = 0.6) +\n  scale_fill_manual(values = c(\"Normaux\" = \"blue\", \"Hors normes\" = \"red\")) +\n  labs(title = \"Boxplot de la distance à la moyenne par niveau de satisfaction\",\n       x = \"Satisfaction\", y = \"Distance à la moyenne (Distance absolue)\") +\n  theme_minimal() +\n  theme(legend.title = element_blank())\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Proportions de 'score_scale' par genre\ntable_score_gender &lt;- table(my_data_frame$score_scale, my_data_frame$Sex)\ntable_score_gender_percent &lt;- prop.table(table_score_gender, 2) * 100  # Calcul par genre\ntable_score_gender_percent\n\n\n                \n                         Men       Women\n  Very Masculine  0.43248438  0.00000000\n  1               7.73666506  0.35488959\n  2              45.77126382  7.72870662\n  3              40.72561269 39.70820189\n  4               4.92551658 33.49763407\n  5               0.38443056 16.04889590\n  Very Feminine   0.02402691  2.66167192\n\n\nShow the code\n# Proportions de 'satisfaction' par genre\ntable_satisfaction_gender &lt;- table(my_data_frame$satisfaction, my_data_frame$Sex)\ntable_satisfaction_gender_percent &lt;- prop.table(table_satisfaction_gender, 2) * 100  # Calcul par genre\ntable_satisfaction_gender_percent\n\n\n        \n              Men    Women\n  High   35.15399 32.66917\n  Low    35.80366 39.75143\n  Medium 29.04235 27.57940\n\n\nShow the code\n# Visualisation de la répartition des scores par genre\nggplot(as.data.frame(table_score_gender_percent), \n       aes(x = Var1, y = Freq, fill = Var2)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  labs(title = \"Répartition des scores par genre\",\n       x = \"Score (1-7)\", y = \"Proportion (%)\") +\n  scale_y_continuous(labels = scales::percent_format(scale = 1)) +\n  theme_minimal() +\n  theme(legend.title = element_blank()) +\n  geom_text(aes(label = scales::percent(Freq / 100)), \n            position = position_dodge(width = 0.8), vjust = -0.5)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Tableau croisé des proportions de satisfaction par score_scale et genre\ntable_satisfaction_score_gender &lt;- table(my_data_frame$satisfaction, my_data_frame$score_scale, my_data_frame$Sex)\n\n# Calculer les proportions par genre et score_scale\ntable_satisfaction_score_gender_percent &lt;- prop.table(table_satisfaction_score_gender, c(2, 3)) * 100\ntable_satisfaction_score_gender_percent\n\n\n, ,  = Men\n\n        \n         Very Masculine         1         2         3         4         5\n  High         33.33333  27.63975  34.06940  37.64775  36.58537  37.50000\n  Low          38.88889  44.40994  36.75079  33.27423  34.63415  31.25000\n  Medium       27.77778  27.95031  29.17981  29.07801  28.78049  31.25000\n        \n         Very Feminine\n  High         0.00000\n  Low          0.00000\n  Medium     100.00000\n\n, ,  = Women\n\n        \n         Very Masculine         1         2         3         4         5\n  High                   16.66667  29.84694  36.61202  29.99411  30.83538\n  Low                    55.55556  40.81633  36.36364  41.95639  41.64619\n  Medium                 27.77778  29.33673  27.02434  28.04950  27.51843\n        \n         Very Feminine\n  High        28.88889\n  Low         45.92593\n  Medium      25.18519\n\n\n\n\nShow the code\n# Visualisation avec un graphique à barres empilées\nggplot(as.data.frame(table_satisfaction_score_gender_percent), \n       aes(x = Var2, y = Freq, fill = Var1)) +\n  geom_bar(stat = \"identity\", position = \"stack\") +  # Barres empilées\n  scale_fill_manual(values = c(\"1\" = \"red\", \"2\" = \"orange\", \"3\" = \"green\")) +  # Couleurs pour chaque niveau de satisfaction\n  labs(title = \"Répartition de la satisfaction par score et genre\",\n       x = \"Score (1-7)\", y = \"Proportion (%)\") +\n  facet_wrap(~ Var3) +  # Facette par genre\n  scale_y_continuous(labels = scales::percent_format(scale = 1)) +  # Format de pourcentage\n  theme_minimal() +\n  theme(legend.title = element_blank()) +\n  geom_text(aes(label = scales::percent(Freq / 100)), \n            position = position_stack(vjust = 0.5))  # Positionner les étiquettes au centre des barres\n\n\n\n\n\n\n\n\n\nShow the code\nsummary(my_data_frame$score_scale)\n\n\nVery Masculine              1              2              3              4 \n            18            340           2297           3709           1904 \n             5  Very Feminine \n           830            136 \n\n\n\n\nShow the code\n# Calcul des proportions de satisfaction par score_scale et genre\ntable_satisfaction_score_gender &lt;- table(my_data_frame$satisfaction, my_data_frame$score_scale, my_data_frame$Sex)\n\n# Calcul des proportions par score_scale et genre\ntable_satisfaction_score_gender_percent &lt;- prop.table(table_satisfaction_score_gender, c(2, 3)) * 100\n\nprint(table_satisfaction_score_gender_percent)\n\n\n, ,  = Men\n\n        \n         Very Masculine         1         2         3         4         5\n  High         33.33333  27.63975  34.06940  37.64775  36.58537  37.50000\n  Low          38.88889  44.40994  36.75079  33.27423  34.63415  31.25000\n  Medium       27.77778  27.95031  29.17981  29.07801  28.78049  31.25000\n        \n         Very Feminine\n  High         0.00000\n  Low          0.00000\n  Medium     100.00000\n\n, ,  = Women\n\n        \n         Very Masculine         1         2         3         4         5\n  High                   16.66667  29.84694  36.61202  29.99411  30.83538\n  Low                    55.55556  40.81633  36.36364  41.95639  41.64619\n  Medium                 27.77778  29.33673  27.02434  28.04950  27.51843\n        \n         Very Feminine\n  High        28.88889\n  Low         45.92593\n  Medium      25.18519\n\n\nShow the code\n# Convertir la table de proportions en dataframe\ntable_satisfaction_score_gender_df &lt;- as.data.frame(table_satisfaction_score_gender_percent)\n\n# Renommer les colonnes pour plus de clarté\nnames(table_satisfaction_score_gender_df) &lt;- c(\"Satisfaction\", \"Score\", \"Sex\", \"Proportion\")\n\n\n# Convertir la table de proportions en dataframe\ntable_satisfaction_score_gender_df &lt;- as.data.frame(table_satisfaction_score_gender_percent)\n\n# Renommer les colonnes pour plus de clarté\nnames(table_satisfaction_score_gender_df) &lt;- c(\"Satisfaction\", \"Score\", \"Sex\", \"Proportion\")\n\n# Visualisation simple avec ggplot\nggplot(table_satisfaction_score_gender_df, aes(x = factor(Score), y = Proportion, fill = factor(Satisfaction))) +\n  geom_bar(stat = \"identity\", position = \"stack\") +  # Barres empilées\n  labs(title = \"Satisfaction par Score et Genre\", \n       x = \"Score\", y = \"Proportion (%)\") +\n  facet_wrap(~ Sex)  # Facette par sexe\n\n\n\n\n\n\n\n\n\nShow the code\nsave(my_data_frame, file = \"my_data_frame.RData\")"
  },
  {
    "objectID": "normes_identite/CGNI.html#construction-de-lindice",
    "href": "normes_identite/CGNI.html#construction-de-lindice",
    "title": "Notre Mesure: Le Cultural Gender Normativity Index (CGNI)",
    "section": "",
    "text": "L’indice que nous proposons repose donc sur la dernière approche présentée:\nUn indice de mesure continue de l’identité de genre, construit comme un indice composite à partir de dimensions non définies a priori comme genrées.\nMais alors, quelles variables choisir pour représenter ces dimensions du genre?\nNotre choix s’est porté sur les pratiques culturelles des français (leurs loisirs culturels) car ces pratiques sont en effet particulièrement genrées (différenciées selon les sexes biologiques), il nous paraissait pertinent de s’appuyer sur ces dernières pour construire notre indice.\n\n\nEn sociologie, la question de la culture et du Genre fait l’objet de travaux ayant montré combien les pratiques culturelles sont différenciées chez les hommes et les femmes (Octobre (2008)) , et ce, dès l’enfance.\nCette différenciation nous permet d’envisager qu’il y ait des pratiques plus ou moins féminines ou masculines, dans la mesure où en moyenne elles sont plus pratiquées par des hommes ou par des femmes.\nCela signifie qu’il existe des normes genrées dans la pratique ou non d’une activité culturelle: le tricot est essentiellement féminin, la chasse est une activité plutôt pratiquée par les hommes.\nCes exemples sont tirés de l’analyse de nos données, en effet, nous avons utilisé la base de données Enquête sur les pratiques culturelles des Français, 2018.\nCette base de données comprend des informations sur les pratiques culturelles des français (9234 individus interrogés) , ainsi que des données socio-démographiques et porte également une question qui va nous intéresser sur le degré de satisfaction en termes de temps libre.\nCette dernière variable (“Vous arrive-t-il d’avoir le sentiment de manquer de temps libre pour faire tout ce dont vous avez envie?”) a retenu notre attention car elle pourrait être une mesure de l’utilité (satisfaction) de l’individu.\n\n\n\n\ncode R\nlibrary(foreign)\nlibrary(questionr) \nlibrary(ggplot2) \nlibrary(tidyverse) \nlibrary(ggmosaic)\nlibrary(GGally) \nlibrary(dataMaid)\nlibrary(dplyr) \nlibrary(GDAtools)\nlibrary(FactoMineR)\nlibrary(gtsummary) \nlibrary(factoextra)\nlibrary(gtsummary) \nlibrary(kableExtra)\nlibrary(RColorBrewer) \nlibrary(FactoMineR) \nlibrary(xtable) \nlibrary(explor)\n\n\n\n\ncode R\ndata&lt;-read.csv2(\"pc18_quetelet_octobre2023.csv\")\n\n\n\n\ncode R\ndata$Sex &lt;- factor(data$SEXE, \n                            levels = c(1, 2), \n                            labels = c(\"Men\", \"Women\"))\nmy_data_frame &lt;- data |&gt; dplyr::rename( \n  Knitting = A1001 , \n  Cards_games = A1002,  \n  Gambling = A1003 , \n  Cooking = A1004 , \n  DIY = A1005  ,\n  Vegetable_garden = A1006 , \n  Ornamental_garden = A1007,  \n  Fishing_hunting = A1008 , \n  Collection = A1009  ,\n  Vehicle_custom = A1010 , \n  No_Amateur=A1011,\n  Making_music = A1901  ,\n  Diary = A1902  ,\n  Writing = A1903,  \n  Painting = A1904,  \n  Montage = A1905 , \n  Circus = A1906  ,\n  Pottery = A1907 , \n  Theater = A1908 , \n  Drawing = A1909 , \n  Dancing = A1910,  \n  Photography = A1911  ,\n  Genealogy = A1912 , \n  Science = A1913  ,\n  None = A1914  ,\n  Video_games = B1  ,\n  TV = C1  ,\n  Radio = E1  ,\n  Library = F1  ,\n  Museums = H112,  \n  Internet = I4 , \n  Concert = G2413 )\n\n\nmy_data_frame$Video_games &lt;- ifelse(my_data_frame$Video_games == 1, 1, 0)\nmy_data_frame$TV &lt;- ifelse(my_data_frame$TV == 5, 0, 1)\nmy_data_frame$Radio &lt;- ifelse(my_data_frame$Radio == 5, 0, 1)\nmy_data_frame$Library&lt;- ifelse(my_data_frame$Radio == 1, 1, 0)\nmy_data_frame$Museums&lt;- ifelse(my_data_frame$Museums == 1, 0, 1)\nmy_data_frame$Internet&lt;- ifelse(my_data_frame$Internet == 5, 0, 1)\nmy_data_frame$Concert&lt;- ifelse(my_data_frame$Concert == 1, 0, 1)\n\n\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(satisfaction = case_when(\n    A2 %in% 1 ~ \"Low\",      # 1 à 4 -&gt; Low\n    A2 %in% 2 ~ \"Medium\",   # 5 à 7 -&gt; Medium\n    A2 %in% 3 ~ \"High\",    # 8 à 10 -&gt; High\n    TRUE ~ NA_character_              \n  ))  \nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(Income = case_when(\n    CRITREVENU %in% 1:4 ~ \"Low\",      # 1 à 4 -&gt; Low\n    CRITREVENU %in% 5:7 ~ \"Medium\",   # 5 à 7 -&gt; Medium\n    CRITREVENU %in% 8:10 ~ \"High\",    # 8 à 10 -&gt; High\n    TRUE ~ NA_character_              \n  ))\n\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(Health = case_when(\n    A15 %in% 1:2 ~ \"Good\",      # 1 à 4 -&gt; Low\n    A15 %in% 3 ~ \"Medium\",   # 5 à 7 -&gt; Medium\n    A15 %in% 4:5 ~ \"Bad\",    # 8 à 10 -&gt; High\n    TRUE ~ NA_character_              \n  ))\n\n\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(Couple = case_when(\n    VITENCOUPLE %in% 1:2 ~ \"Yes\",     \n    VITENCOUPLE %in% 3~ \"No\",  \n    \n    TRUE ~ NA_character_              \n  ))\n\nquartiles &lt;- quantile(data$AGE, probs = c(0.25, 0.5, 0.75), na.rm = TRUE)\n\nmy_data_frame$age_group &lt;- cut(\n  my_data_frame$AGE,\n  breaks = 4,  # Automatically divide into 4 slices\n  labels = c(\"[15-38[\", \"[38-54[\", \"[54-67[\", \"[67-97[\"),  # Labels optionnels\n  include.lowest = TRUE \n)\n\n\n\n\ncode R\nstat_des_1 &lt;- my_data_frame |&gt;\n    tbl_summary(\n        include = c(\"AGE\", \"Income\", \"Couple\", \"CLASSIF\", \"satisfaction\", \"Health\"),\n        by = \"Sex\",\n        statistic = list(\n            all_continuous() ~ \"{min} - {max}\"\n        )\n    ) |&gt;\n    add_overall(last = TRUE) |&gt;\n    add_p(\n        test.args = list(\n            all_continuous() ~ list(simulate.p.value = TRUE),\n            all_categorical() ~ list(simulate.p.value = TRUE)\n        )\n    )\n\nstat_des_1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\nOverall N = 9,2341\np-value2\n\n\n\n\nAGE\n15 - 95\n15 - 97\n15 - 97\n0.042\n\n\nIncome\n\n\n\n\n\n\n&lt;0.001\n\n\n    High\n1,432 (39%)\n1,464 (33%)\n2,896 (36%)\n\n\n\n\n    Low\n762 (21%)\n1,284 (29%)\n2,046 (25%)\n\n\n\n\n    Medium\n1,476 (40%)\n1,644 (37%)\n3,120 (39%)\n\n\n\n\n    Unknown\n492\n680\n1,172\n\n\n\n\nCouple\n2,444 (59%)\n2,567 (51%)\n5,011 (54%)\n&lt;0.001\n\n\n    Unknown\n4\n9\n13\n\n\n\n\nCLASSIF\n\n\n\n\n\n\n&lt;0.001\n\n\n    1\n123 (8.7%)\n63 (4.5%)\n186 (6.6%)\n\n\n\n\n    2\n454 (32%)\n143 (10%)\n597 (21%)\n\n\n\n\n    3\n190 (13%)\n92 (6.6%)\n282 (10%)\n\n\n\n\n    4\n157 (11%)\n126 (9.1%)\n283 (10%)\n\n\n\n\n    5\n278 (20%)\n236 (17%)\n514 (18%)\n\n\n\n\n    6\n194 (14%)\n703 (51%)\n897 (32%)\n\n\n\n\n    7\n13 (0.9%)\n7 (0.5%)\n20 (0.7%)\n\n\n\n\n    8\n11 (0.8%)\n18 (1.3%)\n29 (1.0%)\n\n\n\n\n    9\n1 (&lt;0.1%)\n1 (&lt;0.1%)\n2 (&lt;0.1%)\n\n\n\n\n    Unknown\n2,741\n3,683\n6,424\n\n\n\n\nsatisfaction\n\n\n\n\n\n\n&lt;0.001\n\n\n    High\n1,461 (35%)\n1,656 (33%)\n3,117 (34%)\n\n\n\n\n    Low\n1,488 (36%)\n2,015 (40%)\n3,503 (38%)\n\n\n\n\n    Medium\n1,207 (29%)\n1,398 (28%)\n2,605 (28%)\n\n\n\n\n    Unknown\n6\n3\n9\n\n\n\n\nHealth\n\n\n\n\n\n\n&lt;0.001\n\n\n    Bad\n322 (7.8%)\n461 (9.1%)\n783 (8.5%)\n\n\n\n\n    Good\n2,984 (72%)\n3,426 (68%)\n6,410 (70%)\n\n\n\n\n    Medium\n841 (20%)\n1,157 (23%)\n1,998 (22%)\n\n\n\n\n    Unknown\n15\n28\n43\n\n\n\n\n\n1 Min - Max; n (%)\n\n\n2 Wilcoxon rank sum test; Pearson’s Chi-squared test with simulated p-value (based on 2000 replicates); Fisher’s Exact Test for Count Data with simulated p-value (based on 2000 replicates)\n\n\n\n\n\n\n\n\nLecture: Parmi les individus de sexe masculin, 59% sont en couple. La différence avec les femmes est significative (p&lt;0,001)\n\n\ncode R\ntable &lt;- my_data_frame |&gt;\n  tbl_summary(\n    include = c(  \"Knitting\" , \n                  \"Cards_games\",  \n                  \"Gambling\" , \n                  \"Cooking\" , \n                  \"DIY\"  ,\n                  \"Vegetable_garden\" , \n                  \"Ornamental_garden\",  \n                  \"Fishing_hunting\" , \n                  \"Collection\"  ,\n                  \"Vehicle_custom\", \n                  \"Making_music\"   ,\n                  \"Diary\" ,\n                  \"Writing\" ,  \n                  \"Painting\",  \n                  \"Montage\"  , \n                  \"Circus\"   ,\n                  \"Pottery\" , \n                  \"Theater\" , \n                  \"Drawing\" , \n                  \"Dancing\",  \n                  \"Photography\"  ,\n                  \"Genealogy\" , \n                  \"Science\"  ,\n                  \"None\"  ,\n                  \"No_Amateur\",\n                  \"Video_games\"  ,\n                  \"TV\" ,\n                  \"Radio\"  ,\n                  \"Library\"  ,\n                  \"Museums\",  \n                  \"Internet\", \n                  \"Concert\"),\n    by = \"Sex\"\n  ) |&gt;\n  add_overall(last = TRUE) |&gt;\n  add_p()\n\ntable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\nOverall N = 9,2341\np-value2\n\n\n\n\nKnitting\n73 (1.8%)\n1,370 (27%)\n1,443 (16%)\n&lt;0.001\n\n\nCards_games\n1,899 (46%)\n2,764 (54%)\n4,663 (50%)\n&lt;0.001\n\n\nGambling\n990 (24%)\n970 (19%)\n1,960 (21%)\n&lt;0.001\n\n\nCooking\n1,685 (40%)\n3,473 (68%)\n5,158 (56%)\n&lt;0.001\n\n\nDIY\n2,667 (64%)\n2,283 (45%)\n4,950 (54%)\n&lt;0.001\n\n\nVegetable_garden\n1,335 (32%)\n1,245 (25%)\n2,580 (28%)\n&lt;0.001\n\n\nOrnamental_garden\n1,793 (43%)\n2,198 (43%)\n3,991 (43%)\n0.8\n\n\nFishing_hunting\n722 (17%)\n212 (4.2%)\n934 (10%)\n&lt;0.001\n\n\nCollection\n395 (9.5%)\n281 (5.5%)\n676 (7.3%)\n&lt;0.001\n\n\nVehicle_custom\n264 (6.3%)\n60 (1.2%)\n324 (3.5%)\n&lt;0.001\n\n\nMaking_music\n1,312 (32%)\n1,830 (36%)\n3,142 (34%)\n&lt;0.001\n\n\nDiary\n285 (6.8%)\n1,206 (24%)\n1,491 (16%)\n&lt;0.001\n\n\nWriting\n410 (9.9%)\n746 (15%)\n1,156 (13%)\n&lt;0.001\n\n\nPainting\n667 (16%)\n1,303 (26%)\n1,970 (21%)\n&lt;0.001\n\n\nMontage\n843 (20%)\n586 (12%)\n1,429 (15%)\n&lt;0.001\n\n\nCircus\n116 (2.8%)\n179 (3.5%)\n295 (3.2%)\n0.044\n\n\nPottery\n264 (6.3%)\n705 (14%)\n969 (10%)\n&lt;0.001\n\n\nTheater\n483 (12%)\n800 (16%)\n1,283 (14%)\n&lt;0.001\n\n\nDrawing\n864 (21%)\n1,285 (25%)\n2,149 (23%)\n&lt;0.001\n\n\nDancing\n410 (9.9%)\n1,782 (35%)\n2,192 (24%)\n&lt;0.001\n\n\nPhotography\n1,175 (28%)\n1,176 (23%)\n2,351 (25%)\n&lt;0.001\n\n\nGenealogy\n513 (12%)\n575 (11%)\n1,088 (12%)\n0.14\n\n\nScience\n611 (15%)\n469 (9.2%)\n1,080 (12%)\n&lt;0.001\n\n\nNone\n1,394 (33%)\n1,261 (25%)\n2,655 (29%)\n&lt;0.001\n\n\nNo_Amateur\n276 (6.6%)\n359 (7.1%)\n635 (6.9%)\n0.4\n\n\nVideo_games\n1,760 (42%)\n1,827 (36%)\n3,587 (39%)\n&lt;0.001\n\n\nTV\n3,878 (93%)\n4,806 (95%)\n8,684 (94%)\n0.001\n\n\nRadio\n3,522 (85%)\n4,186 (83%)\n7,708 (83%)\n0.007\n\n\nLibrary\n3,522 (85%)\n4,186 (83%)\n7,708 (83%)\n0.007\n\n\nMuseums\n4,101 (99%)\n5,009 (99%)\n9,110 (99%)\n0.4\n\n\nInternet\n3,459 (83%)\n4,185 (83%)\n7,644 (83%)\n0.4\n\n\nConcert\n3,344 (80%)\n4,234 (83%)\n7,578 (82%)\n&lt;0.001\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\nLecture: Parmi les hommes, 1.8% déclarent pratiquer le tricot, contre 27% des femmes. Cette activité est pratiquée par 16% des répondants.\nLes p-value &lt;10% indiquent que les différences de participation aux pratiques culturelles sont significativement différentes selon le sexe biologique du répondant.\n\n\n\n\n\n\nNote\n\n\n\nNous retiendrons pour la construction de notre indice les pratiques culturelles suivantes:\n“Knitting” , “Cards_games”,“Gambling” , “Cooking” , “DIY” , “Vegetable_garden” , “Fishing_hunting” , “Collection” , “Vehicle_custom”, “Making_music” , “Diary” , “Writing” ,“Painting”,“Montage” , “Pottery” , “Theater” , “Drawing” , “Dancing”,\n“Photography” , “Genealogy” , “Science” , “None” , “Video_games” , “Library” , “Concert”\n\n\n\n\n\n\nAfin de construire notre indice d’identité de genre, nous suivons la méthodologie proposée par Cipriani et al. (n.d.) et réalisons une Analyse des Correspondances Multiples (ACM) sur nos variables “pratiques culturelles”.\n\n\n\n\n\n\nEncadré Technique 1: Détails de la méthode ACM\n\n\n\nL’**ACM** est une extension de l’**Analyse des Correspondances Simples (ACS)** qui permet d’explorer les relations entre plusieurs variables qualitatives en projetant les individus et les modalités dans un espace de faible dimension. Elle est souvent utilisée pour analyser des **questionnaires** et des **tableaux de contingence** complexes.\n### Principaux résultats d’une ACM\n1. **Inertie totale**\nMesure la dispersion des données et est donnée par :\n\\(I_{\\text{total}} = \\frac{q}{q-1} \\sum_{k} \\lambda_k\\)\noù \\(\\lambda_k\\) sont les valeurs propres et \\(q\\) est le nombre total de modalités.\n2. **Valeurs propres \\(\\lambda_k\\)**\nElles indiquent la variance expliquée par chaque axe factoriel. Plus une valeur propre est élevée, plus l’axe correspondant est important dans l’analyse.\n3. **Rapports de corrélation \\(\\eta^2\\)**\nLe **rapport de corrélation** \\(\\eta^2\\) mesure la liaison entre une variable et un axe factoriel :\n\\(\\eta^2 = \\frac{\\sum_{i} f_i d_{i,k}^2}{\\sum_{i} f_i d_{i}^2}\\)\noù $ f_i $ est la fréquence de l’individu/modalité $i $, et $d_{i,k} $ est sa distance à l’axe \\(k\\) .\n4. **Coordonnées des individus et modalités**\nElles sont obtenues à partir des vecteurs propres et permettent la représentation graphique des données :\n\\(C_{i,k} = \\frac{v_{i,k}}{\\sqrt{\\lambda_k}}\\)\noù \\(v_{i,k}\\) est le vecteur propre associé à l’axe \\(k\\).\n5. **Cos² (Qualité de représentation)**\nIndique dans quelle mesure un point est bien représenté sur un axe donné. Une valeur proche de **1** signifie que la projection sur cet axe est pertinente.\n6. **Contributions **\nElles mesurent l’importance d’une modalité ou d’un individu dans la construction d’un axe. Plus une contribution est élevée, plus l’élément joue un rôle important dans l’interprétation de l’axe.\n\n\n\n\ncode R\npratiques_cols_1 &lt;- c( \"Knitting\" , \n                     \"Cards_games\",  \n                     \"Gambling\" , \n                     \"Cooking\" , \n                     \"DIY\"  ,\n                     \"Vegetable_garden\" , \n                     \"Fishing_hunting\" , \n                     \"Collection\"  ,\n                     \"Vehicle_custom\",\n                     \"Making_music\"   ,\n                     \"Diary\" ,\n                     \"Writing\" ,  \n                     \"Painting\",  \n                     \"Montage\"  , \n                     \"Pottery\" , \n                     \"Theater\" , \n                     \"Drawing\" , \n                     \"Dancing\",  \n                     \"Photography\"  ,\n                     \"Genealogy\" , \n                     \"Science\"  ,\n                     \"None\" ,\n                     \"Video_games\"  ,\n                     \"Library\"  ,\n                     \"Concert\"\n                            )\n\n\n#MCA\n\n# Add Sex Column to the selection\ncols_of_interest_1 &lt;- c(\"Sex\", \"AGE\", pratiques_cols_1)\n\n# Build a new dataframe with these columns\ndata_pratiques &lt;- my_data_frame[, cols_of_interest_1]\ndata_pratiques$AGE &lt;- cut(data_pratiques$AGE, \n                          breaks = quantile(data_pratiques$AGE, probs = seq(0, 1, 0.25), na.rm = TRUE), \n                          include.lowest = TRUE)\nra_data &lt;- na.omit(data_pratiques)\n\ncols_to_factor &lt;- c(  \"Knitting\" , \n                      \"Cards_games\",  \n                      \"Gambling\" , \n                      \"Cooking\" , \n                      \"DIY\"  ,\n                      \"Vegetable_garden\" , \n                      \"Fishing_hunting\" , \n                      \"Collection\"  ,\n                      \"Vehicle_custom\",\n                      \"Making_music\"   ,\n                      \"Diary\" ,\n                      \"Writing\" ,  \n                      \"Painting\",  \n                      \"Montage\"  , \n                      \"Pottery\" , \n                      \"Theater\" , \n                      \"Drawing\" , \n                      \"Dancing\",  \n                      \"Photography\"  ,\n                      \"Genealogy\" , \n                      \"Science\"  ,\n                      \"None\"  ,\n                      \"Video_games\"  ,\n                      \"Library\"  ,\n                      \"Concert\")\n\n# apply as.factor to these columnns\nra_data[cols_to_factor] &lt;- lapply(ra_data[cols_to_factor], as.factor)\n\n# running MCA with FactoMiner\nacm2_fm &lt;- ra_data |&gt; \n  FactoMineR::MCA(\n    ncp = Inf,\n    graph = TRUE,\n    quali.sup = 1:2\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn remarque que la variable supplémentaire “Sexe” correspond à la dimension 2 de notre ACM. Cette dimension explique 6,06% de la variance totale.\nUne analyse plus poussée avec le package Explor nous permet de mesurer l’association de la variable supplémentaire Sexe avec cette dimension (dim2), en effet, l’ \\(𝞰^2\\) est de 0,14 , ce qui peut sembler peu mais indique bien que notre variable supplémentaire est liée à cet axe.\nPour construire notre indice, nous utiliserons donc les coordonnées des variables pratiques culturelles le long de cet axe 2.\n\n\ncode R\n# Extract modality names\nmodalites_names &lt;- rownames(acm2_fm$var$coord)\n\n# Check modality names\nhead(modalites_names)\n\n\n[1] \"Knitting_0\"    \"Knitting_1\"    \"Cards_games_0\" \"Cards_games_1\"\n[5] \"Gambling_0\"    \"Gambling_1\"   \n\n\ncode R\n# Extract coordinates for dimension 2\ncoord_dim2_modalites &lt;- acm2_fm$var$coord[, 2]\n\n# Create a table associating the modalities and their coordinates in dimension 2\nmodalites_coord &lt;- data.frame(Modalite = modalites_names, Coord_Dim2 = coord_dim2_modalites)\n\n\n\n# Keep only the two necessary columns\nmodalites_coord_selected &lt;- modalites_coord[, c(\"Modalite\", \"Coord_Dim2\")]\n\nprint(modalites_coord_selected)\n\n\n                             Modalite  Coord_Dim2\nKnitting_0                 Knitting_0  0.04314603\nKnitting_1                 Knitting_1 -0.23295268\nCards_games_0           Cards_games_0 -0.21072530\nCards_games_1           Cards_games_1  0.20656774\nGambling_0                 Gambling_0 -0.17433328\nGambling_1                 Gambling_1  0.64698995\nCooking_0                   Cooking_0 -0.06432635\nCooking_1                   Cooking_1  0.05083253\nDIY_0                           DIY_0 -0.59097111\nDIY_1                           DIY_1  0.51145863\nVegetable_garden_0 Vegetable_garden_0 -0.29999865\nVegetable_garden_1 Vegetable_garden_1  0.77371744\nFishing_hunting_0   Fishing_hunting_0 -0.16671349\nFishing_hunting_1   Fishing_hunting_1  1.48150102\nCollection_0             Collection_0 -0.05539977\nCollection_1             Collection_1  0.70134797\nVehicle_custom_0     Vehicle_custom_0 -0.05128080\nVehicle_custom_1     Vehicle_custom_1  1.41022187\nMaking_music_0         Making_music_0  0.09403755\nMaking_music_1         Making_music_1 -0.18232870\nDiary_0                       Diary_0  0.09378209\nDiary_1                       Diary_1 -0.48702531\nWriting_0                   Writing_0  0.06770001\nWriting_1                   Writing_1 -0.47308017\nPainting_0                 Painting_0  0.04361213\nPainting_1                 Painting_1 -0.16081142\nMontage_0                   Montage_0 -0.07125251\nMontage_1                   Montage_1  0.38917132\nPottery_0                   Pottery_0  0.01201096\nPottery_1                   Pottery_1 -0.10244644\nTheater_0                   Theater_0  0.07187594\nTheater_1                   Theater_1 -0.44542916\nDrawing_0                   Drawing_0  0.04570585\nDrawing_1                   Drawing_1 -0.15068681\nDancing_0                   Dancing_0  0.14396501\nDancing_1                   Dancing_1 -0.46250072\nPhotography_0           Photography_0 -0.07539973\nPhotography_1           Photography_1  0.22074706\nGenealogy_0               Genealogy_0 -0.01967874\nGenealogy_1               Genealogy_1  0.14733732\nScience_0                   Science_0 -0.04008198\nScience_1                   Science_1  0.30261895\nNone_0                         None_0 -0.06572453\nNone_1                         None_1  0.16286315\nVideo_games_0           Video_games_0 -0.22185919\nVideo_games_1           Video_games_1  0.34927205\nLibrary_0                   Library_0 -0.65936864\nLibrary_1                   Library_1  0.13053925\nConcert_0                   Concert_0 -0.23244943\nConcert_1                   Concert_1  0.05079655\n\n\nCe tableau indique les poids utilisés pour la construction de notre indice.\n\n\ncode R\n# Initialize a vector to store the index of each individual\nra_data$indice_culturel &lt;- 0\n\n# Browse each individual\nfor (i in 1:nrow(ra_data)) {\n  \n  # Initialize individual's index to 0\n  indice_individu &lt;- 0\n  \n  # Browse each practice column (columns 3 to 27)\n  for (pratique in 3:27) {\n    \n    # Retrieve the individual's response for this practice (0 or 1)\n    reponse &lt;- ra_data[i, pratique]\n    \n    # If the answer is 1, add the coordinate of the corresponding modality to the index.\n    if (reponse == 1) {\n      \n      # Create the modality name (e.g. “knitting_1” or “knitting_0”)\n      nom_modalite_1 &lt;- paste0(names(ra_data)[pratique], \"_1\")\n      nom_modalite_0 &lt;- paste0(names(ra_data)[pratique], \"_0\")\n      \n      # Find the coordinate associated with the corresponding modality\n      if (nom_modalite_1 %in% modalites_coord$Modalite) {\n        indice_individu &lt;- indice_individu + modalites_coord$Coord_Dim2[modalites_coord$Modalite == nom_modalite_1]\n      }\n      if (nom_modalite_0 %in% modalites_coord$Modalite) {\n        indice_individu &lt;- indice_individu + modalites_coord$Coord_Dim2[modalites_coord$Modalite == nom_modalite_0]\n      }\n    }\n  }\n  \n  # Assign the calculated index to the individual\n  ra_data$indice_culturel[i] &lt;- indice_individu\n}\n####Normalisation\n\n# Calculate minimum and maximum index values\nmin_indice &lt;- min(ra_data$indice_culturel, na.rm = TRUE)\nmax_indice &lt;- max(ra_data$indice_culturel, na.rm = TRUE)\n\n# Normalize index\nra_data$indice_culturel_normalise &lt;- (ra_data$indice_culturel - min_indice) / (max_indice - min_indice)\n\n# Check results\n\nhead(ra_data[, c(\"indice_culturel\", \"indice_culturel_normalise\")])\n\n\n  indice_culturel indice_culturel_normalise\n1       2.8024423                 0.8624142\n2       0.5427446                 0.5073268\n3      -0.4557477                 0.3504244\n4      -0.3429253                 0.3681533\n5       0.0409659                 0.4284777\n6      -0.2367887                 0.3848315\n\n\nNotre indice est donc construit de la façon suivante:\n\\[I_{1j} = \\sum_{k=1}^{Z} w_{1k} \\cdot X_{k j}\\]\nDans cette expression, \\(I_{1j}\\) désigne l’indice de l’individu \\(j\\), tandis que \\(w_{1k}\\) représente le poids associé à chaque variable culturelle \\(X_{kj}\\). La somme englobe toutes les variables culturelles \\(Z\\), ce qui nous permet de saisir l’engagement culturel global de l’individu.\n\n\n\n\n\ncode R\nmy_data_frame$identity&lt;-ra_data$indice_culturel_normalise\nmy_data_frame$indice&lt;-ra_data$indice_culturel\nggplot(my_data_frame, aes(x = identity, fill = Sex)) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) + \n  labs(title = \"Density of The Normalized Cultural Index by Sexe\",\n       x = \"Normalized Cultural Index\",\n       y = \"Density\",\n       fill = \"Sexe\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ncode R\nstat_des_indice&lt;-my_data_frame%&gt;%\n  tbl_summary(include=c(\"identity\"),by = \"Sex\",\n              statistic = list(\n            all_continuous() ~ \"{min} - {max}\"\n        )) %&gt;%\n  add_overall(last = TRUE) %&gt;%\n  add_p()\nstat_des_indice\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\nOverall N = 9,2341\np-value2\n\n\n\n\nidentity\n0.01 - 1.00\n0.00 - 0.91\n0.00 - 1.00\n&lt;0.001\n\n\n\n1 Min - Max\n\n\n2 Wilcoxon rank sum test\n\n\n\n\n\n\n\n\nL’indice normalisé est compris entre 0 et 1. Plus il est proche de zéro plus les individus sont proches de la norme féminine (en termes de pratiques culturelles).\nL’indice est significativement différent selon le sexe biologique des interrogés.\n\n\ncode R\nreg&lt;- lm(identity~Sex, my_data_frame)\nsummary(reg)\n\n\n\nCall:\nlm(formula = identity ~ Sex, data = my_data_frame)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.41933 -0.07875 -0.01093  0.06694  0.58782 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.424436   0.001815  233.79   &lt;2e-16 ***\nSexWomen    -0.099669   0.002450  -40.69   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1171 on 9232 degrees of freedom\nMultiple R-squared:  0.1521,    Adjusted R-squared:  0.152 \nF-statistic:  1656 on 1 and 9232 DF,  p-value: &lt; 2.2e-16\n\n\nLe sexe biologique est très significatif, les valeurs plus faibles de l’indice sont associées au sexe féminin.\n\n\n\n\n\ncode R\ndata$identity&lt;- my_data_frame$identity\nmy_data_frame$identity&lt;-data$identity\n# List of cultural activities\ncultural_activities &lt;- c(\n   \"Knitting\" , \n                      \"Cards_games\",  \n                      \"Gambling\" , \n                      \"Cooking\" , \n                      \"DIY\"  ,\n                      \"Vegetable_garden\" , \n                      \"Fishing_hunting\" , \n                      \"Collection\"  ,\n                      \"Vehicle_custom\",\n                      \"Making_music\"   ,\n                      \"Diary\" ,\n                      \"Writing\" ,  \n                      \"Painting\",  \n                      \"Montage\"  , \n                      \"Pottery\" , \n                      \"Theater\" , \n                      \"Drawing\" , \n                      \"Dancing\",  \n                      \"Photography\"  ,\n                      \"Genealogy\" , \n                      \"Science\"  ,\n                      \"None\"  ,\n                      \"Video_games\"  ,\n                      \"Library\"  ,\n                      \"Concert\"\n)\n\n# Create a data frame to store the results\nresult_table &lt;- data.frame(Activity = character(0), Accuracy = numeric(0))\n\nfor (activity in cultural_activities) {\n  # Perform a Probit regression for the current cultural activity\n  model_formula &lt;- as.formula(paste(activity, \"~ identity\"))\n  model &lt;- glm(model_formula, data = my_data_frame, family = binomial(link = \"probit\"))\n \n  # Calculate predictions\n  predicted &lt;- ifelse(predict(model, type = \"response\") &gt;= 0.5, 1, 0)\n \n  # Calculate the accuracy\n  correct_predictions &lt;- sum(predicted == my_data_frame[[activity]])\n  total_predictions &lt;- nrow(my_data_frame)\n  accuracy &lt;- (correct_predictions / total_predictions) * 100\n \n  # Add the result to the data frame\n  result_table &lt;- rbind(result_table, data.frame(Activity = activity, Accuracy = accuracy))\n}\nresult_table\n\n\n           Activity Accuracy\n1          Knitting 84.37297\n2       Cards_games 51.00715\n3          Gambling 79.18562\n4           Cooking 56.55187\n5               DIY 51.25623\n6  Vegetable_garden 72.89365\n7   Fishing_hunting 93.95712\n8        Collection 92.54927\n9    Vehicle_custom 96.85943\n10     Making_music 68.16114\n11            Diary 85.85662\n12          Writing 88.16331\n13         Painting 78.76327\n14          Montage 84.52458\n15          Pottery 89.50617\n16          Theater 86.53888\n17          Drawing 76.73814\n18          Dancing 79.66212\n19      Photography 74.53974\n20        Genealogy 88.21746\n21          Science 88.30409\n22             None 70.19710\n23      Video_games 62.06411\n24          Library 83.20338\n25          Concert 81.92549\n\n\nNous réalisons une série de régressions Probit sur les différentes pratiques culturelles, avec pour unique régresseur notre indice d’identité, afin de mesurer le pouvoir prédictif (ou accuracy) de ce dernier.\n\n\n\nComparons l’indice obtenu avec d’autres mesures, et plus particulièrement avec les indices échelle d’identité.\nPour cela, nous allons diviser notre indice en 7 catégories, allant du plus féminin au plus masculin.\n\n\ncode R\nmy_data_frame$identity_scale &lt;- cut(\n  my_data_frame$identity,\n  breaks = 7,  # Automatically divide into 7 slices\n  labels = c(\"Very Feminine\", \"1\", \"2\", \"3\", \"4\", \"5\", \"Very Masculine\"), \n  include.lowest = TRUE  \n)\ntable1 &lt;-\n  my_data_frame |&gt; \n  tbl_summary(include = c(identity_scale),\n  by=Sex ,)|&gt; \n    add_p()\ntable1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\np-value2\n\n\n\n\nidentity_scale\n\n\n\n\n&lt;0.001\n\n\n    Very Feminine\n9 (0.2%)\n218 (4.3%)\n\n\n\n\n    1\n403 (9.7%)\n1,506 (30%)\n\n\n\n\n    2\n2,139 (51%)\n2,669 (53%)\n\n\n\n\n    3\n985 (24%)\n576 (11%)\n\n\n\n\n    4\n509 (12%)\n90 (1.8%)\n\n\n\n\n    5\n96 (2.3%)\n10 (0.2%)\n\n\n\n\n    Very Masculine\n21 (0.5%)\n3 (&lt;0.1%)\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\nCe tableau est à mettre en perspective avec les données de Trachman (2022a).\nTout d’abord non remarquons que, comme dans l’enquête de Trachman (2022a), les individus “hors norme” sont peu nombreux (d’après notre indice, moins de 0,1% des femmes ont des pratiques culturelles très masculines; 0,2% des hommes ont des pratiques très féminines) , de même que les individus dont les pratiques culturelles seraient complètement conformes à leur sexe biologique ne sont pas la majorité (4,3% des femmes sont classées comme très féminines, 0,5% des hommes comme très masculins.)\nCela plaide encore une fois pour l’intérêt d’une mesure continue.\nNous allons ensuite explorer plus en détails les variables socio-démographiques qui peuvent influencer notre indice (revenu, âge, catégorie socio-professionnelle …)"
  },
  {
    "objectID": "normes_identite/CGNI.html#variables-socio-économiques-et-identité-de-genre",
    "href": "normes_identite/CGNI.html#variables-socio-économiques-et-identité-de-genre",
    "title": "Vers une Mesure Continue de l’identité de Genre",
    "section": "",
    "text": "Dans cette partie, nous allons analyser les implications socio-économiques de l’identité de genre.\nPour commencer, nous allons regarder les différents profils des individus selon leur indice d’identité.\nPuis nous analyserons les liens entre distance à la norme et l’utilité des individus (leur degré de satisfaction.)\n\n\nShow the code\nstat_des_2 &lt;- my_data_frame |&gt;  \n  tbl_summary(        \n    include = c(\"AGE\", \"Income\", \"Couple\", \"CLASSIF\"),         by = \"identity_scale\") |&gt;  \n  \n  add_overall(last = TRUE) |&gt; \n  add_p(       \n    test.args = list(           \n      all_continuous() ~ list(simulate.p.value = TRUE),             all_categorical() ~ list(simulate.p.value = TRUE)      \n      )    \n    )  \n\n\nstat_des_2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nVery Feminine N = 2271\n1 N = 1,9091\n2 N = 4,8081\n3 N = 1,5611\n4 N = 5991\n5 N = 1061\nVery Masculine N = 241\nOverall N = 9,2341\np-value2\n\n\n\n\nAGE\n44 (32, 57)\n50 (35, 65)\n56 (40, 69)\n55 (37, 68)\n51 (35, 65)\n43 (30, 59)\n37 (30, 57)\n54 (38, 67)\n\n\n\n\nIncome\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\n    High\n88 (44%)\n710 (42%)\n1,428 (34%)\n452 (33%)\n175 (33%)\n34 (36%)\n9 (43%)\n2,896 (36%)\n\n\n\n\n    Low\n48 (24%)\n382 (23%)\n1,118 (27%)\n369 (27%)\n108 (20%)\n17 (18%)\n4 (19%)\n2,046 (25%)\n\n\n\n\n    Medium\n65 (32%)\n592 (35%)\n1,631 (39%)\n536 (39%)\n245 (46%)\n43 (46%)\n8 (38%)\n3,120 (39%)\n\n\n\n\n    Unknown\n26\n225\n631\n204\n71\n12\n3\n1,172\n\n\n\n\nCouple\n109 (48%)\n1,013 (53%)\n2,594 (54%)\n842 (54%)\n373 (62%)\n68 (64%)\n12 (50%)\n5,011 (54%)\n&lt;0.001\n\n\n    Unknown\n2\n4\n5\n1\n1\n0\n0\n13\n\n\n\n\nCLASSIF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\n    1\n0 (0%)\n18 (3.2%)\n95 (6.8%)\n48 (10%)\n16 (6.6%)\n7 (17%)\n2 (18%)\n186 (6.6%)\n\n\n\n\n    2\n6 (8.0%)\n61 (11%)\n278 (20%)\n132 (28%)\n98 (40%)\n19 (46%)\n3 (27%)\n597 (21%)\n\n\n\n\n    3\n3 (4.0%)\n36 (6.4%)\n148 (11%)\n56 (12%)\n33 (14%)\n6 (15%)\n0 (0%)\n282 (10%)\n\n\n\n\n    4\n8 (11%)\n59 (11%)\n140 (10.0%)\n47 (9.8%)\n22 (9.1%)\n4 (9.8%)\n3 (27%)\n283 (10%)\n\n\n\n\n    5\n26 (35%)\n149 (27%)\n229 (16%)\n80 (17%)\n26 (11%)\n3 (7.3%)\n1 (9.1%)\n514 (18%)\n\n\n\n\n    6\n29 (39%)\n224 (40%)\n484 (34%)\n110 (23%)\n47 (19%)\n2 (4.9%)\n1 (9.1%)\n897 (32%)\n\n\n\n\n    7\n1 (1.3%)\n6 (1.1%)\n11 (0.8%)\n1 (0.2%)\n1 (0.4%)\n0 (0%)\n0 (0%)\n20 (0.7%)\n\n\n\n\n    8\n2 (2.7%)\n6 (1.1%)\n16 (1.1%)\n4 (0.8%)\n0 (0%)\n0 (0%)\n1 (9.1%)\n29 (1.0%)\n\n\n\n\n    9\n0 (0%)\n0 (0%)\n2 (0.1%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n2 (&lt;0.1%)\n\n\n\n\n    Unknown\n152\n1,350\n3,405\n1,083\n356\n65\n13\n6,424\n\n\n\n\n\n1 Median (Q1, Q3); n (%)\n\n\n2 Pearson’s Chi-squared test with simulated p-value (based on 2000 replicates); Fisher’s Exact Test for Count Data with simulated p-value (based on 2000 replicates)\n\n\n\n\n\n\n\n\nLecture: Parmi les individus catégorisés comme très féminins selon notre indice, 44% ont des revenus élevés. Les variables étudiées sont significativement différentes selon les degrés d’identité.\nIl semble, d’après cette première table descriptive, que l’âge, les niveaux de revenus ainsi que les professions (CLASSIF) jouent un rôle dans l’identité de genre. Tout comme dans l’étude de Trachman (2022b), les facteurs socio-économiques influencent les variations du genre.\n\n\n\n\n\n\n\nCLASSIF\n\n\n\n\n\n1\nManoeuvre ou ouvrier spécialisé\n\n\n2\nOuvrier qualifié ou hautement qualifié/ technicien(ne) d’atelier\n\n\n3\nTechnicien(ne)\n\n\n4\nAgent de maîtrise, maîtrise administrative ou commerciale, VRP (non cadre)\n\n\n5\nIngénieur, Cadre\n\n\n6\nEmployé(e) de bureau, Employé(e) de commerce, Personnel de services\n\n\n7\nDirecteur général, Adjoint direct\n\n\n8\nNSP\n\n\n9\nREF\n\n\n\nOn peut regarder si les effets sont différents selon le sexe biologique:\n\n\nShow the code\nstat_des &lt;- my_data_frame |&gt;\n    tbl_strata(\n        strata = Sex,  # Stratification par sexe\n        .tbl_fun = ~ .x |&gt;\n            tbl_summary(\n                include = c(\"AGE\", \"Income\", \"Couple\", \"CLASSIF\"),\n                by = \"identity_scale\"  # Stratification supplémentaire par 'identity_scale'\n            ) |&gt;\n            add_overall(last = TRUE) |&gt;\n            add_p(\n                test.args = list(\n                    all_continuous() ~ list(simulate.p.value = TRUE),\n                    all_categorical() ~ list(simulate.p.value = TRUE)\n                )\n            )\n    )\n\nstat_des\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nMen\n\n\nWomen\n\n\n\nVery Feminine N = 91\n1 N = 4031\n2 N = 2,1391\n3 N = 9851\n4 N = 5091\n5 N = 961\nVery Masculine N = 211\nOverall N = 4,1621\np-value2\nVery Feminine N = 2181\n1 N = 1,5061\n2 N = 2,6691\n3 N = 5761\n4 N = 901\n5 N = 101\nVery Masculine N = 31\nOverall N = 5,0721\np-value2\n\n\n\n\nAGE\n50 (36, 59)\n54 (39, 66)\n54 (40, 68)\n52 (35, 66)\n52 (36, 65)\n44 (30, 59)\n37 (28, 56)\n53 (38, 66)\n\n\n44 (32, 56)\n49 (34, 64)\n58 (40, 70)\n57 (39, 71)\n44 (33, 60)\n37 (33, 68)\n34 (33, 57)\n54 (37, 68)\n\n\n\n\nIncome\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.035\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\n    High\n4 (44%)\n160 (44%)\n762 (40%)\n316 (36%)\n153 (34%)\n28 (33%)\n9 (50%)\n1,432 (39%)\n\n\n84 (44%)\n550 (42%)\n666 (29%)\n136 (28%)\n22 (26%)\n6 (60%)\n0 (0%)\n1,464 (33%)\n\n\n\n\n    Low\n4 (44%)\n66 (18%)\n393 (21%)\n192 (22%)\n88 (20%)\n16 (19%)\n3 (17%)\n762 (21%)\n\n\n44 (23%)\n316 (24%)\n725 (32%)\n177 (36%)\n20 (24%)\n1 (10%)\n1 (33%)\n1,284 (29%)\n\n\n\n\n    Medium\n1 (11%)\n134 (37%)\n733 (39%)\n359 (41%)\n203 (46%)\n40 (48%)\n6 (33%)\n1,476 (40%)\n\n\n64 (33%)\n458 (35%)\n898 (39%)\n177 (36%)\n42 (50%)\n3 (30%)\n2 (67%)\n1,644 (37%)\n\n\n\n\n    Unknown\n0\n43\n251\n118\n65\n12\n3\n492\n\n\n26\n182\n380\n86\n6\n0\n0\n680\n\n\n\n\nCouple\n4 (44%)\n224 (56%)\n1,271 (59%)\n561 (57%)\n314 (62%)\n59 (61%)\n11 (52%)\n2,444 (59%)\n0.3\n105 (49%)\n789 (52%)\n1,323 (50%)\n281 (49%)\n59 (66%)\n9 (90%)\n1 (33%)\n2,567 (51%)\n&lt;0.001\n\n\n    Unknown\n0\n1\n2\n0\n1\n0\n0\n4\n\n\n2\n3\n3\n1\n0\n0\n0\n9\n\n\n\n\nCLASSIF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\n    1\n0 (0%)\n6 (5.2%)\n57 (7.9%)\n37 (11%)\n16 (7.7%)\n6 (16%)\n1 (11%)\n123 (8.7%)\n\n\n0 (0%)\n12 (2.7%)\n38 (5.5%)\n11 (7.7%)\n0 (0%)\n1 (25%)\n1 (50%)\n63 (4.5%)\n\n\n\n\n    2\n0 (0%)\n24 (21%)\n214 (30%)\n109 (33%)\n87 (42%)\n17 (46%)\n3 (33%)\n454 (32%)\n\n\n6 (8.1%)\n37 (8.3%)\n64 (9.3%)\n23 (16%)\n11 (31%)\n2 (50%)\n0 (0%)\n143 (10%)\n\n\n\n\n    3\n0 (0%)\n15 (13%)\n98 (14%)\n42 (13%)\n30 (14%)\n5 (14%)\n0 (0%)\n190 (13%)\n\n\n3 (4.1%)\n21 (4.7%)\n50 (7.3%)\n14 (9.8%)\n3 (8.3%)\n1 (25%)\n0 (0%)\n92 (6.6%)\n\n\n\n\n    4\n0 (0%)\n15 (13%)\n76 (11%)\n37 (11%)\n22 (11%)\n4 (11%)\n3 (33%)\n157 (11%)\n\n\n8 (11%)\n44 (9.9%)\n64 (9.3%)\n10 (7.0%)\n0 (0%)\n0 (0%)\n0 (0%)\n126 (9.1%)\n\n\n\n\n    5\n1 (100%)\n31 (27%)\n151 (21%)\n66 (20%)\n25 (12%)\n3 (8.1%)\n1 (11%)\n278 (20%)\n\n\n25 (34%)\n118 (27%)\n78 (11%)\n14 (9.8%)\n1 (2.8%)\n0 (0%)\n0 (0%)\n236 (17%)\n\n\n\n\n    6\n0 (0%)\n21 (18%)\n104 (15%)\n41 (12%)\n26 (13%)\n2 (5.4%)\n0 (0%)\n194 (14%)\n\n\n29 (39%)\n203 (46%)\n380 (55%)\n69 (48%)\n21 (58%)\n0 (0%)\n1 (50%)\n703 (51%)\n\n\n\n\n    7\n0 (0%)\n2 (1.7%)\n9 (1.3%)\n1 (0.3%)\n1 (0.5%)\n0 (0%)\n0 (0%)\n13 (0.9%)\n\n\n1 (1.4%)\n4 (0.9%)\n2 (0.3%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n7 (0.5%)\n\n\n\n\n    8\n0 (0%)\n1 (0.9%)\n7 (1.0%)\n2 (0.6%)\n0 (0%)\n0 (0%)\n1 (11%)\n11 (0.8%)\n\n\n2 (2.7%)\n5 (1.1%)\n9 (1.3%)\n2 (1.4%)\n0 (0%)\n0 (0%)\n0 (0%)\n18 (1.3%)\n\n\n\n\n    9\n0 (0%)\n0 (0%)\n1 (0.1%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (&lt;0.1%)\n\n\n0 (0%)\n0 (0%)\n1 (0.1%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (&lt;0.1%)\n\n\n\n\n    Unknown\n8\n288\n1,422\n650\n302\n59\n12\n2,741\n\n\n144\n1,062\n1,983\n433\n54\n6\n1\n3,683\n\n\n\n\n\n1 Median (Q1, Q3); n (%)\n\n\n2 Fisher’s Exact Test for Count Data with simulated p-value (based on 2000 replicates)\n\n\n\n\n\n\n\n\nLecture: Parmi les hommes classés comme très féminins, 27% appartiennent à la catégorie socio-professionnelle 5 (ingénieur, cadre)\n\n\nNous l’évoquions au début de ce document, ce qui nous intéresse en proposant une mesure continue des variations du genre c’est de pouvoir analyser les distances prises avec les normes de son groupe de référence.\nPour cela, nous allons construire la variable “Distance à la norme”\n\n\nShow the code\nmean_gender &lt;- tapply(my_data_frame$identity, my_data_frame$Sex, mean)\nsd_gender &lt;- tapply(my_data_frame$identity, my_data_frame$Sex, sd)\n\nmy_data_frame$distance&lt;- (my_data_frame$identity - mean_gender[my_data_frame$Sex]) / sd_gender[my_data_frame$Sex]\n\nggplot(my_data_frame, aes(x = distance, color = Sex, fill = Sex)) +\n  geom_density(alpha = 0.4) +\n  labs(title = \"Density of Distance to the Norm, by Sex\", \n       x = \"Distance to the Norm (Z-score)\", y = \"Density\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n#Ou en valeur absolue: \nmean_gender &lt;- tapply(my_data_frame$identity, my_data_frame$Sex, mean)\nsd_gender &lt;- tapply(my_data_frame$identity, my_data_frame$Sex, sd)\n\nmy_data_frame$distance_abs&lt;- abs((my_data_frame$identity - mean_gender[my_data_frame$Sex]) / sd_gender[my_data_frame$Sex])\n\nggplot(my_data_frame, aes(x = distance_abs, color = Sex, fill = Sex)) +\n  geom_density(alpha = 0.4) +\n  labs(title = \"Density of Distance to the Norm, by Sex\", \n       x = \"Distance to the Norm (Z-score)\", y = \"Density\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Catégorisation par quartiles\nmy_data_frame$categories &lt;- cut(my_data_frame$distance, breaks = 4, include.lowest = TRUE,labels = c(\"very Feminine\",\"Feminine\", \"Masculine\", \"very masculine\" ))\n\n#my_data_frame$categories &lt;- cut(my_data_frame$distance,                         breaks = quantile(my_data_frame$distance, probs = c(0, 0.25, 0.75, 1), na.rm = TRUE),                         labels = c(\"Feminine Norms\", \"Medium\", \"Masculine Norms\"),                         include.lowest = TRUE)\n\n\n\n\n\n\n\nShow the code\nlibrary(MASS)\nmy_data_frame$satisfaction&lt;-as.factor((my_data_frame$satisfaction))\n# Ordinal logistic regression model fitting\nordinal_model &lt;- polr(satisfaction ~ distance, data = my_data_frame, Hess = TRUE)\n\n\n# 1. Predict the probabilities for each category\ndistance_vals &lt;- seq(min(my_data_frame$distance), max(my_data_frame$distance))\nnew_data &lt;- data.frame(distance = distance_vals)\n\npredicted_probs &lt;- predict(ordinal_model, newdata = new_data, type = \"probs\")\n\n# 3. Convert results to dataframe\npredicted_probs_df &lt;- as.data.frame(predicted_probs)\npredicted_probs_df$distance &lt;- distance_vals\n\n# 4. Transform data into long format for ggplot2\npredicted_probs_long &lt;- pivot_longer(predicted_probs_df, \n                                     cols = -distance, \n                                     names_to = \"satisfaction\", \n                                     values_to = \"probabilite\")\n\n# 5. Visualize predicted probabilities\nggplot(predicted_probs_long, aes(x = distance, y = probabilite, color = satisfaction)) +\n  geom_line(size = 1.2) +\n  labs(title = \"Probability of satisfaction as a function of deviation from Norms\",\n       x = \"Distance to the Norm\",\n       y = \"Probability\") +\n  \n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n    axis.title.x = element_text(size = 12),\n    axis.title.y = element_text(size = 12)\n  )\n\n\n\n\n\n\n\n\n\nLa satisfaction est mesurée comme étant la réponse à la question “Vous arrive-t-il d’avoir le sentiment de manquer de temps libre pour faire tout ce dont vous avez envie ?”\nCe graphique semble indiquer que la satisfaction en termes de temps libre croît avec la distance à sa norme de genre.\nCet effet est-il vérifié pour les différents niveaux de revenus et le sexe biologique?\n\n\nShow the code\n# Graph with only lines and no scatter points\nggplot(my_data_frame, aes(x = distance, y = as.numeric(satisfaction), color = as.factor(Income))) +\n  geom_smooth(method = \"lm\", aes(linetype = as.factor(Income)), se = FALSE) + # Regression curves without confidence intervals and different line types                              # Gray scale palette\n  scale_linetype_manual(values = c(\"Low\" = \"solid\", \"Medium\" = \"dashed\", \"High\" = \"twodash\")) +  # Line types: solid, dashed, and twodash for the 3rd\n  labs(\n    title = \"Interaction between Distance to the Norm and Income Groups\",\n    x = \"Distance to the Norm (z-score)\",\n    y = \"Satisfaction (ordinal)\",\n    color = \"Income (grouped)\",\n    linetype = \"Line Type\"\n  ) +\n  theme_minimal() +                                                      # Minimalist theme\n  theme(\n    text = element_text(size = 12),                                       # Text size\n    panel.grid = element_blank(),                                          # Remove gridlines\n    panel.border = element_blank(),                                        # Remove borders around the plot\n    plot.background = element_blank(),                                     # Remove gray background\n    legend.position = \"top\",                                              # Place legend at the top\n    axis.title = element_text(color = \"black\"),                            # Axis titles in black\n    axis.text = element_text(color = \"black\")                              # Axis text in black\n  )\n\n\n\n\n\n\n\n\n\nL’effet semble s’inverser pour les bas revenus, s’écarter de la norme s’accompagne d’une baisse de la satisfaction ressentie.\nQu’en est-il si on regarde ces effets par sexe?\n\n\nShow the code\nbase_femmes &lt;- my_data_frame %&gt;%\n  filter(Sex == \"Women\")\n\n# Creating a table without NA\nfemmes_categories &lt;- base_femmes %&gt;%\n  tbl_summary(\n    include = c(Income, LNAIS, Couple,satisfaction, Health, age_group),\n    by = categories,\n    statistic = ~ \"{p}%\",\n    percent = \"row\",\n    missing = \"no\"  \n  ) %&gt;%\n  add_p()\nfemmes_categories\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nvery Feminine N = 7131\nFeminine N = 3,8711\nMasculine N = 4671\nvery masculine N = 211\np-value2\n\n\n\n\nIncome\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\n    High\n20%\n72%\n8.2%\n0.6%\n\n\n\n\n    Low\n11%\n79%\n9.1%\n0.3%\n\n\n\n\n    Medium\n12%\n77%\n10.0%\n0.5%\n\n\n\n\nLNAIS\n\n\n\n\n\n\n\n\n&gt;0.9\n\n\n    1\n14%\n76%\n9.3%\n0.4%\n\n\n\n\n    2\n14%\n77%\n8.6%\n0.4%\n\n\n\n\nCouple\n14%\n76%\n9.8%\n0.6%\n0.041\n\n\nsatisfaction\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\n    High\n8.5%\n81%\n10.0%\n0.2%\n\n\n\n\n    Low\n18%\n73%\n8.8%\n0.5%\n\n\n\n\n    Medium\n15%\n76%\n8.9%\n0.5%\n\n\n\n\nHealth\n\n\n\n\n\n\n\n\n\n\n\n\n    Bad\n8.5%\n82%\n9.1%\n0.2%\n\n\n\n\n    Good\n16%\n75%\n8.8%\n0.4%\n\n\n\n\n    Medium\n11%\n78%\n10%\n0.5%\n\n\n\n\nage_group\n\n\n\n\n\n\n\n\n\n\n\n\n    [15-38[\n20%\n69%\n10%\n1.0%\n\n\n\n\n    [38-54[\n17%\n73%\n9.4%\n0.3%\n\n\n\n\n    [54-67[\n9.7%\n81%\n9.0%\n0.2%\n\n\n\n\n    [67-97[\n6.1%\n86%\n7.7%\n0.2%\n\n\n\n\n\n1 \n\n\n2 Pearson’s Chi-squared test; Fisher’s exact test\n\n\n\n\n\n\n\n\nShow the code\nbase_hommes &lt;- my_data_frame %&gt;%\n  filter(Sex == \"Men\")\n\n\nhommes_categories &lt;- base_hommes %&gt;%\n  tbl_summary(\n    include = c(Income, LNAIS, Couple, satisfaction, Health, age_group),\n    by = categories,\n    statistic = ~ \"{p}%\",\n    percent = \"row\",\n    missing = \"no\"  \n  ) %&gt;%\n  add_p()\nhommes_categories\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nvery Feminine N = 4551\nFeminine N = 3,1121\nMasculine N = 5751\nvery masculine N = 201\np-value2\n\n\n\n\nIncome\n\n\n\n\n\n\n\n\n\n\n\n\n    High\n13%\n74%\n12%\n0.6%\n\n\n\n\n    Low\n10%\n76%\n13%\n0.4%\n\n\n\n\n    Medium\n9.8%\n75%\n15%\n0.3%\n\n\n\n\nLNAIS\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\n    1\n11%\n74%\n15%\n0.5%\n\n\n\n\n    2\n14%\n79%\n6.1%\n0.2%\n\n\n\n\nCouple\n10%\n75%\n15%\n0.5%\n0.3\n\n\nsatisfaction\n\n\n\n\n\n\n\n\n0.5\n\n\n    High\n11%\n76%\n13%\n0.3%\n\n\n\n\n    Low\n11%\n73%\n15%\n0.5%\n\n\n\n\n    Medium\n11%\n75%\n13%\n0.7%\n\n\n\n\nHealth\n\n\n\n\n\n\n\n\n\n\n\n\n    Bad\n8.1%\n80%\n12%\n0%\n\n\n\n\n    Good\n11%\n74%\n14%\n0.6%\n\n\n\n\n    Medium\n10%\n76%\n14%\n0.1%\n\n\n\n\nage_group\n\n\n\n\n\n\n\n\n\n\n\n\n    [15-38[\n10%\n72%\n17%\n1.0%\n\n\n\n\n    [38-54[\n11%\n75%\n13%\n0.5%\n\n\n\n\n    [54-67[\n11%\n75%\n14%\n0.3%\n\n\n\n\n    [67-97[\n12%\n79%\n8.8%\n0%\n\n\n\n\n\n1 \n\n\n2 Fisher’s exact test; Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\nShow the code\n# Fit ordinal logistic regression model including SEX\nordinal_model2 &lt;- polr(satisfaction ~ distance * Sex, data = my_data_frame, Hess = TRUE)\n\n# Create a sequence of values for conformity\nconformity_vals &lt;- seq(min(my_data_frame$distance), max(my_data_frame$distance))\n\n# Create a new dataset with all combinations of conformity and SEX\nnew_data &lt;- expand.grid(distance = distance_vals, Sex = c(\"Men\", \"Women\"))\n\n# Predict probabilities for each combination of conformity and SEXE\npredicted_probs &lt;- predict(ordinal_model2, newdata = new_data, type = \"probs\")\n\n# Convert results to dataframe\npredicted_probs_df &lt;- as.data.frame(predicted_probs)\npredicted_probs_df$distance &lt;- new_data$distance\npredicted_probs_df$Sex &lt;- new_data$Sex\n\n# Correctly name probability columns for satisfaction levels 1, 2 and 3\ncolnames(predicted_probs_df)[1:3] &lt;- c(\"satisfaction_1\", \"satisfaction_2\", \"satisfaction_3\")\n\n# Transformation to long format for easier viewing with ggplot2\npredicted_probs_long &lt;- pivot_longer(predicted_probs_df, \n                                     cols = starts_with(\"satisfaction\"),  # Selects columns satisfaction_1, 2 and 3\n                                     names_to = \"satisfaction\", \n                                     values_to = \"probabilite\")\n\n# Modify names for simple labels\npredicted_probs_long$satisfaction &lt;- factor(predicted_probs_long$satisfaction, \n                                            levels = c(\"satisfaction_1\", \"satisfaction_2\", \"satisfaction_3\"),\n                                            labels = c(\"Low\", \"Medium\", \"High\"))\n\n# Visualize predicted probabilities for each gender\nggplot(predicted_probs_long, aes(x = distance, y = probabilite, color = satisfaction, linetype = Sex)) +\n  geom_line(size = 1.2) +\n  labs(title = \"Predicted Probabilities of Satisfaction Based on Distance to the Norm\",\n       x = \"Distance to the Norm\",\n       y = \"Probability\") +\n  scale_color_manual(values = c(\"#87CEEB\", \"#4682B4\", \"#1E90FF\")) +  # \n  scale_linetype_manual(values = c(\"solid\", \"dashed\")) +  # Differentiates between men and women\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n    axis.title.x = element_text(size = 12),\n    axis.title.y = element_text(size = 12)\n  )\n\n\n\n\n\n\n\n\n\nCe graphique montre des différences significatives entre hommes et femmes, chez les femmes l’éloignement aux normes semble augmenter l’insatisfaction, cet effet n’est pas aussi net chez les hommes.\n\n\nShow the code\nrego &lt;- MASS::polr(\n  satisfaction ~ Sex + Income + age_group + categories,\n  data = my_data_frame\n)\n\ntheme_gtsummary_language(\"en\", decimal.mark = \",\")\nrego |&gt; \n  tbl_regression(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  ) |&gt; \n  bold_labels() |&gt; \n  add_global_p(keep = TRUE) |&gt; \n  as_kable_extra(format = \"latex\", booktabs = TRUE) |&gt; \n  kable_styling(latex_options = c(\"hold_position\", \"scale_down\"), full_width = FALSE)\n\n\n\n\n\nShow the code\nrego |&gt; \n  ggstats::ggcoef_table(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  )\n\n\n\n\n\n\n\n\n\nShow the code\nrego |&gt; \n  broom.helpers::plot_marginal_predictions() |&gt; \n  patchwork::wrap_plots(ncol = 1) &\n  scale_y_continuous(labels = scales::percent) &\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n#Contrôle par le temps passé au travail et distance absolue\n\n# Catégorisation par quartiles\nmy_data_frame$categories_abs &lt;- cut(my_data_frame$distance_abs,                         breaks = 4, na.rm = TRUE ,                         labels = c(\"Low Distance\", \"Medium_low\", \"Medium_high\", \"High Distance\"),                         include.lowest = TRUE)\nrego3 &lt;- MASS::polr(\n  satisfaction ~ Sex + Income + age_group + categories_abs,\n  data = my_data_frame\n)\n\ntheme_gtsummary_language(\"en\", decimal.mark = \",\")\nrego3 |&gt; \n  tbl_regression(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  ) |&gt; \n  bold_labels() |&gt; \n  add_global_p(keep = TRUE) |&gt; \n  as_kable_extra(format = \"latex\", booktabs = TRUE) |&gt; \n  kable_styling(latex_options = c(\"hold_position\", \"scale_down\"), full_width = FALSE)\n\n\n\n\n\nShow the code\nrego3 |&gt; \n  ggstats::ggcoef_table(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  )\n\n\n\n\n\n\n\n\n\nShow the code\nrego3 |&gt; \n  broom.helpers::plot_marginal_predictions() |&gt; \n  patchwork::wrap_plots(ncol = 1) &\n  scale_y_continuous(labels = scales::percent) &\n  coord_flip()\n\n\n\n\n\n\n\n\n\nEn utilisant une autre variable proxy de l’utilité: l’état de santé déclaré.\n\n\nShow the code\n#Une autre mesure de l'utilité: l'état de santé déclaré\n\nmy_data_frame$Health&lt;-as.factor(my_data_frame$Health)\nrego4 &lt;- MASS::polr(\n  Health ~ Sex + Income + age_group + categories_abs,\n  data = my_data_frame\n)\n\ntheme_gtsummary_language(\"en\", decimal.mark = \",\")\nrego4 |&gt; \n  tbl_regression(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  ) |&gt; \n  bold_labels() |&gt; \n  add_global_p(keep = TRUE) |&gt; \n  as_kable_extra(format = \"latex\", booktabs = TRUE) |&gt; \n  kable_styling(latex_options = c(\"hold_position\", \"scale_down\"), full_width = FALSE)\n\n\n\n\n\nShow the code\nrego4 |&gt; \n  ggstats::ggcoef_table(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  )\n\n\n\n\n\n\n\n\n\nShow the code\nrego4 |&gt; \n  broom.helpers::plot_marginal_predictions() |&gt; \n  patchwork::wrap_plots(ncol = 1) &\n  scale_y_continuous(labels = scales::percent) &\n  coord_flip()"
  },
  {
    "objectID": "normes_identite/CGNI.html#indice-alternatif",
    "href": "normes_identite/CGNI.html#indice-alternatif",
    "title": "Vers une Mesure Continue de l’identité de Genre",
    "section": "",
    "text": "Show the code\nsummary(my_data_frame$Library)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  1.0000  1.0000  0.8347  1.0000  1.0000 \n\n\nShow the code\nmy_data_frame$SEXE&lt;-as.factor(my_data_frame$SEXE)\nreg_lm&lt;- lm(Sex~ Knitting+ \n                  Cards_games+  \n                  Gambling+ \n                  Cooking+ \n                  DIY+\n                  Vegetable_garden+ \n                  Ornamental_garden+  \n                  Fishing_hunting+ \n                  Collection+\n                  Vehicle_custom + \n                  Making_music +\n                  Diary +\n                  Writing +  \n                  Painting +  \n                  Montage + \n                  Circus +\n                  Pottery + \n                  Theater + \n                  Drawing + \n                  Dancing +  \n                  Photography +\n                  Genealogy + \n                  Science +\n                  None +\n                  No_Amateur +\n                  Video_games +\n                  TV +\n                  Radio+\n                  Library+\n                  Museums +  \n                  Internet + \n                  Concert, data=my_data_frame)\n\n\n\nn &lt;- nrow(my_data_frame)\n\n# Indices pour la division (2/3 pour l'entraînement, 1/3 pour le test)\ntrain_index &lt;- sample(1:n, size = 2 * n / 3)  # 2/3 des indices pour l'entraînement\n\n# Créer l'ensemble d'entraînement et l'ensemble de test\ntrain_data &lt;- my_data_frame[train_index, ]  # Enregistrement d'entraînement\ntest_data &lt;- my_data_frame[-train_index, ]  # Enregistrement de test\n\n# Vérifier les tailles\ncat(\"Nombre d'observations dans l'ensemble d'entraînement :\", nrow(train_data), \"\\n\")\n\n\nNombre d'observations dans l'ensemble d'entraînement : 6156 \n\n\nShow the code\ncat(\"Nombre d'observations dans l'ensemble de test :\", nrow(test_data), \"\\n\")\n\n\nNombre d'observations dans l'ensemble de test : 3078 \n\n\nShow the code\n# Charger les bibliothèques nécessaires\nlibrary(glmnet)\nlibrary(pROC)\n\n# Définir la matrice X pour l'entraînement\nx &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                  Vegetable_garden + Ornamental_garden + Fishing_hunting + \n                  Collection + Vehicle_custom + Making_music + Diary + Writing + \n                  Painting + Montage + Circus + Pottery + Theater + Drawing + \n                  Dancing + Photography + Genealogy + Science + None + No_Amateur +\n                  Video_games + TV + Radio + Library + Museums + Internet + Concert,\n                  train_data)[, -1]\n\n# Variable cible y pour l'entraînement\ny &lt;- train_data$SEXE\n\n# Ajuster le modèle LASSO avec validation croisée\ncv_lasso &lt;- cv.glmnet(x, y, alpha = 1, family = \"binomial\")\nbest_lambda &lt;- cv_lasso$lambda.min  # Lambda optimal\n\n# Vérifie les coefficients pour le lambda optimal\nprint(coef(cv_lasso, s = \"lambda.min\"))\n\n\n33 x 1 sparse Matrix of class \"dgCMatrix\"\n                             s1\n(Intercept)       -6.594268e-01\nKnitting           2.897789e+00\nCards_games        2.442634e-01\nGambling          -4.166131e-01\nCooking            1.178967e+00\nDIY               -1.041022e+00\nVegetable_garden  -3.655189e-01\nOrnamental_garden  2.772988e-01\nFishing_hunting   -1.289056e+00\nCollection        -6.543257e-01\nVehicle_custom    -1.748330e+00\nMaking_music      -2.121348e-01\nDiary              1.466762e+00\nWriting           -9.833754e-02\nPainting           4.373124e-01\nMontage           -9.239000e-01\nCircus             .           \nPottery            5.402698e-01\nTheater           -2.806501e-02\nDrawing           -1.061173e-01\nDancing            1.639313e+00\nPhotography       -4.795022e-01\nGenealogy         -2.433708e-01\nScience           -8.540327e-01\nNone              -2.186679e-01\nNo_Amateur         4.344182e-01\nVideo_games       -1.824566e-01\nTV                 8.141467e-01\nRadio             -2.640448e-01\nLibrary           -8.467656e-16\nMuseums           -8.953888e-02\nInternet           1.465727e-01\nConcert            4.438503e-02\n\n\nShow the code\nprint(best_lambda)\n\n\n[1] 0.0008359059\n\n\nShow the code\n# Préparer X_test (même traitement que pour l'entraînement)\nx_test &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                       Vegetable_garden + Ornamental_garden + Fishing_hunting + \n                       Collection + Vehicle_custom + Making_music + Diary + Writing + \n                       Painting + Montage + Circus + Pottery + Theater + Drawing + \n                       Dancing + Photography + Genealogy + Science + None + No_Amateur +\n                       Video_games + TV + Radio + Library + Museums + Internet + Concert,\n                       test_data)[, -1]\n\n# Prédire les probabilités sur les données de test avec le meilleur lambda\npreds &lt;- predict(cv_lasso, newx = x_test, s = \"lambda.min\", type = \"response\")\n\n# Variable cible y_test pour l'ensemble de test\ny_test &lt;- test_data$SEXE\n\n# Calcul de l'AUC avec pROC\nroc_curve &lt;- roc(y_test, preds)\nauc_value &lt;- auc(roc_curve)\nprint(paste(\"AUC:\", auc_value))\n\n\n[1] \"AUC: 0.865934928476251\"\n\n\nShow the code\n# Calculer la courbe ROC\nroc_curve &lt;- roc(y_test, preds)\n\n# Afficher la courbe ROC\nplot(roc_curve, main = \"Courbe ROC\", col = \"blue\", lwd = 2)\n\n# Optionnel : Ajouter la ligne de base (diagonale)\nabline(a = 0, b = 1, col = \"red\", lty = 2)\n\n\n\n\n\n\n\n\n\nShow the code\n# Afficher les coefficients pour le meilleur lambda\ncoefficients &lt;- coef(cv_lasso, s = \"lambda.min\")\n\n# Convertir en data.frame pour une meilleure lisibilité\ncoefficients_df &lt;- as.data.frame(as.matrix(coefficients))\ncolnames(coefficients_df) &lt;- \"Coefficient\"\ncoefficients_df$Variable &lt;- rownames(coefficients_df)\n\n# Filtrer pour ne garder que les variables avec des coefficients non nuls\ncoefficients_non_zero &lt;- coefficients_df[coefficients_df$Coefficient != 0, ]\n\n# Afficher les variables gardées et leurs coefficients\nprint(coefficients_non_zero)\n\n\n                    Coefficient          Variable\n(Intercept)       -6.594268e-01       (Intercept)\nKnitting           2.897789e+00          Knitting\nCards_games        2.442634e-01       Cards_games\nGambling          -4.166131e-01          Gambling\nCooking            1.178967e+00           Cooking\nDIY               -1.041022e+00               DIY\nVegetable_garden  -3.655189e-01  Vegetable_garden\nOrnamental_garden  2.772988e-01 Ornamental_garden\nFishing_hunting   -1.289056e+00   Fishing_hunting\nCollection        -6.543257e-01        Collection\nVehicle_custom    -1.748330e+00    Vehicle_custom\nMaking_music      -2.121348e-01      Making_music\nDiary              1.466762e+00             Diary\nWriting           -9.833754e-02           Writing\nPainting           4.373124e-01          Painting\nMontage           -9.239000e-01           Montage\nPottery            5.402698e-01           Pottery\nTheater           -2.806501e-02           Theater\nDrawing           -1.061173e-01           Drawing\nDancing            1.639313e+00           Dancing\nPhotography       -4.795022e-01       Photography\nGenealogy         -2.433708e-01         Genealogy\nScience           -8.540327e-01           Science\nNone              -2.186679e-01              None\nNo_Amateur         4.344182e-01        No_Amateur\nVideo_games       -1.824566e-01       Video_games\nTV                 8.141467e-01                TV\nRadio             -2.640448e-01             Radio\nLibrary           -8.467656e-16           Library\nMuseums           -8.953888e-02           Museums\nInternet           1.465727e-01          Internet\nConcert            4.438503e-02           Concert\n\n\nShow the code\n###CREATION INDICE\n\n# Récupérer les coefficients du modèle pour le meilleur lambda\ncoefficients &lt;- coef(cv_lasso, s = \"lambda.min\")\n\n# Convertir en data.frame et filtrer les variables non nulles\ncoefficients_df &lt;- as.data.frame(as.matrix(coefficients))\ncolnames(coefficients_df) &lt;- \"Coefficient\"\ncoefficients_df$Variable &lt;- rownames(coefficients_df)\ncoefficients_non_zero &lt;- coefficients_df[coefficients_df$Coefficient != 0, ]\n\n# Préparer la matrice X des pratiques pour l'ensemble de test (ou d'entraînement si nécessaire)\nx_test &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                       Vegetable_garden + Ornamental_garden + Fishing_hunting + \n                       Collection + Vehicle_custom + Making_music + Diary + Writing + \n                       Painting + Montage + Circus + Pottery + Theater + Drawing + \n                       Dancing + Photography + Genealogy + Science + None + No_Amateur +\n                       Video_games + TV + Radio + Library + Museums + Internet + Concert,\n                       test_data)[, -1]  # Assurez-vous d'enlever l'intercept avec [, -1]\n\n# Sélectionner les variables pertinentes\nmatched_vars &lt;- intersect(rownames(coefficients_non_zero), colnames(x_test))\nx_test &lt;- x_test[, matched_vars, drop = FALSE]\ncoef_vector &lt;- coefficients_non_zero$Coefficient[matched_vars]  # Associer les coefficients\n\nprint(paste(\"Dimension de x_test :\", dim(x_test)[1], \"x\", dim(x_test)[2]))\n\n\n[1] \"Dimension de x_test : 3078 x 31\"\n\n\nShow the code\nprint(paste(\"Longueur de coef_vector :\", length(coef_vector)))\n\n\n[1] \"Longueur de coef_vector : 31\"\n\n\nShow the code\nprint(paste(\"Nombre de valeurs NA dans x_test :\", sum(is.na(x_test))))\n\n\n[1] \"Nombre de valeurs NA dans x_test : 0\"\n\n\nShow the code\nprint(paste(\"Nombre de valeurs NA dans coef_vector :\", sum(is.na(coef_vector))))\n\n\n[1] \"Nombre de valeurs NA dans coef_vector : 31\"\n\n\nShow the code\nprint(\"Variables dans coefficients_non_zero :\")\n\n\n[1] \"Variables dans coefficients_non_zero :\"\n\n\nShow the code\nprint(coefficients_non_zero$Variable)\n\n\n [1] \"(Intercept)\"       \"Knitting\"          \"Cards_games\"      \n [4] \"Gambling\"          \"Cooking\"           \"DIY\"              \n [7] \"Vegetable_garden\"  \"Ornamental_garden\" \"Fishing_hunting\"  \n[10] \"Collection\"        \"Vehicle_custom\"    \"Making_music\"     \n[13] \"Diary\"             \"Writing\"           \"Painting\"         \n[16] \"Montage\"           \"Pottery\"           \"Theater\"          \n[19] \"Drawing\"           \"Dancing\"           \"Photography\"      \n[22] \"Genealogy\"         \"Science\"           \"None\"             \n[25] \"No_Amateur\"        \"Video_games\"       \"TV\"               \n[28] \"Radio\"             \"Library\"           \"Museums\"          \n[31] \"Internet\"          \"Concert\"          \n\n\nShow the code\nprint(\"Colonnes de x_test :\")\n\n\n[1] \"Colonnes de x_test :\"\n\n\nShow the code\nprint(colnames(x_test))\n\n\n [1] \"Knitting\"          \"Cards_games\"       \"Gambling\"         \n [4] \"Cooking\"           \"DIY\"               \"Vegetable_garden\" \n [7] \"Ornamental_garden\" \"Fishing_hunting\"   \"Collection\"       \n[10] \"Vehicle_custom\"    \"Making_music\"      \"Diary\"            \n[13] \"Writing\"           \"Painting\"          \"Montage\"          \n[16] \"Pottery\"           \"Theater\"           \"Drawing\"          \n[19] \"Dancing\"           \"Photography\"       \"Genealogy\"        \n[22] \"Science\"           \"None\"              \"No_Amateur\"       \n[25] \"Video_games\"       \"TV\"                \"Radio\"            \n[28] \"Library\"           \"Museums\"           \"Internet\"         \n[31] \"Concert\"          \n\n\nShow the code\n# Exclure \"(Intercept)\" des coefficients\ncoefficients_filtered &lt;- coefficients_non_zero[coefficients_non_zero$Variable != \"(Intercept)\", ]\n\n# Aligner les coefficients sur x_test\ncoef_vector &lt;- coefficients_filtered$Coefficient[match(colnames(x_test), coefficients_filtered$Variable)]\n\n\n\n# Calcul des scores\ntest_data$score &lt;- x_test %*% coef_vector\n\n# Normalisation des scores\nmin_score &lt;- min(test_data$score, na.rm = TRUE)\nmax_score &lt;- max(test_data$score, na.rm = TRUE)\n\nif (max_score &gt; min_score) {\n  test_data$score_normalise &lt;- (test_data$score - min_score) / (max_score - min_score)\n} else {\n  test_data$score_normalise &lt;- 0\n}\n\n# Visualisation avec ggplot2\nlibrary(ggplot2)\nggplot(test_data, aes(x = score_normalise, color = SEXE, fill = SEXE)) +\n  geom_density(alpha = 0.4) + \n  labs(title = \"Densité du Score Normalisé\", x = \"Score Normalisé\", y = \"Densité\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Préparer la matrice X pour l'ensemble complet (train + test)\nx_full &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                       Vegetable_garden + Ornamental_garden + Fishing_hunting + \n                       Collection + Vehicle_custom + Making_music + Diary + Writing + \n                       Painting + Montage + Circus + Pottery + Theater + Drawing + \n                       Dancing + Photography + Genealogy + Science + None + No_Amateur +\n                       Video_games + TV + Radio + Library + Museums + Internet + Concert,\n                       my_data_frame)[, -1]  # Exclure l'intercept\n\n# Sélectionner les variables pertinentes (identiques à celles du modèle LASSO)\nmatched_vars &lt;- intersect(rownames(coefficients_non_zero), colnames(x_full))\nx_full &lt;- x_full[, matched_vars, drop = FALSE]  # Garder uniquement les variables sélectionnées\n# Aligner les coefficients sur x_full\ncoef_vector_full &lt;- coefficients_filtered$Coefficient[match(colnames(x_full), coefficients_filtered$Variable)]\n\n# Calcul des scores pour l'ensemble complet\nmy_data_frame$score &lt;- x_full %*% coef_vector_full\n# Normalisation des scores\nmin_score_full &lt;- min(my_data_frame$score, na.rm = TRUE)\nmax_score_full &lt;- max(my_data_frame$score, na.rm = TRUE)\n\nif (max_score_full &gt; min_score_full) {\n  my_data_frame$score_normalise &lt;- (my_data_frame$score - min_score_full) / (max_score_full - min_score_full)\n} else {\n  my_data_frame$score_normalise &lt;- 0\n}\n# Visualisation du score normalisé pour l'ensemble complet avec ggplot2\nlibrary(ggplot2)\nggplot(my_data_frame, aes(x = score_normalise, color = SEXE, fill = SEXE)) +\n  geom_density(alpha = 0.4) + \n  labs(title = \"Densité du Score Normalisé (Ensemble Complet)\", x = \"Score Normalisé\", y = \"Densité\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Calculer la corrélation entre indice_normalise et score_normalise\ncorrelation_value &lt;- cor(my_data_frame$identity, my_data_frame$score_normalise, use = \"complete.obs\")\nprint(paste(\"Corrélation entre indice_normalise et score_normalise :\", correlation_value))\n\n\n[1] \"Corrélation entre indice_normalise et score_normalise : -0.64021199798235\"\n\n\nShow the code\n# Visualiser la relation entre indice_normalise et score_normalise\nlibrary(ggplot2)\nggplot(my_data_frame, aes(x = identity, y = score_normalise)) +\n  geom_point(alpha = 0.5) +\n  labs(title = \"Relation entre indice_normalise et score_normalise\", \n       x = \"Indice Normalisé\", \n       y = \"Score Normalisé\") +\n  theme_minimal() +\n  geom_smooth(method = \"lm\", col = \"red\", se = FALSE)  # Ajouter une droite de régression linéaire\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Create a data frame to store the results\nresult_table_score &lt;- data.frame(Activity = character(0), Accuracy = numeric(0))\n\nfor (activity in cultural_activities) {\n  # Perform a Probit regression for the current cultural activity\n  model_formula &lt;- as.formula(paste(activity, \"~ score_normalise\"))\n  model &lt;- glm(model_formula, data = my_data_frame, family = binomial(link = \"probit\"))\n \n  # Calculate predictions\n  predicted &lt;- ifelse(predict(model, type = \"response\") &gt;= 0.5, 1, 0)\n \n  # Calculate the accuracy\n  correct_predictions &lt;- sum(predicted == my_data_frame[[activity]])\n  total_predictions &lt;- nrow(my_data_frame)\n  accuracy &lt;- (correct_predictions / total_predictions) * 100\n \n  # Add the result to the data frame\n  result_table_score &lt;- rbind(result_table, data.frame(Activity = activity, Accuracy = accuracy))\n}\nresult_table_score\n\n\n           Activity Accuracy\n1          Knitting 84.37297\n2       Cards_games 51.00715\n3          Gambling 79.18562\n4           Cooking 56.55187\n5               DIY 51.25623\n6  Vegetable_garden 72.89365\n7   Fishing_hunting 93.95712\n8        Collection 92.54927\n9    Vehicle_custom 96.85943\n10     Making_music 68.16114\n11            Diary 85.85662\n12          Writing 88.16331\n13         Painting 78.76327\n14          Montage 84.52458\n15          Pottery 89.50617\n16          Theater 86.53888\n17          Drawing 76.73814\n18          Dancing 79.66212\n19      Photography 74.53974\n20        Genealogy 88.21746\n21          Science 88.30409\n22             None 70.19710\n23      Video_games 62.06411\n24          Library 83.20338\n25          Concert 81.92549\n26          Concert 82.06628\n\n\n\n\nShow the code\nmy_data_frame$score_scale &lt;- cut(\n  my_data_frame$score_normalise,\n  breaks = 7,  # Automatically divide into 7 slices\n  labels = c(\"Very Masculine\", \"1\", \"2\", \"3\", \"4\", \"5\", \"Very Feminine\"), \n  include.lowest = TRUE  \n)\ntable1 &lt;-\n  my_data_frame |&gt; \n  tbl_summary(include = c(score_scale),\n  by=Sex ,)|&gt; \n    add_p()\ntable1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4 1621\nWomen N = 5 0721\np-value2\n\n\n\n\nscore_scale\n\n\n\n\n&lt;0,001\n\n\n    Very Masculine\n18 (0,4%)\n0 (0%)\n\n\n\n\n    1\n322 (7,7%)\n18 (0,4%)\n\n\n\n\n    2\n1 905 (46%)\n392 (7,7%)\n\n\n\n\n    3\n1 695 (41%)\n2 014 (40%)\n\n\n\n\n    4\n205 (4,9%)\n1 699 (33%)\n\n\n\n\n    5\n16 (0,4%)\n814 (16%)\n\n\n\n\n    Very Feminine\n1 (&lt;0,1%)\n135 (2,7%)\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\nrappel des données de Trachman:\nLa majorité des femmes se disent plutôt féminines et la majorité des hommes plutôt masculins. Ceci suggère un sentiment de “normalité” du point de vue du genre\nCependant, l’intensité de ces positionnements diffère selon le sexe. Un tiers des hommes se disent très masculins, tandis que moins d’un quart des femmes se disent très féminines\nDe plus, un peu plus de 9 % des femmes se considèrent « pas très féminines », contre seulement 2 % des hommes qui se disent « pas très masculins »"
  },
  {
    "objectID": "normes_identite/CGNI.html#score-distance-à-la-norme",
    "href": "normes_identite/CGNI.html#score-distance-à-la-norme",
    "title": "Vers une Mesure Continue de l’identité de Genre",
    "section": "",
    "text": "Show the code\n# Calculer la moyenne des scores normalisés pour chaque genre\nmean_scores_by_gender &lt;- my_data_frame %&gt;%\n  group_by(SEXE) %&gt;%\n  summarise(mean_score_by_gender = mean(score_normalise, na.rm = TRUE))\n\n# Afficher les moyennes par genre\nprint(mean_scores_by_gender)\n\n\n# A tibble: 2 × 2\n  SEXE  mean_score_by_gender\n  &lt;fct&gt;                &lt;dbl&gt;\n1 1                    0.419\n2 2                    0.595\n\n\nShow the code\n# Fusionner les données avec la moyenne par genre\nmy_data_frame &lt;- my_data_frame %&gt;%\n  left_join(mean_scores_by_gender, by = \"SEXE\")\n\n# Calculer la distance entre le score normalisé de chaque individu et la moyenne de son genre\nmy_data_frame$distance_to_mean_gender &lt;- abs(my_data_frame$score_normalise - my_data_frame$mean_score_by_gender)\n\n\nggplot(my_data_frame, aes(x = distance_to_mean_gender, color = Sex, fill = Sex)) +\n  geom_density(alpha = 0.4) +\n  labs(title = \"Density of Distance to the Norm, by Sex\", \n       x = \"Distance to the Norm (Z-score)\", y = \"Density\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nlibrary(MASS)\nlibrary(tidyr)\nlibrary(ggplot2)\n\n# Assurez-vous que 'distance_to_mean_gender' est bien numérique\nmy_data_frame$distance_to_mean_gender &lt;- as.numeric(my_data_frame$distance_to_mean_gender)\n\n# Vérification du type de la variable\nprint(paste(\"Type de distance_to_mean_gender :\", class(my_data_frame$distance_to_mean_gender)))\n\n\n[1] \"Type de distance_to_mean_gender : numeric\"\n\n\nShow the code\n# Ordinal logistic regression model fitting\nmy_data_frame$satisfaction &lt;- as.factor(my_data_frame$satisfaction)  # Assurez-vous que satisfaction est bien un facteur ordinal\n\n# Ajuster le modèle\nordinal_model &lt;- polr(satisfaction ~ distance_to_mean_gender, data = my_data_frame, Hess = TRUE)\n\n# 1. Créer les valeurs de distance pour la prédiction\ndistance_vals &lt;- seq(min(my_data_frame$distance_to_mean_gender, na.rm = TRUE), \n                     max(my_data_frame$distance_to_mean_gender, na.rm = TRUE), length.out = 100)\n\n# 2. Créer un nouveau data frame pour les prédictions\nnew_data &lt;- data.frame(distance_to_mean_gender = distance_vals)\n\n# 3. Prédire les probabilités pour chaque catégorie\npredicted_probs &lt;- predict(ordinal_model, newdata = new_data, type = \"probs\")\n\n# 4. Convertir les résultats en data frame\npredicted_probs_df &lt;- as.data.frame(predicted_probs)\npredicted_probs_df$distance_to_mean_gender &lt;- distance_vals\n\n# 5. Transformer les données en format long pour ggplot2\npredicted_probs_long &lt;- pivot_longer(predicted_probs_df, \n                                     cols = -distance_to_mean_gender, \n                                     names_to = \"satisfaction\", \n                                     values_to = \"probabilite\")\n\n# 6. Visualiser les probabilités prédites\nggplot(predicted_probs_long, aes(x = distance_to_mean_gender, y = probabilite, color = satisfaction)) +\n  geom_line(size = 1.2) +\n  labs(title = \"Probability of satisfaction as a function of deviation from Norms\",\n       x = \"Distance to the Norm\",\n       y = \"Probability\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n    axis.title.x = element_text(size = 12),\n    axis.title.y = element_text(size = 12)\n  )"
  },
  {
    "objectID": "normes_identite/CGNI.html#lasso-2",
    "href": "normes_identite/CGNI.html#lasso-2",
    "title": "Vers une Mesure Continue de l’identité de Genre",
    "section": "",
    "text": "Show the code\nn_2 &lt;- nrow(my_data_frame)\n\n# Indices pour la division (2/3 pour l'entraînement, 1/3 pour le test)\ntrain_index &lt;- sample(1:n_2, size = 2 * n_2 / 3)  # 2/3 des indices pour l'entraînement\n\n# Créer l'ensemble d'entraînement et l'ensemble de test\ntrain_data &lt;- my_data_frame[train_index, ]  # Enregistrement d'entraînement\ntest_data &lt;- my_data_frame[-train_index, ]  # Enregistrement de test\n\n# Vérifier les tailles\ncat(\"Nombre d'observations dans l'ensemble d'entraînement :\", nrow(train_data), \"\\n\")\n\n\nNombre d'observations dans l'ensemble d'entraînement : 6156 \n\n\nShow the code\ncat(\"Nombre d'observations dans l'ensemble de test :\", nrow(test_data), \"\\n\")\n\n\nNombre d'observations dans l'ensemble de test : 3078 \n\n\nShow the code\n# Charger les bibliothèques nécessaires\nlibrary(glmnet)\nlibrary(pROC)\n\n# Définir la matrice X pour l'entraînement\nx_2 &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                  Vegetable_garden + Fishing_hunting + \n                  Collection + Vehicle_custom + Making_music + Diary + Writing + \n                  Painting + Montage +  Pottery + Theater + Drawing + \n                  Dancing + Photography + Genealogy + Science + None + \n                  Video_games + Library +  Concert,\n                  train_data)[, -1]\n\n# Variable cible y pour l'entraînement\ny_2 &lt;- train_data$SEXE\n\n# Ajuster le modèle LASSO avec validation croisée\ncv_lasso_2 &lt;- cv.glmnet(x_2, y_2, alpha = 1, family = \"binomial\")\nbest_lambda_2 &lt;- cv_lasso_2$lambda.min  # Lambda optimal\n\n# Vérifie les coefficients pour le lambda optimal\nprint(coef(cv_lasso_2, s = \"lambda.min\"))\n\n\n26 x 1 sparse Matrix of class \"dgCMatrix\"\n                           s1\n(Intercept)       0.241278327\nKnitting          3.292132453\nCards_games       0.210011234\nGambling         -0.440924009\nCooking           1.121404608\nDIY              -1.056417444\nVegetable_garden -0.257143930\nFishing_hunting  -1.469151636\nCollection       -0.719078970\nVehicle_custom   -1.538434788\nMaking_music     -0.100324107\nDiary             1.450903260\nWriting          -0.195681167\nPainting          0.601249644\nMontage          -0.946011138\nPottery           0.425091964\nTheater          -0.146702323\nDrawing          -0.243913677\nDancing           1.583552273\nPhotography      -0.372015708\nGenealogy        -0.290551260\nScience          -0.839985429\nNone             -0.208211076\nVideo_games      -0.161655611\nLibrary          -0.190150904\nConcert           0.002970803\n\n\nShow the code\nprint(best_lambda_2)\n\n\n[1] 0.0004980784\n\n\nShow the code\n# Préparer X_test (même traitement que pour l'entraînement)\nx_test_2 &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                  Vegetable_garden + Fishing_hunting + \n                  Collection + Vehicle_custom + Making_music + Diary + Writing + \n                  Painting + Montage +  Pottery + Theater + Drawing + \n                  Dancing + Photography + Genealogy + Science + None + \n                  Video_games + Library +  Concert,\n                       test_data)[, -1]\n\n# Prédire les probabilités sur les données de test avec le meilleur lambda\npreds_2 &lt;- predict(cv_lasso_2, newx = x_test_2, s = \"lambda.min\", type = \"response\")\n\n# Variable cible y_test pour l'ensemble de test\ny_test_2 &lt;- test_data$SEXE\n\n# Calcul de l'AUC avec pROC\nroc_curve_2 &lt;- roc(y_test_2, preds_2)\nauc_value_2 &lt;- auc(roc_curve_2)\nprint(paste(\"AUC:\", auc_value_2))\n\n\n[1] \"AUC: 0.861803379874\"\n\n\nShow the code\n# Calculer la courbe ROC\nroc_curve_2 &lt;- roc(y_test_2, preds_2)\n\n# Afficher la courbe ROC\nplot(roc_curve_2, main = \"Courbe ROC 2\", col = \"blue\", lwd = 2)\n\n# Optionnel : Ajouter la ligne de base (diagonale)\nabline(a = 0, b = 1, col = \"red\", lty = 2)\n\n\n\n\n\n\n\n\n\nShow the code\n# Afficher les coefficients pour le meilleur lambda\ncoefficients_2 &lt;- coef(cv_lasso_2, s = \"lambda.min\")\n\n# Convertir en data.frame pour une meilleure lisibilité\ncoefficients_df_2 &lt;- as.data.frame(as.matrix(coefficients_2))\ncolnames(coefficients_df_2) &lt;- \"Coefficient\"\ncoefficients_df_2$Variable &lt;- rownames(coefficients_df_2)\n\n# Filtrer pour ne garder que les variables avec des coefficients non nuls\ncoefficients_non_zero_2 &lt;- coefficients_df_2[coefficients_df_2$Coefficient != 0, ]\n\n# Afficher les variables gardées et leurs coefficients\nprint(coefficients_non_zero_2)\n\n\n                  Coefficient         Variable\n(Intercept)       0.241278327      (Intercept)\nKnitting          3.292132453         Knitting\nCards_games       0.210011234      Cards_games\nGambling         -0.440924009         Gambling\nCooking           1.121404608          Cooking\nDIY              -1.056417444              DIY\nVegetable_garden -0.257143930 Vegetable_garden\nFishing_hunting  -1.469151636  Fishing_hunting\nCollection       -0.719078970       Collection\nVehicle_custom   -1.538434788   Vehicle_custom\nMaking_music     -0.100324107     Making_music\nDiary             1.450903260            Diary\nWriting          -0.195681167          Writing\nPainting          0.601249644         Painting\nMontage          -0.946011138          Montage\nPottery           0.425091964          Pottery\nTheater          -0.146702323          Theater\nDrawing          -0.243913677          Drawing\nDancing           1.583552273          Dancing\nPhotography      -0.372015708      Photography\nGenealogy        -0.290551260        Genealogy\nScience          -0.839985429          Science\nNone             -0.208211076             None\nVideo_games      -0.161655611      Video_games\nLibrary          -0.190150904          Library\nConcert           0.002970803          Concert\n\n\nShow the code\n###CREATION INDICE\n\n# Récupérer les coefficients du modèle pour le meilleur lambda\ncoefficients_2 &lt;- coef(cv_lasso_2, s = \"lambda.min\")\n\n# Convertir en data.frame et filtrer les variables non nulles\ncoefficients_df_2 &lt;- as.data.frame(as.matrix(coefficients_2))\ncolnames(coefficients_df_2) &lt;- \"Coefficient\"\ncoefficients_df_2$Variable &lt;- rownames(coefficients_df_2)\ncoefficients_non_zero_2 &lt;- coefficients_df_2[coefficients_df_2$Coefficient != 0, ]\n\n# Préparer la matrice X des pratiques pour l'ensemble de test (ou d'entraînement si nécessaire)\nx_test_2 &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                  Vegetable_garden + Fishing_hunting + \n                  Collection + Vehicle_custom + Making_music + Diary + Writing + \n                  Painting + Montage +  Pottery + Theater + Drawing + \n                  Dancing + Photography + Genealogy + Science + None + \n                  Video_games + Library +  Concert,\n                       test_data)[, -1]  # Assurez-vous d'enlever l'intercept avec [, -1]\n\n# Sélectionner les variables pertinentes\nmatched_vars_2 &lt;- intersect(rownames(coefficients_non_zero_2), colnames(x_test_2))\nx_test_2 &lt;- x_test_2[, matched_vars_2, drop = FALSE]\ncoef_vector_2 &lt;- coefficients_non_zero_2$Coefficient[matched_vars_2]  # Associer les coefficients\n\n#print(paste(\"Dimension de x_test :\", dim(x_test)[1], \"x\", dim(x_test)[2]))\n#print(paste(\"Longueur de coef_vector :\", length(coef_vector)))\n#print(paste(\"Nombre de valeurs NA dans x_test :\", sum(is.na(x_test))))\n#print(paste(\"Nombre de valeurs NA dans coef_vector :\", sum(is.na(coef_vector))))\n\n#print(\"Variables dans coefficients_non_zero :\")\n#print(coefficients_non_zero$Variable)\n\n#print(\"Colonnes de x_test :\")\n#print(colnames(x_test))\n\n\n# Exclure \"(Intercept)\" des coefficients\ncoefficients_filtered_2 &lt;- coefficients_non_zero_2[coefficients_non_zero_2$Variable != \"(Intercept)\", ]\n\n# Aligner les coefficients sur x_test\ncoef_vector_2 &lt;- coefficients_filtered_2$Coefficient[match(colnames(x_test_2), coefficients_filtered_2$Variable)]\n\n\n\n# Calcul des scores\ntest_data$score_2 &lt;- x_test_2 %*% coef_vector_2\n\n# Normalisation des scores\nmin_score_2 &lt;- min(test_data$score_2, na.rm = TRUE)\nmax_score_2 &lt;- max(test_data$score_2, na.rm = TRUE)\n\nif (max_score_2 &gt; min_score_2) {\n  test_data$score_normalise_2 &lt;- (test_data$score_2 - min_score_2) / (max_score_2 - min_score_2)\n} else {\n  test_data$score_normalise_2 &lt;- 0\n}\n\n# Visualisation avec ggplot2\nlibrary(ggplot2)\nggplot(test_data, aes(x = score_normalise_2, color = SEXE, fill = SEXE)) +\n  geom_density(alpha = 0.4) + \n  labs(title = \"Densité du Score Normalisé 2\", x = \"Score Normalisé 2\", y = \"Densité\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\n# Préparer la matrice X pour l'ensemble complet (train + test)\nx_full_2 &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                  Vegetable_garden + Fishing_hunting + \n                  Collection + Vehicle_custom + Making_music + Diary + Writing + \n                  Painting + Montage +  Pottery + Theater + Drawing + \n                  Dancing + Photography + Genealogy + Science + None + \n                  Video_games + Library +  Concert,\n                       my_data_frame)[, -1]  # Exclure l'intercept\n\n# Sélectionner les variables pertinentes (identiques à celles du modèle LASSO)\nmatched_vars_2 &lt;- intersect(rownames(coefficients_non_zero_2), colnames(x_full_2))\nx_full_2 &lt;- x_full_2[, matched_vars_2, drop = FALSE]  # Garder uniquement les variables sélectionnées\n# Aligner les coefficients sur x_full\ncoef_vector_full_2 &lt;- coefficients_filtered_2$Coefficient[match(colnames(x_full_2), coefficients_filtered_2$Variable)]\n\n# Calcul des scores pour l'ensemble complet\nmy_data_frame$score_2 &lt;- x_full_2 %*% coef_vector_full_2\n# Normalisation des scores\nmin_score_full_2 &lt;- min(my_data_frame$score_2, na.rm = TRUE)\nmax_score_full_2 &lt;- max(my_data_frame$score_2, na.rm = TRUE)\n\nif (max_score_full_2 &gt; min_score_full_2) {\n  my_data_frame$score_normalise_2 &lt;- (my_data_frame$score_2 - min_score_full_2) / (max_score_full_2 - min_score_full_2)\n} else {\n  my_data_frame$score_normalise_2 &lt;- 0\n}\n# Visualisation du score normalisé pour l'ensemble complet avec ggplot2\nlibrary(ggplot2)\nggplot(my_data_frame, aes(x = score_normalise_2, color = SEXE, fill = SEXE)) +\n  geom_density(alpha = 0.4) + \n  labs(title = \"Densité du Score Normalisé 2(Ensemble Complet)\", x = \"Score Normalisé\", y = \"Densité\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\n# Calculer la corrélation entre indice_normalise et score_normalise\ncorrelation_value_2 &lt;- cor(my_data_frame$identity, my_data_frame$score_normalise_2, use = \"complete.obs\")\nprint(paste(\"Corrélation entre indice_normalise et score_normalise 2:\", correlation_value))\n\n\n[1] \"Corrélation entre indice_normalise et score_normalise 2: -0.64021199798235\"\n\n\nShow the code\n# Visualiser la relation entre indice_normalise et score_normalise\nlibrary(ggplot2)\nggplot(my_data_frame, aes(x = identity, y = score_normalise_2)) +\n  geom_point(alpha = 0.5) +\n  labs(title = \"Relation entre indice_normalise et score_normalise 2\", \n       x = \"Indice Normalisé\", \n       y = \"Score Normalisé\") +\n  theme_minimal() +\n  geom_smooth(method = \"lm\", col = \"red\", se = FALSE)  # Ajouter une droite de régression linéaire\n\n\n\n\n\n\n\n\n\nShow the code\n# Créer un data frame pour stocker les résultats\nresult_table_score_2 &lt;- data.frame(Activity_2 = character(0), Accuracy_2 = numeric(0))\n\ncultural_activities_2 &lt;- c(\n   \"Knitting\", \"Cards_games\", \"Gambling\", \"Cooking\", \"DIY\",\n   \"Vegetable_garden\", \"Fishing_hunting\", \"Collection\", \"Vehicle_custom\",\n   \"Making_music\", \"Diary\", \"Writing\", \"Painting\", \"Montage\",\n   \"Pottery\", \"Theater\", \"Drawing\", \"Dancing\", \"Photography\",\n   \"Genealogy\", \"Science\", \"None\", \"Video_games\", \"Library\", \"Concert\"\n)\n\nfor (activity_2 in cultural_activities_2) {\n  # Effectuer une régression Probit pour l'activité culturelle actuelle\n  model_formula_2 &lt;- as.formula(paste(activity_2, \"~ score_normalise_2\"))\n  model_2 &lt;- glm(model_formula_2, data = my_data_frame, family = binomial(link = \"probit\"))\n \n  # Calculer les prédictions\n  predicted_2 &lt;- ifelse(predict(model_2, type = \"response\") &gt;= 0.5, 1, 0)\n \n  # Calculer la précision\n  correct_predictions_2 &lt;- sum(predicted_2 == my_data_frame[[activity_2]])\n  total_predictions_2 &lt;- nrow(my_data_frame)\n  accuracy_2 &lt;- (correct_predictions_2 / total_predictions_2) * 100\n \n  # Ajouter le résultat au data frame\n  result_table_score_2 &lt;- rbind(result_table_score_2, data.frame(Activity_2 = activity_2, Accuracy_2 = accuracy_2))\n}\n\n# Afficher le tableau des résultats\nprint(result_table_score_2)\n\n\n         Activity_2 Accuracy_2\n1          Knitting   93.63223\n2       Cards_games   56.69266\n3          Gambling   78.77410\n4           Cooking   70.69526\n5               DIY   57.79727\n6  Vegetable_garden   72.05978\n7   Fishing_hunting   90.35088\n8        Collection   92.67923\n9    Vehicle_custom   96.52372\n10     Making_music   65.97358\n11            Diary   84.30799\n12          Writing   87.48105\n13         Painting   78.68746\n14          Montage   84.52458\n15          Pottery   89.50617\n16          Theater   86.10570\n17          Drawing   76.72731\n18          Dancing   76.38077\n19      Photography   74.53974\n20        Genealogy   88.21746\n21          Science   88.30409\n22             None   71.10678\n23      Video_games   61.29521\n24          Library   83.47412\n25          Concert   82.06628\n\n\n\n\nShow the code\noptions(repos = c(CRAN = \"https://cran.rstudio.com/\"))\n# Charger les bibliothèques\nlibrary(MASS)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(ggeffects)\n\n# Vérifier et convertir la variable dépendante en facteur ordonné\nmy_data_frame$satisfaction &lt;- as.ordered(my_data_frame$satisfaction)\n\n# Ajuster le modèle avec la méthode logistique\nmodel_ordinal &lt;- polr(satisfaction ~ distance_to_mean_gender, \n                       data = my_data_frame, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model_ordinal)\n\n\nCall:\npolr(formula = satisfaction ~ distance_to_mean_gender, data = my_data_frame, \n    method = \"logistic\")\n\nCoefficients:\n                         Value Std. Error t value\ndistance_to_mean_gender 0.1989     0.2735  0.7272\n\nIntercepts:\n           Value    Std. Error t value \nHigh|Low    -0.6542   0.0336   -19.4644\nLow|Medium   0.9512   0.0345    27.6055\n\nResidual Deviance: 20135.51 \nAIC: 20141.51 \n(9 observations effacées parce que manquantes)\n\n\nShow the code\nlibrary(lmtest)\n\n# Calculer les p-values\ncoeftest(model_ordinal)\n\n\n\nt test of coefficients:\n\n                        Estimate Std. Error t value Pr(&gt;|t|)\ndistance_to_mean_gender  0.19889    0.27350  0.7272   0.4671\n\n\nShow the code\n# Calculer les odds ratios\nexp(coef(model_ordinal))\n\n\ndistance_to_mean_gender \n               1.220052 \n\n\nShow the code\n# Générer une séquence de valeurs pour distance_to_mean_gender_2\nnew_data &lt;- data.frame(distance_to_mean_gender = seq(\n  min(my_data_frame$distance_to_mean_gender, na.rm = TRUE),\n  max(my_data_frame$distance_to_mean_gender, na.rm = TRUE),\n  length.out = 100\n))\n\n# Vérifier que les types sont corrects\nstr(new_data)\n\n\n'data.frame':   100 obs. of  1 variable:\n $ distance_to_mean_gender: num  1.87e-05 4.78e-03 9.54e-03 1.43e-02 1.91e-02 ...\n\n\nShow the code\n# Prédictions des probabilités\npred_probs &lt;- predict(model_ordinal, newdata = new_data, type = \"probs\")\n\n# Transformer les probabilités en data.frame\npred_probs_df &lt;- as.data.frame(pred_probs)\n\n# Ajouter la variable explicative\npred_probs_df$distance_to_mean_gender &lt;- new_data$distance_to_mean_gender\n\n# Restructurer les données pour ggplot\npred_probs_long &lt;- pivot_longer(pred_probs_df, cols = -distance_to_mean_gender, \n                                names_to = \"Satisfaction\", values_to = \"Probability\")\n\n# Visualiser les effets\nggplot(pred_probs_long, aes(x = distance_to_mean_gender, y = Probability, color = Satisfaction)) +\n  geom_line(size = 1) +\n  labs(title = \"Probabilités prédites de satisfaction en fonction de la distance au score moyen\",\n       x = \"Distance au score moyen de genre\",\n       y = \"Probabilité prédite\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\n# Calcul des effets marginaux\neffects_plot &lt;- ggpredict(model_ordinal, terms = \"distance_to_mean_gender\")\n\n# Visualisation des effets marginaux\nplot(effects_plot) + \n  ggtitle(\"Effet marginal de distance_to_mean_gender sur la satisfaction\")\n\n\n\n\n\n\n\n\n\nShow the code\n# Vérifier et forcer la variable explicative à être numérique\nmy_data_frame$distance_to_mean_gender &lt;- as.numeric(my_data_frame$distance_to_mean_gender) \n\n\n\n\nShow the code\n# Charger les bibliothèques nécessaires\nlibrary(MASS)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(ggeffects)\nlibrary(lmtest)\n\n# Vérifier et convertir la variable dépendante en facteur ordonné\nmy_data_frame$satisfaction &lt;- as.ordered(my_data_frame$satisfaction)\n\n# Vérifier et forcer la variable explicative à être numérique\nmy_data_frame$distance_to_mean_gender &lt;- as.numeric(my_data_frame$distance_to_mean_gender)\n\n# Ajuster le modèle avec la méthode logistique, incluant l'interaction avec Sex\nmodel_ordinal_sex &lt;- polr(satisfaction ~ distance_to_mean_gender * Sex, \n                          data = my_data_frame, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model_ordinal_sex)\n\n\nCall:\npolr(formula = satisfaction ~ distance_to_mean_gender * Sex, \n    data = my_data_frame, method = \"logistic\")\n\nCoefficients:\n                                    Value Std. Error t value\ndistance_to_mean_gender           0.66137    0.46790   1.413\nSexWomen                          0.09023    0.06443   1.400\ndistance_to_mean_gender:SexWomen -0.77024    0.58331  -1.320\n\nIntercepts:\n           Value    Std. Error t value \nHigh|Low    -0.6065   0.0473   -12.8234\nLow|Medium   0.9993   0.0481    20.7786\n\nResidual Deviance: 20133.42 \nAIC: 20143.42 \n(9 observations effacées parce que manquantes)\n\n\nShow the code\n# Calculer les p-values\ncoeftest(model_ordinal_sex)\n\n\n\nt test of coefficients:\n\n                                  Estimate Std. Error t value Pr(&gt;|t|)\ndistance_to_mean_gender           0.661372   0.467899  1.4135   0.1575\nSexWomen                          0.090232   0.064432  1.4004   0.1614\ndistance_to_mean_gender:SexWomen -0.770243   0.583306 -1.3205   0.1867\n\n\nShow the code\n# Calculer les odds ratios\nexp(coef(model_ordinal_sex))\n\n\n         distance_to_mean_gender                         SexWomen \n                       1.9374481                        1.0944276 \ndistance_to_mean_gender:SexWomen \n                       0.4629006 \n\n\nShow the code\n# Générer une séquence de valeurs pour distance_to_mean_gender\nnew_data_sex_men &lt;- data.frame(distance_to_mean_gender = seq(\n  min(my_data_frame$distance_to_mean_gender, na.rm = TRUE),\n  max(my_data_frame$distance_to_mean_gender, na.rm = TRUE),\n  length.out = 100\n))\nnew_data_sex_men$Sex &lt;- \"Men\"  # Spécifier que c'est pour les hommes\n\nnew_data_sex_women &lt;- data.frame(distance_to_mean_gender = seq(\n  min(my_data_frame$distance_to_mean_gender, na.rm = TRUE),\n  max(my_data_frame$distance_to_mean_gender, na.rm = TRUE),\n  length.out = 100\n))\nnew_data_sex_women$Sex &lt;- \"Women\"  # Spécifier que c'est pour les femmes\n\n# Combiner les données pour hommes et femmes\nnew_data_sex &lt;- rbind(new_data_sex_men, new_data_sex_women)\n\n# Prédictions des probabilités pour chaque catégorie de satisfaction\npred_probs_sex &lt;- predict(model_ordinal_sex, newdata = new_data_sex, type = \"probs\")\n\n# Transformer les probabilités en data.frame\npred_probs_df_sex &lt;- as.data.frame(pred_probs_sex)\n\n# Ajouter la variable explicative (distance_to_mean_gender) et Sex\npred_probs_df_sex$distance_to_mean_gender &lt;- new_data_sex$distance_to_mean_gender\npred_probs_df_sex$Sex &lt;- new_data_sex$Sex\n\n# Restructurer les données pour ggplot\npred_probs_long_sex &lt;- pivot_longer(pred_probs_df_sex, cols = -c(distance_to_mean_gender, Sex), \n                                    names_to = \"Satisfaction\", values_to = \"Probability\")\n\n# Visualiser les effets selon le sexe\nggplot(pred_probs_long_sex, aes(x = distance_to_mean_gender, y = Probability, color = Satisfaction, linetype = Sex)) +\n  geom_line(size = 1) +\n  labs(title = \"Probabilités prédites de satisfaction en fonction de la distance au score moyen, par sexe\",\n       x = \"Distance au score moyen de genre\",\n       y = \"Probabilité prédite\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\n# Calcul des effets marginaux pour chaque sexe\neffects_plot_sex &lt;- ggpredict(model_ordinal_sex, terms = c(\"distance_to_mean_gender\", \"Sex\"))\n\n# Visualisation des effets marginaux par sexe\nplot(effects_plot_sex) + \n  ggtitle(\"Effet marginal de distance_to_mean_gender sur la satisfaction, par sexe\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Charger les bibliothèques nécessaires\nlibrary(MASS)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(ggeffects)\nlibrary(lmtest)\n\n# Vérifier et convertir la variable dépendante en facteur ordonné\nmy_data_frame$satisfaction &lt;- as.ordered(my_data_frame$satisfaction)\n\n# Vérifier et forcer la variable explicative à être numérique\nmy_data_frame$distance_abs &lt;- as.numeric(my_data_frame$distance_abs)\n\n# Ajuster le modèle avec la méthode logistique, incluant l'interaction avec Sex\nmodel_ordinal_sex_abs &lt;- polr(satisfaction ~ distance_abs * Sex, \n                              data = my_data_frame, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model_ordinal_sex_abs)\n\n\nCall:\npolr(formula = satisfaction ~ distance_abs * Sex, data = my_data_frame, \n    method = \"logistic\")\n\nCoefficients:\n                         Value Std. Error t value\ndistance_abs           0.03373    0.04550  0.7413\nSexWomen              -0.02619    0.06039 -0.4336\ndistance_abs:SexWomen  0.07107    0.05949  1.1946\n\nIntercepts:\n           Value    Std. Error t value \nHigh|Low    -0.6312   0.0472   -13.3727\nLow|Medium   0.9754   0.0479    20.3602\n\nResidual Deviance: 20127.49 \nAIC: 20137.49 \n(9 observations effacées parce que manquantes)\n\n\nShow the code\n# Calculer les p-values\ncoeftest(model_ordinal_sex_abs)\n\n\n\nt test of coefficients:\n\n                       Estimate Std. Error t value Pr(&gt;|t|)\ndistance_abs           0.033732   0.045504  0.7413   0.4585\nSexWomen              -0.026185   0.060393 -0.4336   0.6646\ndistance_abs:SexWomen  0.071069   0.059493  1.1946   0.2323\n\n\nShow the code\n# Calculer les odds ratios\nexp(coef(model_ordinal_sex_abs))\n\n\n         distance_abs              SexWomen distance_abs:SexWomen \n            1.0343070             0.9741547             1.0736553 \n\n\nShow the code\n# Générer une séquence de valeurs pour distance_abs\nnew_data_sex_men_abs &lt;- data.frame(distance_abs = seq(\n  min(my_data_frame$distance_abs, na.rm = TRUE),\n  max(my_data_frame$distance_abs, na.rm = TRUE),\n  length.out = 100\n))\nnew_data_sex_men_abs$Sex &lt;- \"Men\"  # Spécifier que c'est pour les hommes\n\nnew_data_sex_women_abs &lt;- data.frame(distance_abs = seq(\n  min(my_data_frame$distance_abs, na.rm = TRUE),\n  max(my_data_frame$distance_abs, na.rm = TRUE),\n  length.out = 100\n))\nnew_data_sex_women_abs$Sex &lt;- \"Women\"  # Spécifier que c'est pour les femmes\n\n# Combiner les données pour hommes et femmes\nnew_data_sex_abs &lt;- rbind(new_data_sex_men_abs, new_data_sex_women_abs)\n\n# Prédictions des probabilités pour chaque catégorie de satisfaction\npred_probs_sex_abs &lt;- predict(model_ordinal_sex_abs, newdata = new_data_sex_abs, type = \"probs\")\n\n# Transformer les probabilités en data.frame\npred_probs_df_sex_abs &lt;- as.data.frame(pred_probs_sex_abs)\n\n# Ajouter la variable explicative (distance_abs) et Sex\npred_probs_df_sex_abs$distance_abs &lt;- new_data_sex_abs$distance_abs\npred_probs_df_sex_abs$Sex &lt;- new_data_sex_abs$Sex\n\n# Restructurer les données pour ggplot\npred_probs_long_sex_abs &lt;- pivot_longer(pred_probs_df_sex_abs, cols = -c(distance_abs, Sex), \n                                         names_to = \"Satisfaction\", values_to = \"Probability\")\n\n# Visualiser les effets selon le sexe\nggplot(pred_probs_long_sex_abs, aes(x = distance_abs, y = Probability, color = Satisfaction, linetype = Sex)) +\n  geom_line(size = 1) +\n  labs(title = \"Probabilités prédites de satisfaction en fonction de la distance absolue au score moyen, par sexe\",\n       x = \"Distance absolue au score moyen de genre\",\n       y = \"Probabilité prédite\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\n# Calcul des effets marginaux pour chaque sexe\neffects_plot_sex_abs &lt;- ggpredict(model_ordinal_sex_abs, terms = c(\"distance_abs\", \"Sex\"))\n\n# Visualisation des effets marginaux par sexe\nplot(effects_plot_sex_abs) + \n  ggtitle(\"Effet marginal de distance_abs sur la satisfaction, par sexe\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Charger les bibliothèques nécessaires\nlibrary(MASS)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(ggeffects)\nlibrary(lmtest)\n\n# Vérifier et convertir la variable dépendante en facteur ordonné\nmy_data_frame$Health &lt;- as.ordered(my_data_frame$Health)\n\n# Vérifier et forcer la variable explicative à être numérique\nmy_data_frame$distance_to_mean_gender &lt;- as.numeric(my_data_frame$distance_to_mean_gender)\n\n# Ajuster le modèle avec la méthode logistique, incluant l'interaction avec Sex\nmodel_ordinal_sex &lt;- polr(Health ~ distance_to_mean_gender * Sex, \n                          data = my_data_frame, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model_ordinal_sex)\n\n\nCall:\npolr(formula = Health ~ distance_to_mean_gender * Sex, data = my_data_frame, \n    method = \"logistic\")\n\nCoefficients:\n                                    Value Std. Error t value\ndistance_to_mean_gender          -0.67943    0.54325 -1.2507\nSexWomen                         -0.04176    0.07519 -0.5554\ndistance_to_mean_gender:SexWomen  1.17361    0.68187  1.7212\n\nIntercepts:\n            Value    Std. Error t value \nBad|Good     -2.3932   0.0613   -39.0681\nGood|Medium   1.2633   0.0545    23.1766\n\nResidual Deviance: 14569.98 \nAIC: 14579.98 \n(43 observations effacées parce que manquantes)\n\n\nShow the code\n# Calculer les p-values\ncoeftest(model_ordinal_sex)\n\n\n\nt test of coefficients:\n\n                                  Estimate Std. Error t value Pr(&gt;|t|)  \ndistance_to_mean_gender          -0.679434   0.543253 -1.2507  0.21108  \nSexWomen                         -0.041757   0.075186 -0.5554  0.57865  \ndistance_to_mean_gender:SexWomen  1.173612   0.681866  1.7212  0.08525 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nShow the code\n# Calculer les odds ratios\nexp(coef(model_ordinal_sex))\n\n\n         distance_to_mean_gender                         SexWomen \n                       0.5069037                        0.9591026 \ndistance_to_mean_gender:SexWomen \n                       3.2336507 \n\n\nShow the code\n# Générer une séquence de valeurs pour distance_to_mean_gender\nnew_data_sex_men &lt;- data.frame(distance_to_mean_gender = seq(\n  min(my_data_frame$distance_to_mean_gender, na.rm = TRUE),\n  max(my_data_frame$distance_to_mean_gender, na.rm = TRUE),\n  length.out = 100\n))\nnew_data_sex_men$Sex &lt;- \"Men\"  # Spécifier que c'est pour les hommes\n\nnew_data_sex_women &lt;- data.frame(distance_to_mean_gender = seq(\n  min(my_data_frame$distance_to_mean_gender, na.rm = TRUE),\n  max(my_data_frame$distance_to_mean_gender, na.rm = TRUE),\n  length.out = 100\n))\nnew_data_sex_women$Sex &lt;- \"Women\"  # Spécifier que c'est pour les femmes\n\n# Combiner les données pour hommes et femmes\nnew_data_sex &lt;- rbind(new_data_sex_men, new_data_sex_women)\n\n# Prédictions des probabilités pour chaque catégorie de satisfaction\npred_probs_sex &lt;- predict(model_ordinal_sex, newdata = new_data_sex, type = \"probs\")\n\n# Transformer les probabilités en data.frame\npred_probs_df_sex &lt;- as.data.frame(pred_probs_sex)\n\n# Ajouter la variable explicative (distance_to_mean_gender) et Sex\npred_probs_df_sex$distance_to_mean_gender &lt;- new_data_sex$distance_to_mean_gender\npred_probs_df_sex$Sex &lt;- new_data_sex$Sex\n\n# Restructurer les données pour ggplot\npred_probs_long_sex &lt;- pivot_longer(pred_probs_df_sex, cols = -c(distance_to_mean_gender, Sex), \n                                    names_to = \"Health\", values_to = \"Probability\")\n\n# Visualiser les effets selon le sexe\nggplot(pred_probs_long_sex, aes(x = distance_to_mean_gender, y = Probability, color = Health, linetype = Sex)) +\n  geom_line(size = 1) +\n  labs(title = \"Probabilités prédites de santé en fonction de la distance au score moyen, par sexe\",\n       x = \"Distance au score moyen de genre\",\n       y = \"Probabilité prédite\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\n# Calcul des effets marginaux pour chaque sexe\neffects_plot_sex &lt;- ggpredict(model_ordinal_sex, terms = c(\"distance_to_mean_gender\", \"Sex\"))\n\n# Visualisation des effets marginaux par sexe\nplot(effects_plot_sex) + \n  ggtitle(\"Effet marginal de distance_to_mean_gender sur la satisfaction, par sexe\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(my_data_frame, aes(x = distance_to_mean_gender, fill = satisfaction)) +\n  geom_bar(position = \"fill\") +\n  labs(title = \"Répartition de la satisfaction par distance_to_mean_gender\",\n       x = \"Distance au score moyen de genre\",\n       y = \"Proportion\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set3\")\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(my_data_frame, aes(x = satisfaction, y = distance_to_mean_gender, fill = satisfaction)) +\n  geom_violin(trim = FALSE) +\n  labs(title = \"Distribution de distance_to_mean_gender par satisfaction\",\n       x = \"Satisfaction\",\n       y = \"Distance au score moyen de genre\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set3\")\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Calculer la distance absolue par rapport à la moyenne et à l'écart-type pour chaque sexe\nmean_gender_score &lt;- tapply(my_data_frame$distance_to_mean_gender, my_data_frame$Sex, mean)\nsd_gender &lt;- tapply(my_data_frame$distance_to_mean_gender, my_data_frame$Sex, sd)\n\n# Calculer la distance absolue par rapport à la moyenne et l'écart-type\nmy_data_frame$distance_abs_score &lt;- abs((my_data_frame$distance_to_mean_gender - mean_gender_score[my_data_frame$Sex]) / sd_gender[my_data_frame$Sex])\n\n# Créer une colonne norm_status pour identifier les individus \"hors normes\" (distance_abs_score &gt; 2 par exemple)\nmy_data_frame$norm_status &lt;- ifelse(my_data_frame$distance_abs_score &gt; 2, \"Hors normes\", \"Normaux\")\n\n# Vérifier que la colonne a bien été ajoutée\nhead(my_data_frame)\n\n\n         IDENT18    POND_INIT         POND TYPMEN NHAB TUU2016 REG SEXE AGE\n1 Z01202A00002V2 0.9702619959 5205.7105547      1    1       2  84    1  59\n2   Z01202A00004 0.9702619959 13909.706241      4    3       2  84    1  16\n3 Z01202A00006V2 0.9702619959  6949.074595      4    3       2  84    1  47\n4   Z01202A00007 0.9702619959 4162.1183557      3    2       2  84    2  74\n5   Z01202A00008 0.9702619959 2823.6286989      1    1       2  84    1  71\n6   Z01202A00010 0.9702619959 4602.0810455      4    3       2  84    1  52\n  CRITAGE AUTRENF PETITENF LNAIS REVENU TRANREV CRITREVENU CLASS_univprat\n1       3       2       NA     1      1      NA          6              2\n2       1       2       NA     1      1      NA          8              3\n3       3       2       NA     1      1      NA          9              4\n4       4       1        2     2      1      NA          4              1\n5       4       2       NA     1      2       3          3              1\n6       3      NA        2     1      1      NA          9              4\n  CLASS_univprat_name A15 A16 A17 A18_SQ1 A18_SQ2 A18_SQ3 A18_SQ4 VITENCOUPLE\n1          Bain audio   2   2   3      NA      NA      NA      NA           3\n2            Tout-num   1   2   3      NA      NA      NA      NA           3\n3        Culture patr   4   1   2       1       1       1       1           1\n4         Petit ecran   3   2   3      NA      NA      NA      NA           1\n5         Petit ecran   3   2   3      NA      NA      NA      NA           3\n6        Culture patr   2   2   3      NA      NA      NA      NA           1\n  NOIKISH NOICONJ CSTOT CSTOT_conj G_PCS_MENAGE_ SG_PCS_MENAGE_ I_PCS_MENAGE\n1       1      NA    48         NA           III          III B            0\n2       3      NA    NA         NA           III          III C            1\n3       2       1    33         42             I          I   B            0\n4       2       1    56         68             V          V   A            0\n5       1      NA    64         NA            VI          VI  B            0\n6       1       2    37         37             I          I   A            0\n  SEXE_pers1 ANAIS_pers1 AGE_pers1 AGEJANV_pers1 LNAIS_pers1 DEPNAIS_pers1\n1          1        1959        59            58           1            69\n2          1        1978        39            39           1            39\n3          2        1975        43            42           1             1\n4          1        1934        83            83           2              \n5          1        1946        71            71           1             1\n6          1        1966        52            51           1             1\n  ANARRIV_pers1 ANARRIV_pers1_C_1 AGARRIV_pers1 AGARRIV_pers1_C_1 COUPLE_pers1\n1            NA                NA            NA                NA            3\n2            NA                NA            NA                NA            1\n3            NA                NA            NA                NA            1\n4             1              1971            NA                NA            1\n5            NA                NA            NA                NA            3\n6            NA                NA            NA                NA            1\n  NOI_99_pers1 CONJOINT_pers1 ETAMATRI_pers1 MER1E_pers1 MERELOG_pers1\n1           NA             NA              1           3            NA\n2           NA              2              2           2            NA\n3           NA              2              1           2            22\n4           NA              2              2           3            NA\n5           NA             NA              1           3            NA\n6           NA              2              2           2            NA\n  PERELOG_pers1 PER1E_pers1 LIENTYP_pers1 LIENPERS_pers1 SEXE_pers2 ANAIS_pers2\n1            NA           3            NA             NA         NA          NA\n2            22           1            NA             NA          2        1979\n3            NA           2            NA             NA          1        1971\n4            NA           3            NA             NA          2        1943\n5            NA           3            NA             NA         NA          NA\n6            22           3            NA             NA          2        1963\n  AGE_pers2 AGEJANV_pers2 LNAIS_pers2 DEPNAIS_pers2 ANARRIV_pers2\n1        NA            NA          NA                          NA\n2        39            38           1            38            NA\n3        47            46           1             1            NA\n4        74            74           2                           1\n5        NA            NA          NA                          NA\n6        55            54           1             1            NA\n  ANARRIV_pers2_C_1 AGARRIV_pers2 AGARRIV_pers2_C_1 COUPLE_pers2 NOI_99_pers2\n1                NA            NA                NA           NA           NA\n2                NA            NA                NA            1           NA\n3                NA            NA                NA            1           NA\n4              1973            NA                NA            1           NA\n5                NA            NA                NA           NA           NA\n6                NA            NA                NA            1           NA\n  CONJOINT_pers2 ETAMATRI_pers2 MER1E_pers2 MERELOG_pers2 PERELOG_pers2\n1             NA             NA          NA            NA            NA\n2              1              2           2            22            NA\n3              1              1           2            NA            NA\n4              1              2           3            NA            NA\n5             NA             NA          NA            NA            NA\n6              1              2           2            22            NA\n  PER1E_pers2 LIENTYP_pers2 LIENPERS_pers2 SEXE_pers3 ANAIS_pers3 AGE_pers3\n1          NA            NA             NA         NA          NA        NA\n2           2            NA             NA          1        2001        16\n3           3            NA             NA          1        2002        16\n4           3            NA             NA         NA          NA        NA\n5          NA            NA             NA         NA          NA        NA\n6           2            NA             NA          1        1995        22\n  AGEJANV_pers3 LNAIS_pers3 DEPNAIS_pers3 ANARRIV_pers3 ANARRIV_pers3_C_1\n1            NA          NA                          NA                NA\n2            16           1            84            NA                NA\n3            15           1            69            NA                NA\n4            NA          NA                          NA                NA\n5            NA          NA                          NA                NA\n6            22           1             1            NA                NA\n  AGARRIV_pers3 AGARRIV_pers3_C_1 COUPLE_pers3 NOI_99_pers3 CONJOINT_pers3\n1            NA                NA           NA           NA             NA\n2            NA                NA            3           NA             NA\n3            NA                NA            3           NA             NA\n4            NA                NA           NA           NA             NA\n5            NA                NA           NA           NA             NA\n6            NA                NA            3           NA             NA\n  ETAMATRI_pers3 MER1E_pers3 MERELOG_pers3 PERELOG_pers3 PER1E_pers3\n1             NA          NA            NA            NA          NA\n2              1           1             2             1           1\n3              1           1             1            21           2\n4             NA          NA            NA            NA          NA\n5             NA          NA            NA            NA          NA\n6              1           1             2             1           1\n  LIENTYP_pers3 LIENPERS_pers3 SEXE_pers4 ANAIS_pers4 AGE_pers4 AGEJANV_pers4\n1            NA             NA         NA          NA        NA            NA\n2            NA             NA         NA          NA        NA            NA\n3            NA             NA         NA          NA        NA            NA\n4            NA             NA         NA          NA        NA            NA\n5            NA             NA         NA          NA        NA            NA\n6            NA             NA         NA          NA        NA            NA\n  LNAIS_pers4 DEPNAIS_pers4 ANARRIV_pers4 ANARRIV_pers4_C_1 AGARRIV_pers4\n1          NA                          NA                NA            NA\n2          NA                          NA                NA            NA\n3          NA                          NA                NA            NA\n4          NA                          NA                NA            NA\n5          NA                          NA                NA            NA\n6          NA                          NA                NA            NA\n  AGARRIV_pers4_C_1 COUPLE_pers4 NOI_99_pers4 CONJOINT_pers4 ETAMATRI_pers4\n1                NA           NA           NA             NA             NA\n2                NA           NA           NA             NA             NA\n3                NA           NA           NA             NA             NA\n4                NA           NA           NA             NA             NA\n5                NA           NA           NA             NA             NA\n6                NA           NA           NA             NA             NA\n  MER1E_pers4 MERELOG_pers4 PERELOG_pers4 PER1E_pers4 LIENTYP_pers4\n1          NA            NA            NA          NA            NA\n2          NA            NA            NA          NA            NA\n3          NA            NA            NA          NA            NA\n4          NA            NA            NA          NA            NA\n5          NA            NA            NA          NA            NA\n6          NA            NA            NA          NA            NA\n  LIENPERS_pers4 SEXE_pers5 ANAIS_pers5 AGE_pers5 AGEJANV_pers5 LNAIS_pers5\n1             NA         NA          NA        NA            NA          NA\n2             NA         NA          NA        NA            NA          NA\n3             NA         NA          NA        NA            NA          NA\n4             NA         NA          NA        NA            NA          NA\n5             NA         NA          NA        NA            NA          NA\n6             NA         NA          NA        NA            NA          NA\n  DEPNAIS_pers5 ANARRIV_pers5 ANARRIV_pers5_C_1 AGARRIV_pers5 AGARRIV_pers5_C_1\n1            NA            NA                NA            NA                NA\n2            NA            NA                NA            NA                NA\n3            NA            NA                NA            NA                NA\n4            NA            NA                NA            NA                NA\n5            NA            NA                NA            NA                NA\n6            NA            NA                NA            NA                NA\n  COUPLE_pers5 NOI_99_pers5 CONJOINT_pers5 ETAMATRI_pers5 MER1E_pers5\n1           NA           NA             NA             NA          NA\n2           NA           NA             NA             NA          NA\n3           NA           NA             NA             NA          NA\n4           NA           NA             NA             NA          NA\n5           NA           NA             NA             NA          NA\n6           NA           NA             NA             NA          NA\n  MERELOG_pers5 PERELOG_pers5 PER1E_pers5 LIENTYP_pers5 LIENPERS_pers5\n1            NA            NA          NA            NA             NA\n2            NA            NA          NA            NA             NA\n3            NA            NA          NA            NA             NA\n4            NA            NA          NA            NA             NA\n5            NA            NA          NA            NA             NA\n6            NA            NA          NA            NA             NA\n  SEXE_pers6 ANAIS_pers6 AGE_pers6 AGEJANV_pers6 LNAIS_pers6 DEPNAIS_pers6\n1         NA          NA        NA            NA          NA            NA\n2         NA          NA        NA            NA          NA            NA\n3         NA          NA        NA            NA          NA            NA\n4         NA          NA        NA            NA          NA            NA\n5         NA          NA        NA            NA          NA            NA\n6         NA          NA        NA            NA          NA            NA\n  ANARRIV_pers6 ANARRIV_pers6_C_1 AGARRIV_pers6 AGARRIV_pers6_C_1 COUPLE_pers6\n1            NA                NA            NA                NA           NA\n2            NA                NA            NA                NA           NA\n3            NA                NA            NA                NA           NA\n4            NA                NA            NA                NA           NA\n5            NA                NA            NA                NA           NA\n6            NA                NA            NA                NA           NA\n  NOI_99_pers6 CONJOINT_pers6 ETAMATRI_pers6 MER1E_pers6 MERELOG_pers6\n1           NA             NA             NA          NA            NA\n2           NA             NA             NA          NA            NA\n3           NA             NA             NA          NA            NA\n4           NA             NA             NA          NA            NA\n5           NA             NA             NA          NA            NA\n6           NA             NA             NA          NA            NA\n  PERELOG_pers6 PER1E_pers6 LIENTYP_pers6 LIENPERS_pers6 SEXE_pers7 ANAIS_pers7\n1            NA          NA            NA             NA         NA          NA\n2            NA          NA            NA             NA         NA          NA\n3            NA          NA            NA             NA         NA          NA\n4            NA          NA            NA             NA         NA          NA\n5            NA          NA            NA             NA         NA          NA\n6            NA          NA            NA             NA         NA          NA\n  AGE_pers7 AGEJANV_pers7 LNAIS_pers7 DEPNAIS_pers7 ANARRIV_pers7\n1        NA            NA          NA            NA            NA\n2        NA            NA          NA            NA            NA\n3        NA            NA          NA            NA            NA\n4        NA            NA          NA            NA            NA\n5        NA            NA          NA            NA            NA\n6        NA            NA          NA            NA            NA\n  ANARRIV_pers7_C_1 AGARRIV_pers7 AGARRIV_pers7_C_1 COUPLE_pers7 NOI_99_pers7\n1                NA            NA                NA           NA           NA\n2                NA            NA                NA           NA           NA\n3                NA            NA                NA           NA           NA\n4                NA            NA                NA           NA           NA\n5                NA            NA                NA           NA           NA\n6                NA            NA                NA           NA           NA\n  CONJOINT_pers7 ETAMATRI_pers7 MER1E_pers7 MERELOG_pers7 PERELOG_pers7\n1             NA             NA          NA            NA            NA\n2             NA             NA          NA            NA            NA\n3             NA             NA          NA            NA            NA\n4             NA             NA          NA            NA            NA\n5             NA             NA          NA            NA            NA\n6             NA             NA          NA            NA            NA\n  PER1E_pers7 LIENTYP_pers7 LIENPERS_pers7 SEXE_pers8 ANAIS_pers8 AGE_pers8\n1          NA            NA             NA         NA          NA        NA\n2          NA            NA             NA         NA          NA        NA\n3          NA            NA             NA         NA          NA        NA\n4          NA            NA             NA         NA          NA        NA\n5          NA            NA             NA         NA          NA        NA\n6          NA            NA             NA         NA          NA        NA\n  AGEJANV_pers8 LNAIS_pers8 DEPNAIS_pers8 ANARRIV_pers8 ANARRIV_pers8_C_1\n1            NA          NA            NA            NA                NA\n2            NA          NA            NA            NA                NA\n3            NA          NA            NA            NA                NA\n4            NA          NA            NA            NA                NA\n5            NA          NA            NA            NA                NA\n6            NA          NA            NA            NA                NA\n  AGARRIV_pers8 AGARRIV_pers8_C_1 COUPLE_pers8 NOI_99_pers8 CONJOINT_pers8\n1            NA                NA           NA           NA             NA\n2            NA                NA           NA           NA             NA\n3            NA                NA           NA           NA             NA\n4            NA                NA           NA           NA             NA\n5            NA                NA           NA           NA             NA\n6            NA                NA           NA           NA             NA\n  ETAMATRI_pers8 MER1E_pers8 MERELOG_pers8 PERELOG_pers8 PER1E_pers8\n1             NA          NA            NA            NA          NA\n2             NA          NA            NA            NA          NA\n3             NA          NA            NA            NA          NA\n4             NA          NA            NA            NA          NA\n5             NA          NA            NA            NA          NA\n6             NA          NA            NA            NA          NA\n  LIENTYP_pers8 LIENPERS_pers8 A1 A2 A3 A4 A5 A6 A71 A72 A73 A74 A75 A8 A9\n1            NA             NA  1  1  1  2  1  1   0   0   1   0   0  5  4\n2            NA             NA  1  2  1  4  1  3   1   0   0   0   0  1  5\n3            NA             NA  1  3  1  1  1  1   0   0   1   0   0  2  3\n4            NA             NA  2  3  2 NA  1  1   1   0   0   0   0  5  2\n5            NA             NA  2  3  2 NA  2 NA  NA  NA  NA  NA  NA  4  5\n6            NA             NA  1  1  1  2  1  1   1   0   0   0   0  5  3\n  Knitting Cards_games Gambling Cooking DIY Vegetable_garden Ornamental_garden\n1        0           0        0       0   1                0                 0\n2        0           0        0       0   0                0                 0\n3        0           0        0       1   0                1                 0\n4        1           0        0       1   0                1                 0\n5        0           0        1       0   0                0                 0\n6        0           1        0       1   1                1                 1\n  Fishing_hunting Collection Vehicle_custom No_Amateur A1012 A1013 A1101 A1102\n1               1          1              1          0     0     0    NA    NA\n2               0          0              0          1     0     0    NA    NA\n3               0          0              0          0     0     0    NA    NA\n4               0          0              0          0     0     0    NA    NA\n5               0          0              0          0     0     0     1     0\n6               0          0              0          0     0     0     1     0\n  A1103 A1104 A1105 A1106 A1107 A1108 A1109 A1110 A1111 A1112 A1113 A12 A13\n1    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   1   1\n2    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   1   1\n3    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   2  NA\n4    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   2  NA\n5     0     0     0     0     0     0     0     0     0     0     0   2  NA\n6     0     0     0     0     0     1     0     0     0     0     0   1   3\n  Making_music Diary Writing Painting Montage Circus Pottery Theater Drawing\n1            0     0       0        0       0      0       0       0       0\n2            1     0       0        1       1      0       0       0       1\n3            1     0       0        1       0      0       0       0       0\n4            0     0       0        0       0      0       0       0       0\n5            0     0       0        0       0      0       0       0       0\n6            0     0       0        0       0      0       0       0       0\n  Dancing Photography Genealogy Science None A1915 A1916 RECODE_A21 A20_musique\n1       0           1         0       0    0     0     0          1          NA\n2       0           1         0       1    0     0     0          4           8\n3       0           0         0       0    0     0     0          2          44\n4       0           0         0       0    1     0     0         NA          NA\n5       0           0         0       0    1     0     0         NA          NA\n6       0           0         0       0    1     0     0         NA          NA\n  A21_musique A22_musique A23_musique A241_musique A242_musique A243_musique\n1          NA          NA          NA           NA           NA           NA\n2           2          15          NA           NA           NA           NA\n3           1          NA           1            1            0            0\n4          NA          NA          NA           NA           NA           NA\n5          NA          NA          NA           NA           NA           NA\n6          NA          NA          NA           NA           NA           NA\n  A244_musique A245_musique A246_musique A25_musique A261_musique A262_musique\n1           NA           NA           NA          NA           NA           NA\n2           NA           NA           NA          NA            0            0\n3            0            0            0          NA            1            0\n4           NA           NA           NA          NA           NA           NA\n5           NA           NA           NA          NA           NA           NA\n6           NA           NA           NA          NA           NA           NA\n  A263_musique A264_musique A265_musique A266_musique A267_musique A27_musique\n1           NA           NA           NA           NA           NA            \n2            1            0            0            0            0            \n3            0            0            0            0            0         268\n4           NA           NA           NA           NA           NA            \n5           NA           NA           NA           NA           NA            \n6           NA           NA           NA           NA           NA            \n  A28_musique A2901_musique A2902_musique A2903_musique A2904_musique\n1                        NA            NA            NA            NA\n2                         1             1             0             0\n3                         0             0             0             0\n4                        NA            NA            NA            NA\n5                        NA            NA            NA            NA\n6                        NA            NA            NA            NA\n  A2905_musique A2906_musique A2907_musique A2908_musique A2909_musique\n1            NA            NA            NA            NA            NA\n2             0             0             0             0             0\n3             0             0             0             0             1\n4            NA            NA            NA            NA            NA\n5            NA            NA            NA            NA            NA\n6            NA            NA            NA            NA            NA\n  A2910_musique A2911_musique A2912_musique A2913_musique A20_journal\n1            NA            NA            NA            NA          NA\n2             0             0             0             0          NA\n3             0             0             0             0          NA\n4            NA            NA            NA            NA          NA\n5            NA            NA            NA            NA          NA\n6            NA            NA            NA            NA          NA\n  A21_journal A22_journal A23_journal A241_journal A242_journal A243_journal\n1          NA          NA          NA           NA           NA           NA\n2          NA          NA          NA           NA           NA           NA\n3          NA          NA          NA           NA           NA           NA\n4          NA          NA          NA           NA           NA           NA\n5          NA          NA          NA           NA           NA           NA\n6          NA          NA          NA           NA           NA           NA\n  A244_journal A245_journal A246_journal A25_journal A20_romans A21_romans\n1           NA           NA           NA          NA         NA         NA\n2           NA           NA           NA          NA         NA         NA\n3           NA           NA           NA          NA         NA         NA\n4           NA           NA           NA          NA         NA         NA\n5           NA           NA           NA          NA         NA         NA\n6           NA           NA           NA          NA         NA         NA\n  A22_romans A23_romans A241_romans A242_romans A243_romans A244_romans\n1         NA         NA          NA          NA          NA          NA\n2         NA         NA          NA          NA          NA          NA\n3         NA         NA          NA          NA          NA          NA\n4         NA         NA          NA          NA          NA          NA\n5         NA         NA          NA          NA          NA          NA\n6         NA         NA          NA          NA          NA          NA\n  A245_romans A246_romans A25_romans A20_peinture A21_peinture A22_peinture\n1          NA          NA         NA           NA           NA           NA\n2          NA          NA         NA            5            2           15\n3          NA          NA         NA           39            1           NA\n4          NA          NA         NA           NA           NA           NA\n5          NA          NA         NA           NA           NA           NA\n6          NA          NA         NA           NA           NA           NA\n  A23_peinture A241_peinture A242_peinture A243_peinture A244_peinture\n1           NA            NA            NA            NA            NA\n2           NA            NA            NA            NA            NA\n3            2            NA            NA            NA            NA\n4           NA            NA            NA            NA            NA\n5           NA            NA            NA            NA            NA\n6           NA            NA            NA            NA            NA\n  A245_peinture A246_peinture A25_peinture A20_montages A21_montages\n1            NA            NA           NA           NA           NA\n2            NA            NA           NA           15            1\n3            NA            NA            2           NA           NA\n4            NA            NA           NA           NA           NA\n5            NA            NA           NA           NA           NA\n6            NA            NA           NA           NA           NA\n  A22_montages A23_montages A241_montages A242_montages A243_montages\n1           NA           NA            NA            NA            NA\n2           NA            2            NA            NA            NA\n3           NA           NA            NA            NA            NA\n4           NA           NA            NA            NA            NA\n5           NA           NA            NA            NA            NA\n6           NA           NA            NA            NA            NA\n  A244_montages A245_montages A246_montages A25_montages A20_cirque A21_cirque\n1            NA            NA            NA           NA         NA         NA\n2            NA            NA            NA            2         NA         NA\n3            NA            NA            NA           NA         NA         NA\n4            NA            NA            NA           NA         NA         NA\n5            NA            NA            NA           NA         NA         NA\n6            NA            NA            NA           NA         NA         NA\n  A22_cirque A23_cirque A241_cirque A242_cirque A243_cirque A244_cirque\n1         NA         NA          NA          NA          NA          NA\n2         NA         NA          NA          NA          NA          NA\n3         NA         NA          NA          NA          NA          NA\n4         NA         NA          NA          NA          NA          NA\n5         NA         NA          NA          NA          NA          NA\n6         NA         NA          NA          NA          NA          NA\n  A245_cirque A246_cirque A25_cirque A20_poterie A21_poterie A22_poterie\n1          NA          NA         NA          NA          NA          NA\n2          NA          NA         NA          NA          NA          NA\n3          NA          NA         NA          NA          NA          NA\n4          NA          NA         NA          NA          NA          NA\n5          NA          NA         NA          NA          NA          NA\n6          NA          NA         NA          NA          NA          NA\n  A23_poterie A241_poterie A242_poterie A243_poterie A244_poterie A245_poterie\n1          NA           NA           NA           NA           NA           NA\n2          NA           NA           NA           NA           NA           NA\n3          NA           NA           NA           NA           NA           NA\n4          NA           NA           NA           NA           NA           NA\n5          NA           NA           NA           NA           NA           NA\n6          NA           NA           NA           NA           NA           NA\n  A246_poterie A25_poterie A20_theatre A21_theatre A22_theatre A23_theatre\n1           NA          NA          NA          NA          NA          NA\n2           NA          NA          NA          NA          NA          NA\n3           NA          NA          NA          NA          NA          NA\n4           NA          NA          NA          NA          NA          NA\n5           NA          NA          NA          NA          NA          NA\n6           NA          NA          NA          NA          NA          NA\n  A241_theatre A242_theatre A243_theatre A244_theatre A245_theatre A246_theatre\n1           NA           NA           NA           NA           NA           NA\n2           NA           NA           NA           NA           NA           NA\n3           NA           NA           NA           NA           NA           NA\n4           NA           NA           NA           NA           NA           NA\n5           NA           NA           NA           NA           NA           NA\n6           NA           NA           NA           NA           NA           NA\n  A25_theatre A20_dessin A21_dessin A22_dessin A23_dessin A241_dessin\n1          NA         NA         NA         NA         NA          NA\n2          NA          5          1         NA          1           0\n3          NA         NA         NA         NA         NA          NA\n4          NA         NA         NA         NA         NA          NA\n5          NA         NA         NA         NA         NA          NA\n6          NA         NA         NA         NA         NA          NA\n  A242_dessin A243_dessin A244_dessin A245_dessin A246_dessin A25_dessin\n1          NA          NA          NA          NA          NA         NA\n2           0           0           1           0           0         NA\n3          NA          NA          NA          NA          NA         NA\n4          NA          NA          NA          NA          NA         NA\n5          NA          NA          NA          NA          NA         NA\n6          NA          NA          NA          NA          NA         NA\n  A20_danse A21_danse A22_danse A23_danse A241_danse A242_danse A243_danse\n1        NA        NA        NA        NA         NA         NA         NA\n2        NA        NA        NA        NA         NA         NA         NA\n3        NA        NA        NA        NA         NA         NA         NA\n4        NA        NA        NA        NA         NA         NA         NA\n5        NA        NA        NA        NA         NA         NA         NA\n6        NA        NA        NA        NA         NA         NA         NA\n  A244_danse A245_danse A246_danse A25_danse A3001_danse A3002_danse\n1         NA         NA         NA        NA          NA          NA\n2         NA         NA         NA        NA          NA          NA\n3         NA         NA         NA        NA          NA          NA\n4         NA         NA         NA        NA          NA          NA\n5         NA         NA         NA        NA          NA          NA\n6         NA         NA         NA        NA          NA          NA\n  A3003_danse A3004_danse A3005_danse A3006_danse A3007_danse A3008_danse\n1          NA          NA          NA          NA          NA          NA\n2          NA          NA          NA          NA          NA          NA\n3          NA          NA          NA          NA          NA          NA\n4          NA          NA          NA          NA          NA          NA\n5          NA          NA          NA          NA          NA          NA\n6          NA          NA          NA          NA          NA          NA\n  A3009_danse A3010_danse A20_photo A21_photo A22_photo A23_photo A241_photo\n1          NA          NA        30         1        NA         2         NA\n2          NA          NA        13         1        NA         2         NA\n3          NA          NA        NA        NA        NA        NA         NA\n4          NA          NA        NA        NA        NA        NA         NA\n5          NA          NA        NA        NA        NA        NA         NA\n6          NA          NA        NA        NA        NA        NA         NA\n  A242_photo A243_photo A244_photo A245_photo A246_photo A25_photo\n1         NA         NA         NA         NA         NA         2\n2         NA         NA         NA         NA         NA         2\n3         NA         NA         NA         NA         NA        NA\n4         NA         NA         NA         NA         NA        NA\n5         NA         NA         NA         NA         NA        NA\n6         NA         NA         NA         NA         NA        NA\n  A20_genealogie A21_genealogie A22_genealogie A23_genealogie A241_genealogie\n1             NA             NA             NA             NA              NA\n2             NA             NA             NA             NA              NA\n3             NA             NA             NA             NA              NA\n4             NA             NA             NA             NA              NA\n5             NA             NA             NA             NA              NA\n6             NA             NA             NA             NA              NA\n  A242_genealogie A243_genealogie A244_genealogie A245_genealogie\n1              NA              NA              NA              NA\n2              NA              NA              NA              NA\n3              NA              NA              NA              NA\n4              NA              NA              NA              NA\n5              NA              NA              NA              NA\n6              NA              NA              NA              NA\n  A246_genealogie A25_genealogie A20_activite_scientifique\n1              NA             NA                        NA\n2              NA             NA                        15\n3              NA             NA                        NA\n4              NA             NA                        NA\n5              NA             NA                        NA\n6              NA             NA                        NA\n  A21_activite_scientifique A22_activite_scientifique A23_activite_scientifique\n1                        NA                        NA                        NA\n2                         1                        NA                         1\n3                        NA                        NA                        NA\n4                        NA                        NA                        NA\n5                        NA                        NA                        NA\n6                        NA                        NA                        NA\n  A241_activite_scientifique A242_activite_scientifique\n1                         NA                         NA\n2                          0                          0\n3                         NA                         NA\n4                         NA                         NA\n5                         NA                         NA\n6                         NA                         NA\n  A243_activite_scientifique A244_activite_scientifique\n1                         NA                         NA\n2                          0                          1\n3                         NA                         NA\n4                         NA                         NA\n5                         NA                         NA\n6                         NA                         NA\n  A245_activite_scientifique A246_activite_scientifique\n1                         NA                         NA\n2                          0                          0\n3                         NA                         NA\n4                         NA                         NA\n5                         NA                         NA\n6                         NA                         NA\n  A25_activite_scientifique A311 A312 A313 A314 A315 A316 A32 A32BIS A33\n1                        NA    0    0    1    0    0    0   2     NA   1\n2                        NA    1    1    1    0    0    0   2     14   2\n3                        NA    1    0    0    0    0    0  NA     14   2\n4                        NA   NA   NA   NA   NA   NA   NA  NA     NA  NA\n5                        NA   NA   NA   NA   NA   NA   NA  NA     NA  NA\n6                        NA   NA   NA   NA   NA   NA   NA  NA     NA  NA\n  Video_games B2 B3 B401 B402 B403 B404 B405 B406 B407 B408 B409 B410 B5 B601\n1           1  4  4    1    0    0    0    0    0    0    0    0    0  2    1\n2           1  3  2    1    0    0    0    0    1    0    0    0    0  1    0\n3           0 NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA   NA\n4           0 NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA   NA\n5           0 NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA   NA\n6           0 NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA   NA\n  B602 B603 B604 B605 B606 B607 B608 B609 B610 B611 B612 B613 B614 B7 TV C2\n1    0    1    0    0    0    0    0    0    0    0    0    0    0  4  1  1\n2    0    0    1    0    1    1    0    0    1    0    0    0    0  2  1  4\n3   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA  1  2\n4   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA  1  4\n5   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA  1  1\n6   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA  1  1\n  C301 C302 C303 C304 C305 C306 C307 C308 C309 C310 C4 C5 C61 C62 C63 C64 C65\n1    1    1    0    0    0    1    0    0    0    0 NA NA   1   0   0   0   0\n2    1    0    0    0    0    0    0    0    0    0 28 30   1   0   0   1   0\n3    1    1    0    0    0    0    0    0    0    0 NA NA   1   0   0   0   0\n4    1    1    1    0    0    1    0    0    0    0 28 29   1   0   0   0   0\n5    1    0    0    0    0    0    0    0    0    0 29 29   1   0   0   0   0\n6    1    1    1    0    0    0    0    0    0    0  7 24   1   0   0   0   0\n  C66 C67 C701 C702 C703 C704 C705 C706 C707 C708 C709 C710 C711 C712 C713 C8\n1   0   0    1    0    0    0    0    1    1    0    1    0    0    0    0  2\n2   0   0    1    1    0    0    0    0    1    0    1    0    0    0    0  4\n3   0   0    0    0    0    0    0    0    1    0    1    0    0    0    0  4\n4   0   0    1    1    1    1    0    0    0    0    1    1    0    0    0  1\n5   0   0    1    1    0    1    0    0    0    0    0    0    0    0    0  4\n6   0   0    1    0    0    0    0    0    1    0    1    0    0    0    0  4\n  C10 C10_C_1 C11 C12 C12_C_1 C13 C14 C15 C161 C162 C163 C164 C165 C166 C167\n1   1       3   1   1       4   2   4   3    1    0    0    0    0    0    0\n2   1       0   2   1       3   2   3   1    0    1    1    1    0    0    0\n3   1       1   1   1       3   2   3   5   NA   NA   NA   NA   NA   NA   NA\n4   1       5   2   1       7   2   2   5   NA   NA   NA   NA   NA   NA   NA\n5   1      24   2   1       5   1   3   5   NA   NA   NA   NA   NA   NA   NA\n6   1       2   1   1       2   2   2   5   NA   NA   NA   NA   NA   NA   NA\n  C1701 C1702 C1703 C1704 C1705 C1706 C1707 C1708 C1709 C1710 C1711 C1712 C1713\n1     1     0     0     0     0     0     0     0     1     0     0     0     0\n2     1     1     1     1     1     1     1     0     1     1     0     0     0\n3    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n4    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n5    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n6    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n  C18 C19 C2001 C2002 C2003 C2004 C2005 C2006 C2007 C2008 C2009 C2010 C211 C212\n1   4   1     1     0     0     0     0     0     0     0     0     0    1    0\n2   1   2     1     0     0     0     0     1     0     0     0     0    0    1\n3  NA   2     1     1     0     0     0     0     0     0     0     0    1    0\n4  NA   4     0     0     1     0     0     0     0     0     0     0    1    0\n5  NA   1     1     0     0     0     0     0     0     0     0     0    1    0\n6  NA   1     1     1     0     0     0     0     0     0     0     0    1    0\n  C213 C214 C215 C216 C217 C221 C222 C223 C224 C225 C226 C227 C228 C23 C24\n1    0    0    0    0    0    1    0    1    1    0    0    0    0   3   2\n2    0    0    0    0    0    0    1    0    0    1    0    0    0   1   1\n3    0    0    0    0    0    0    0    1    0    0    0    0    0   3   1\n4    0    0    0    0    0    0    0    1    0    0    0    0    0   3   2\n5    0    0    0    0    0    0    0    1    0    0    0    0    0   3   2\n6    0    0    0    0    0    0    0    1    0    0    0    0    0   3   2\n  C2601 C2602 C2603 C2604 C2605 C2606 C2607 C2608 C2609 C2610 C2611 C2612 C2613\n1     1     0     0     1     0     0     0     1     0     1     0     0     0\n2     1     1     0     1     1     0     1     1     0     1     0     0     1\n3     1     0     0     0     0     1     0     0     1     1     0     0     0\n4     0     0     1     0     0     0     0     0     0     0     0     0     0\n5     0     1     0     0     0     0     0     0     0     0     1     0     0\n6     1     1     0     1     0     0     0     0     0     1     0     0     0\n  C2614 C2615 C2616 C2617 C2618 C2701 C2702 C2703 C2704 C2705 C2706 C2707 C2708\n1     0     0     0     0     0     1     0     0     1     0     0     0     0\n2     0     0     0     0     0     1     1     0     0     1     0     0     1\n3     0     0     0     0     0     0     0     0     0     0     0     0     0\n4     0     0     0     0     0     0     0     1     0     0     0     1     0\n5     0     0     0     0     0     0     1     0     0     0     0     0     0\n6     0     0     0     0     0     0     1     0     1     0     0     0     0\n  C2709 C2710 C2711 C2712 C2713 C2714 C2715 C2716 C2717 C2718 C2801 C2802 C2803\n1     0     0     0     0     0     0     0     0     0     0     0     0     0\n2     0     0     0     0     0     0     0     0     0     0     0     0     0\n3     0     0     0     0     0     0     0     0     0     1     0     0     0\n4     0     0     0     0     0     0     0     0     0     0     0     0     0\n5     0     0     1     0     0     0     0     0     0     0     0     0     0\n6     0     0     0     0     0     0     0     0     0     0     0     0     0\n  C2804 C2805 C2806 C2807 C2808 C2809 C2810 C2811 C2812 C2813 C2814 C2815 C2816\n1     0     0     0     0     0     0     0     0     0     0     0     1     1\n2     0     0     1     0     0     0     0     0     0     0     0     0     0\n3     0     0     0     0     0     0     0     0     0     0     0     0     1\n4     0     0     0     0     1     0     0     0     1     0     0     0     0\n5     0     0     0     0     1     0     0     0     0     0     0     0     0\n6     0     0     0     0     1     0     0     0     0     0     0     1     0\n  C2817 C2818 C2901 C2902 C2903 C2904 C2905 C2906 C2907 C2908 C2909 C2910 C2911\n1     0     0     0     0     0     0     0     1     0     0     0     1     0\n2     0     0     1     0     0     1     0     1     0     1     1     1     1\n3     0     0     0     0     1     0     0     1     1     0     0     1     1\n4     0     0     0     0     0     0     0     0     0     0     0     1     1\n5     0     0     0     0     0     0     0     0     0     0     0     0     0\n6     0     0     0     0     0     0     0     1     0     0     0     1     0\n  C2912 C2913 C2914 C2915 C2916 C2917 C30 C31 C3201 C3202 C3203 C3204 C3205\n1     1     0     1     0     0     0   2   2     1     0     0     0     0\n2     0     0     1     0     0     0   1   2     1     0     0     0     0\n3     1     0     0     0     0     0   1   5    NA    NA    NA    NA    NA\n4     0     0     0     0     0     0   2   5    NA    NA    NA    NA    NA\n5     0     0     1     0     0     0   3   5    NA    NA    NA    NA    NA\n6     0     0     1     0     0     0   1   4     0     1     0     0     0\n  C3206 C3207 C3208 C3209 C3210 C331 C332 C333 C334 C335 C336 C337 C341 C342\n1     0     0     0     0     0    1    0    0    0    0    0    0    0    0\n2     1     0     0     0     0    0    1    0    1    0    0    0    0    1\n3    NA    NA    NA    NA    NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n4    NA    NA    NA    NA    NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n5    NA    NA    NA    NA    NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n6     0     0     0     0     0    1    0    0    0    0    0    0    0    0\n  C343 C344 C345 C346 C347 C348 C35 C36 C3801 C3802 C3803 C3804 C3805 C3806\n1    1    0    0    0    0    0   3   2     0     0     0     1     0     0\n2    0    0    1    0    0    0   2   1     0     1     0     1     1     0\n3   NA   NA   NA   NA   NA   NA  NA  NA    NA    NA    NA    NA    NA    NA\n4   NA   NA   NA   NA   NA   NA  NA  NA    NA    NA    NA    NA    NA    NA\n5   NA   NA   NA   NA   NA   NA  NA  NA    NA    NA    NA    NA    NA    NA\n6    1    0    0    0    0    0   3   2     0     0     0     0     0     0\n  C3807 C3808 C3809 C3810 C3811 C3812 C3813 C3814 C3815 C3816 C3817 C3818 C3901\n1     0     0     0     1     0     0     0     0     0     0     0     0     0\n2     1     1     0     1     0     0     1     0     0     0     0     0     0\n3    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n4    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n5    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n6     0     0     0     1     0     1     0     0     0     0     0     0     0\n  C3902 C3903 C3904 C3905 C3906 C3907 C3908 C3909 C3910 C3911 C3912 C3913 C3914\n1     0     0     1     0     0     0     0     0     1     0     0     0     0\n2     1     0     1     1     0     0     0     0     0     0     0     1     0\n3    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n4    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n5    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n6     0     0     0     0     0     0     0     0     0     0     0     0     0\n  C3915 C3916 C3917 C3918 C4001 C4002 C4003 C4004 C4005 C4006 C4007 C4008 C4009\n1     0     0     0     0     0     0     0     0     0     0     0     0     0\n2     0     0     0     0     0     0     0     0     0     0     0     0     0\n3    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n4    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n5    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n6     0     0     0     1     0     0     0     0     0     0     0     0     0\n  C4010 C4011 C4012 C4013 C4014 C4015 C4016 C4017 C4018 C4101 C4102 C4103 C4104\n1     0     0     0     0     0     1     1     0     0     0     0     0     0\n2     0     0     0     0     0     0     1     0     0     1     1     0     1\n3    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n4    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n5    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n6     0     0     0     0     0     1     0     0     0     0     1     0     1\n  C4105 C4106 C4107 C4108 C4109 C4110 C4111 C4112 C4113 C4114 C4115 C4116 C4117\n1     0     0     0     0     0     0     0     0     0     1     0     0     0\n2     0     0     0     0     1     0     0     0     0     0     0     0     0\n3    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n4    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n5    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n6     0     0     0     0     0     0     0     0     1     1     0     0     0\n  C42 D101 D102 D103 D104 D105 D106 D107 D108 D109 D110 D111 D112 D113 D114\n1   4    0    0    0    0    0    0    0    0    1    1    0    0    0    0\n2   1    1    1    1    1    1    1    1    1    1    1    1    0    1    1\n3  NA    0    1    1    0    1    0    0    0    0    0    1    0    1    0\n4  NA    0    0    0    0    0    0    0    0    0    0    0    1    1    0\n5  NA    0    0    0    0    0    0    0    0    0    1    0    0    0    0\n6   4    1    0    0    0    1    0    0    0    0    1    0    0    1    0\n  D115 D116 D117 D2 D31 D32 D33 D34 D35 D36 D37 D38 D39 D41 D42 D43 D44 D5 D6\n1    0    0    0  1   0   1   0   1   0   0   0   0   0   0   1   0   0  3  2\n2    0    0    0  2   0   0   0   0   1   0   0   0   0  NA  NA  NA  NA  2  2\n3    0    0    0  1   1   1   1   0   0   0   0   0   0  NA  NA  NA  NA  1  2\n4    0    0    0  1   1   0   0   0   0   0   0   0   0  NA  NA  NA  NA  3  1\n5    0    0    0  3   1   1   0   0   0   0   0   0   0  NA  NA  NA  NA  3  2\n6    0    0    0  1   1   1   1   0   0   0   0   0   0  NA  NA  NA  NA  2  2\n  D8 Radio E2 E2_C_1 E3      E4 E501 E502 E503 E504 E505 E506 E507 E508 E509\n1  4     1  1      1  1 109.000    0    0    1    1    0    0    0    0    1\n2  2     0 NA        NA      NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n3  1     1  1      2  1 182.718    0    0    0    1    0    0    0    0    0\n4  1     1  1      2  3   5.000    0    0    0    0    0    0    0    0    0\n5  4     1  2        NA 294.000    0    0    0    0    0    0    0    0    0\n6  1     1  1      1  1 181.719    0    0    0    1    0    0    1    0    1\n  E510 E511 E512 E513 E514 E6 E7 E81 E82 E83 E84 E85 E86 E87 E88 E89 E8BIS\n1    0    0    0    0    0  2  1   1   0   0   0   0   1   0   0   0     1\n2   NA   NA   NA   NA   NA NA  1   0   0   1   0   0   0   0   0   0     1\n3    1    0    0    0    0  1  1   1   0   1   0   0   1   0   0   0     1\n4    0    1    0    0    0  2  5   1   0   0   0   0   1   1   0   0     3\n5    0    1    0    0    0  2  3   0   0   0   0   0   0   1   0   0     3\n6    0    0    0    0    0  2  1   0   0   0   0   0   1   0   0   0     1\n  E1001 E1002 E1003 E1004 E1005 E1006 E1007 E1008 E1009 E1010 E1011 E1012 E1013\n1     0     0     0     1     0     0     0     0     1     0     0     0     0\n2     0     0     0     0     0     0     1     0     0     0     0     0     0\n3     1     0     0     1     0     0     0     0     1     1     1     0     0\n4     1     0     0     0     0     0     0     0     0     0     1     0     1\n5     1     0     0     0     0     0     0     0     0     1     0     0     0\n6     1     0     1     0     0     0     0     0     1     1     0     0     0\n  E1014 E1015 E1201 E1202 E1203 E1204 E1205 E1206 E1207 E1208 E1209 E1210 E1211\n1     0     0     0     0     0     1     0     0     0     0     1     0     0\n2     0     0     0     0     0     0     0     0     1     0     0     0     0\n3     0     0     0     0     0     0     0     0     0     0     1     0     0\n4     0     0     1     0     1     0     0     0     0     0     0     0     1\n5     0     0     0     0     0     0     0     0     0     0     0     0     0\n6     0     0     0     0     0     1     0     0     0     0     0     0     0\n  E1212 E1213 E1214 E1215 E1301 E1302 E1303 E1304 E1305 E1306 E1307 E1308 E1309\n1     0     0     0     0     0     0     0     0     0     1     1     0     0\n2     0     0     0     0     0     0     0     0     0     0     0     0     0\n3     0     0     0     0     0     0     0     0     0     0     1     0     0\n4     0     0     0     0     0     0     0     0     0     0     0     1     0\n5     0     0     1     0     0     0     0     0     0     0     0     0     0\n6     0     0     0     0     0     0     0     0     0     0     1     1     0\n  E1310 E1311 E1312 E1313 E1314 E1315 E1401 E1402 E1403 E1404 E1405 E1406 E1407\n1     0     1     1     0     0     0     1     0     0     0     0     0     0\n2     0     1     1     0     0     0     1     0     1     1     0     1     1\n3     0     0     0     0     0     0     1     1     0     0     0     0     0\n4     1     0     0     0     0     0     0     0     0     0     0     0     0\n5     0     0     0     1     0     0     0     0     0     0     0     0     0\n6     0     1     0     0     0     0     0     0     1     1     0     0     0\n  E1408 E1409 E1410 E1411 E1412 E1413 E1414 E1415 E1416 E1417 E15 E17 E18 E19\n1     0     0     1     1     0     0     0     0     0     0   1   2   4   1\n2     0     0     0     0     1     0     1     1     0     0   1   1   2   1\n3     0     0     1     1     0     0     0     1     0     0   1   2   3   1\n4     0     0     1     1     0     0     1     1     0     0   1  NA  NA   1\n5     0     0     1     0     0     0     0     0     0     0   1   4   4   4\n6     0     0     0     1     0     0     1     0     0     0   1   3   4   1\n  Library F21 F22 F23 F24 F25 F3 F3BIS01 F3BIS02 F3BIS03 F3BIS04 F3BIS05\n1       1  NA  NA  NA  NA  NA  5      NA      NA      NA      NA      NA\n2       0  NA  NA  NA  NA  NA  4       0       0       0       0       0\n3       1  NA  NA  NA  NA  NA  5      NA      NA      NA      NA      NA\n4       1  NA  NA  NA  NA  NA  5      NA      NA      NA      NA      NA\n5       1  NA  NA  NA  NA  NA  5      NA      NA      NA      NA      NA\n6       1  NA  NA  NA  NA  NA  5      NA      NA      NA      NA      NA\n  F3BIS06 F3BIS07 F3BIS08 F3BIS09 F3BIS10 F4 F5 F601 F602 F603 F604 F605 F606\n1      NA      NA      NA      NA      NA NA  2    0    1    1    0    0    0\n2       0       1       0       0       0  4  4   NA   NA   NA   NA   NA   NA\n3      NA      NA      NA      NA      NA NA  3    0    0    0    0    0    0\n4      NA      NA      NA      NA      NA NA  3    0    0    0    0    0    0\n5      NA      NA      NA      NA      NA NA  4   NA   NA   NA   NA   NA   NA\n6      NA      NA      NA      NA      NA NA  4   NA   NA   NA   NA   NA   NA\n  F607 F608 F609 F610 F611 F612 F613 F614 F615 F616 F617 F618 F619 F620 F701\n1    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0\n2   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n3    0    1    1    0    0    0    0    1    0    1    0    0    0    0    0\n4    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0\n5   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n6   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n  F702 F703 F704 F705 F706 F707 F708 F709 F710 F711 F712 F713 F714 F715 F716\n1    1    1    0    0    0    0    0    0    0    0    0    0    0    1    0\n2   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n3    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0\n4    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1\n5   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n6   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n  F717 F718 F719 F720 F801 F802 F803 F804 F805 F806 F807 F808 F809 F810 F811\n1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1\n2   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n3    0    0    0    0    0    0    1    0    0    0    0    0    0    0    1\n4    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n5   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n6   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n  F812 F813 F814 F815 F816 F817 F818 F819 F820 F9 F11 F11BIS F11TER F121 F122\n1    0    0    0    0    0    0    0    0    0  2   2      2      3    1    0\n2   NA   NA   NA   NA   NA   NA   NA   NA   NA NA  NA     NA     NA   NA   NA\n3    0    0    0    0    0    0    0    0    0  2   3      2      2    1    0\n4    0    0    0    0    0    0    0    1    0  1   4      3      3    1    0\n5   NA   NA   NA   NA   NA   NA   NA   NA   NA NA  NA     NA     NA   NA   NA\n6   NA   NA   NA   NA   NA   NA   NA   NA   NA NA  NA     NA     NA   NA   NA\n  F123 F124 F125 F126 F12BIS F13 F13_C_1 F14 F15 F15_C_1 F1601 F1602 F1603\n1    0    0    0    0     NA   1      10  NA  NA       0     0     0     0\n2   NA   NA   NA   NA     NA  NA       0  NA  NA       0    NA    NA    NA\n3    0    0    0    0     NA   1      12   1   1       9     1     1     1\n4    0    0    0    0     NA   1       3  NA  NA       0     0     0     0\n5   NA   NA   NA   NA     NA  NA       0  NA  NA       0    NA    NA    NA\n6   NA   NA   NA   NA     NA  NA       0  NA  NA       0    NA    NA    NA\n  F1604 F1605 F1606 F1607 F1608 F1609 F1610 F1611 F1612 F1613 F1614 F1615 F1616\n1     1     0     0     0     0     0     0     0     0     0     0     0     0\n2    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n3     0     0     0     0     0     0     0     0     0     0     0     0     0\n4     0     0     0     0     0     0     0     0     0     0     0     0     1\n5    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n6    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n  F1617 F1618 F17 G2401 G2402 G2403 G2404 G2405 G2406 G2407 G2408 G2409 G2410\n1     0     0   1     1     0     0     0     0     0     0     0     1     0\n2    NA    NA  NA     0     0     0     0     0     0     0     0     0     0\n3     0     0   1     1     0     1     1     0     0     0     0     1     1\n4     0     0   4     1     0     0     0     0     0     0     0     0     0\n5    NA    NA  NA     0     0     0     0     0     0     0     0     0     0\n6    NA    NA  NA     1     0     0     1     0     0     0     0     0     0\n  G2411 G2412 Concert G2414 G2415 G2501 G2502 G2503 G2504 G2505 G2506 G2507\n1     0     0       1     0     0     0     0     0     0     0     0     0\n2     0     0       0     0     0    NA    NA    NA    NA    NA    NA    NA\n3     1     1       1     0     0     1     0     0     0     0     0     0\n4     0     0       1     0     0     0     0     0     0     0     0     0\n5     0     0       0     0     0    NA    NA    NA    NA    NA    NA    NA\n6     0     0       1     0     0     0     0     0     1     0     0     0\n  G2508 G2509 G2510 G2511 G2512 G2513 G2514 G2515 G26val_variet_francaise\n1     0     0     0     0     0     1     0     0                      NA\n2    NA    NA    NA    NA    NA    NA    NA    NA                      NA\n3     0     0     0     0     1     0     0     0                       1\n4     0     0     0     0     0     1     0     0                      NA\n5    NA    NA    NA    NA    NA    NA    NA    NA                      NA\n6     0     0     0     0     0     0     0     0                      NA\n  G26val_musiques_monde G26val_musiques_tradi G26val_variet_internationale\n1                    NA                    NA                           NA\n2                    NA                    NA                           NA\n3                    NA                    NA                           NA\n4                    NA                    NA                           NA\n5                    NA                    NA                           NA\n6                    NA                    NA                            1\n  G26val_rnb G26val_electro_techno G26val_hip_hop_rap G26val_metal_hard\n1         NA                    NA                 NA                NA\n2         NA                    NA                 NA                NA\n3         NA                    NA                 NA                NA\n4         NA                    NA                 NA                NA\n5         NA                    NA                 NA                NA\n6         NA                    NA                 NA                NA\n  G26val_pop_rock G26val_jazz G26val_opera G26val_musique_classique\n1              NA          NA           NA                       NA\n2              NA          NA           NA                       NA\n3              NA          NA           NA                        1\n4              NA          NA           NA                       NA\n5              NA          NA           NA                       NA\n6              NA          NA           NA                       NA\n  G26unit_variet_francaise G26unit_musiques_monde G26unit_musiques_tradi\n1                       NA                     NA                     NA\n2                       NA                     NA                     NA\n3                        3                     NA                     NA\n4                       NA                     NA                     NA\n5                       NA                     NA                     NA\n6                       NA                     NA                     NA\n  G26unit_variet_internationale G26unit_rnb G26unit_electro_techno\n1                            NA          NA                     NA\n2                            NA          NA                     NA\n3                            NA          NA                     NA\n4                            NA          NA                     NA\n5                            NA          NA                     NA\n6                             3          NA                     NA\n  G26unit_hip_hop_rap G26unit_metal_hard G26unit_pop_rock G26unit_jazz\n1                  NA                 NA               NA           NA\n2                  NA                 NA               NA           NA\n3                  NA                 NA               NA           NA\n4                  NA                 NA               NA           NA\n5                  NA                 NA               NA           NA\n6                  NA                 NA               NA           NA\n  G26unit_opera G26unit_musique_classique G271 G272 G273 G274 G275 G276 G277\n1            NA                        NA   NA   NA   NA   NA   NA   NA   NA\n2            NA                        NA   NA   NA   NA   NA   NA   NA   NA\n3            NA                         3    1    0    0    0    0    0    0\n4            NA                        NA   NA   NA   NA   NA   NA   NA   NA\n5            NA                        NA   NA   NA   NA   NA   NA   NA   NA\n6            NA                        NA    1    0    0    0    0    0    0\n  G278 G28 G29 G3001 G3002 G3003 G3004 G3005 G3006 G3007 G3008 G3009 G3010 G31\n1   NA  NA  NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA  NA\n2   NA  NA  NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA  NA\n3    0   2   2     0     1     0     0     1     0     0     0     0     0   1\n4   NA  NA  NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA  NA\n5   NA  NA  NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA  NA\n6    0   2   2     0     1     1     0     0     1     0     0     0     0   1\n  G11 G12 G13 G14 G15 G16 G17 G18 G211 G212 G213 G214 G215 G216 G217 G218 G3A\n1   0   0   1   1   1   0   0   0    0    0    1    0    0    0    0    0   2\n2   0   0   0   1   0   0   0   0    0    0    0    0    0    1    0    0   1\n3   0   1   1   1   1   0   0   0    0    0    1    1    0    0    0    0   1\n4   0   0   1   0   0   0   0   0    0    0    0    0    0    1    0    0   2\n5   0   0   0   0   0   1   0   0   NA   NA   NA   NA   NA   NA   NA   NA   2\n6   0   0   1   1   1   0   0   0    0    0    0    1    0    0    0    0   1\n  G3B G6BIS G4 G4_C_1 G5 G6 G701 G702 G703 G704 G705 G706 G707 G708 G709 G710\n1   1     2 NA     NA NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n2  NA     2  1      6  3  2    1    1    0    0    1    0    1    0    0    0\n3  NA     2  1      2  3  2    0    0    0    0    0    1    0    0    0    0\n4   2     2 NA     NA NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n5   1     2 NA     NA NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n6  NA     2  1      6  3  2    1    1    0    1    1    0    0    0    0    0\n  G711 G712 G713 G714 G715 G716 G717 G718 G8 G9 G1001 G1002 G1003 G1004 G1005\n1   NA   NA   NA   NA   NA   NA   NA   NA NA NA    NA    NA    NA    NA    NA\n2    0    0    1    0    0    0    0    0  1 NA     0     0     0     0     0\n3    0    0    0    0    0    0    0    0  2  2     0     1     0     0     1\n4   NA   NA   NA   NA   NA   NA   NA   NA NA NA    NA    NA    NA    NA    NA\n5   NA   NA   NA   NA   NA   NA   NA   NA NA NA    NA    NA    NA    NA    NA\n6    0    0    0    0    0    0    0    0  2  2     0     1     0     0     0\n  G1006 G1007 G1008 G1009 G1010 G111 G121 G122 G123 G124 G125 G126 G127 G131\n1    NA    NA    NA    NA    NA   NA    1    1    1    1    0    0    0    0\n2     1     0     0     0     0    2    0    1    1    1    0    0    0    0\n3     0     0     0     0     0    1    1    1    1    1    0    0    0    0\n4    NA    NA    NA    NA    NA   NA    0    0    1    0    0    0    0    0\n5    NA    NA    NA    NA    NA   NA    0    0    1    0    0    0    0    0\n6     0     0     0     0     0    1    0    0    1    1    0    0    0    0\n  G132 G133 G134 G135 G136 G137 G14val_danse G14val_cirque G14val_spectacle_rue\n1    0    1    0    0    0    0           NA            NA                    2\n2    0    0    0    1    0    0           NA            NA                   NA\n3    0    0    0    1    0    0           NA            NA                   NA\n4    0    1    0    0    0    0           NA            NA                    1\n5    0    0    0    1    0    0           NA            NA                   NA\n6    0    1    1    0    0    0           NA            NA                    1\n  G14val_theatre G14unit_danse G14unit_cirque G14unit_spectacle_rue\n1             NA            NA             NA                     3\n2             NA            NA             NA                    NA\n3             NA            NA             NA                    NA\n4             NA            NA             NA                     3\n5             NA            NA             NA                    NA\n6              4            NA             NA                     3\n  G14unit_theatre G161 G162 G163 G164 G165 G166 G167 G171 G172 G173 G174 G175\n1              NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n2              NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n3              NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n4              NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n5              NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n6               3   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n  G176 G17B01 G17B02 G17B03 G17B04 G17B05 G17B06 G17B07 G17B08 G17B09 G17B10\n1   NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA\n2   NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA\n3   NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA\n4   NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA\n5   NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA\n6   NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA\n  G181 G182 G183 G184 G185 G186 G187 G188 G189 G20A1 G20A2 G20A3 G20A4 G20A5\n1    1    0    1    0    0    0    0    0    0    NA    NA    NA    NA    NA\n2   NA   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA    NA    NA    NA\n3   NA   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA    NA    NA    NA\n4    1    0    0    0    0    0    0    0    0    NA    NA    NA    NA    NA\n5   NA   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA    NA    NA    NA\n6    1    0    1    0    0    0    0    0    0     0     0     1     1     0\n  G20A6 G20A7 G20B G21 G2201 G2202 G2203 G2204 G2205 G2206 G2207 G2208 G2209\n1    NA    NA   NA  NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n2    NA    NA   NA  NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n3    NA    NA   NA  NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n4    NA    NA   NA  NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n5    NA    NA   NA  NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n6     0     0    2   2     0     1     0     0     0     1     0     0     0\n  G2210 G23 G32 G331 G332 G333 G334 G335 G336 G337 G338 G339 G351 G352 G353\n1    NA   3   2   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n2    NA  NA   2   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n3    NA  NA   1    1    0    0    0    0    0    0    0    0    1    0    0\n4    NA   4   2   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n5    NA  NA   2   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n6     0   1   2   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n  G354 G355 G356 G357 G36 G37 G3801 G3802 G3803 G3804 G3805 G3806 G3807 G3808\n1   NA   NA   NA   NA  NA  NA    NA    NA    NA    NA    NA    NA    NA    NA\n2   NA   NA   NA   NA  NA  NA    NA    NA    NA    NA    NA    NA    NA    NA\n3    0    0    0    0   2   2     0     1     0     0     0     0     0     0\n4   NA   NA   NA   NA  NA  NA    NA    NA    NA    NA    NA    NA    NA    NA\n5   NA   NA   NA   NA  NA  NA    NA    NA    NA    NA    NA    NA    NA    NA\n6   NA   NA   NA   NA  NA  NA    NA    NA    NA    NA    NA    NA    NA    NA\n  G3809 G3810 G39 H101 H102 H103 H104 H105 H106 H107 H108 H109 H110 H111\n1    NA    NA  NA    0    1    0    1    0    0    0    0    1    1    0\n2    NA    NA  NA    1    1    1    1    0    1    1    1    1    1    1\n3     0     0   2    0    0    1    1    0    1    1    0    1    1    0\n4    NA    NA  NA    0    0    1    1    0    0    1    0    1    0    0\n5    NA    NA  NA    0    0    1    1    0    0    0    0    0    0    0\n6    NA    NA  NA    1    1    1    1    0    1    1    1    1    1    0\n  Museums H113 H114 H201 H202 H203 H204 H205 H206 H207 H208 H209 H210 H211 H212\n1       1    0    0    0    0    0    0    0    0    0    0    1    0    0    0\n2       1    0    0    1    1    1    0    0    1    1    0    1    1    1    0\n3       1    0    0    0    0    0    0    0    0    0    0    0    1    0    0\n4       1    0    0    0    0    1    0    0    0    0    0    0    0    0    0\n5       1    0    0    0    0    0    0    0    0    0    0    0    0    0    1\n6       1    0    0    0    0    0    0    0    1    0    0    1    0    0    0\n  H214 H215 H301 H302 H303 H304 H305 H306 H307 H308 H309 H310 H4 H4_C_1 H4F H51\n1    0    0   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA     NA  NA  NA\n2    0    0    1    1    1    0    1    0    0    0    0    0  1      5   3   1\n3    0    0    0    0    0    0    1    0    0    0    0    0  1      1   3   1\n4    0    0   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA     NA  NA  NA\n5    0    0   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA     NA  NA  NA\n6    0    0   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA NA     NA  NA  NA\n  H52 H53 H54 H55 H56 H57 H6 H7 H801 H802 H803 H804 H805 H806 H807 H808 H809\n1  NA  NA  NA  NA  NA  NA NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n2   0   1   1   0   0   0  3  3    0    0    0    0    1    0    1    0    0\n3   0   0   0   0   0   0  2  1    0    1    0    0    1    0    0    0    0\n4  NA  NA  NA  NA  NA  NA NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n5  NA  NA  NA  NA  NA  NA NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n6  NA  NA  NA  NA  NA  NA NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n  H810 H9 H1001 H1002 H1003 H1004 H1005 H1006 H1007 H1008 H1009 H1010 H11\n1   NA NA     1     1     1     1     1     1     0     0     0     0   1\n2    0  3     1     1     1     1     1     0     0     0     0     0   1\n3    0  2     0     0     0     0     0     0     0     1     0     0  NA\n4   NA NA     0     0     0     0     0     0     0     1     0     0  NA\n5   NA NA     0     0     0     0     0     0     0     1     0     0  NA\n6   NA NA     1     1     1     1     0     0     0     0     0     0   1\n  H11_C_1 H11F H121 H122 H123 H124 H125 H126 H127 H13 H14 H1501 H1502 H1503\n1      10    3    1    0    0    0    0    0    0   2   1     1     1     0\n2      10    3    1    0    1    1    0    0    0   3   3     0     0     0\n3      NA   NA   NA   NA   NA   NA   NA   NA   NA  NA  NA    NA    NA    NA\n4      NA   NA   NA   NA   NA   NA   NA   NA   NA  NA  NA    NA    NA    NA\n5      NA   NA   NA   NA   NA   NA   NA   NA   NA  NA  NA    NA    NA    NA\n6       3    3    1    0    1    1    0    0    0   1  NA     0     1     0\n  H1504 H1505 H1506 H1507 H1508 H1509 H1510 H16 I101 I102 I103 I104 I105 I106\n1     0     1     1     0     0     0     0   1    1    1    1    1    0    0\n2     0     1     0     1     0     0     0   2    0    1    0    1    1    1\n3    NA    NA    NA    NA    NA    NA    NA  NA    1    1    0    1    1    0\n4    NA    NA    NA    NA    NA    NA    NA  NA    1    1    0    1    0    0\n5    NA    NA    NA    NA    NA    NA    NA  NA    1    1    0    0    0    0\n6     0     0     1     0     0     0     0   1    0    1    1    1    0    0\n  I107 I108 I109 I110 I111 I112 I113 I114 I115 I2 I3 Internet I5 I6 I71 I72 I73\n1    1    1    0    0    1    1    0    0    0  1  3        1  2 NA   0   0   0\n2    1    0    1    1    1    1    0    0    0  3  3        1  1  1   0   0   0\n3    1    0    1    1    1    1    0    0    0  1  3        1  1  1   1   0   0\n4    1    0    0    0    1    0    0    0    0  1 NA        0  2 NA  NA  NA  NA\n5    0    0    0    0    1    0    0    0    0  1 NA        0  2 NA  NA  NA  NA\n6    1    1    1    1    1    1    0    0    0  3  3        1  2 NA   1   0   0\n  I74 I75 I76 I77 I78 I79 SITUA TRAVAIL ACTIVANTE STATUTECL STATUT CS2D\n1   0   0   0   1   0   0     1      NA        NA         3      3   48\n2   0   0   0   1   0   0     3       2         2        NA     NA   NA\n3   0   0   0   0   0   0     1      NA        NA         8      2   33\n4  NA  NA  NA  NA  NA  NA     5       2         1        NA     NA   NA\n5  NA  NA  NA  NA  NA  NA     5       2         1        NA     NA   NA\n6   0   0   0   0   0   0     1      NA        NA         6      6   37\n  TYPEMPLOI TEMPTRAV SUPERVISION CLASSIF CLASSIF2 SALARIES\n1         6       NA           1       4       NA       NA\n2        NA       NA          NA      NA       NA       NA\n3         6        1           3      NA        5       NA\n4        NA       NA          NA      NA       NA       NA\n5        NA       NA          NA      NA       NA       NA\n6         6       NA           1      NA       NA        3\n                ACTIVLIB STATUTECLANTE STATUTANTE CS2D_ante SUPERVISIONANTE\n1  Transport automobiles            NA         NA        NA              NA\n2                                   NA         NA        NA              NA\n3 Bailleur public social            NA         NA        NA              NA\n4                                    3          3        56               3\n5                                    3          3        64               3\n6             Restaurant            NA         NA        NA              NA\n  CLASSIFANTE CLASSIFANTE2 RECHEMPLOI S10 S10_C_1 S11 S11_C_1 S12 S12_C_1\n1          NA           NA          3   1       5   1      35   1      30\n2          NA           NA         NA  NA      NA  NA          NA        \n3          NA           NA          3   1       5   1      38   1     110\n4           6           NA          3  NA      NA  NA          NA        \n5           2           NA          3  NA      NA  NA          NA        \n6          NA           NA          3   1       7   1      45   1       3\n  SITUA_conj TRAVAIL_conj ACTIVANTE_conj STATUTECL_conj STATUT_conj CS2D_conj\n1         NA           NA             NA             NA          NA        NA\n2         NA           NA             NA             NA          NA        NA\n3          1           NA             NA              1           1        42\n4          5            2              1             NA          NA        NA\n5         NA           NA             NA             NA          NA        NA\n6          1           NA             NA              3           3        37\n  TYPEMPLOI_conj TEMPTRAV_conj SUPERVISION_conj CLASSIF_conj CLASSIF2_conj\n1             NA            NA               NA           NA            NA\n2             NA            NA               NA           NA            NA\n3              6             1                3           NA             5\n4             NA            NA               NA           NA            NA\n5             NA            NA               NA           NA            NA\n6              6            NA                3            5            NA\n  SALARIES_conj     ACTIVLIB_conj STATUTECLANTE_conj STATUTANTE_conj\n1            NA                                   NA              NA\n2            NA                                   NA              NA\n3            NA        Coll\\xe8ge                 NA              NA\n4            NA                                    3               3\n5            NA                                   NA              NA\n6            NA Assurance maladie                 NA              NA\n  CS2D_ante_conj SUPERVISIONANTE_conj CLASSIFANTE_conj CLASSIFANTE2_conj\n1             NA                   NA               NA                NA\n2             NA                   NA               NA                NA\n3             NA                   NA               NA                NA\n4             68                    3                1                NA\n5             NA                   NA               NA                NA\n6             NA                   NA               NA                NA\n  RECHEMPLOI_conj AGDIP DATDIP DATDIP_C_1 DIPLOM DIPLOMACT FORMEL NAIM NAIP\n1              NA    NA      1       1976      6        NA      2    1    1\n2              NA    NA      1       2017      5         4      1   NA   NA\n3               3    NA      1       1993     10        NA      2    1    1\n4               3    NA     NA         NA      2        NA      2    2    2\n5              NA    NA      1       1966      4        NA      2    1    1\n6               3    NA      1       1983      6        NA      2    1    1\n  NATIO1N1 NATIO1N2 NATIO1N3 NATIO1N4 NATIO1N5 NATIO1N6 NATIOM NATIOP SPECIAL\n1        1        0        0        0        0        0      1      1      NA\n2        1        0        0        0        0        0      1      1      NA\n3        1        0        0        0        0        0      1      1     315\n4        0        0        1        0        0        0      2      2      NA\n5        1        0        0        0        0        0      1      1      NA\n6        1        0        0        0        0        0      1      1      NA\n  SPECIAL_CODE_CITE_13 SPECIALACT SPECIALACT_CODE_CITE_13 AGDIP_conj\n1                   NA         NA                      NA         NA\n2                   NA        708                     732         NA\n3                  421         NA                      NA         NA\n4                   NA         NA                      NA         NA\n5                   NA         NA                      NA         NA\n6                   NA         NA                      NA         NA\n  DATDIP_conj DATDIP_C_1_conj DIPLOM_conj DIPLOMACT_conj FORMEL_conj NAIM_conj\n1          NA              NA          NA             NA          NA        NA\n2          NA              NA          NA             NA          NA        NA\n3           1            1997          12             NA           2         1\n4          NA              NA           1             NA           2         2\n5          NA              NA          NA             NA          NA        NA\n6           1            1981           7             NA           2         1\n  NAIP_conj NATIO1N1_conj NATIO1N2_conj NATIO1N3_conj NATIO1N4_conj\n1        NA            NA            NA            NA            NA\n2        NA            NA            NA            NA            NA\n3         1             1             0             0             0\n4         2             0             0             1             0\n5        NA            NA            NA            NA            NA\n6         1             1             0             0             0\n  NATIO1N5_conj NATIO1N6_conj NATIOM_conj NATIOP_conj SPECIAL_conj\n1            NA            NA          NA          NA           NA\n2            NA            NA          NA          NA           NA\n3             0             0           1           1          805\n4             0             0           2           2           NA\n5            NA            NA          NA          NA           NA\n6             0             0           1           1           NA\n  SPECIAL_CODE_CITE_13_conj SPECIALACT_conj SPECIALACT_CODE_CITE_13_conj M1_SQ1\n1                        NA              NA                           NA      3\n2                        NA              NA                           NA      1\n3                      1014              NA                           NA      1\n4                        NA              NA                           NA      4\n5                        NA              NA                           NA      4\n6                        NA              NA                           NA      1\n  M1_SQ2 M1_SQ3 M1_SQ4 M1_SQ5 M1_SQ7 M1_SQ8 M1_SQ9 M1_SQ10 M1_SQ11 M1_SQ12 M201\n1      1      1      1      4      4      2      4       2       2       4    1\n2      2      3      1      1      1      1      4       3       1       2    0\n3      1      1      1      3      4      4      4       4       4       3    1\n4      4      4      4      4      4      4      4       4       4       4    0\n5      4      4      5      4      4      4      4       4       4       4    0\n6      1      3      2      1      4      4      4       4       4       4    1\n  M202 M203 M204 M205 M206 M207 M208 M209 M210 M211 M212 M213 M214 M215 M216\n1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n2    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0\n3    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n4    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0\n5    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0\n6    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n  M301 M302 M303 M304 M305 M306 M307 M308 M309 M310 M311 M312 M313 M314 M315\n1    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n2    1    1    0    1    0    0    0    0    0    0    0    0    0    0    0\n3    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n4    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0\n5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1\n6    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n  M316 M401 M402 M403 M404 M405 M406 M407 M408 M409 M410 M7_1 M7_2 M7_3 M81 M82\n1    0    1    1    0    0    0    0    0    0    0    0   NA   NA   NA  NA  NA\n2    0    1    1    0    0    0    0    0    0    0    0   NA   NA   NA  NA  NA\n3    0    1    1    0    0    0    0    0    0    0    0   NA   NA   NA  NA  NA\n4    0    1    1    0    0    0    0    0    0    0    0   NA   NA   NA  NA  NA\n5    0    1    1    0    0    0    0    0    0    0    0   NA   NA   NA  NA  NA\n6    0    1    1    0    0    0    0    0    0    0    0   NA   NA   NA  NA  NA\n  adulte_enfance1 adulte_enfance2 adultes_enfance M9_adulte1 M9_BIS1_adulte1\n1              NA              NA              12         NA              NA\n2               1               2              12          1              NA\n3              NA              NA              12         NA              NA\n4               1               2              12          6              NA\n5               1               2              12          1              NA\n6               1               2              12          1              NA\n  M9_BIS2_adulte1 M9_adulte2 M9_BIS1_adulte2 M9_BIS2_adulte2 M121 M122 M123\n1              NA         NA              NA              NA    1    0    0\n2              NA          1              NA              NA    0    1    0\n3              NA         NA              NA              NA    1    0    0\n4              NA          6              NA              NA    0    1    0\n5              NA          1              NA              NA    1    0    0\n6              NA          1              NA              NA    0    1    0\n  M124 M125 M14 M16 M17 M18 STATUTECLCD_PER STATUTCD_PER CSTOT_PER\n1    0    0   2   1   1   1               3            3        65\n2    0    0   2   2  NA   1               1            1        53\n3    0    0   1   2  NA   1               1            1        52\n4    0    0   1   1   4   1               7            7        21\n5    0    0   2   1   1   1               3            3        67\n6    0    0   1   1   2   1               7            7        21\n  CLASSIFCD_PER1 CLASSIFCD_PER2 M19 M20 STATUTECLCD_MER STATUTCD_MER CSTOT_MER\n1              2             NA   6   1               4            4        56\n2             NA              4   7   1               2            2        52\n3             NA              6   4   1               3            3        55\n4             NA             NA   1   2              NA           NA        99\n5              8             NA  14   1               3            3        54\n6             NA             NA   6   1               5            5        21\n  CLASSIFCD_MER1 CLASSIFCD_MER2 M21 CATLOGAC EMMENAG EMMENAG_C_1 STOC ACC\n1              6             NA  14        1       1        1959    2   2\n2             NA              6   3        1       1        2012    5   2\n3              6             NA   4        1       1        2002    2   2\n4             NA             NA   1        1       1        1991    2   2\n5              6             NA  14        1       1        2003    2   2\n6             NA             NA   2        1       1        1991    2   2\n  C9_anglais C9_espagnol C9_portugais C9_italien C9_allemand C9_arabe\n1        Non         Non          Non        Non         Non      Non\n2                                                                    \n3                                                                    \n4        Non         Non          Oui        Non         Non      Non\n5                                                                    \n6                                                                    \n  C9_autreslangues C25_anglais C25_espagnol C25_portugais C25_italien\n1              Oui                                                   \n2                          Oui          Oui           Non         Oui\n3                          Oui          Non           Non         Non\n4              Non                                                   \n5                                                                    \n6                                                                    \n  C25_allemand C25_arabe C25_coreen C25_japonais C25_autreslangues C37_anglais\n1                                                                             \n2          Non       Non        Non          Non               Non         Non\n3          Non       Non        Non          Non               Non            \n4                                                                             \n5                                                                             \n6                                                                             \n  C37_espagnol C37_italien C37_allemand C37_arabe C37_japonais\n1                                                             \n2          Oui         Non          Non       Non          Non\n3                                                             \n4                                                             \n5                                                             \n6                                                             \n  C37_autreslangues D7_anglais D7_espagnol D7_italien D7_allemand D7_portugais\n1                                                                             \n2               Non                                                           \n3                                                                             \n4                          Non         Non        Non         Non          Oui\n5                                                                             \n6                                                                             \n  D7_arabe D7_autreslangues E16_anglais E16_espagnol E16_italien E16_allemand\n1                                   Oui          Non         Non          Non\n2                                   Oui          Non         Non          Non\n3                                   Oui          Non         Non          Non\n4      Non              Non         Non          Non         Non          Non\n5                                   Non          Non         Non          Non\n6                                   Oui          Non         Non          Non\n  E16_portugais E16_arabe E16_turc E16_chinois E16_coreen E16_japonais\n1           Non       Non      Non         Non        Non          Non\n2           Non       Non      Non         Non        Non          Non\n3           Non       Non      Non         Non        Non          Non\n4           Oui       Non      Non         Non        Non          Non\n5           Non       Non      Non         Non        Non          Non\n6           Non       Non      Non         Non        Non          Non\n  E16_russe E16_autreslangues F10_anglais F10_espagnol F10_italien F10_allemand\n1       Non               Non                                                  \n2       Non               Non                                                  \n3       Non               Non                                                  \n4       Non               Non         Non          Non         Non          Non\n5       Non               Non                                                  \n6       Non               Non                                                  \n  F10_portugais F10_arabe F10_autreslangues M13_anglais M13_espagnol\n1                                                                   \n2                                                   Oui          Non\n3                                                                   \n4           Oui       Non               Non         Non          Non\n5                                                                   \n6                                                   Oui          Non\n  M13_italien M13_allemand M13_portugais M13_arabe M13_autreslangues\n1                                                                   \n2         Oui          Non           Non       Non               Non\n3                                                                   \n4         Non          Non           Oui       Non               Non\n5                                                                   \n6         Non          Non           Non       Non               Non\n  M15_anglais M15_espagnol M15_italien M15_allemand M15_portugais M15_arabe\n1                                                                          \n2                                                                          \n3         Oui          Non         Non          Oui           Non       Non\n4         Non          Non         Non          Non           Oui       Non\n5                                                                          \n6         Oui          Non         Non          Non           Non       Non\n  M15_autreslangues   Sex satisfaction Income Health Couple age_group  identity\n1                     Men          Low Medium   Good     No   [54-67[ 0.8624142\n2                     Men       Medium   High   Good     No   [15-38[ 0.5073268\n3               Non   Men         High   High    Bad    Yes   [38-54[ 0.3504244\n4               Non Women         High    Low Medium    Yes   [54-67[ 0.3681533\n5                     Men         High    Low Medium     No   [54-67[ 0.4284777\n6               Non   Men          Low   High   Good    Yes   [38-54[ 0.3848315\n      indice identity_scale    distance distance_abs categories categories_abs\n1  2.8024423 Very Masculine  3.36401698   3.36401698  Masculine    Medium_high\n2  0.5427446              3  0.63666730   0.63666730   Feminine   Low Distance\n3 -0.4557477              2 -0.56846635   0.56846635   Feminine   Low Distance\n4 -0.3429253              2  0.41247337   0.41247337   Feminine   Low Distance\n5  0.0409659              2  0.03104383   0.03104383   Feminine   Low Distance\n6 -0.2367887              2 -0.30419303   0.30419303   Feminine   Low Distance\n       score score_normalise    score_scale mean_score_by_gender\n1 -4.7431719       0.1076284 Very Masculine            0.4189343\n2 -1.0152326       0.3660092              2            0.4189343\n3  1.6901460       0.5535170              3            0.4189343\n4  3.9975170       0.7134392              4            0.5953428\n5 -0.1747180       0.4242646              2            0.4189343\n6  0.7268407       0.4867510              3            0.4189343\n  distance_to_mean_gender    score_2 score_normalise_2 distance_abs_score\n1             0.311305867 -5.5039343         0.1089070          3.8565094\n2             0.052925125 -2.0626560         0.3443974          0.3842434\n3             0.134582688  1.1780061         0.5661594          0.9559863\n4             0.118096370  3.7610020         0.7429166          0.1789834\n5             0.005330327 -0.8392860         0.4281139          1.1654076\n6             0.067816700 -0.3775367         0.4597119          0.1398309\n  norm_status\n1 Hors normes\n2     Normaux\n3     Normaux\n4     Normaux\n5     Normaux\n6     Normaux\n\n\nShow the code\n# Calculer la proportion de \"hors normes\"\ntotal_individuals &lt;- nrow(my_data_frame)\nhors_normes &lt;- sum(my_data_frame$norm_status == \"Hors normes\")\n\nproportion_hors_normes &lt;- hors_normes / total_individuals\nproportion_hors_normes\n\n\n[1] 0.04700022\n\n\nShow the code\n# Calculer la répartition des individus \"hors normes\" par niveau de satisfaction\ntable_satisfaction_hors_normes &lt;- table(my_data_frame$norm_status, my_data_frame$satisfaction)\n\n# Convertir en pourcentage\ntable_satisfaction_hors_normes_percent &lt;- prop.table(table_satisfaction_hors_normes, 1) * 100\ntable_satisfaction_hors_normes_percent\n\n\n             \n                  High      Low   Medium\n  Hors normes 27.64977 47.23502 25.11521\n  Normaux     34.09168 37.51564 28.39267\n\n\nShow the code\n# Visualisation de la proportion d'individus \"hors normes\"\nggplot(data = data.frame(Status = c(\"Normaux\", \"Hors normes\"), \n                         Proportion = c(1 - proportion_hors_normes, proportion_hors_normes)),\n       aes(x = Status, y = Proportion, fill = Status)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE) +\n  geom_text(aes(label = scales::percent(Proportion)), vjust = -0.5, size = 5) +\n  scale_fill_manual(values = c(\"blue\", \"red\")) +\n  labs(title = \"Proportion d'individus Hors Normes vs Normaux\",\n       x = \"Statut\", y = \"Proportion\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Visualisation avec boxplot pour la distance à la moyenne par niveau de satisfaction\nggplot(my_data_frame, aes(x = satisfaction, y = distance_abs_score, fill = norm_status)) +\n  geom_boxplot(outlier.colour = \"red\", outlier.size = 3, alpha = 0.6) +\n  scale_fill_manual(values = c(\"Normaux\" = \"blue\", \"Hors normes\" = \"red\")) +\n  labs(title = \"Boxplot de la distance à la moyenne par niveau de satisfaction\",\n       x = \"Satisfaction\", y = \"Distance à la moyenne (Distance absolue)\") +\n  theme_minimal() +\n  theme(legend.title = element_blank())\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Proportions de 'score_scale' par genre\ntable_score_gender &lt;- table(my_data_frame$score_scale, my_data_frame$Sex)\ntable_score_gender_percent &lt;- prop.table(table_score_gender, 2) * 100  # Calcul par genre\ntable_score_gender_percent\n\n\n                \n                         Men       Women\n  Very Masculine  0.43248438  0.00000000\n  1               7.73666506  0.35488959\n  2              45.77126382  7.72870662\n  3              40.72561269 39.70820189\n  4               4.92551658 33.49763407\n  5               0.38443056 16.04889590\n  Very Feminine   0.02402691  2.66167192\n\n\nShow the code\n# Proportions de 'satisfaction' par genre\ntable_satisfaction_gender &lt;- table(my_data_frame$satisfaction, my_data_frame$Sex)\ntable_satisfaction_gender_percent &lt;- prop.table(table_satisfaction_gender, 2) * 100  # Calcul par genre\ntable_satisfaction_gender_percent\n\n\n        \n              Men    Women\n  High   35.15399 32.66917\n  Low    35.80366 39.75143\n  Medium 29.04235 27.57940\n\n\nShow the code\n# Visualisation de la répartition des scores par genre\nggplot(as.data.frame(table_score_gender_percent), \n       aes(x = Var1, y = Freq, fill = Var2)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  labs(title = \"Répartition des scores par genre\",\n       x = \"Score (1-7)\", y = \"Proportion (%)\") +\n  scale_y_continuous(labels = scales::percent_format(scale = 1)) +\n  theme_minimal() +\n  theme(legend.title = element_blank()) +\n  geom_text(aes(label = scales::percent(Freq / 100)), \n            position = position_dodge(width = 0.8), vjust = -0.5)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Tableau croisé des proportions de satisfaction par score_scale et genre\ntable_satisfaction_score_gender &lt;- table(my_data_frame$satisfaction, my_data_frame$score_scale, my_data_frame$Sex)\n\n# Calculer les proportions par genre et score_scale\ntable_satisfaction_score_gender_percent &lt;- prop.table(table_satisfaction_score_gender, c(2, 3)) * 100\ntable_satisfaction_score_gender_percent\n\n\n, ,  = Men\n\n        \n         Very Masculine         1         2         3         4         5\n  High         33.33333  27.63975  34.06940  37.64775  36.58537  37.50000\n  Low          38.88889  44.40994  36.75079  33.27423  34.63415  31.25000\n  Medium       27.77778  27.95031  29.17981  29.07801  28.78049  31.25000\n        \n         Very Feminine\n  High         0.00000\n  Low          0.00000\n  Medium     100.00000\n\n, ,  = Women\n\n        \n         Very Masculine         1         2         3         4         5\n  High                   16.66667  29.84694  36.61202  29.99411  30.83538\n  Low                    55.55556  40.81633  36.36364  41.95639  41.64619\n  Medium                 27.77778  29.33673  27.02434  28.04950  27.51843\n        \n         Very Feminine\n  High        28.88889\n  Low         45.92593\n  Medium      25.18519\n\n\n\n\nShow the code\n# Visualisation avec un graphique à barres empilées\nggplot(as.data.frame(table_satisfaction_score_gender_percent), \n       aes(x = Var2, y = Freq, fill = Var1)) +\n  geom_bar(stat = \"identity\", position = \"stack\") +  # Barres empilées\n  scale_fill_manual(values = c(\"1\" = \"red\", \"2\" = \"orange\", \"3\" = \"green\")) +  # Couleurs pour chaque niveau de satisfaction\n  labs(title = \"Répartition de la satisfaction par score et genre\",\n       x = \"Score (1-7)\", y = \"Proportion (%)\") +\n  facet_wrap(~ Var3) +  # Facette par genre\n  scale_y_continuous(labels = scales::percent_format(scale = 1)) +  # Format de pourcentage\n  theme_minimal() +\n  theme(legend.title = element_blank()) +\n  geom_text(aes(label = scales::percent(Freq / 100)), \n            position = position_stack(vjust = 0.5))  # Positionner les étiquettes au centre des barres\n\n\n\n\n\n\n\n\n\nShow the code\nsummary(my_data_frame$score_scale)\n\n\nVery Masculine              1              2              3              4 \n            18            340           2297           3709           1904 \n             5  Very Feminine \n           830            136 \n\n\n\n\nShow the code\n# Calcul des proportions de satisfaction par score_scale et genre\ntable_satisfaction_score_gender &lt;- table(my_data_frame$satisfaction, my_data_frame$score_scale, my_data_frame$Sex)\n\n# Calcul des proportions par score_scale et genre\ntable_satisfaction_score_gender_percent &lt;- prop.table(table_satisfaction_score_gender, c(2, 3)) * 100\n\nprint(table_satisfaction_score_gender_percent)\n\n\n, ,  = Men\n\n        \n         Very Masculine         1         2         3         4         5\n  High         33.33333  27.63975  34.06940  37.64775  36.58537  37.50000\n  Low          38.88889  44.40994  36.75079  33.27423  34.63415  31.25000\n  Medium       27.77778  27.95031  29.17981  29.07801  28.78049  31.25000\n        \n         Very Feminine\n  High         0.00000\n  Low          0.00000\n  Medium     100.00000\n\n, ,  = Women\n\n        \n         Very Masculine         1         2         3         4         5\n  High                   16.66667  29.84694  36.61202  29.99411  30.83538\n  Low                    55.55556  40.81633  36.36364  41.95639  41.64619\n  Medium                 27.77778  29.33673  27.02434  28.04950  27.51843\n        \n         Very Feminine\n  High        28.88889\n  Low         45.92593\n  Medium      25.18519\n\n\nShow the code\n# Convertir la table de proportions en dataframe\ntable_satisfaction_score_gender_df &lt;- as.data.frame(table_satisfaction_score_gender_percent)\n\n# Renommer les colonnes pour plus de clarté\nnames(table_satisfaction_score_gender_df) &lt;- c(\"Satisfaction\", \"Score\", \"Sex\", \"Proportion\")\n\n\n# Convertir la table de proportions en dataframe\ntable_satisfaction_score_gender_df &lt;- as.data.frame(table_satisfaction_score_gender_percent)\n\n# Renommer les colonnes pour plus de clarté\nnames(table_satisfaction_score_gender_df) &lt;- c(\"Satisfaction\", \"Score\", \"Sex\", \"Proportion\")\n\n# Visualisation simple avec ggplot\nggplot(table_satisfaction_score_gender_df, aes(x = factor(Score), y = Proportion, fill = factor(Satisfaction))) +\n  geom_bar(stat = \"identity\", position = \"stack\") +  # Barres empilées\n  labs(title = \"Satisfaction par Score et Genre\", \n       x = \"Score\", y = \"Proportion (%)\") +\n  facet_wrap(~ Sex)  # Facette par sexe\n\n\n\n\n\n\n\n\n\nShow the code\nsave(my_data_frame, file = \"my_data_frame.RData\")"
  },
  {
    "objectID": "enseignement.html",
    "href": "enseignement.html",
    "title": "enseignement",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "enseignement.html#quarto",
    "href": "enseignement.html#quarto",
    "title": "enseignement",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "enseignement.html#running-code",
    "href": "enseignement.html#running-code",
    "title": "enseignement",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "eco_co/TD_5.html",
    "href": "eco_co/TD_5.html",
    "title": "TD 5: Analyse des Politiques de Redistribution avec la Courbe de Lorenz",
    "section": "",
    "text": "Introduction\nLes politiques de redistribution sont des mesures mises en place pour réduire les inégalités économiques au sein d’une société. Elles incluent des actions comme la progressivité fiscale, les transferts sociaux, et la protection sociale. Ces politiques visent à améliorer la répartition des ressources en faveur des plus défavorisés.\nL’une des façons d’analyser les inégalités économiques est d’utiliser la courbe de Lorenz, qui montre comment les revenus ou les richesses sont répartis parmi la population. Une courbe qui se rapproche de la diagonale (l’égalité parfaite) signifie une répartition plus équitable, tandis qu’une courbe éloignée indique une forte concentration des ressources dans les mains d’une petite partie de la population.\n\n\nObjectif\nL’objectif de ce TD est de comprendre la distribution des revenus dans une population et d’analyser l’impact des politiques de redistribution à l’aide de la courbe de Lorenz. Nous utilisons les données INSEE 2022 pour calculer cette courbe et la visualiser de manière interactive.\n\n\nShow the code\nlibrary(readxl)\n# Charger les bibliothèques nécessaires\nlibrary(ineq)\nlibrary(plotly)\ndecile &lt;- read_excel(\"inegalites_revenus.xls\")\n# Exemple de données fictives (revenus)\nrevenus &lt;- decile$revenus\n\n# Calcul de la courbe de Lorenz\nlorenz_curve &lt;- Lc(revenus)\n\n# Extraire les points de la courbe de Lorenz\nperc_pop &lt;- lorenz_curve$p * 100  # Proportion de la population en %\ncum_revenus &lt;- lorenz_curve$L * 100  # Proportion des revenus cumulés en %\n\n# Créer le data frame avec les données\ndata_lorenz &lt;- data.frame(\n  perc_pop = perc_pop,\n  cum_revenus = cum_revenus\n)\n\n# Créer la colonne \"text\" pour l'info-bulle\ndata_lorenz$text &lt;- paste0(\n  round(data_lorenz$perc_pop, 1), \"% de la population détient \", \n  round(data_lorenz$cum_revenus, 1), \"% des revenus\"\n)\n\n# Créer le graphique interactif avec plot_ly\nfig &lt;- plot_ly(\n  data = data_lorenz, \n  x = ~perc_pop, \n  y = ~cum_revenus, \n  type = 'scatter', \n  mode = 'lines',  # Courbe continue\n  line = list(color = \"blue\"),\n  hoverinfo = 'none'  # Ne pas afficher de texte sur la ligne continue\n)\n\n# Ajouter les points pour l'interaction\nfig &lt;- fig %&gt;%\n  add_trace(\n    x = ~perc_pop, \n    y = ~cum_revenus, \n    type = 'scatter', \n    mode = 'markers',  # Afficher des points\n    text = ~text,  # Utiliser directement la colonne \"text\" pour l'info-bulle\n    hoverinfo = 'text',  # Afficher le texte au survol des points\n    marker = list(color = \"blue\", size = 8)  # Marqueurs bleus\n  )\n\n# Ajouter la ligne d'égalité parfaite (diagonale)\nfig &lt;- fig %&gt;%\n  add_trace(\n    x = c(0, 100), \n    y = c(0, 100), \n    mode = \"lines\", \n    line = list(dash = \"dash\", color = \"red\"),\n    name = \"Égalité parfaite\"\n  )\n\n# Mise en forme du graphique\nfig &lt;- fig %&gt;%\n  layout(\n    title = \"Courbe de Lorenz des revenus\",\n    xaxis = list(title = \"Proportion de la population (%)\"),\n    yaxis = list(title = \"Proportion des revenus cumulés (%)\"),\n    showlegend = FALSE\n  )\n\n# Affichage du graphique interactif\nfig"
  },
  {
    "objectID": "eco_co/TD_3.html",
    "href": "eco_co/TD_3.html",
    "title": "TD 3",
    "section": "",
    "text": "Objectifs\n\nComprendre les différentes formes de chômage et leurs causes.\nAnalyser les approches classiques et keynésiennes du chômage.\nAppliquer la loi d’Okun et la courbe de Phillips à des cas concrets.\n\n\n\nExercice 1 : Identification des Types de Chômage\nConsigne : Associez chaque situation à l’un des types de chômage étudiés (volontaire, frictionnel, conjoncturel, structurel, technologique). Justifiez votre choix.\n\nUn ouvrier d’une usine textile perd son emploi en raison de la délocalisation de la production vers un pays à main-d’œuvre moins chère.\nUn jeune diplômé cherche son premier emploi après l’obtention de son diplôme.\nUne entreprise de tourisme licencie plusieurs employés suite à une crise économique qui réduit fortement la demande.\nUne secrétaire perd son emploi car son entreprise adopte un logiciel d’intelligence artificielle qui automatise son travail.\nUn cadre refuse plusieurs offres d’emploi jugées insuffisamment rémunérées et attend une meilleure opportunité.\n\n\n\nExercice 2 : L’Approche Classique et l’Approche Keynésienne\nConsigne : Complétez le tableau ci-dessous en indiquant les différences fondamentales entre les approches classique et keynésienne du chômage.\n\n\n\n\n\n\n\n\nCritères\nApproche Classique\nApproche Keynésienne\n\n\n\n\nRôle du marché du travail\n?\n?\n\n\nCauses principales du chômage\n?\n?\n\n\nSolutions préconisées\n?\n?\n\n\n\n\n\nExercice 3 : Application de la Loi d’Okun\nConsigne : On suppose que la croissance du PIB d’un pays est de 1,5 % et que la loi d’Okun indique qu’un taux de croissance de 2 % est nécessaire pour réduire le chômage de 1 %. Calculez la variation approximative du chômage dans ce pays.\n\n\nExercice 4 : Courbe de Phillips et Inflation\nConsigne : À partir des données suivantes, représentez graphiquement la courbe de Phillips et analysez son évolution.\n\n\n\nAnnée\nTaux de chômage (%)\nTaux d’inflation (%)\n\n\n2018\n6,0\n2,5\n\n\n2019\n5,5\n3,0\n\n\n2020\n7,0\n1,5\n\n\n2021\n6,5\n2,0\n\n\n\n\nExpliquez la relation observée entre chômage et inflation.\nQue se passe-t-il si cette relation n’est plus vérifiée ?\n\n\n\nExercice 5 : Etude de texte\n“Le RMI et son successeur le RSA découragent-ils certains jeunes de travailler ?”\nO. Bargain et A. Vicard\n\nQuelle est la principale question à laquelle cet article tente de répondre concernant le RMI et le RSA chez les jeunes ?\nPourquoi les auteurs se concentrent-ils sur les jeunes autour de 25 ans sans enfant pour étudier l’impact du RMI et du RSA sur l’emploi ?\nQuelle était la condition d’âge pour être éligible au RMI puis au RSA en France, et comment cela se compare-t-il à la situation dans la plupart des autres pays de l’OCDE ?\nQuelle est la méthode d’analyse utilisée dans cette étude pour évaluer l’effet du RMI et du RSA sur l’emploi des jeunes ? Expliquez brièvement en quoi elle consiste.\nQuels sont les principaux résultats de l’étude concernant l’effet désincitatif du RMI sur l’emploi des jeunes sans enfant et peu qualifiés ? Cet effet a-t-il évolué au cours de la période étudiée (2004-2009) ?\nComment le passage du RMI au RSA en 2009 a-t-il affecté l’emploi des jeunes, selon les résultats de cette étude ? Y a-t-il un effet ré-incitatif notable du RSA par rapport au RMI ?\nL’étude observe-t-elle des différences dans l’effet du RMI et du RSA sur l’emploi en fonction du niveau de qualification des jeunes ? Si oui, lesquelles ?\nSelon l’étude, le potentiel effet désincitatif des minima sociaux devrait principalement concerner quel type d’emploi ? Les résultats empiriques confirment-ils cette prédiction ?\nQuels sont les arguments avancés dans le texte pour suggérer que l’effet de trappe à inactivité mis en évidence n’est pas attribuable à d’autres facteurs qu’à l’existence du RMI ou du RSA ?\nQuelles sont les principales limites de cette étude, notamment en termes de généralisation des résultats à d’autres populations ?\nComment l’étude compare-t-elle la situation française en matière d’accès au revenu minimum pour les jeunes avec celle d’autres pays européens ?\nQuelles sont les principales différences entre le RMI et le RSA en termes de procédure d’accompagnement et de cumul avec les revenus du travail ?\n\nExercice : La Relance Keynésienne et le Multiplicateur Keynésien\nContexte\nUn gouvernement souhaite relancer l’économie en augmentant les dépenses publiques de 50 milliards d’euros. On suppose que l’économie suit le modèle keynésien avec une propension marginale à consommer (PMC) de 0,8.\nQuestions\n\nCalcul du multiplicateur\n\n\nRappelez la formule du multiplicateur keynésien.\n\nCalculez sa valeur avec une PMC de 0,8\n\nImpact sur le PIB\n\n\nDéterminez l’impact total sur le PIB de cette hausse des dépenses publiques.\n\nVariation avec une PMC différente\n\n\nQue se passe-t-il si la PMC est de 0,6 ? Recalculez le multiplicateur et l’impact sur le PIB.\n\nExpliquez pourquoi une PMC plus faible réduit l’effet de relance.\n\nLimites de la relance keynésienne\n\n\nQuels sont les risques ou limites de l’utilisation du multiplicateur keynésien dans une politique de relance ?\n\nEn quoi l’endettement public peut-il influencer l’efficacité d’une telle politique ?"
  },
  {
    "objectID": "eco_co/summary.html",
    "href": "eco_co/summary.html",
    "title": "Summary",
    "section": "",
    "text": "Summary\nIn summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "eco_co/simulation.html",
    "href": "eco_co/simulation.html",
    "title": "simulation",
    "section": "",
    "text": "# Charger les bibliothèques\nlibrary(shiny)\n\nWarning: le package 'shiny' a été compilé avec la version R 4.4.2\n\nlibrary(ggplot2)\nlibrary(reshape2)\nlibrary(plotly)\n\nWarning: le package 'plotly' a été compilé avec la version R 4.4.2\n\n\n\nAttachement du package : 'plotly'\n\n\nL'objet suivant est masqué depuis 'package:ggplot2':\n\n    last_plot\n\n\nL'objet suivant est masqué depuis 'package:stats':\n\n    filter\n\n\nL'objet suivant est masqué depuis 'package:graphics':\n\n    layout\n\n# Interface utilisateur\nui &lt;- fluidPage(\n  titlePanel(\"Simulation des Politiques Monétaires\"),\n  sidebarLayout(\n    sidebarPanel(\n      numericInput(\"inflation_init\", \"Inflation initiale (%)\", value = 5, min = 0, max = 20, step = 0.1),\n      numericInput(\"croissance_init\", \"Croissance initiale (%)\", value = 3, min = -10, max = 10, step = 0.1),\n      numericInput(\"chomage_init\", \"Chômage initial (%)\", value = 6, min = 0, max = 20, step = 0.1),\n      numericInput(\"variation_taux\", \"Variation des taux directeurs (%)\", value = 1, min = -5, max = 5, step = 0.1),\n      actionButton(\"simuler\", \"Lancer la simulation\")\n    ),\n    mainPanel(\n      plotlyOutput(\"graphique\")\n    )\n  )\n)\n\n# Fonction de simulation des effets des politiques\nserver &lt;- function(input, output) {\n  simuler_politique &lt;- eventReactive(input$simuler, {\n    mois &lt;- 1:12\n    inflation &lt;- numeric(12)\n    croissance &lt;- numeric(12)\n    chomage &lt;- numeric(12)\n    \n    inflation[1] &lt;- input$inflation_init\n    croissance[1] &lt;- input$croissance_init\n    chomage[1] &lt;- input$chomage_init\n    \n    for (i in 2:12) {\n      inflation[i] &lt;- max(0, inflation[i-1] - 0.5 * input$variation_taux)\n      croissance[i] &lt;- max(0, croissance[i-1] - 0.3 * input$variation_taux)\n      chomage[i] &lt;- max(0, chomage[i-1] + 0.2 * input$variation_taux)\n    }\n    \n    data.frame(Mois = mois, Inflation = inflation, Croissance = croissance, Chômage = chomage)\n  })\n  \n  output$graphique &lt;- renderPlotly({\n    resultats &lt;- simuler_politique()\n    resultats_melted &lt;- melt(resultats, id.vars = \"Mois\")\n\n    p &lt;- ggplot(resultats_melted, aes(x = Mois, y = value, color = variable, group = variable, text = paste(variable, \":\", round(value, 2), \"%\"))) +\n      geom_line(size = 1) +\n      geom_point() +\n      scale_color_manual(values = c(\"Inflation\" = \"lightblue\", \"Croissance\" = \"darkblue\", \"Chômage\" = \"purple\")) +\n      labs(\n        title = \"Simulation des Effets des Politiques Monétaires\",\n        x = \"Mois\",\n        y = \"Valeur\",\n        color = \"Indicateur\"\n      ) +\n      theme_minimal()\n    \n    ggplotly(p, tooltip = \"text\")\n  })\n}\n\n# Lancer l'application Shiny\nshinyApp(ui, server)\n\n\nListening on http://127.0.0.1:4659"
  },
  {
    "objectID": "eco_co/regles.html",
    "href": "eco_co/regles.html",
    "title": "TD2: Le Défi du Déficit Public",
    "section": "",
    "text": "# 🎯 Introduction: Règles du jeu et Carnet de Bord\n*Prenez les rênes d’un pays et guidez-le vers la prospérité… ou la faillite !*\nBienvenue dans **Le Défi du Déficit Public**, un jeu immersif où vous incarnez le dirigeant d’un pays fictif. Votre mission ? Prendre des décisions politiques et économiques stratégiques pour atteindre vos objectifs tout en maintenant un équilibre budgétaire.\nLe jeu repose sur trois types de cartes :\n- 🏛 **Cartes Politiques** : Décisions économiques à mettre en place. - ⚡ **Cartes Événements** : Crises ou opportunités influençant le pays. - 🎭 **Cartes Objectifs Secrets** : Buts spécifiques à accomplir en fin de partie."
  },
  {
    "objectID": "eco_co/regles.html#mise-en-place",
    "href": "eco_co/regles.html#mise-en-place",
    "title": "TD2: Le Défi du Déficit Public",
    "section": "🚀 Mise en place",
    "text": "🚀 Mise en place\n1. Chaque joueur reçoit une carte **Objectif Secret** (gardée secrète). 2. On distribue **5 cartes Politiques** à chaque joueur. 3. Les **cartes Événements** sont placées en pioche commune.\n\n\nShow the code\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(grid)\n\n# Dimensions en mm (standard pour carte à jouer)\nlargeur_mm &lt;- 63\nhauteur_mm &lt;- 88\n\n# Fonction pour créer une carte avec texte ajusté\ncreate_card &lt;- function(nom, description, type) {\n  couleur &lt;- ifelse(type == \"Politique\", \"#1f78b4\", \n                    ifelse(type == \"Événement\", \"#e31a1c\", \"#33a02c\")) # Couleurs distinctes\n\n  ggplot() +\n    annotate(\"rect\", xmin = 0, xmax = largeur_mm, ymin = 0, ymax = hauteur_mm, fill = \"white\", color = \"black\", linewidth = 1.5) +\n    annotate(\"rect\", xmin = 2, xmax = largeur_mm - 2, ymin = hauteur_mm - 8, ymax = hauteur_mm - 2, fill = couleur, color = \"black\") +\n    annotate(\"text\", x = largeur_mm / 2, y = hauteur_mm - 5, label = type, size = 3.5, fontface = \"bold\", color = \"white\") +\n    annotate(\"text\", x = largeur_mm / 2, y = hauteur_mm - 15, label = nom, size = 5, fontface = \"bold\") +\n    # Ajouter chaque ligne de description avec un saut de ligne\n    annotate(\"text\", x = largeur_mm / 2, y = hauteur_mm / 2 - 5, label = paste(description, collapse = \"\\n\"), size = 4, fontface = \"italic\", lineheight = 1.2) +\n    theme_void()\n}\n\n# Cartes POLITIQUES\ncartes_politiques &lt;- data.frame(\n  Type = \"Politique\",\n  Nom = c(\"Augmenter les impôts\", \"Baisser les impôts\", \"Augmenter les \\ndépenses publiques\",\n          \"Réduire les \\ndépenses publiques\", \"Baisser le taux d’intérêt\", \"Augmenter \\nle taux d’intérêt\",\n          \"Investir en R&D\", \"\\nPrivatiser \\ndes \\nentreprises publiques\", \"Lancer un \\nplan de relance\"),\n  Effet = c(\"+ Recettes publiques, \\n- Consommation\",\n            \"- Recettes publiques, \\n+ Consommation\",\n            \"+ PIB, \\n+ Emploi, \\n+ Déficit public\",\n            \"- PIB, \\n- Déficit, \\n- Emploi\",\n            \"+ Investissement, \\n+ PIB\",\n            \"- Inflation, \\n- PIB\",\n            \"+ Productivité, \\n+ PIB à long terme\",\n            \"+ Recettes ponctuelles, \\n- Emploi public\",\n            \"+ Croissance rapide, \\n+ Dette publique\"),\n  stringsAsFactors = FALSE\n)\n\n# Cartes ÉVÉNEMENTS\ncartes_evenements &lt;- data.frame(\n  Type = \"Événement\",\n  Nom = c(\"Crise Financière\", \"Boom Technologique\", \"Choc Pétrolier\", \"Hausse des Exportations\",\n          \"Manifestations Sociales\", \"Crise du Logement\", \"Dévaluation de \\nla Monnaie\"),\n  Effet = c(\"Les banques resserrent \\nle crédit.\",\n            \"Les entreprises innovent \\nfortement.\",\n            \"Le prix du pétrole \\nexplose.\",\n            \"Forte demande \\nétrangère.\",\n            \"Protestations contre \\nl’austérité.\",\n            \"Explosion des prix \\nimmobiliers.\",\n            \"La monnaie nationale \\nperd de la valeur.\"),\n  stringsAsFactors = FALSE\n)\n\n# Cartes OBJECTIFS SECRETS\ncartes_objectifs &lt;- data.frame(\n  Type = \"Objectif\",\n  Nom = c(\"Pays Social\", \"Pays Libéral\", \"Pays Écologique\", \"Pays Industriel\", \"Pays Équilibré\"),\n  Effet = c(\"Réduire le chômage \\nsous 5 %.\",\n            \"Atteindre un déficit \\nnul sans toucher aux impôts.\",\n            \"Réduire les émissions \\nde CO₂ de 20 %.\",\n            \"Augmenter la production \\nmanufacturière de 15 %.\",\n            \"Maintenir une inflation \\nentre 1 % et 3 %.\"),\n  stringsAsFactors = FALSE\n)\n\n# Génération de toutes les cartes\ncartes_plots &lt;- lapply(1:nrow(cartes_politiques), function(i) {\n  create_card(cartes_politiques$Nom[i], cartes_politiques$Effet[i], cartes_politiques$Type[i])\n})\n\ncartes_plots &lt;- c(cartes_plots, lapply(1:nrow(cartes_evenements), function(i) {\n  create_card(cartes_evenements$Nom[i], cartes_evenements$Effet[i], cartes_evenements$Type[i])\n}))\n\ncartes_plots &lt;- c(cartes_plots, lapply(1:nrow(cartes_objectifs), function(i) {\n  create_card(cartes_objectifs$Nom[i], cartes_objectifs$Effet[i], cartes_objectifs$Type[i])\n}))\n\n# Affichage en grille (4 cartes par ligne)\ngrid.arrange(grobs = cartes_plots, ncol = 4)\n\n\n\n\n\n\n\n\n\nShow the code\n# Sauvegarde en PDF avec dimensions exactes\npdf(\"cartes_jeu.pdf\", width = largeur_mm / 25.4, height = hauteur_mm / 25.4)  # Conversion mm → pouces\nfor (plot in cartes_plots) {\n  print(plot)\n}\ndev.off()\n\n\npng \n  2"
  },
  {
    "objectID": "eco_co/regles.html#tour-de-jeu",
    "href": "eco_co/regles.html#tour-de-jeu",
    "title": "TD2: Le Défi du Déficit Public",
    "section": "🔄 Tour de Jeu",
    "text": "🔄 Tour de Jeu\n1. **Jouer une carte politique** 🎟 : Le joueur choisit une action et l’applique. 2. **Tirer une carte événement** ⚡ : Une situation externe influence l’économie. 3. **Évaluer les effets** 📊 : Mise à jour du déficit, croissance, emploi, etc."
  },
  {
    "objectID": "eco_co/regles.html#fin-du-jeu-et-victoire",
    "href": "eco_co/regles.html#fin-du-jeu-et-victoire",
    "title": "TD2: Le Défi du Déficit Public",
    "section": "🏁 Fin du jeu et victoire",
    "text": "🏁 Fin du jeu et victoire\nLe gagnant est celui qui **équilibre son budget** tout en atteignant son **objectif secret**."
  },
  {
    "objectID": "eco_co/plan_cours.html",
    "href": "eco_co/plan_cours.html",
    "title": "Plan du Cours",
    "section": "",
    "text": "Objectifs\n- Présenter les principales théories économiques sur le rôle de l’État dans l’économie. - Expliquer les courants classiques et keynésiens. La synthèse : le modèle IS-LM\nA ce cours est associée une application de simulation de politiques économiques:\nhttps://pascalinev.shinyapps.io/eco_generale/\nActivités\n1. Lecture d’extraits d’œuvres classiques (Adam Smith, John Maynard Keynes). 2. Comparaison des approches keynésiennes et classiques à travers un exemple concret (ex. : crise économique de 2008). 3. Discussion : Quel rôle l’État doit-il jouer dans l’économie actuelle ?\n\n\n\n\n\n\nDocuments Complémentaire\n\n\n\nhttps://www.radiofrance.fr/franceculture/podcasts/entendez-vous-l-eco/monnaie-le-carburant-de-la-croissance-3375007"
  },
  {
    "objectID": "eco_co/plan_cours.html#séance-1-introduction-aux-théories-économiques-de-létat",
    "href": "eco_co/plan_cours.html#séance-1-introduction-aux-théories-économiques-de-létat",
    "title": "Plan du Cours",
    "section": "",
    "text": "Objectifs\n- Présenter les principales théories économiques sur le rôle de l’État dans l’économie. - Expliquer les courants classiques et keynésiens. La synthèse : le modèle IS-LM\nA ce cours est associée une application de simulation de politiques économiques:\nhttps://pascalinev.shinyapps.io/eco_generale/\nActivités\n1. Lecture d’extraits d’œuvres classiques (Adam Smith, John Maynard Keynes). 2. Comparaison des approches keynésiennes et classiques à travers un exemple concret (ex. : crise économique de 2008). 3. Discussion : Quel rôle l’État doit-il jouer dans l’économie actuelle ?\n\n\n\n\n\n\nDocuments Complémentaire\n\n\n\nhttps://www.radiofrance.fr/franceculture/podcasts/entendez-vous-l-eco/monnaie-le-carburant-de-la-croissance-3375007"
  },
  {
    "objectID": "eco_co/plan_cours.html#séance-2-le-cadre-institutionnel-et-le-processus-budgétaire",
    "href": "eco_co/plan_cours.html#séance-2-le-cadre-institutionnel-et-le-processus-budgétaire",
    "title": "Plan du Cours",
    "section": "Séance 2 : Le cadre institutionnel et le processus budgétaire",
    "text": "Séance 2 : Le cadre institutionnel et le processus budgétaire\nObjectifs\n- Comprendre le rôle des institutions dans l’élaboration du budget de l’État et les règles de l’Union européenne.\nActivités\n1. Étude de cas : Analyse d’un budget national (ex. : budget français) et son approbation par les institutions européennes. 2. Discussion : L’impact des critères de Maastricht sur les politiques budgétaires nationales. 3. Débat : Les limites du processus budgétaire dans l’UE face aux crises économiques."
  },
  {
    "objectID": "eco_co/plan_cours.html#séance-3-la-politique-monétaire-et-la-bce",
    "href": "eco_co/plan_cours.html#séance-3-la-politique-monétaire-et-la-bce",
    "title": "Plan du Cours",
    "section": "Séance 3 : La politique monétaire et la BCE",
    "text": "Séance 3 : La politique monétaire et la BCE\nObjectifs\n- Analyser les mécanismes de la politique monétaire et leur impact sur les économies nationales au sein de l’UEM.\nActivités\n1. Étude de cas : Analyse des décisions de la BCE pendant la crise de la zone euro (2010-2012). 2. Simulation : Prendre des décisions en tant que membres du conseil de la BCE concernant les taux d’intérêt face à une crise économique. 3. Discussion : Les limites de l’indépendance de la BCE."
  },
  {
    "objectID": "eco_co/plan_cours.html#séance-4-les-politiques-économiques-face-aux-inégalités-sociales-et-économiques",
    "href": "eco_co/plan_cours.html#séance-4-les-politiques-économiques-face-aux-inégalités-sociales-et-économiques",
    "title": "Plan du Cours",
    "section": "Séance 4 : Les politiques économiques face aux inégalités sociales et économiques",
    "text": "Séance 4 : Les politiques économiques face aux inégalités sociales et économiques\nObjectifs\n- Analyser les causes et les conséquences des inégalités économiques. - Étudier les différentes politiques économiques visant à réduire les inégalités sociales. - Discuter des arbitrages entre croissance économique et équité sociale.\nActivités\n1. Étude de cas : Analyse des politiques redistributives mises en place dans des pays européens (exemple : impôt progressif, transferts sociaux). 2. Discussion : Les inégalités sont-elles inévitables dans une économie de marché ? Quels rôles pour l’État ? 3. Atelier : Proposer une stratégie économique pour réduire les inégalités dans un pays fictif en respectant des contraintes budgétaires."
  },
  {
    "objectID": "eco_co/plan_cours.html#séance-5-les-réformes-structurelles-en-france-et-en-europe",
    "href": "eco_co/plan_cours.html#séance-5-les-réformes-structurelles-en-france-et-en-europe",
    "title": "Plan du Cours",
    "section": "Séance 5 : Les réformes structurelles en France et en Europe",
    "text": "Séance 5 : Les réformes structurelles en France et en Europe\nObjectifs\n- Étudier les réformes structurelles en France et en Europe et leur impact sur l’économie à long terme.\nActivités\n1. Étude de cas : Analyse des réformes du marché du travail en France (réforme des retraites, loi El Khomri). 2. Discussion : Quels sont les effets des réformes structurelles sur la croissance économique et l’emploi ? 3. Présentation en groupe : Comparer les réformes structurelles dans plusieurs pays européens et leurs résultats."
  },
  {
    "objectID": "eco_co/plan_cours.html#séance-6-la-crise-des-subprimes-et-les-réponses-politiques",
    "href": "eco_co/plan_cours.html#séance-6-la-crise-des-subprimes-et-les-réponses-politiques",
    "title": "Plan du Cours",
    "section": "Séance 6 : La crise des subprimes et les réponses politiques",
    "text": "Séance 6 : La crise des subprimes et les réponses politiques\nObjectifs\n- Comprendre les causes de la crise des subprimes et les réponses politiques mises en place.\nActivités\n1. Étude de cas : Analyser les origines de la crise des subprimes et les réponses économiques des États-Unis et de l’Europe. 2. Simulation : Recommandations pour des politiques économiques après un choc externe. 3. Discussion : Quel rôle pour l’État face à une crise financière globale ?"
  },
  {
    "objectID": "eco_co/plan_cours.html#séance-7-la-crise-des-dettes-souveraines-analyse-et-solutions",
    "href": "eco_co/plan_cours.html#séance-7-la-crise-des-dettes-souveraines-analyse-et-solutions",
    "title": "Plan du Cours",
    "section": "Séance 7 : La crise des dettes souveraines : analyse et solutions",
    "text": "Séance 7 : La crise des dettes souveraines : analyse et solutions\nObjectifs\n- Analyser la crise des dettes souveraines en Europe et les solutions mises en œuvre.\nActivités\n1. Étude de cas : Analyser la gestion de la crise de la dette en Grèce et en Espagne. 2. Débat : Les politiques d’austérité : nécessaire réduction des déficits ou frein à la croissance ? 3. Discussion : Quels mécanismes de solidarité économique peuvent être mis en place au sein de l’UE pour éviter de futures crises de dette souveraine ?"
  },
  {
    "objectID": "eco_co/plan_cours.html#séance-8-le-chômage-déséquilibre-du-marché-du-travail",
    "href": "eco_co/plan_cours.html#séance-8-le-chômage-déséquilibre-du-marché-du-travail",
    "title": "Plan du Cours",
    "section": "Séance 8 : Le chômage : déséquilibre du marché du travail",
    "text": "Séance 8 : Le chômage : déséquilibre du marché du travail\nObjectifs\n- Définir et analyser les types de chômage et les difficultés de mesure.\nActivités\n1. Analyse de données : Étudier les taux de chômage dans différents pays européens (France, Allemagne, Espagne). 2. Discussion : Les limites des indicateurs officiels du chômage (ex. taux de chômage et sous-emploi). 3. Cas pratique : Identifier les facteurs influençant le chômage dans un pays de l’UE (récession, changements technologiques, etc.)."
  },
  {
    "objectID": "eco_co/plan_cours.html#séance-9-analyse-néoclassique-du-marché-du-travail",
    "href": "eco_co/plan_cours.html#séance-9-analyse-néoclassique-du-marché-du-travail",
    "title": "Plan du Cours",
    "section": "Séance 9 : Analyse néoclassique du marché du travail",
    "text": "Séance 9 : Analyse néoclassique du marché du travail\nObjectifs\n- Appliquer les principes néoclassiques du marché du travail aux réalités contemporaines.\nActivités\n1. Étude de cas : Analyser l’impact des réformes du marché du travail en France à travers le prisme néoclassique. 2. Discussion : Les néoclassiques ont-ils une réponse adéquate aux défis du chômage structurel et du chômage technologique ? 3. Simulation : Déterminer l’impact des politiques d’offre (réduire les impôts, flexibiliser le marché du travail) sur le chômage."
  },
  {
    "objectID": "eco_co/plan_cours.html#séance-10-politiques-de-lemploi-analyse-et-débat",
    "href": "eco_co/plan_cours.html#séance-10-politiques-de-lemploi-analyse-et-débat",
    "title": "Plan du Cours",
    "section": "Séance 10 : Politiques de l’emploi : analyse et débat",
    "text": "Séance 10 : Politiques de l’emploi : analyse et débat\nObjectifs\n- Analyser les politiques de l’emploi mises en œuvre en France et en Europe.\nActivités\n1. Étude de cas : Analyser les politiques actives de l’emploi (formation, subventions à l’embauche) dans différents pays européens. 2. Simulation : Proposer des solutions pour réduire le chômage dans un pays fictif (par exemple, une nation européenne en récession). 3. Débat : Quelle politique de l’emploi est la plus efficace face au chômage des jeunes et au chômage de longue durée ?"
  },
  {
    "objectID": "eco_co/plan_cours.html#fil-conducteur-pour-les-td-simulation-de-gestion-économique",
    "href": "eco_co/plan_cours.html#fil-conducteur-pour-les-td-simulation-de-gestion-économique",
    "title": "Plan du Cours",
    "section": "Fil conducteur pour les TD : Simulation de gestion économique",
    "text": "Fil conducteur pour les TD : Simulation de gestion économique\nTout au long des séances, les étudiants seront divisés en groupes représentant différents acteurs économiques (gouvernement, secteur privé, banques centrales, syndicats, etc.). Chaque TD permettra aux groupes de prendre des décisions politiques et économiques basées sur les théories et concepts étudiés en cours. À chaque séance, les groupes présenteront leurs choix et leur analyse de l’impact de leurs décisions sur l’économie du pays fictif qu’ils gèrent. Cela permettra d’illustrer de manière concrète l’application des connaissances théoriques et de favoriser un apprentissage interactif."
  },
  {
    "objectID": "eco_co/index.html",
    "href": "eco_co/index.html",
    "title": "Présentation",
    "section": "",
    "text": "Comprendre les modalités, les objectifs et les enjeux de la politique économique.\nComprendre les contours et caractéristiques du chômage, le fonctionnement du marché du travail et la pluralité des politiques de l’emploi.\n\n\n\n\n* Le cours d’économie générale (S2) suppose la maîtrise des savoir-faire suivants :\n\nMesure de proportion, pourcentage de répartition.\nTaux de variation, taux de variation cumulé, coefficient multiplicateur, indice simple.\nMoyenne arithmétique simple et pondérée.\nIndice synthétique.\nMédiane.\nÉcart et rapport inter-quantile.\nCorrélation et causalité.\nTaux de variation moyen.\nValeur nominale, valeur réelle (notamment, taux d’intérêt nominal et taux d’intérêt réel).\n\n- Savoir exploiter : Tableau à double-entrée, diagrammes de répartition, représentation de séries chronologiques, représentation graphique de fonctions simples (offre, demande, coût) et interprétation de leurs pentes et de leurs déplacements.\n* Les théories, notions et mécanismes abordés au semestre 1 en Économie Générale et en Histoire de la Pensée Economique avec notamment\n- Les différents agrégats macroéconomiques\n- Les grandes fonctions macroéconomiques"
  },
  {
    "objectID": "eco_co/index.html#objectifs",
    "href": "eco_co/index.html#objectifs",
    "title": "Présentation",
    "section": "",
    "text": "Comprendre les modalités, les objectifs et les enjeux de la politique économique.\nComprendre les contours et caractéristiques du chômage, le fonctionnement du marché du travail et la pluralité des politiques de l’emploi."
  },
  {
    "objectID": "eco_co/index.html#pré-requis",
    "href": "eco_co/index.html#pré-requis",
    "title": "Présentation",
    "section": "",
    "text": "* Le cours d’économie générale (S2) suppose la maîtrise des savoir-faire suivants :\n\nMesure de proportion, pourcentage de répartition.\nTaux de variation, taux de variation cumulé, coefficient multiplicateur, indice simple.\nMoyenne arithmétique simple et pondérée.\nIndice synthétique.\nMédiane.\nÉcart et rapport inter-quantile.\nCorrélation et causalité.\nTaux de variation moyen.\nValeur nominale, valeur réelle (notamment, taux d’intérêt nominal et taux d’intérêt réel).\n\n- Savoir exploiter : Tableau à double-entrée, diagrammes de répartition, représentation de séries chronologiques, représentation graphique de fonctions simples (offre, demande, coût) et interprétation de leurs pentes et de leurs déplacements.\n* Les théories, notions et mécanismes abordés au semestre 1 en Économie Générale et en Histoire de la Pensée Economique avec notamment\n- Les différents agrégats macroéconomiques\n- Les grandes fonctions macroéconomiques"
  },
  {
    "objectID": "eco_co/chap_2.html",
    "href": "eco_co/chap_2.html",
    "title": "Chapitre 2: Le cadre institutionnel et le processus budgétaire",
    "section": "",
    "text": "La question du budget de l’Etat est au coeur de l’actualité, mais comment est élaboré le budget de l’Etat? Comment a-t-il évolué au cours du temps? Quelles différences entre déficit public et dette publique? Comment est construit le budget dans le cadre des réglementations européennes?"
  },
  {
    "objectID": "eco_co/chap_2.html#introduction",
    "href": "eco_co/chap_2.html#introduction",
    "title": "Chapitre 2: Le cadre institutionnel et le processus budgétaire",
    "section": "",
    "text": "La question du budget de l’Etat est au coeur de l’actualité, mais comment est élaboré le budget de l’Etat? Comment a-t-il évolué au cours du temps? Quelles différences entre déficit public et dette publique? Comment est construit le budget dans le cadre des réglementations européennes?"
  },
  {
    "objectID": "eco_co/chap_2.html#le-budget-de-letat",
    "href": "eco_co/chap_2.html#le-budget-de-letat",
    "title": "Chapitre 2: Le cadre institutionnel et le processus budgétaire",
    "section": "Le budget de l’Etat",
    "text": "Le budget de l’Etat\nPour présenter le budget de l’Etat, nous nous référons au site suivant\n\nLes recettes\nLes impôts et les taxes (dont TVA)\n\n\nShow the code\n# Charger les bibliothèques\nlibrary(readxl)\n\nlibrary(ggplot2)\nlibrary(plotly)\n\n# Lire les données depuis le fichier Excel\ndonnees &lt;- read_excel(\"donnees.xls\")\ndonnees &lt;- donnees[-1,]\ndonnees$Valeur&lt;- donnees$`Évaluations 2024 révisées`\n\n# Ajouter une colonne pour le pourcentage\ndonnees$Pourcentage &lt;- round(donnees$Valeur / sum(donnees$Valeur) * 100, 1)\n\n# Création du camembert interactif avec plotly\np_interactif &lt;- plot_ly(donnees, labels = ~Recette, values = ~Valeur, type = \"pie\",\n                        textinfo = \"label+percent\", hoverinfo = \"label+percent+value\",\n                        marker = list(line = list(color = \"#FFFFFF\", width = 1))) %&gt;%\n  layout(title = \"Répartition des Recettes\")\n\n# Afficher le graphique interactif\np_interactif\n\n\n\n\n\n\nSource: Ministère de l’Economie, des Finances et de l’Industrie, projet de loi de finances 2025\n\n\nLes Dépenses\n\n\nShow the code\ndepenses &lt;- read_xlsx(\"depenses.xlsx\")\ndepenses$depenses&lt;-depenses$`Dépenses publiques`\n\n  \n# Création du camembert interactif avec plotly\np_interactif2 &lt;- plot_ly(depenses, labels = ~Structure, values = ~depenses, type = \"pie\",\n                        textinfo = \"label+percent\", hoverinfo = \"label+percent+value\",\n                        marker = list(line = list(color = \"#FFFFFF\", width = 1))) %&gt;%\n  layout(title = \"Répartition des Dépenses\")\n\n# Afficher le graphique interactif\np_interactif2\n\n\n\n\n\n\n\n\n\nEvolution du solde budgétaire\n\n\nShow the code\ndette &lt;- read_excel(\"dette.xls\")\n\ndette$year&lt;-dette$Année\ndette$deficit&lt;-dette$`Déficit public notifié`\n\nggplot(dette, aes(x =year, y = deficit)) +\n  geom_line(color = \"blue\", size = 1) +  # Courbe bleue pour l'évolution de la variable\n  geom_hline(yintercept = -3, linetype = \"dashed\", color = \"orange\", size = 1) +  # Ligne horizontale à y = 3\n  scale_y_continuous(limits = c(-10, 2), name = \"en % du PIB\") +  # Limiter l'axe y de -10 à 2 et ajouter un libellé\n  labs(title = \"Solde des finances Publiques\",\n       x = \"Année\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nEvolution des dépenses et recettes\n\n\nShow the code\nrecettes &lt;- read_excel(\"recettes.xls\")\n# Création du graphique avec ggplot2\nggplot(recettes, aes(x = year)) + \n  geom_line(aes(y = Depenses, color = \"Dépenses Publiques\"), size = 1.2) +  # Courbe bleue\n  geom_line(aes(y = Recettes, color = \"Recettes\"), size = 1.2) +  # Courbe orange\n  scale_color_manual(values = c(\"Dépenses Publiques\" = \"blue\", \"Recettes\" = \"orange\")) +  # Couleurs\n  labs(title = \"Évolution des Dépenses et Recettes Publiques\",\n       x = \"Année\",\n       y = \"Valeurs (% du PIB)\",\n       color = \"Légende\") +  # Étiquettes\n  theme_minimal() +  # Thème\n  theme(text = element_text(size = 12))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\ndeficit_europe &lt;- read_excel(\"deficit_europe.xls\")\ndeficit_europe$deficit&lt;-deficit_europe$`Solde des finances publiques\n(en % du PIB)`\nggplot(deficit_europe, aes(x = reorder(Pays, deficit), y = deficit)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +  # Barres bleues\n  coord_flip() +  # Inverser les axes pour horizontal\n  labs(title = \"Déficit par pays\", x = \"Pays\", y = \"Déficit (%)\") +\n  theme_minimal()"
  },
  {
    "objectID": "eco_co/chap_2.html#les-règles-qui-régissent-le-budget-de-letat",
    "href": "eco_co/chap_2.html#les-règles-qui-régissent-le-budget-de-letat",
    "title": "Chapitre 2: Le cadre institutionnel et le processus budgétaire",
    "section": "Les règles qui régissent le budget de l’Etat",
    "text": "Les règles qui régissent le budget de l’Etat\n\nLes principes budgétaires\n\n\n\n\n\n\nCitation\n\n\n\nle budget doit répondre à plusieurs principes budgétaires comme l’universalité, l’unité, la spécialité et l’annualité.\n\nL’universalité budgétaire de l’État, signifie que, normalement — sauf pour quelques exceptions —, toutes les recettes doivent alimenter le budget de l’État sans être affectées à une dépense précise. C’est un grand pot commun qui permet d’alimenter toutes les politiques publiques sans distinction.\nLe budget de l’État doit aussi être présenté dans un document unique avec toutes les dépenses et toutes les recettes. Ce document doit être le plus exhaustif possible. C’est un enjeu de lisibilité et de transparence pour les citoyens et pour permettre au Parlement, qui va ensuite voter ce texte, de travailler efficacement.\nLe budget doit également détailler l’autorisation des crédits par destination, c’est-à-dire qu’une dépense va être prévue dans un but défini, c’est le principe de spécialité.\nLe dernier principe, c’est l’annualité. Chaque année, on détermine les recettes et les dépenses pour une année. Le budget tient compte, bien sûr, du fait que certaines politiques publiques sont pluriannuelles. Mais on fait en sorte que chaque année, on puisse faire de la justification au premier euro, c’est-à-dire que chaque dépense puisse être justifiée annuellement.\n\n\n\n\n\nLes règles européennes\nLe traité de Maastricht prévoit deux critères de convergence:\n\nUne limitation du déficit public &lt; 3% du PIB\nUn plafonnement de la dette publique, qui ne doit pas excéder 60% du PIB\n\n\n\n\n\n\n\nDébat\n\n\n\nDonnez des arguments Pour et Contre une discipline budgétaire suivant ces critères définis."
  },
  {
    "objectID": "eco_co/cartes.html",
    "href": "eco_co/cartes.html",
    "title": "Cartes du jeu",
    "section": "",
    "text": "library(ggplot2)\nlibrary(gridExtra)\nlibrary(grid)\n\n# Dimensions en mm (standard pour carte à jouer)\nlargeur_mm &lt;- 63\nhauteur_mm &lt;- 88\n\n# Fonction pour créer une carte avec texte ajusté\ncreate_card &lt;- function(nom, description, type) {\n  couleur &lt;- ifelse(type == \"Politique\", \"#1f78b4\", \n                    ifelse(type == \"Événement\", \"#e31a1c\", \"#33a02c\")) # Couleurs distinctes\n\n  ggplot() +\n    annotate(\"rect\", xmin = 0, xmax = largeur_mm, ymin = 0, ymax = hauteur_mm, fill = \"white\", color = \"black\", linewidth = 1.5) +\n    annotate(\"rect\", xmin = 2, xmax = largeur_mm - 2, ymin = hauteur_mm - 8, ymax = hauteur_mm - 2, fill = couleur, color = \"black\") +\n    annotate(\"text\", x = largeur_mm / 2, y = hauteur_mm - 5, label = type, size = 3.5, fontface = \"bold\", color = \"white\") +\n    annotate(\"text\", x = largeur_mm / 2, y = hauteur_mm - 15, label = nom, size = 5, fontface = \"bold\") +\n    # Ajouter chaque ligne de description avec un saut de ligne\n    annotate(\"text\", x = largeur_mm / 2, y = hauteur_mm / 2 - 5, label = paste(description, collapse = \"\\n\"), size = 4, fontface = \"italic\", lineheight = 1.2) +\n    theme_void()\n}\n\n# Cartes POLITIQUES\ncartes_politiques &lt;- data.frame(\n  Type = \"Politique\",\n  Nom = c(\"Augmenter les impôts\", \"Baisser les impôts\", \"Augmenter les \\ndépenses publiques\",\n          \"Réduire les \\ndépenses publiques\", \"Baisser le taux d’intérêt\", \"Augmenter \\nle taux d’intérêt\",\n          \"Investir en R&D\", \"\\nPrivatiser \\ndes \\nentreprises publiques\", \"Lancer un \\nplan de relance\"),\n  Effet = c(\"+ Recettes publiques, \\n- Consommation\",\n            \"- Recettes publiques, \\n+ Consommation\",\n            \"+ PIB, \\n+ Emploi, \\n+ Déficit public\",\n            \"- PIB, \\n- Déficit, \\n- Emploi\",\n            \"+ Investissement, \\n+ PIB\",\n            \"- Inflation, \\n- PIB\",\n            \"+ Productivité, \\n+ PIB à long terme\",\n            \"+ Recettes ponctuelles, \\n- Emploi public\",\n            \"+ Croissance rapide, \\n+ Dette publique\"),\n  stringsAsFactors = FALSE\n)\n\n# Cartes ÉVÉNEMENTS\ncartes_evenements &lt;- data.frame(\n  Type = \"Événement\",\n  Nom = c(\"Crise Financière\", \"Boom Technologique\", \"Choc Pétrolier\", \"Hausse des Exportations\",\n          \"Manifestations Sociales\", \"Crise du Logement\", \"Dévaluation de \\nla Monnaie\"),\n  Effet = c(\"Les banques resserrent \\nle crédit.\",\n            \"Les entreprises innovent \\nfortement.\",\n            \"Le prix du pétrole \\nexplose.\",\n            \"Forte demande \\nétrangère.\",\n            \"Protestations contre \\nl’austérité.\",\n            \"Explosion des prix \\nimmobiliers.\",\n            \"La monnaie nationale \\nperd de la valeur.\"),\n  stringsAsFactors = FALSE\n)\n\n# Cartes OBJECTIFS SECRETS\ncartes_objectifs &lt;- data.frame(\n  Type = \"Objectif\",\n  Nom = c(\"Pays Social\", \"Pays Libéral\", \"Pays Écologique\", \"Pays Industriel\", \"Pays Équilibré\"),\n  Effet = c(\"Réduire le chômage \\nsous 5 %.\",\n            \"Atteindre un déficit \\nnul sans toucher aux impôts.\",\n            \"Réduire les émissions \\nde CO₂ de 20 %.\",\n            \"Augmenter la production \\nmanufacturière de 15 %.\",\n            \"Maintenir une inflation \\nentre 1 % et 3 %.\"),\n  stringsAsFactors = FALSE\n)\n\n# Génération de toutes les cartes\ncartes_plots &lt;- lapply(1:nrow(cartes_politiques), function(i) {\n  create_card(cartes_politiques$Nom[i], cartes_politiques$Effet[i], cartes_politiques$Type[i])\n})\n\ncartes_plots &lt;- c(cartes_plots, lapply(1:nrow(cartes_evenements), function(i) {\n  create_card(cartes_evenements$Nom[i], cartes_evenements$Effet[i], cartes_evenements$Type[i])\n}))\n\ncartes_plots &lt;- c(cartes_plots, lapply(1:nrow(cartes_objectifs), function(i) {\n  create_card(cartes_objectifs$Nom[i], cartes_objectifs$Effet[i], cartes_objectifs$Type[i])\n}))\n\n# Affichage en grille (4 cartes par ligne)\ngrid.arrange(grobs = cartes_plots, ncol = 4)\n\n\n\n\n\n\n\n# Sauvegarde en PDF avec dimensions exactes\npdf(\"cartes_jeu.pdf\", width = largeur_mm / 25.4, height = hauteur_mm / 25.4)  # Conversion mm → pouces\nfor (plot in cartes_plots) {\n  print(plot)\n}\ndev.off()\n\npng \n  2 \n\n# Sauvegarde en PNG avec **format exact 63 × 88 mm**\nfor (i in seq_along(cartes_plots)) {\n  ggsave(filename = paste0(\"carte_\", i, \".png\"), plot = cartes_plots[[i]], \n         width = 63, height = 88, units = \"mm\", dpi = 300)\n}"
  },
  {
    "objectID": "eco_co/chapitre_1.html",
    "href": "eco_co/chapitre_1.html",
    "title": "chapitre 1: Introduction aux théories économiques de l’Etat",
    "section": "",
    "text": "Plus ou moins d’Etat? Celui-ci doit-il intervenir dans l’économie? Si oui, comment? Quels sont ses objectifs et ses outils? Que nous dit la théorie économique?\nCe chapitre s’appuie sur le Précis d’économie d’Emmanuel Combe (“Précis d’économie  PUF” n.d.)\n\n\n\nAllocation des ressources: l’Etat réalise des dépenses pour entretenir son administration et financer les biens collectifs (défense, infrastructures …)\nRedistribution: Vers l’égalité d’accès des citoyens à certaines ressources\nRégulation: Soutenir l’activité économique\n\n\n\n\n\n\nShow the code\n# Étape 1 : Préparer les données\ndata_france &lt;- data.frame(\n  periode = c(\"2000\", \"2005\", \"2010\", \"2015\", \"2020\"),\n  croissance = c(3.0, 2.5, 1.2, 1.8, -0.5),  # Croissance économique (%)\n  emploi = c(93, 91, 89, 87, 85),           # Taux d'emploi (%)\n  prix = c(1.5, 2.0, 1.8, 1.6, 0.5),        # Inflation (%)\n  commerce = c(0.2, -0.5, -1.0, -1.5, -2.0) # Balance commerciale (% du PIB)\n)\n\n# Étape 2 : Normaliser les données\nnormalize &lt;- function(x) {\n  (x - min(x)) / (max(x) - min(x))\n}\n\ndata_normalized &lt;- data_france\ndata_normalized[, -1] &lt;- as.data.frame(lapply(data_france[, -1], normalize))\n\n# Étape 3 : Préparer les données pour le graphique radar\n# Installer et charger le package fmsb si nécessaire\n\nlibrary(fmsb)\n\n# Ajouter les lignes pour les max et min (requis pour le package fmsb)\nradar_data &lt;- rbind(\n  rep(1, 4),  # Valeurs maximales après normalisation\n  rep(0, 4),  # Valeurs minimales après normalisation\n  data_normalized[, -1]  # Données normalisées\n)\n\n# Nommer les colonnes pour le graphique radar\ncolnames(radar_data) &lt;- c(\"Croissance\", \"Emploi\", \"Prix\", \"Commerce\")\nrownames(radar_data) &lt;- c(\"Max\", \"Min\", data_france$periode)\n\n# Étape 4 : Tracer le carré magique\nradarchart(\n  radar_data,\n  axistype = 1,\n  pcol = rainbow(nrow(data_france)),  # Couleurs pour chaque période\n  pfcol = rainbow(nrow(data_france), alpha = 0.4),  # Couleurs remplies\n  plwd = 2,  # Épaisseur des lignes\n  cglcol = \"grey\", cglty = 1, axislabcol = \"black\", caxislabels = seq(0, 1, 0.2),\n  title = \"Carré magique de Kaldor - France à différentes périodes\"\n)\n\n# Ajouter une légende\nlegend(\n  \"topright\",\n  legend = data_france$periode,\n  col = rainbow(nrow(data_france)),\n  lty = 1, lwd = 2\n)"
  },
  {
    "objectID": "eco_co/chapitre_1.html#introduction",
    "href": "eco_co/chapitre_1.html#introduction",
    "title": "chapitre 1: Introduction aux théories économiques de l’Etat",
    "section": "",
    "text": "Plus ou moins d’Etat? Celui-ci doit-il intervenir dans l’économie? Si oui, comment? Quels sont ses objectifs et ses outils? Que nous dit la théorie économique?\nCe chapitre s’appuie sur le Précis d’économie d’Emmanuel Combe (“Précis d’économie  PUF” n.d.)\n\n\n\nAllocation des ressources: l’Etat réalise des dépenses pour entretenir son administration et financer les biens collectifs (défense, infrastructures …)\nRedistribution: Vers l’égalité d’accès des citoyens à certaines ressources\nRégulation: Soutenir l’activité économique\n\n\n\n\n\n\nShow the code\n# Étape 1 : Préparer les données\ndata_france &lt;- data.frame(\n  periode = c(\"2000\", \"2005\", \"2010\", \"2015\", \"2020\"),\n  croissance = c(3.0, 2.5, 1.2, 1.8, -0.5),  # Croissance économique (%)\n  emploi = c(93, 91, 89, 87, 85),           # Taux d'emploi (%)\n  prix = c(1.5, 2.0, 1.8, 1.6, 0.5),        # Inflation (%)\n  commerce = c(0.2, -0.5, -1.0, -1.5, -2.0) # Balance commerciale (% du PIB)\n)\n\n# Étape 2 : Normaliser les données\nnormalize &lt;- function(x) {\n  (x - min(x)) / (max(x) - min(x))\n}\n\ndata_normalized &lt;- data_france\ndata_normalized[, -1] &lt;- as.data.frame(lapply(data_france[, -1], normalize))\n\n# Étape 3 : Préparer les données pour le graphique radar\n# Installer et charger le package fmsb si nécessaire\n\nlibrary(fmsb)\n\n# Ajouter les lignes pour les max et min (requis pour le package fmsb)\nradar_data &lt;- rbind(\n  rep(1, 4),  # Valeurs maximales après normalisation\n  rep(0, 4),  # Valeurs minimales après normalisation\n  data_normalized[, -1]  # Données normalisées\n)\n\n# Nommer les colonnes pour le graphique radar\ncolnames(radar_data) &lt;- c(\"Croissance\", \"Emploi\", \"Prix\", \"Commerce\")\nrownames(radar_data) &lt;- c(\"Max\", \"Min\", data_france$periode)\n\n# Étape 4 : Tracer le carré magique\nradarchart(\n  radar_data,\n  axistype = 1,\n  pcol = rainbow(nrow(data_france)),  # Couleurs pour chaque période\n  pfcol = rainbow(nrow(data_france), alpha = 0.4),  # Couleurs remplies\n  plwd = 2,  # Épaisseur des lignes\n  cglcol = \"grey\", cglty = 1, axislabcol = \"black\", caxislabels = seq(0, 1, 0.2),\n  title = \"Carré magique de Kaldor - France à différentes périodes\"\n)\n\n# Ajouter une légende\nlegend(\n  \"topright\",\n  legend = data_france$periode,\n  col = rainbow(nrow(data_france)),\n  lty = 1, lwd = 2\n)"
  },
  {
    "objectID": "eco_co/chapitre_1.html#justifications-de-letat-minimal-les-classiques",
    "href": "eco_co/chapitre_1.html#justifications-de-letat-minimal-les-classiques",
    "title": "chapitre 1: Introduction aux théories économiques de l’Etat",
    "section": "Justifications de l’Etat minimal : les Classiques",
    "text": "Justifications de l’Etat minimal : les Classiques\nLes Classiques prônent une intervention minimale de l’Etat dans l’économie (Sabéran 2008)\n\n\n\n\n\n\nCitation\n\n\n\n« Le troisième et dernier devoir du souverain ou de la république est celui d’élever et d’entretenir ces ouvrages et ces établissements publics dont une grande société retire d’immense avantages, mais qui sont néanmoins de nature à ne pouvoir être entrepris ou entretenus par un ou par quelques particuliers, attendu que pour ceux-ci, le profit ne saurait jamais leur en rembourser la dépense. Ce devoir exige aussi, pour le remplir, des dépenses dont l’étendue varie selon les divers degrés de la société. Après les travaux et les établissements publics nécessaires pour la défense de la société et pour l’administration de la justice, deux objets dont nous avons parlé, les autres travaux et établissements de ce genre sont principalement ceux pour faciliter le commerce de la société, et ceux destinés à étendre l’instruction parmi le peuple ».\nA Smith « Recherches sur la nature et les causes de la richesse des nations », 1776, livre V, chapitre I.\n\n\n\nRemédier aux défaillances de marché\n\nLes Externalités\nDéfinition: Situation dans laquelle la consommation ou la production d’un agent influe positivement ou négativement sur l’utilité d’un autre agent, sans que cette intéraction ne transite par le marché, c’est à dire par le mécanisme des prix.\nL’origine des externalités réside dans l’imperfection des droits de propriété.\nDans le cas d’une externalité négative, le coût marginal privé est inférier au coût marginal social .\n\n\nLes Biens Publics\n\n\n\n\n\n\n\n\n\nExcluabilité\nNon Excluabilité\n\n\n\n\nRivalité\nBiens Privatifs (ex: aliments, vêtements …)\nBiens Communs (ex: Ressources marines…)\n\n\nNon Rivalité\nBiens de Club (ex: autoroute)\nBiens Collectifs (ex: Radio, défense nationale …)\n\n\n\nUn des problèmes des biens collectifs est que le libre jeu du marché peut conduire à une situation non-optimale car les individus sont tentés de se comporter en Free Rider.\n\nBien collectif et dilemme du prisonnier\n\n\n\npayer\nne pas payer\n\n\npayer\n(10, 10)\n(2,15)\n\n\nne pas payer\n(15,2)\n(5,5)\n\n\n\n\n\n\nVeiller au fonctionnement concurrentiel des marchés\n\nLes lois anti-trust:\npolitique de concurrence: contrôle des concentrations d’entreprises, abus de position dominante, ententes anti-concurrentielles .\n\n\nRégulation des monopoles\nLorsque le monopole est justifié, l’Etat doit en surveiller le fonctionnement:\n\nTaxation du monopole naturel\nObligation de tarification au coût moyen\nPrix plafond"
  },
  {
    "objectID": "eco_co/chapitre_1.html#justifications-dune-intervention-prononcée-de-letat-lanalyse-keynésienne",
    "href": "eco_co/chapitre_1.html#justifications-dune-intervention-prononcée-de-letat-lanalyse-keynésienne",
    "title": "chapitre 1: Introduction aux théories économiques de l’Etat",
    "section": "Justifications d’une intervention prononcée de l’Etat: l’analyse keynésienne",
    "text": "Justifications d’une intervention prononcée de l’Etat: l’analyse keynésienne\n\nLe modèle IS-LM\nIl s’agit d’un modèle d’inspiration keynésienne qui met en lumière le rôle des politiques budgétaires et monétaires.\nLe modèle IS-LM décrit les équilibres sur deux marchés: le marché des biens et services et le marché de la monnaie, et comment ensemble ils déterminent l’équilibre général dans une économie.\nL’équilibre général est atteint lorsque le marché des biens et services ainsi que le marché de la monnaie sont à l’équilibre pour un niveau particulier de taux d’intéret (i) et de revenu (Y).\n\nLe marché de la monnaie\nLa demande de monnaie:\nPlusieurs facteurs déterminent la quantité de monnaie que je souhaite détenir :\n\nRevenu : Plus mon revenu est élevé, plus mes dépenses augmentent, ce qui accroît ma nécessité de disposer de liquidités ou d’argent sur mon compte courant.\nPrix : Si les biens et services deviennent plus chers, j’ai besoin d’une quantité d’argent plus importante pour les acheter.\nTaux d’intérêt : Si le taux d’intérêt est élevé, j’ai tendance à préférer mettre davantage d’argent de côté en le plaçant dans des investissements, car cela peut me rapporter des intérêts. Cela réduit donc la quantité de monnaie que je souhaite détenir immédiatement.\nArbitrage entre titres et monnaie : Le taux d’intérêt influence ma décision quant à la répartition de mes actifs entre les titres financiers (investissements) et la monnaie. Si les taux d’intérêt augmentent, j’ai davantage d’incitation à investir dans des titres qui génèrent des intérêts, ce qui diminue ma demande de monnaie.\n\nEn résumé, mon niveau de revenu, les prix des biens, le taux d’intérêt et la possibilité de réaliser un arbitrage entre les investissements et la détention de monnaie sont des déterminants importants de la quantité de monnaie que je souhaite détenir.\nSoit formellement :\n\\(Md=PY*L(i)\\)\nGraphiquement, la fonction de demande de monnaie est décroissante, la fonction d’offre est une droite verticale. On considère que l’offre de monnaie est exogène, fixée par la banque centrale.\n\n\nLe marché des biens\nEn économie fermée, la demande totale de biens est la somme de la consommation des ménages, de l’investissement des ménages et des entreprises, et des dépenses publiques. Soit:\n\\(Z = C+I+G\\)\nLes déterminants de la consommation:\nLe ménage doit arbitrer entre la consommation du bien agrégé aujourd’hui et la consommation du bien dans le futur. Il choisit entre la consommation et l’épargne.\nLa fonction de consommation peut s’écrire : \\(C = C (Y_D, i)\\)\n\\(Y_{D}\\) est le revenu disponible des ménages, c’est-à-dire le revenu qui leur reste après qu’ils aient payé les impôts et perçu les transferts publics.\nLes déterminants de l’Investissement :\nLorsque la demande augmente, alors les entreprises investissent pour répondre à cette demande. Lorsque le taux d’intérêt augmente, le coût pour investir augmente (coût du crédit et/ou coût d’opportunité).\n\\(I = I (Y, i)\\)\nLes dépenses publiques:\nLes dépenses gouvernementales, G, sont la troisième composante de la demande globale. Avec les impôts, T, elles représentent les variables de la politique budgétaire (les choix d’impôts et de dépenses du gouvernement). Elles sont considérées comme exogènes (elles ne dépendent pas du modèle.)\n\n\n\n\n\n\nNote\n\n\n\nA ce cours est associée une application de simulation de politiques économiques:\nhttps://pascalinev.shinyapps.io/eco_generale/\nA vous de jouer …"
  },
  {
    "objectID": "eco_co/dossiers.html",
    "href": "eco_co/dossiers.html",
    "title": "dossiers",
    "section": "",
    "text": "Sujet 1 : Comment gérer une inflation galopante dans un pays fictif ?\nSujet 2 : Stratégies de relance économique face à une récession prolongée : politique budgétaire vs politique monétaire.\nSujet 3 : Quelle politique monétaire adopter face à une crise bancaire dans un pays fictif ?\nSujet 4 : Impact des taux d’intérêt sur l’investissement et l’emploi : simulations pour un pays en stagnation économique.\n\n\n\n\n\nSujet 5 : Gestion d’une crise économique mondiale : quelles mesures pour limiter les impacts sur un pays fictif ?\nSujet 6 : Réponse à une crise des subprimes dans une économie fictive : politiques keynésiennes ou classiques ?\nSujet 7 : Gestion d’une crise de la dette souveraine dans un État fictif : réformes nécessaires et mécanismes de solidarité.\nSujet 8 : Lutte contre une bulle spéculative immobilière : stratégies de régulation économique.\n\n\n\n\n\nSujet 9 : Réformer le marché du travail pour réduire le chômage structurel : une étude de cas fictive.\nSujet 10 : Quelles réformes structurelles pour stimuler la croissance économique à long terme dans un pays fictif ?\nSujet 11 : Impact d’une réforme fiscale sur l’économie et les inégalités sociales dans un pays fictif.\nSujet 12 : Réformes de la sécurité sociale et des retraites : équilibre budgétaire ou justice sociale ?\n\n\n\n\n\nSujet 13 : Stratégies pour réduire le chômage des jeunes dans une économie fictive en crise.\nSujet 14 : Flexibiliser le marché du travail pour réduire le chômage : une simulation basée sur une approche néoclassique.\nSujet 15 : Sous-emploi et chômage de longue durée : quelles politiques actives pour un pays fictif ?\n\n\n\n\n\nSujet 16 : Comment concilier croissance économique et transition écologique dans une économie fictive ?\nSujet 17 : Politiques publiques pour réduire les émissions de carbone tout en maintenant la compétitivité économique.\nSujet 18 : Transition énergétique et réforme des subventions aux énergies fossiles dans un pays fictif.\n\n\n\n\n\nSujet 19 : Impact d’un choc externe (hausse des prix du pétrole) sur un pays fictif : réponses économiques et budgétaires.\nSujet 20 : Comment protéger une économie fictive des effets négatifs de la mondialisation ?\nSujet 21 : Gestion d’un déficit commercial chronique dans un pays fictif : politiques pour stimuler les exportations.\n\n\n\n\n\nSujet 22 : Réduire le déficit budgétaire sans freiner la croissance : un défi pour une économie fictive.\nSujet 23 : Investir dans les infrastructures publiques pour relancer une économie fictive en récession.\nSujet 24 : Quelles priorités budgétaires pour un pays fictif confronté à une explosion de sa dette publique ?\n\n\n\n\n\nSujet 25 : Stabiliser le secteur bancaire après une crise systémique : stratégies pour un État fictif.\nSujet 26 : Encadrer les cryptomonnaies et intégrer une monnaie numérique nationale : enjeux et opportunités.\nSujet 27 : Quelles régulations pour éviter une nouvelle crise financière dans un système économique fictif ?\n\n\n\n\n\nSujet 28 : Lutter contre les inégalités économiques dans un pays fictif : politiques redistributives ou croissance inclusive ?\nSujet 29 : Mise en place d’un revenu universel : quels impacts économiques dans un pays fictif ?\nSujet 30 : Taxation des grandes fortunes pour financer l’investissement public : un équilibre difficile à atteindre."
  },
  {
    "objectID": "eco_co/dossiers.html#gestion-économique-et-politique-monétaire",
    "href": "eco_co/dossiers.html#gestion-économique-et-politique-monétaire",
    "title": "dossiers",
    "section": "",
    "text": "Sujet 1 : Comment gérer une inflation galopante dans un pays fictif ?\nSujet 2 : Stratégies de relance économique face à une récession prolongée : politique budgétaire vs politique monétaire.\nSujet 3 : Quelle politique monétaire adopter face à une crise bancaire dans un pays fictif ?\nSujet 4 : Impact des taux d’intérêt sur l’investissement et l’emploi : simulations pour un pays en stagnation économique."
  },
  {
    "objectID": "eco_co/dossiers.html#réponses-aux-crises-économiques",
    "href": "eco_co/dossiers.html#réponses-aux-crises-économiques",
    "title": "dossiers",
    "section": "",
    "text": "Sujet 5 : Gestion d’une crise économique mondiale : quelles mesures pour limiter les impacts sur un pays fictif ?\nSujet 6 : Réponse à une crise des subprimes dans une économie fictive : politiques keynésiennes ou classiques ?\nSujet 7 : Gestion d’une crise de la dette souveraine dans un État fictif : réformes nécessaires et mécanismes de solidarité.\nSujet 8 : Lutte contre une bulle spéculative immobilière : stratégies de régulation économique."
  },
  {
    "objectID": "eco_co/dossiers.html#réformes-structurelles-et-politiques-publiques",
    "href": "eco_co/dossiers.html#réformes-structurelles-et-politiques-publiques",
    "title": "dossiers",
    "section": "",
    "text": "Sujet 9 : Réformer le marché du travail pour réduire le chômage structurel : une étude de cas fictive.\nSujet 10 : Quelles réformes structurelles pour stimuler la croissance économique à long terme dans un pays fictif ?\nSujet 11 : Impact d’une réforme fiscale sur l’économie et les inégalités sociales dans un pays fictif.\nSujet 12 : Réformes de la sécurité sociale et des retraites : équilibre budgétaire ou justice sociale ?"
  },
  {
    "objectID": "eco_co/dossiers.html#chômage-et-marché-du-travail",
    "href": "eco_co/dossiers.html#chômage-et-marché-du-travail",
    "title": "dossiers",
    "section": "",
    "text": "Sujet 13 : Stratégies pour réduire le chômage des jeunes dans une économie fictive en crise.\nSujet 14 : Flexibiliser le marché du travail pour réduire le chômage : une simulation basée sur une approche néoclassique.\nSujet 15 : Sous-emploi et chômage de longue durée : quelles politiques actives pour un pays fictif ?"
  },
  {
    "objectID": "eco_co/dossiers.html#croissance-économique-et-transition-écologique",
    "href": "eco_co/dossiers.html#croissance-économique-et-transition-écologique",
    "title": "dossiers",
    "section": "",
    "text": "Sujet 16 : Comment concilier croissance économique et transition écologique dans une économie fictive ?\nSujet 17 : Politiques publiques pour réduire les émissions de carbone tout en maintenant la compétitivité économique.\nSujet 18 : Transition énergétique et réforme des subventions aux énergies fossiles dans un pays fictif."
  },
  {
    "objectID": "eco_co/dossiers.html#relations-économiques-internationales",
    "href": "eco_co/dossiers.html#relations-économiques-internationales",
    "title": "dossiers",
    "section": "",
    "text": "Sujet 19 : Impact d’un choc externe (hausse des prix du pétrole) sur un pays fictif : réponses économiques et budgétaires.\nSujet 20 : Comment protéger une économie fictive des effets négatifs de la mondialisation ?\nSujet 21 : Gestion d’un déficit commercial chronique dans un pays fictif : politiques pour stimuler les exportations."
  },
  {
    "objectID": "eco_co/dossiers.html#politiques-budgétaires-et-dépenses-publiques",
    "href": "eco_co/dossiers.html#politiques-budgétaires-et-dépenses-publiques",
    "title": "dossiers",
    "section": "",
    "text": "Sujet 22 : Réduire le déficit budgétaire sans freiner la croissance : un défi pour une économie fictive.\nSujet 23 : Investir dans les infrastructures publiques pour relancer une économie fictive en récession.\nSujet 24 : Quelles priorités budgétaires pour un pays fictif confronté à une explosion de sa dette publique ?"
  },
  {
    "objectID": "eco_co/dossiers.html#systèmes-financiers-et-régulation",
    "href": "eco_co/dossiers.html#systèmes-financiers-et-régulation",
    "title": "dossiers",
    "section": "",
    "text": "Sujet 25 : Stabiliser le secteur bancaire après une crise systémique : stratégies pour un État fictif.\nSujet 26 : Encadrer les cryptomonnaies et intégrer une monnaie numérique nationale : enjeux et opportunités.\nSujet 27 : Quelles régulations pour éviter une nouvelle crise financière dans un système économique fictif ?"
  },
  {
    "objectID": "eco_co/dossiers.html#inégalités-sociales-et-redistribution",
    "href": "eco_co/dossiers.html#inégalités-sociales-et-redistribution",
    "title": "dossiers",
    "section": "",
    "text": "Sujet 28 : Lutter contre les inégalités économiques dans un pays fictif : politiques redistributives ou croissance inclusive ?\nSujet 29 : Mise en place d’un revenu universel : quels impacts économiques dans un pays fictif ?\nSujet 30 : Taxation des grandes fortunes pour financer l’investissement public : un équilibre difficile à atteindre."
  },
  {
    "objectID": "eco_co/intro.html",
    "href": "eco_co/intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Introduction\nThis is a book created from markdown and executable code.\nSee (knuth84?) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "eco_co/plot.html",
    "href": "eco_co/plot.html",
    "title": "CC",
    "section": "",
    "text": "library(readxl)\n\nlibrary(ggplot2)\nlibrary(plotly)\n\nWarning: le package 'plotly' a été compilé avec la version R 4.4.2\n\n\n\nAttachement du package : 'plotly'\n\n\nL'objet suivant est masqué depuis 'package:ggplot2':\n\n    last_plot\n\n\nL'objet suivant est masqué depuis 'package:stats':\n\n    filter\n\n\nL'objet suivant est masqué depuis 'package:graphics':\n\n    layout\n\nphillips &lt;- read_excel(\"phillips.xls\")\n\nphillips$inflation&lt;-phillips$inflation\nphillips$chomage&lt;-phillips$chomage\n\nggplot(phillips, aes(x =chomage, y = inflation)) +\n  geom_point(color = \"blue\", size = 1) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"black\")+\n  labs(title = \"\",\n       y= \"Inflation (%)\",\n       x = \"Chômage (%)\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(plotly)\ndecile &lt;- read_excel(\"inegalites_revenus.xls\")\n\nNew names:\n• `` -&gt; `...3`\n• `` -&gt; `...8`\n• `` -&gt; `...9`\n• `` -&gt; `...10`\n\ndecile$D1_D9&lt;-decile$`Rapport inter-decile`\ndecile$year&lt;-decile$year\ndecile$year &lt;- as.numeric(decile$year)\n\nWarning: NAs introduits lors de la conversion automatique\n\ndecile$year_gini&lt;- as.numeric(decile$year_gini)\ndecile$Gini &lt;-decile$Gini\nggplot(decile, aes(x =year, y = D1_D9)) +\n  geom_point(color = \"blue\", size = 1) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"black\")+\n  labs(title = \"\",\n       y= \"Rapport Inter-Décile (D9/D1)\",\n       x = \"Année\") +\n  scale_x_continuous(breaks = seq(1995, 2021, by = 10))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 10 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 10 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n  theme_minimal()\n\nList of 136\n $ line                            :List of 6\n  ..$ colour       : chr \"black\"\n  ..$ linewidth    : num 0.5\n  ..$ linetype     : num 1\n  ..$ lineend      : chr \"butt\"\n  ..$ arrow        : logi FALSE\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_line\" \"element\"\n $ rect                            :List of 5\n  ..$ fill         : chr \"white\"\n  ..$ colour       : chr \"black\"\n  ..$ linewidth    : num 0.5\n  ..$ linetype     : num 1\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_rect\" \"element\"\n $ text                            :List of 11\n  ..$ family       : chr \"\"\n  ..$ face         : chr \"plain\"\n  ..$ colour       : chr \"black\"\n  ..$ size         : num 11\n  ..$ hjust        : num 0.5\n  ..$ vjust        : num 0.5\n  ..$ angle        : num 0\n  ..$ lineheight   : num 0.9\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : logi FALSE\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ title                           : NULL\n $ aspect.ratio                    : NULL\n $ axis.title                      : NULL\n $ axis.title.x                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 2.75points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x.top                :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 0\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 2.75points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x.bottom             : NULL\n $ axis.title.y                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : num 90\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.75points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.y.left               : NULL\n $ axis.title.y.right              :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : num -90\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 2.75points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text                       :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : chr \"grey30\"\n  ..$ size         : 'rel' num 0.8\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 2.2points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x.top                 :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 0\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 2.2points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x.bottom              : NULL\n $ axis.text.y                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 1\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.2points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.y.left                : NULL\n $ axis.text.y.right               :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 2.2points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.theta                 : NULL\n $ axis.text.r                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0.5\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.2points 0points 2.2points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.ticks                      : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ axis.ticks.x                    : NULL\n $ axis.ticks.x.top                : NULL\n $ axis.ticks.x.bottom             : NULL\n $ axis.ticks.y                    : NULL\n $ axis.ticks.y.left               : NULL\n $ axis.ticks.y.right              : NULL\n $ axis.ticks.theta                : NULL\n $ axis.ticks.r                    : NULL\n $ axis.minor.ticks.x.top          : NULL\n $ axis.minor.ticks.x.bottom       : NULL\n $ axis.minor.ticks.y.left         : NULL\n $ axis.minor.ticks.y.right        : NULL\n $ axis.minor.ticks.theta          : NULL\n $ axis.minor.ticks.r              : NULL\n $ axis.ticks.length               : 'simpleUnit' num 2.75points\n  ..- attr(*, \"unit\")= int 8\n $ axis.ticks.length.x             : NULL\n $ axis.ticks.length.x.top         : NULL\n $ axis.ticks.length.x.bottom      : NULL\n $ axis.ticks.length.y             : NULL\n $ axis.ticks.length.y.left        : NULL\n $ axis.ticks.length.y.right       : NULL\n $ axis.ticks.length.theta         : NULL\n $ axis.ticks.length.r             : NULL\n $ axis.minor.ticks.length         : 'rel' num 0.75\n $ axis.minor.ticks.length.x       : NULL\n $ axis.minor.ticks.length.x.top   : NULL\n $ axis.minor.ticks.length.x.bottom: NULL\n $ axis.minor.ticks.length.y       : NULL\n $ axis.minor.ticks.length.y.left  : NULL\n $ axis.minor.ticks.length.y.right : NULL\n $ axis.minor.ticks.length.theta   : NULL\n $ axis.minor.ticks.length.r       : NULL\n $ axis.line                       : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ axis.line.x                     : NULL\n $ axis.line.x.top                 : NULL\n $ axis.line.x.bottom              : NULL\n $ axis.line.y                     : NULL\n $ axis.line.y.left                : NULL\n $ axis.line.y.right               : NULL\n $ axis.line.theta                 : NULL\n $ axis.line.r                     : NULL\n $ legend.background               : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.margin                   : 'margin' num [1:4] 5.5points 5.5points 5.5points 5.5points\n  ..- attr(*, \"unit\")= int 8\n $ legend.spacing                  : 'simpleUnit' num 11points\n  ..- attr(*, \"unit\")= int 8\n $ legend.spacing.x                : NULL\n $ legend.spacing.y                : NULL\n $ legend.key                      : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.key.size                 : 'simpleUnit' num 1.2lines\n  ..- attr(*, \"unit\")= int 3\n $ legend.key.height               : NULL\n $ legend.key.width                : NULL\n $ legend.key.spacing              : 'simpleUnit' num 5.5points\n  ..- attr(*, \"unit\")= int 8\n $ legend.key.spacing.x            : NULL\n $ legend.key.spacing.y            : NULL\n $ legend.frame                    : NULL\n $ legend.ticks                    : NULL\n $ legend.ticks.length             : 'rel' num 0.2\n $ legend.axis.line                : NULL\n $ legend.text                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : 'rel' num 0.8\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.text.position            : NULL\n $ legend.title                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.title.position           : NULL\n $ legend.position                 : chr \"right\"\n $ legend.position.inside          : NULL\n $ legend.direction                : NULL\n $ legend.byrow                    : NULL\n $ legend.justification            : chr \"center\"\n $ legend.justification.top        : NULL\n $ legend.justification.bottom     : NULL\n $ legend.justification.left       : NULL\n $ legend.justification.right      : NULL\n $ legend.justification.inside     : NULL\n $ legend.location                 : NULL\n $ legend.box                      : NULL\n $ legend.box.just                 : NULL\n $ legend.box.margin               : 'margin' num [1:4] 0cm 0cm 0cm 0cm\n  ..- attr(*, \"unit\")= int 1\n $ legend.box.background           : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.box.spacing              : 'simpleUnit' num 11points\n  ..- attr(*, \"unit\")= int 8\n  [list output truncated]\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi TRUE\n - attr(*, \"validate\")= logi TRUE\n\n  ggplot(decile, aes(x =year_gini, y = Gini)) +\n  geom_point(color = \"blue\", size = 1) +\n  labs(title = \"\",\n       y= \"Gini\",\n       x = \"Année\") +\n    scale_x_continuous(breaks = seq(1975, 2021, by = 10))\n\nWarning: Removed 5 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n  theme_minimal()\n\nList of 136\n $ line                            :List of 6\n  ..$ colour       : chr \"black\"\n  ..$ linewidth    : num 0.5\n  ..$ linetype     : num 1\n  ..$ lineend      : chr \"butt\"\n  ..$ arrow        : logi FALSE\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_line\" \"element\"\n $ rect                            :List of 5\n  ..$ fill         : chr \"white\"\n  ..$ colour       : chr \"black\"\n  ..$ linewidth    : num 0.5\n  ..$ linetype     : num 1\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_rect\" \"element\"\n $ text                            :List of 11\n  ..$ family       : chr \"\"\n  ..$ face         : chr \"plain\"\n  ..$ colour       : chr \"black\"\n  ..$ size         : num 11\n  ..$ hjust        : num 0.5\n  ..$ vjust        : num 0.5\n  ..$ angle        : num 0\n  ..$ lineheight   : num 0.9\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : logi FALSE\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ title                           : NULL\n $ aspect.ratio                    : NULL\n $ axis.title                      : NULL\n $ axis.title.x                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 2.75points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x.top                :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 0\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 2.75points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x.bottom             : NULL\n $ axis.title.y                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : num 90\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.75points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.y.left               : NULL\n $ axis.title.y.right              :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : num -90\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 2.75points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text                       :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : chr \"grey30\"\n  ..$ size         : 'rel' num 0.8\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 2.2points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x.top                 :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 0\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 2.2points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x.bottom              : NULL\n $ axis.text.y                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 1\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.2points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.y.left                : NULL\n $ axis.text.y.right               :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 2.2points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.theta                 : NULL\n $ axis.text.r                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0.5\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.2points 0points 2.2points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.ticks                      : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ axis.ticks.x                    : NULL\n $ axis.ticks.x.top                : NULL\n $ axis.ticks.x.bottom             : NULL\n $ axis.ticks.y                    : NULL\n $ axis.ticks.y.left               : NULL\n $ axis.ticks.y.right              : NULL\n $ axis.ticks.theta                : NULL\n $ axis.ticks.r                    : NULL\n $ axis.minor.ticks.x.top          : NULL\n $ axis.minor.ticks.x.bottom       : NULL\n $ axis.minor.ticks.y.left         : NULL\n $ axis.minor.ticks.y.right        : NULL\n $ axis.minor.ticks.theta          : NULL\n $ axis.minor.ticks.r              : NULL\n $ axis.ticks.length               : 'simpleUnit' num 2.75points\n  ..- attr(*, \"unit\")= int 8\n $ axis.ticks.length.x             : NULL\n $ axis.ticks.length.x.top         : NULL\n $ axis.ticks.length.x.bottom      : NULL\n $ axis.ticks.length.y             : NULL\n $ axis.ticks.length.y.left        : NULL\n $ axis.ticks.length.y.right       : NULL\n $ axis.ticks.length.theta         : NULL\n $ axis.ticks.length.r             : NULL\n $ axis.minor.ticks.length         : 'rel' num 0.75\n $ axis.minor.ticks.length.x       : NULL\n $ axis.minor.ticks.length.x.top   : NULL\n $ axis.minor.ticks.length.x.bottom: NULL\n $ axis.minor.ticks.length.y       : NULL\n $ axis.minor.ticks.length.y.left  : NULL\n $ axis.minor.ticks.length.y.right : NULL\n $ axis.minor.ticks.length.theta   : NULL\n $ axis.minor.ticks.length.r       : NULL\n $ axis.line                       : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ axis.line.x                     : NULL\n $ axis.line.x.top                 : NULL\n $ axis.line.x.bottom              : NULL\n $ axis.line.y                     : NULL\n $ axis.line.y.left                : NULL\n $ axis.line.y.right               : NULL\n $ axis.line.theta                 : NULL\n $ axis.line.r                     : NULL\n $ legend.background               : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.margin                   : 'margin' num [1:4] 5.5points 5.5points 5.5points 5.5points\n  ..- attr(*, \"unit\")= int 8\n $ legend.spacing                  : 'simpleUnit' num 11points\n  ..- attr(*, \"unit\")= int 8\n $ legend.spacing.x                : NULL\n $ legend.spacing.y                : NULL\n $ legend.key                      : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.key.size                 : 'simpleUnit' num 1.2lines\n  ..- attr(*, \"unit\")= int 3\n $ legend.key.height               : NULL\n $ legend.key.width                : NULL\n $ legend.key.spacing              : 'simpleUnit' num 5.5points\n  ..- attr(*, \"unit\")= int 8\n $ legend.key.spacing.x            : NULL\n $ legend.key.spacing.y            : NULL\n $ legend.frame                    : NULL\n $ legend.ticks                    : NULL\n $ legend.ticks.length             : 'rel' num 0.2\n $ legend.axis.line                : NULL\n $ legend.text                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : 'rel' num 0.8\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.text.position            : NULL\n $ legend.title                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.title.position           : NULL\n $ legend.position                 : chr \"right\"\n $ legend.position.inside          : NULL\n $ legend.direction                : NULL\n $ legend.byrow                    : NULL\n $ legend.justification            : chr \"center\"\n $ legend.justification.top        : NULL\n $ legend.justification.bottom     : NULL\n $ legend.justification.left       : NULL\n $ legend.justification.right      : NULL\n $ legend.justification.inside     : NULL\n $ legend.location                 : NULL\n $ legend.box                      : NULL\n $ legend.box.just                 : NULL\n $ legend.box.margin               : 'margin' num [1:4] 0cm 0cm 0cm 0cm\n  ..- attr(*, \"unit\")= int 1\n $ legend.box.background           : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.box.spacing              : 'simpleUnit' num 11points\n  ..- attr(*, \"unit\")= int 8\n  [list output truncated]\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi TRUE\n - attr(*, \"validate\")= logi TRUE"
  },
  {
    "objectID": "eco_co/references.html",
    "href": "eco_co/references.html",
    "title": "References",
    "section": "",
    "text": "References"
  },
  {
    "objectID": "eco_co/TD_1.html",
    "href": "eco_co/TD_1.html",
    "title": "TD 1",
    "section": "",
    "text": "Considérons le modèle IS-LM suivant:\n\\(C=200+0,25Y^D\\)\n\\(I=150+0,25Y-1000i\\)\n\\(G=250\\)\n\\(T=200\\)\n\\((M/P)^d=2Y-8000i\\)\n\\((M/P)^s=1600\\)\n\n\n\nEtablir l’équation de la courbe \\(IS\\)\nEtablir l’équation de la courbe \\(LM\\)\nTrouver le produit d’équilibre \\(Y^*\\) , le taux d’intérêt d’équilibre \\(i^*\\), la consommation \\(C\\) et l’investissement \\(I\\)\nDonner une représentation graphique des courbes \\(IS\\) et \\(LM\\) .\nSupposons maintenant que l’offre de monnaie augmente et passeà \\((M/P)^s=1840\\) . Trouvez les valeurs de \\(Y^*\\), \\(i^*\\), \\(C\\) et \\(I\\). Expliquez les effets de la politique d’expansion monétaire.\nReprenons la valeur initiale de l’offre de monnaie, soit \\((M/P)^s=1600\\), et supposons maintenant que les dépenses augmentent jusqu’à \\(G=400\\). Calculez les nouvelles valeurs d’équilibre. Résumer les effets d’une politique d’expansion budgétaire sur \\(Y\\), \\(i\\), \\(C\\) et \\(I\\)."
  },
  {
    "objectID": "eco_co/TD_1.html#modèle-is-lm",
    "href": "eco_co/TD_1.html#modèle-is-lm",
    "title": "TD 1",
    "section": "",
    "text": "Considérons le modèle IS-LM suivant:\n\\(C=200+0,25Y^D\\)\n\\(I=150+0,25Y-1000i\\)\n\\(G=250\\)\n\\(T=200\\)\n\\((M/P)^d=2Y-8000i\\)\n\\((M/P)^s=1600\\)\n\n\n\nEtablir l’équation de la courbe \\(IS\\)\nEtablir l’équation de la courbe \\(LM\\)\nTrouver le produit d’équilibre \\(Y^*\\) , le taux d’intérêt d’équilibre \\(i^*\\), la consommation \\(C\\) et l’investissement \\(I\\)\nDonner une représentation graphique des courbes \\(IS\\) et \\(LM\\) .\nSupposons maintenant que l’offre de monnaie augmente et passeà \\((M/P)^s=1840\\) . Trouvez les valeurs de \\(Y^*\\), \\(i^*\\), \\(C\\) et \\(I\\). Expliquez les effets de la politique d’expansion monétaire.\nReprenons la valeur initiale de l’offre de monnaie, soit \\((M/P)^s=1600\\), et supposons maintenant que les dépenses augmentent jusqu’à \\(G=400\\). Calculez les nouvelles valeurs d’équilibre. Résumer les effets d’une politique d’expansion budgétaire sur \\(Y\\), \\(i\\), \\(C\\) et \\(I\\)."
  },
  {
    "objectID": "eco_co/TD_1.html#travail-sur-les-données.",
    "href": "eco_co/TD_1.html#travail-sur-les-données.",
    "title": "TD 1",
    "section": "Travail sur les données.",
    "text": "Travail sur les données.\nRecherchez les données des différentes variables du carré magique de Kaldor."
  },
  {
    "objectID": "eco_co/test.html",
    "href": "eco_co/test.html",
    "title": "Quiz interactif : L’État et l’économie",
    "section": "",
    "text": "library(shiny)\n\nWarning: le package 'shiny' a été compilé avec la version R 4.4.2\n\n# Interface utilisateur\nui &lt;- fluidPage(\n  # Application title\n  titlePanel(\"Quiz interactif : L'État et l'économie\"),\n  \n  # Mise en forme globale\n  tags$style(HTML(\"\n    body {\n      background-color: #f4f7f6;\n      font-family: 'Arial', sans-serif;\n    }\n    h4 {\n      color: #4e73df;\n      font-weight: bold;\n    }\n    .question-container {\n      background-color: #ffffff;\n      border-radius: 8px;\n      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n      padding: 20px;\n      margin: 15px 0;\n    }\n    .submit-btn {\n      background-color: #28a745;\n      color: white;\n      border: none;\n      padding: 10px 20px;\n      font-size: 16px;\n      border-radius: 5px;\n      cursor: pointer;\n    }\n    .submit-btn:hover {\n      background-color: #218838;\n    }\n    .result-box {\n      background-color: #ffffff;\n      border-radius: 8px;\n      padding: 15px;\n      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n      margin: 20px 0;\n    }\n    .feedback {\n      font-size: 14px;\n      color: #333333;\n    }\n    .note {\n      font-size: 18px;\n      font-weight: bold;\n      color: #28a745;\n    }\n  \")),\n  \n  # Layout des questions\n  fluidRow(\n    column(12, div(class = \"question-container\", \n      h4(\"1. Quel courant économique considère que le marché s’autorégule ?\"),\n      radioButtons(\"q1\", \"Sélectionnez une option\", \n                   choices = c(\"Keynésien\", \"Classique\", \"Marxiste\", \"Monétariste\"),\n                   selected = NULL)\n    )),\n    \n    column(12, div(class = \"question-container\", \n      h4(\"2. Que signifie un multiplicateur de 1,5 après une dépense publique de 10 milliards ?\"),\n      radioButtons(\"q2\", \"Sélectionnez une option\", \n                   choices = c(\"L'effet sur le PIB est nul\", \"Le PIB augmente de 5 milliards\", \"Le PIB augmente de 15 milliards\", \"Le déficit diminue de 15 milliards\"),\n                   selected = NULL)\n    )),\n    \n    column(12, div(class = \"question-container\", \n      h4(\"3. Comment calcule-t-on le taux de déficit public ?\"),\n      radioButtons(\"q3\", \"Sélectionnez une option\", \n                   choices = c(\"Déficit / Dette\", \"Déficit / PIB\", \"Dette / PIB\", \"PIB / Déficit\"),\n                   selected = NULL)\n    )),\n    \n    column(12, div(class = \"question-container\", \n      h4(\"4. Quel est le seuil maximal du déficit public selon Maastricht ?\"),\n      radioButtons(\"q4\", \"Sélectionnez une option\", \n                   choices = c(\"2%\", \"3%\", \"60%\", \"5%\"),\n                   selected = NULL)\n    )),\n    \n    column(12, div(class = \"question-container\", \n      h4(\"5. Quelle est la bonne formule du taux de chômage ?\"),\n      radioButtons(\"q5\", \"Sélectionnez une option\", \n                   choices = c(\"Nombre de chômeurs / Population totale\", \"Nombre de chômeurs / Population active\", \"Population inactive / Population totale\", \"Nombre de chômeurs / Population en âge de travailler\"),\n                   selected = NULL)\n    )),\n    \n    column(12, div(class = \"question-container\", \n      h4(\"6. Quel est l'effet du multiplicateur keynésien sur la demande ?\"),\n      radioButtons(\"q6\", \"Sélectionnez une option\", \n                   choices = c(\"Il augmente la demande globale\", \"Il diminue la demande globale\", \"Il n'a aucun effet sur la demande globale\"),\n                   selected = NULL)\n    )),\n    \n    column(12, div(class = \"question-container\", \n      h4(\"7. Quelle est la principale caractéristique de la réforme Hartz en Allemagne ?\"),\n      radioButtons(\"q7\", \"Sélectionnez une option\", \n                   choices = c(\"Réduction du temps de travail\", \"Réduction des indemnités de chômage\", \"Création d'un marché du travail flexible\", \"Augmentation des salaires\"),\n                   selected = NULL)\n    )),\n    \n    column(12, div(class = \"question-container\", \n      h4(\"8. Quelle est la réforme majeure du chômage en France après 2017 ?\"),\n      radioButtons(\"q8\", \"Sélectionnez une option\", \n                   choices = c(\"Introduction du RSA\", \"Création de Pôle Emploi\", \"Réforme de l'assurance chômage\", \"Réduction des cotisations sociales\"),\n                   selected = NULL)\n    )),\n    \n    column(12, div(class = \"question-container\", \n      h4(\"9. Taux de croissance du PIB : Si le PIB de la France en 2020 est de 2 200 milliards et en 2021 de 2 300 milliards, quel est le taux de croissance ?\"),\n      numericInput(\"q9\", \"Répondez en pourcentage\", value = NULL)\n    )),\n    \n    column(12, div(class = \"question-container\", \n      h4(\"10. Taux de chômage : Si la population active de la France en 2021 est de 30 millions et le nombre de chômeurs est de 2 millions, quel est le taux de chômage ?\"),\n      numericInput(\"q10\", \"Répondez en pourcentage\", value = NULL)\n    )),\n    \n    column(12, div(class = \"question-container\", \n      h4(\"11. Quel est le niveau actuel de la dette publique en France ?\"),\n      radioButtons(\"q11\", \"Sélectionnez une option\", \n                   choices = c(\"1 200 milliards\", \"2 400 milliards\", \"3 000 milliards\", \"3 500 milliards\"),\n                   selected = NULL)\n    )),\n    \n    column(12, div(class = \"question-container\", \n      h4(\"12. Quel est le taux de chômage actuel en France ?\"),\n      radioButtons(\"q12\", \"Sélectionnez une option\", \n                   choices = c(\"7%\", \"8%\", \"10%\", \"12%\"),\n                   selected = NULL)\n    )),\n    \n    # Bouton pour soumettre les réponses\n    column(12, actionButton(\"submit\", \"Soumettre les réponses\", class = \"submit-btn\"))\n  ),\n  \n  # Résultats\n  fluidRow(\n    column(12, div(class = \"result-box\", \n      textOutput(\"feedback\"),\n      textOutput(\"note\")\n    ))\n  )\n)\n\n# Serveur\nserver &lt;- function(input, output, session) {\n  \n  # Calcul de la note sur 20 et du feedback\n  observeEvent(input$submit, {\n    \n    # Nombre de réponses correctes\n    correct_answers &lt;- 0\n    feedback_text &lt;- \"\"\n    \n    # Vérification des réponses\n    if(input$q1 == \"Classique\") {\n      correct_answers &lt;- correct_answers + 1\n      feedback_text &lt;- paste(feedback_text, \"1. Correct! Les classiques pensent que le marché s'auto-régule.\\n\", sep = \"\")\n    } else {\n      feedback_text &lt;- paste(feedback_text, \"1. Incorrect. La bonne réponse est 'Classique'.\\n\", sep = \"\")\n    }\n    \n    if(input$q2 == \"Le PIB augmente de 15 milliards\") {\n      correct_answers &lt;- correct_answers + 1\n      feedback_text &lt;- paste(feedback_text, \"2. Correct! Le multiplicateur de 1,5 implique que l'effet sur le PIB est de 15 milliards.\\n\", sep = \"\")\n    } else {\n      feedback_text &lt;- paste(feedback_text, \"2. Incorrect. La bonne réponse est 'Le PIB augmente de 15 milliards'.\\n\", sep = \"\")\n    }\n    \n    if(input$q3 == \"Déficit / PIB\") {\n      correct_answers &lt;- correct_answers + 1\n      feedback_text &lt;- paste(feedback_text, \"3. Correct! Le taux de déficit public se calcule en divisant le déficit par le PIB.\\n\", sep = \"\")\n    } else {\n      feedback_text &lt;- paste(feedback_text, \"3. Incorrect. La bonne réponse est 'Déficit / PIB'.\\n\", sep = \"\")\n    }\n    \n    if(input$q4 == \"3%\") {\n      correct_answers &lt;- correct_answers + 1\n      feedback_text &lt;- paste(feedback_text, \"4. Correct! Le traité de Maastricht fixe à 3% du PIB la limite acceptable pour le déficit public.\\n\", sep = \"\")\n    } else {\n      feedback_text &lt;- paste(feedback_text, \"4. Incorrect. La bonne réponse est '3%'.\\n\", sep = \"\")\n    }\n    \n    if(input$q5 == \"Nombre de chômeurs / Population active\") {\n      correct_answers &lt;- correct_answers + 1\n      feedback_text &lt;- paste(feedback_text, \"5. Correct! Le taux de chômage se calcule en divisant le nombre de chômeurs par la population active.\\n\", sep = \"\")\n    } else {\n      feedback_text &lt;- paste(feedback_text, \"5. Incorrect. La bonne réponse est 'Nombre de chômeurs / Population active'.\\n\", sep = \"\")\n    }\n    \n    if(input$q6 == \"Il augmente la demande globale\") {\n      correct_answers &lt;- correct_answers + 1\n      feedback_text &lt;- paste(feedback_text, \"6. Correct! Le multiplicateur keynésien augmente la demande globale.\\n\", sep = \"\")\n    } else {\n      feedback_text &lt;- paste(feedback_text, \"6. Incorrect. La bonne réponse est 'Il augmente la demande globale'.\\n\", sep = \"\")\n    }\n    \n    if(input$q7 == \"Création d'un marché du travail flexible\") {\n      correct_answers &lt;- correct_answers + 1\n      feedback_text &lt;- paste(feedback_text, \"7. Correct! La réforme Hartz visait à rendre le marché du travail plus flexible.\\n\", sep = \"\")\n    } else {\n      feedback_text &lt;- paste(feedback_text, \"7. Incorrect. La bonne réponse est 'Création d'un marché du travail flexible'.\\n\", sep = \"\")\n    }\n    \n    if(input$q8 == \"Réforme de l'assurance chômage\") {\n      correct_answers &lt;- correct_answers + 1\n      feedback_text &lt;- paste(feedback_text, \"8. Correct! La réforme majeure du chômage en France après 2017 est l'assurance chômage.\\n\", sep = \"\")\n    } else {\n      feedback_text &lt;- paste(feedback_text, \"8. Incorrect. La bonne réponse est 'Réforme de l'assurance chômage'.\\n\", sep = \"\")\n    }\n    \n    # Exercices calculatoires\n    # Taux de croissance\n    if(!is.null(input$q9)) {\n      growth_rate &lt;- ((2300 - 2200) / 2200) * 100\n      if(abs(input$q9 - growth_rate) &lt; 1) {\n        correct_answers &lt;- correct_answers + 1\n        feedback_text &lt;- paste(feedback_text, \"9. Correct! Le taux de croissance est de \", round(growth_rate, 2), \"%.\\n\", sep = \"\")\n      } else {\n        feedback_text &lt;- paste(feedback_text, \"9. Incorrect. Le taux de croissance est de \", round(growth_rate, 2), \"%.\\n\", sep = \"\")\n      }\n    }\n    \n    # Taux de chômage\n    if(!is.null(input$q10)) {\n      unemployment_rate &lt;- (2 / 30) * 100\n      if(abs(input$q10 - unemployment_rate) &lt; 1) {\n        correct_answers &lt;- correct_answers + 1\n        feedback_text &lt;- paste(feedback_text, \"10. Correct! Le taux de chômage est de \", round(unemployment_rate, 2), \"%.\\n\", sep = \"\")\n      } else {\n        feedback_text &lt;- paste(feedback_text, \"10. Incorrect. Le taux de chômage est de \", round(unemployment_rate, 2), \"%.\\n\", sep = \"\")\n      }\n    }\n    \n    # Résultats d'actualité\n    if(input$q11 == \"2 400 milliards\") {\n      correct_answers &lt;- correct_answers + 1\n      feedback_text &lt;- paste(feedback_text, \"11. Correct! La dette publique de la France est d'environ 2 400 milliards.\\n\", sep = \"\")\n    } else {\n      feedback_text &lt;- paste(feedback_text, \"11. Incorrect. La bonne réponse est '2 400 milliards'.\\n\", sep = \"\")\n    }\n    \n    if(input$q12 == \"7%\") {\n      correct_answers &lt;- correct_answers + 1\n      feedback_text &lt;- paste(feedback_text, \"12. Correct! Le taux de chômage en France est d'environ 7%. \\n\", sep = \"\")\n    } else {\n      feedback_text &lt;- paste(feedback_text, \"12. Incorrect. La bonne réponse est '7%'.\\n\", sep = \"\")\n    }\n    \n    # Calcul de la note\n    note &lt;- (correct_answers / 20) * 20\n    \n    # Afficher le feedback global et la note finale\n    output$feedback &lt;- renderText({\n      feedback_text\n    })\n    \n    output$note &lt;- renderText({\n      paste(\"Votre note finale est : \", round(note, 2), \"/20.\", sep = \"\")\n    })\n  })\n}\n\n# Lancer l'application\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "normes_identite/conclusion.html",
    "href": "normes_identite/conclusion.html",
    "title": "Conclusion",
    "section": "",
    "text": "Nous avons pu voir l’intérêt que portent les économistes aux questions d’identité.\nChamp récent de la discipline, l’économie de l’identité propose plusieurs directions de recherche: d’un point de vue théorique, elle cherche à introduire dans des modèles économiques traditionnels la variable identité, afin d’enrichir notre compréhension des phénomènes économiques.\nParce qu’elle influence les choix, l’identité doit être prise en compte dans une discipline où ces choix individuels sont un objet d’études.\nL’identité influence les préférences individuelles et notamment la coopération (à la participation de biens publics par exemple), elle agit sur les performances individuelles et influence les actions des individus.\nCes derniers font face à des arbitrages entre leurs caractéristiques intrinsèques et les normes sociales (ou prescriptions) qui prévalent dans leur environnement.\nIl y a donc là de nombreux questionnements sur les dynamiques de formation de l’identité et ses répercussions socio-économiques .\nD’un point de vue empirique, l’une des premières difficultés auxquelles fait face le chercheur est la mesure de cette variable aux contours flous et aux multiples dimensions.\nL’emploi de variables catégorielles (comme la variable binaire homme/femme) contient des limites lorsque l’objectif est de mesurer la distance aux normes d’identité.\nLes données continues provenant de déclarations et positionnements individuels sur une échelle graduée (par exemple, dans quelle mesure je me perçois comme très masculin/féminin), répond en partie aux problèmes évoqués précédemment, cependant, les données sont rares et ces déclarations subjectives peuvent souffrir de biais de désirabilité.\nUne autre possibilité est de construire des indices continus basés sur des dimensions de l’identité identifiée a priori ou non.\nEn outre, une mesure continue semble plus appropriée mais pose des questions quand à sa construction, à l’existence de données adéquates, à la reproductibilité des indicateurs pour des comparaisons dans le temps et l’espace.\nNous avons proposé une mesure continue du genre basée sur les pratiques culturelles des français. Notre indice converge vers les indices d’échelle dans la mesure où il indique que la plupart des individus ne sont pas totalement conformes, que peu d’individus s’écartent des normes (entendues dans notre étude comme un comportement moyen), que ces divergences ou convergences sont reliées aux caractéristiques socio-économiques des individus.\nEnfin, nous avons proposé d’étudier empiriquement la relation entre identité et satisfaction. Celle-ci n’apparaît pas comme évidente et est sensible au niveau de revenus des individus ainsi qu’à leur sexe biologique.\nLes premiers résultats observés indiquent une relation négative entre distance aux normes de genre et satisfaction individuelle pour les femmes, cette relation n’est pas aussi prononcée chez les hommes.\nLa satisfaction (en termes de disposition de son temps libre) semble décroître avec l’augmentation de la distance aux normes chez les individus aux revenus les plus faibles.\nCes résultats sont préliminaires et méritent d’être approfondis.\nLa notion d’identité est donc complexe, mouvante, relative. Sa mesure pose des difficultés de comparaisons dans le temps et l’espace. L’enquête sur les pratiques culturelles des français a été répétée dans le temps et cela pourrait être une piste de recherche d’étudier l’évolution de cet indice d’identité de genre à travers le temps, pour une vision dynamique de cette mesure."
  },
  {
    "objectID": "normes_identite/index.html",
    "href": "normes_identite/index.html",
    "title": "Introduction",
    "section": "",
    "text": "Introduction\nAvec ses cheveux courts, lors de son élection, miss France 2024 a défrayé la chronique.\nAu vue des réactions épidermiques, la dunkerquoise Eve Gilles semblait transgresser là une norme de genre instituée.\nAvec cet exemple, qui peut sembler trivial, nous souhaitons aborder la question fondamentale de l’identité, et plus spécifiquement, de l’identité de genre.\nL’identité peut être définie comme le sentiment que l’on a de soi (“A person’ sense of self”) , c’est une notion multiple, protéiforme, difficile à appréhender et plus encore: à mesurer.\nMais pourquoi les économistes devraient-ils s’intéresser à cette variable identité?\nComment et pourquoi intègrent-ils cette notion dans leurs modèles?\nSi la nécessité de proposer des modèles intégrant cette variable nous semble pertinente, vient alors la question de la difficile mesure de ce concept fondamental.\nEnfin, quelles répercussions socio-économiques peut-on observer à travers la mise en lien de cette mesure de l’identité et des variables économiques?"
  },
  {
    "objectID": "normes_identite/mesure.html",
    "href": "normes_identite/mesure.html",
    "title": "Mesurer l’identité: une impossibilité?",
    "section": "",
    "text": "Si nous acceptons l’idée qu’il est pertinent pour les économistes d’intégrer dans leurs modèles la variable Identité , alors la question de sa mesure est fondamentale.\nL’identité est multiple, dans ce document, nous nous focalisons sur l’identité de genre des individus.\nUne des raisons pour lesquelles nous portons notre attention sur cette dimension est que l’identité de genre nous semble être l’une des plus importantes dans la construction individuelle.\nAvant même la naissance d’un enfant, la question fondamentale de son sexe biologique est omniprésente: c’est une fille ou un garçon?\nL’organisation de la société est centrée autour de cette distinction genrée, les inégalités persistantes entre hommes et femmes justifient également notre intérêt pour cette dimension de l’identité.\nLes questionnements sur la non-binarité influencent également notre réflexion, peut-on proposer une mesure de l’identité de genre qui tienne compte d’un continuum entre deux pôles (masculin et féminin), permettant ainsi de mesurer une distance à ces extremum?\nNous verrons donc comment est abordée la mesure de l’identité de genre dans la littérature existante, puis proposerons une mesure continue de cette identité, avec une approche empirique basée sur les pratiques culturelles (genrées) des français."
  },
  {
    "objectID": "normes_identite/mesure.html#lapproche-dichotomique-hommesfemmes",
    "href": "normes_identite/mesure.html#lapproche-dichotomique-hommesfemmes",
    "title": "Mesurer l’identité: une impossibilité?",
    "section": "L’approche dichotomique: Hommes/Femmes",
    "text": "L’approche dichotomique: Hommes/Femmes\nLorsque la dimension du genre veut être prise en compte dans les études économiques, bien souvent on se réfère au sexe biologique des individus: homme/femme.\nCette approche binaire est notamment liée à la commodité des données.\nEn effet, dans les bases de données, cette information figure presque toujours, elle permet d’étudier et de mettre en évidence des différences, souvent des inégalités, entre les deux sexes biologiques.\nCependant, certains individus ne se retrouvent pas dans cette dichotomie, alors la possibilité d’intégrer une troisième option dans les questionnaires est parfois envisagée.\nMais là encore, une approche catégorielle peine à saisir ce qui nous semble fondamental dans une étude empirique de l’identité: la distance aux Prescriptions ou normes."
  },
  {
    "objectID": "normes_identite/mesure.html#les-approches-de-mesure-continue",
    "href": "normes_identite/mesure.html#les-approches-de-mesure-continue",
    "title": "Mesurer l’identité: une impossibilité?",
    "section": "Les approches de mesure continue",
    "text": "Les approches de mesure continue\nAfin de prendre en compte la diversité des positions individuelles le long d’un axe Masculin/Féminin, des études ont proposé une approche continue de mesure de l’identité de genre. Nous les distinguons de la façon suivante: certaines études reposent sur un positionnement individuel de l’individu sur une échelle de mesure.\nD’autres études proposent la construction d’indices composites pour mesurer la dimension continue du genre.\n\nDes échelles de mesure\nLes travaux proposant des mesures continues du genre basées sur des échelles de gradation reposent sur les déclarations individuelles des enquêtés, qui se positionnent le long d’un ou plusieurs axes.\nPar exemple, Magliozzi, Saperstein, and Westbrook (2016) propose aux enquêtés de se situer sur plusieurs échelles (comment je me perçois: de très masculin à pas du tout masculin, et de très féminin à pas du tout féminin), mais aussi comment les autres me perçoivent.\n\n\n\n\n\nEn France, l’étude Virage a permis de poser des questions similaires, les résultats de cette étude ont fait l’objet d’un papier rédigé par Trachman (2022).\nIl est intéressant de voir qu’en effet, l’identité de genre est faite de nuances, la plupart des individus interrogés ne s’identifient pas aux pôles extrêmes de leur sexe biologique (23,3% des femmes interrogées s’identifient comme très féminines; 30,6% des hommes interrogés s’identifient comme très masculins).\nPeu d’individus dévient des normes (1% des femmes interrogées se disent très masculines, 2,3% des hommes interrogés se disent très féminins.)\nCes résultats mettent en lumière la complexité de l’identité de genre, et peut-être confirment la nécessité d’aller au delà du binaire dans les mesures proposées.\nCette approche par gradation a l’avantage de demander directement aux individus le sentiment qu’ils ont d’eux même, et donc de tendre vers la définition même de l’identité.\nL’inconvénient repose sur l’accessibilité des données, elle suppose d’intégrer ces questions dans les questionnaires et ces informations sont donc peu disponibles mais liées à des enquêtes bien spécifiques.\nUn autre biais est peut-être également que cette approche repose sur la subjectivité des personnes interrogées, elles peuvent être influencées par le biais de la désirabilité sociale (je réponds avec la peur d’être jugé si je réponds mal, je réponds ce qui me semble être conforme aux normes).\nIl peut donc être intéressant de combiner ces approches avec d’autres mesures plus indirectes mais, peut-être, moins subjectives.\n\n\nLes indices composites\nDans la famille des mesures continues de l’identité de genre, certains chercheurs ont construit leurs propres indices de mesures continues.\n\nAvec Définitions a priori des dimensions genrées\nParmi les indices composites, un outil très utilisé est le Bem Sex Role Inventory (Bem (1974)).\nIl s’agit de créer un indice composite à partir de réponses des enquêtés qui se classent par rapport à différents items.\nCes items sont identifiés au préalable comme plutôt masculin (ex:agressif), plutôt féminin (ex: lunatique) ou neutres (ex: naïf).\nCette approche permet de capturer une distance aux normes, cependant elle suppose de définir au préalable ce qui relève de l’ordre du masculin et du féminin.\nUne approche originale récente d’économistes a combiné les 2 approches vues jusqu’ici (échelle de gradation et indice composite), il s’agit des travaux de Brenøe et al. (2022).\n\n\nSans Définitions a priori\nUne autre approche consiste à construire un indice composite à partir de variables identifiées statistiquement comme genrées, c’est à dire déduire de l’analyse statistique les pratiques ou comportements plus ou moins masculins ou féminins (dans la mesure où ils sont statistiquement significativement différenciés selon les sexes biologiques) et de construire un indice en fonction des poids que représentent chaque variable sur un axe masculin/féminin.\nCette approche est notamment utilisée en médecine (Pelletier, Ditto, and Pilote (2015).)\nNous avons suivi cette dernière approche pour notre étude, en nous référant notamment aux travaux de Cipriani et al. (n.d.) qui offrent un guide pratique pour la réalisation d’un tel indicateur."
  },
  {
    "objectID": "normes_identite/socio.html",
    "href": "normes_identite/socio.html",
    "title": "Implications socio-économiques",
    "section": "",
    "text": "Dans cette partie, nous allons analyser les implications socio-économiques de l’identité de genre.\nPour commencer, nous allons regarder les différents profils des individus selon leur indice d’identité.\nPuis nous analyserons les liens entre distance à la norme et l’utilité des individus (leur degré de satisfaction.)"
  },
  {
    "objectID": "normes_identite/socio.html#variables-socio-économiques-et-identité-de-genre",
    "href": "normes_identite/socio.html#variables-socio-économiques-et-identité-de-genre",
    "title": "Implications socio-économiques",
    "section": "Variables socio-économiques et identité de genre",
    "text": "Variables socio-économiques et identité de genre\n\n\ncode R\nlibrary(foreign)\nlibrary(questionr) \nlibrary(ggplot2) \nlibrary(tidyverse) \nlibrary(ggmosaic)\nlibrary(GGally) \nlibrary(dataMaid)\nlibrary(dplyr) \nlibrary(GDAtools)\nlibrary(FactoMineR)\nlibrary(gtsummary) \nlibrary(factoextra)\nlibrary(gtsummary) \nlibrary(kableExtra)\nlibrary(RColorBrewer) \nlibrary(FactoMineR) \nlibrary(xtable) \nlibrary(explor)\n\n\n\n\ncode R\nload(\"my_data_frame.RData\")\n\nstat_des &lt;- my_data_frame |&gt;\n    tbl_summary(\n        include = c(\"AGE\", \"Income\", \"Couple\", \"CLASSIF\"),\n        by = \"identity_scale\") |&gt;\n    add_overall(last = TRUE) |&gt;\n    add_p(\n        test.args = list(\n            all_continuous() ~ list(simulate.p.value = TRUE),\n            all_categorical() ~ list(simulate.p.value = TRUE)\n        )\n    )\n\nstat_des\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nVery Feminine N = 2271\n1 N = 1,9091\n2 N = 4,8081\n3 N = 1,5611\n4 N = 5991\n5 N = 1061\nVery Masculine N = 241\nOverall N = 9,2341\np-value2\n\n\n\n\nAGE\n44 (32, 57)\n50 (35, 65)\n56 (40, 69)\n55 (37, 68)\n51 (35, 65)\n43 (30, 59)\n37 (30, 57)\n54 (38, 67)\n\n\n\n\nIncome\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\n    High\n88 (44%)\n710 (42%)\n1,428 (34%)\n452 (33%)\n175 (33%)\n34 (36%)\n9 (43%)\n2,896 (36%)\n\n\n\n\n    Low\n48 (24%)\n382 (23%)\n1,118 (27%)\n369 (27%)\n108 (20%)\n17 (18%)\n4 (19%)\n2,046 (25%)\n\n\n\n\n    Medium\n65 (32%)\n592 (35%)\n1,631 (39%)\n536 (39%)\n245 (46%)\n43 (46%)\n8 (38%)\n3,120 (39%)\n\n\n\n\n    Unknown\n26\n225\n631\n204\n71\n12\n3\n1,172\n\n\n\n\nCouple\n109 (48%)\n1,013 (53%)\n2,594 (54%)\n842 (54%)\n373 (62%)\n68 (64%)\n12 (50%)\n5,011 (54%)\n&lt;0.001\n\n\n    Unknown\n2\n4\n5\n1\n1\n0\n0\n13\n\n\n\n\nCLASSIF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\n    1\n0 (0%)\n18 (3.2%)\n95 (6.8%)\n48 (10%)\n16 (6.6%)\n7 (17%)\n2 (18%)\n186 (6.6%)\n\n\n\n\n    2\n6 (8.0%)\n61 (11%)\n278 (20%)\n132 (28%)\n98 (40%)\n19 (46%)\n3 (27%)\n597 (21%)\n\n\n\n\n    3\n3 (4.0%)\n36 (6.4%)\n148 (11%)\n56 (12%)\n33 (14%)\n6 (15%)\n0 (0%)\n282 (10%)\n\n\n\n\n    4\n8 (11%)\n59 (11%)\n140 (10.0%)\n47 (9.8%)\n22 (9.1%)\n4 (9.8%)\n3 (27%)\n283 (10%)\n\n\n\n\n    5\n26 (35%)\n149 (27%)\n229 (16%)\n80 (17%)\n26 (11%)\n3 (7.3%)\n1 (9.1%)\n514 (18%)\n\n\n\n\n    6\n29 (39%)\n224 (40%)\n484 (34%)\n110 (23%)\n47 (19%)\n2 (4.9%)\n1 (9.1%)\n897 (32%)\n\n\n\n\n    7\n1 (1.3%)\n6 (1.1%)\n11 (0.8%)\n1 (0.2%)\n1 (0.4%)\n0 (0%)\n0 (0%)\n20 (0.7%)\n\n\n\n\n    8\n2 (2.7%)\n6 (1.1%)\n16 (1.1%)\n4 (0.8%)\n0 (0%)\n0 (0%)\n1 (9.1%)\n29 (1.0%)\n\n\n\n\n    9\n0 (0%)\n0 (0%)\n2 (0.1%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n2 (&lt;0.1%)\n\n\n\n\n    Unknown\n152\n1,350\n3,405\n1,083\n356\n65\n13\n6,424\n\n\n\n\n\n1 Median (Q1, Q3); n (%)\n\n\n2 Pearson’s Chi-squared test with simulated p-value (based on 2000 replicates); Fisher’s Exact Test for Count Data with simulated p-value (based on 2000 replicates)\n\n\n\n\n\n\n\n\nLecture: Parmi les individus catégorisés comme très féminins selon notre indice, 44% ont des revenus élevés. Les variables étudiées sont significativement différentes selon les degrés d’identité.\nIl semble, d’après cette première table descriptive, que l’âge, les niveaux de revenus ainsi que les professions (CLASSIF) jouent un rôle dans l’identité de genre. Tout comme dans l’étude de Trachman (2022), les facteurs socio-économiques influencent les variations du genre.\n\n\n\n\n\n\n\nCLASSIF\n\n\n\n\n\n1\nManoeuvre ou ouvrier spécialisé\n\n\n2\nOuvrier qualifié ou hautement qualifié/ technicien(ne) d’atelier\n\n\n3\nTechnicien(ne)\n\n\n4\nAgent de maîtrise, maîtrise administrative ou commerciale, VRP (non cadre)\n\n\n5\nIngénieur, Cadre\n\n\n6\nEmployé(e) de bureau, Employé(e) de commerce, Personnel de services\n\n\n7\nDirecteur général, Adjoint direct\n\n\n8\nNSP\n\n\n9\nREF\n\n\n\nOn peut regarder si les effets sont différents selon le sexe biologique:\n\n\ncode R\nstat_des &lt;- my_data_frame |&gt;\n    tbl_strata(\n        strata = Sex,  # Stratification par sexe\n        .tbl_fun = ~ .x |&gt;\n            tbl_summary(\n                include = c(\"AGE\", \"Income\", \"Couple\", \"CLASSIF\"),\n                by = \"identity_scale\"  # Stratification supplémentaire par 'identity_scale'\n            ) |&gt;\n            add_overall(last = TRUE) |&gt;\n            add_p(\n                test.args = list(\n                    all_continuous() ~ list(simulate.p.value = TRUE),\n                    all_categorical() ~ list(simulate.p.value = TRUE)\n                )\n            )\n    )\n\nstat_des\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nMen\n\n\nWomen\n\n\n\nVery Feminine N = 91\n1 N = 4031\n2 N = 2,1391\n3 N = 9851\n4 N = 5091\n5 N = 961\nVery Masculine N = 211\nOverall N = 4,1621\np-value2\nVery Feminine N = 2181\n1 N = 1,5061\n2 N = 2,6691\n3 N = 5761\n4 N = 901\n5 N = 101\nVery Masculine N = 31\nOverall N = 5,0721\np-value2\n\n\n\n\nAGE\n50 (36, 59)\n54 (39, 66)\n54 (40, 68)\n52 (35, 66)\n52 (36, 65)\n44 (30, 59)\n37 (28, 56)\n53 (38, 66)\n\n\n44 (32, 56)\n49 (34, 64)\n58 (40, 70)\n57 (39, 71)\n44 (33, 60)\n37 (33, 68)\n34 (33, 57)\n54 (37, 68)\n\n\n\n\nIncome\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.039\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\n    High\n4 (44%)\n160 (44%)\n762 (40%)\n316 (36%)\n153 (34%)\n28 (33%)\n9 (50%)\n1,432 (39%)\n\n\n84 (44%)\n550 (42%)\n666 (29%)\n136 (28%)\n22 (26%)\n6 (60%)\n0 (0%)\n1,464 (33%)\n\n\n\n\n    Low\n4 (44%)\n66 (18%)\n393 (21%)\n192 (22%)\n88 (20%)\n16 (19%)\n3 (17%)\n762 (21%)\n\n\n44 (23%)\n316 (24%)\n725 (32%)\n177 (36%)\n20 (24%)\n1 (10%)\n1 (33%)\n1,284 (29%)\n\n\n\n\n    Medium\n1 (11%)\n134 (37%)\n733 (39%)\n359 (41%)\n203 (46%)\n40 (48%)\n6 (33%)\n1,476 (40%)\n\n\n64 (33%)\n458 (35%)\n898 (39%)\n177 (36%)\n42 (50%)\n3 (30%)\n2 (67%)\n1,644 (37%)\n\n\n\n\n    Unknown\n0\n43\n251\n118\n65\n12\n3\n492\n\n\n26\n182\n380\n86\n6\n0\n0\n680\n\n\n\n\nCouple\n4 (44%)\n224 (56%)\n1,271 (59%)\n561 (57%)\n314 (62%)\n59 (61%)\n11 (52%)\n2,444 (59%)\n0.3\n105 (49%)\n789 (52%)\n1,323 (50%)\n281 (49%)\n59 (66%)\n9 (90%)\n1 (33%)\n2,567 (51%)\n0.005\n\n\n    Unknown\n0\n1\n2\n0\n1\n0\n0\n4\n\n\n2\n3\n3\n1\n0\n0\n0\n9\n\n\n\n\nCLASSIF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\n    1\n0 (0%)\n6 (5.2%)\n57 (7.9%)\n37 (11%)\n16 (7.7%)\n6 (16%)\n1 (11%)\n123 (8.7%)\n\n\n0 (0%)\n12 (2.7%)\n38 (5.5%)\n11 (7.7%)\n0 (0%)\n1 (25%)\n1 (50%)\n63 (4.5%)\n\n\n\n\n    2\n0 (0%)\n24 (21%)\n214 (30%)\n109 (33%)\n87 (42%)\n17 (46%)\n3 (33%)\n454 (32%)\n\n\n6 (8.1%)\n37 (8.3%)\n64 (9.3%)\n23 (16%)\n11 (31%)\n2 (50%)\n0 (0%)\n143 (10%)\n\n\n\n\n    3\n0 (0%)\n15 (13%)\n98 (14%)\n42 (13%)\n30 (14%)\n5 (14%)\n0 (0%)\n190 (13%)\n\n\n3 (4.1%)\n21 (4.7%)\n50 (7.3%)\n14 (9.8%)\n3 (8.3%)\n1 (25%)\n0 (0%)\n92 (6.6%)\n\n\n\n\n    4\n0 (0%)\n15 (13%)\n76 (11%)\n37 (11%)\n22 (11%)\n4 (11%)\n3 (33%)\n157 (11%)\n\n\n8 (11%)\n44 (9.9%)\n64 (9.3%)\n10 (7.0%)\n0 (0%)\n0 (0%)\n0 (0%)\n126 (9.1%)\n\n\n\n\n    5\n1 (100%)\n31 (27%)\n151 (21%)\n66 (20%)\n25 (12%)\n3 (8.1%)\n1 (11%)\n278 (20%)\n\n\n25 (34%)\n118 (27%)\n78 (11%)\n14 (9.8%)\n1 (2.8%)\n0 (0%)\n0 (0%)\n236 (17%)\n\n\n\n\n    6\n0 (0%)\n21 (18%)\n104 (15%)\n41 (12%)\n26 (13%)\n2 (5.4%)\n0 (0%)\n194 (14%)\n\n\n29 (39%)\n203 (46%)\n380 (55%)\n69 (48%)\n21 (58%)\n0 (0%)\n1 (50%)\n703 (51%)\n\n\n\n\n    7\n0 (0%)\n2 (1.7%)\n9 (1.3%)\n1 (0.3%)\n1 (0.5%)\n0 (0%)\n0 (0%)\n13 (0.9%)\n\n\n1 (1.4%)\n4 (0.9%)\n2 (0.3%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n7 (0.5%)\n\n\n\n\n    8\n0 (0%)\n1 (0.9%)\n7 (1.0%)\n2 (0.6%)\n0 (0%)\n0 (0%)\n1 (11%)\n11 (0.8%)\n\n\n2 (2.7%)\n5 (1.1%)\n9 (1.3%)\n2 (1.4%)\n0 (0%)\n0 (0%)\n0 (0%)\n18 (1.3%)\n\n\n\n\n    9\n0 (0%)\n0 (0%)\n1 (0.1%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (&lt;0.1%)\n\n\n0 (0%)\n0 (0%)\n1 (0.1%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (&lt;0.1%)\n\n\n\n\n    Unknown\n8\n288\n1,422\n650\n302\n59\n12\n2,741\n\n\n144\n1,062\n1,983\n433\n54\n6\n1\n3,683\n\n\n\n\n\n1 Median (Q1, Q3); n (%)\n\n\n2 Fisher’s Exact Test for Count Data with simulated p-value (based on 2000 replicates)\n\n\n\n\n\n\n\n\nLecture: Parmi les hommes classés comme très féminins, 27% appartiennent à la catégorie socio-professionnelle 5 (ingénieur, cadre)"
  },
  {
    "objectID": "normes_identite/socio.html#distance-à-la-norme",
    "href": "normes_identite/socio.html#distance-à-la-norme",
    "title": "Implications socio-économiques",
    "section": "Distance à la norme",
    "text": "Distance à la norme\nNous l’évoquions au début de ce document, ce qui nous intéresse en proposant une mesure continue des variations du genre c’est de pouvoir analyser les distances prises avec les normes de son groupe de référence.\nPour cela, nous allons construire la variable “Distance à la norme”\n\n\ncode R\nmean_gender &lt;- tapply(my_data_frame$identity, my_data_frame$Sex, mean)\nsd_gender &lt;- tapply(my_data_frame$identity, my_data_frame$Sex, sd)\n\nmy_data_frame$distance&lt;- (my_data_frame$identity - mean_gender[my_data_frame$Sex]) / sd_gender[my_data_frame$Sex]\n\nggplot(my_data_frame, aes(x = distance, color = Sex, fill = Sex)) +\n  geom_density(alpha = 0.4) +\n  labs(title = \"Density of Distance to the Norm, by Sex\", \n       x = \"Distance to the Norm\", y = \"Density\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\ncode R\n#Ou en valeur absolue:\n\nmean_gender &lt;- tapply(my_data_frame$identity, my_data_frame$Sex, mean)\nsd_gender &lt;- tapply(my_data_frame$identity, my_data_frame$Sex, sd)\n\nmy_data_frame$distance_abs&lt;- abs((my_data_frame$identity - mean_gender[my_data_frame$Sex]) / sd_gender[my_data_frame$Sex])\n\nggplot(my_data_frame, aes(x = distance_abs, color = Sex, fill = Sex)) +\n  geom_density(alpha = 0.4) +\n  labs(title = \"Density of Distance to the Norm, by Sex\", \n       x = \"Distance to the Norm\", y = \"Density\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\ncode R\n# Catégorisation par quartiles\nmy_data_frame$categories &lt;- cut(my_data_frame$distance, \n                       breaks = quantile(my_data_frame$distance, probs = c(0, 0.25, 0.75, 1), na.rm = TRUE), \n                       labels = c(\"Feminine Norms\", \"Medium\", \"Masculine Norms\"), \n                       include.lowest = TRUE)"
  },
  {
    "objectID": "eco_co/politiques monetaires.html",
    "href": "eco_co/politiques monetaires.html",
    "title": "TD : Les politiques monétaires",
    "section": "",
    "text": "Introduction\n\nCe TD porte sur les politiques monétaires et leur impact sur l’économie.\nNous étudierons le rôle des banques centrales, l’inflation, les taux d’intérêt et la transmission des politiques monétaires.\n\n\n\nExercice 1 : Effet des taux d’intérêt sur l’investissement\nUn pays connaît un taux d’intérêt de 5 %. Une entreprise envisage d’investir 1 million d’euros dans un projet qui rapporte un rendement annuel de 6 %.\nQuestions :\n\nCet investissement est-il rentable ? Justifiez votre réponse.\nSi la banque centrale abaisse le taux directeur à 3 %, quel sera l’effet attendu sur l’investissement ?\nExpliquez pourquoi une baisse des taux peut stimuler l’économie.\n\n\n\nExercice 2 : Politique monétaire et inflation\nVous avez les données suivantes :\n\n\n\nAnnée\nInflation (%)\nTaux directeur (%)\n\n\n\n\n2020\n1,2 %\n0,5 %\n\n\n2021\n2,8 %\n1,0 %\n\n\n2022\n6,5 %\n3,5 %\n\n\n2023\n4,2 %\n4,5 %\n\n\n\nQuestions :\n\nAnalysez l’évolution du taux directeur en réponse à l’inflation.\nEn 2023, la banque centrale doit-elle encore augmenter les taux ? Justifiez.\nQuels sont les risques d’une hausse trop rapide des taux ?\n\n\n\nExercice 3 : Masse monétaire et croissance\nUne économie a une masse monétaire de 1 000 milliards d’euros et un PIB de 2 500 milliards d’euros.\nQuestions :\n\nCalculez la vitesse de circulation de la monnaie.\nSi la banque centrale augmente la masse monétaire de 5 %, quel pourrait être l’effet sur le PIB (en supposant une relation proportionnelle) ?\nExpliquez pourquoi une expansion monétaire excessive peut conduire à l’inflation.\n\n\n\nExercice 4 : Transmission de la politique monétaire\nUne banque centrale augmente son taux directeur de 2 % à 4 %.\nQuestions :\n\nQuel sera l’impact attendu sur :\n\nLe coût du crédit pour les ménages et entreprises ?\nLe niveau de la consommation et de l’investissement ?\nLa valeur de la monnaie nationale par rapport aux autres devises ?\n\nExpliquez pourquoi une politique monétaire restrictive peut ralentir la croissance.\n\n\n\nExercice 5 : Étude de cas – Politique monétaire de la BCE\nEn réponse à une inflation élevée en 2022, la BCE a progressivement relevé ses taux.\nQuestions :\n\nRecherchez les décisions prises par la BCE entre 2022 et 2023.\nQuels étaient les objectifs de ces hausses de taux ?\nQuels ont été les effets constatés sur l’inflation et la croissance ?"
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html",
    "href": "enseignements/eco_co_chapitre_1.html",
    "title": "Economie Contemporaine",
    "section": "",
    "text": "Plus ou moins d’Etat? Celui-ci doit-il intervenir dans l’économie? Si oui, comment? Quels sont ses objectifs et ses outils? Que nous dit la théorie économique?\nCe chapitre s’appuie sur le Précis d’économie d’Emmanuel Combe (“Précis d’économie  PUF” n.d.)"
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#introduction",
    "href": "enseignements/eco_co_chapitre_1.html#introduction",
    "title": "Economie Contemporaine",
    "section": "",
    "text": "Plus ou moins d’Etat? Celui-ci doit-il intervenir dans l’économie? Si oui, comment? Quels sont ses objectifs et ses outils? Que nous dit la théorie économique?\nCe chapitre s’appuie sur le Précis d’économie d’Emmanuel Combe (“Précis d’économie  PUF” n.d.)"
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#justifications-de-letat-minimal-les-classiques",
    "href": "enseignements/eco_co_chapitre_1.html#justifications-de-letat-minimal-les-classiques",
    "title": "Economie Contemporaine",
    "section": "Justifications de l’Etat minimal : les Classiques",
    "text": "Justifications de l’Etat minimal : les Classiques\nLes Classiques prônent une intervention minimale de l’Etat dans l’économie (Sabéran 2008)"
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#justifications-dune-intervention-prononcée-de-letat-lanalyse-keynésienne",
    "href": "enseignements/eco_co_chapitre_1.html#justifications-dune-intervention-prononcée-de-letat-lanalyse-keynésienne",
    "title": "Economie Contemporaine",
    "section": "Justifications d’une intervention prononcée de l’Etat: l’analyse keynésienne",
    "text": "Justifications d’une intervention prononcée de l’Etat: l’analyse keynésienne"
  },
  {
    "objectID": "actualites.html",
    "href": "actualites.html",
    "title": "Actualités",
    "section": "",
    "text": "&lt;h5 class=\"card-title\"&gt;Titre de l'article&lt;/h5&gt;\n&lt;p class=\"card-text\"&gt;Résumé de l'article...&lt;/p&gt;\n&lt;a href=\"lien_article.html\" class=\"btn btn-primary\"&gt;Lire la suite&lt;/a&gt;"
  },
  {
    "objectID": "actualites.html#dernières-actualités",
    "href": "actualites.html#dernières-actualités",
    "title": "Actualités",
    "section": "",
    "text": "&lt;div class=\"card\" style=\"margin-bottom:1rem;\"&gt;\n  &lt;img src=\"image_article1.jpg\" class=\"card-img-top\" alt=\"Article 1\"&gt;\n  &lt;div class=\"card-body\"&gt;\n    &lt;h5 class=\"card-title\"&gt;Titre de l'Article 1&lt;/h5&gt;\n    &lt;p class=\"card-text\"&gt;Résumé rapide de l'article 1.&lt;/p&gt;\n    &lt;a href=\"article1.html\" class=\"btn btn-primary\"&gt;Lire la suite&lt;/a&gt;\n  &lt;/div&gt;\n&lt;/div&gt;"
  },
  {
    "objectID": "actualites.html#vidéos-récentes",
    "href": "actualites.html#vidéos-récentes",
    "title": "Actualités",
    "section": "Vidéos récentes",
    "text": "Vidéos récentes\n\nVidéo 1\n\n\n\n\nVidéo 2"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Pascaline Vincent",
    "section": "",
    "text": "Economie Contemporaine\n\n\n\n\n\n\n\n\n\nSep 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nEconomie Contemporaine\n\n\n\n\n\n\n\n\n\nSep 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nMon premier article\n\n\n\n\n\n\nMoi\n\n\nSep 29, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/article_1.html",
    "href": "blog/article_1.html",
    "title": "Economie Contemporaine",
    "section": "",
    "text": "Test des actualités"
  },
  {
    "objectID": "blog/article_2.html",
    "href": "blog/article_2.html",
    "title": "Mon premier article",
    "section": "",
    "text": "un deuxième article"
  },
  {
    "objectID": "blog/eco_co_1.html",
    "href": "blog/eco_co_1.html",
    "title": "Economie Contemporaine",
    "section": "",
    "text": "Mots clés\n\n\n\nAllocation des ressources - Choix économique - Economie Positive et Normative - Rareté - Macroéconomie - Microéconomie"
  },
  {
    "objectID": "blog/eco_co_1.html#definitions",
    "href": "blog/eco_co_1.html#definitions",
    "title": "Economie Contemporaine",
    "section": "Definitions:",
    "text": "Definitions:\nRessources: Moyens matériels ou immatériels qui permettent de satisfaire les besoins des agents économiques\nBesoin: sentiment de manque que l’on cherche à satisfaire"
  },
  {
    "objectID": "blog/eco_co_1.html#approche-théorique",
    "href": "blog/eco_co_1.html#approche-théorique",
    "title": "Economie Contemporaine",
    "section": "Approche théorique",
    "text": "Approche théorique\n\nFournir des représentations simplifiées de la réalité pour aider à prévoir et comprendre les phénomènes économiques\nRepose sur des hypothèses\nConfrontation de ces hypothèses et validation empirique"
  },
  {
    "objectID": "blog/eco_co_1.html#approche-empirique",
    "href": "blog/eco_co_1.html#approche-empirique",
    "title": "Economie Contemporaine",
    "section": "Approche empirique",
    "text": "Approche empirique\n\nUtilisation de données réelles pour tester les théories économiques\nValider les modèles\nAnalyser des relations économiques"
  },
  {
    "objectID": "eco_co/eco_co_1.html",
    "href": "eco_co/eco_co_1.html",
    "title": "Economie Contemporaine : 1er Cours",
    "section": "",
    "text": "Mots clés\n\n\n\nAllocation des ressources - Choix économique - Economie Positive et Normative - Rareté - Macroéconomie - Microéconomie"
  },
  {
    "objectID": "eco_co/eco_co_1.html#definitions",
    "href": "eco_co/eco_co_1.html#definitions",
    "title": "Economie Contemporaine : 1er Cours",
    "section": "Definitions:",
    "text": "Definitions:\nRessources: Moyens matériels ou immatériels qui permettent de satisfaire les besoins des agents économiques\nBesoin: sentiment de manque que l’on cherche à satisfaire"
  },
  {
    "objectID": "eco_co/eco_co_1.html#approche-théorique",
    "href": "eco_co/eco_co_1.html#approche-théorique",
    "title": "Economie Contemporaine : 1er Cours",
    "section": "Approche théorique",
    "text": "Approche théorique\n\nFournir des représentations simplifiées de la réalité pour aider à prévoir et comprendre les phénomènes économiques\nRepose sur des hypothèses\nConfrontation de ces hypothèses et validation empirique"
  },
  {
    "objectID": "eco_co/eco_co_1.html#approche-empirique",
    "href": "eco_co/eco_co_1.html#approche-empirique",
    "title": "Economie Contemporaine : 1er Cours",
    "section": "Approche empirique",
    "text": "Approche empirique\n\nUtilisation de données réelles pour tester les théories économiques\nValider les modèles\nAnalyser des relations économiques"
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#citation",
    "href": "enseignements/eco_co_chapitre_1.html#citation",
    "title": "Economie Contemporaine",
    "section": "Citation",
    "text": "Citation\n« Le troisième et dernier devoir du souverain ou de la république est celui d’élever et d’entretenir ces ouvrages et ces établissements publics dont une grande société retire d’immense avantages, mais qui sont néanmoins de nature à ne pouvoir être entrepris ou entretenus par un ou par quelques particuliers, attendu que pour ceux-ci, le profit ne saurait jamais leur en rembourser la dépense. Ce devoir exige aussi, pour le remplir, des dépenses dont l’étendue varie selon les divers degrés de la société. Après les travaux et les établissements publics nécessaires pour la défense de la société et pour l’administration de la justice, deux objets dont nous avons parlé, les autres travaux et établissements de ce genre sont principalement ceux pour faciliter le commerce de la société, et ceux destinés à étendre l’instruction parmi le peuple ».\nA Smith « Recherches sur la nature et les causes de la richesse des nations », 1776, livre V, chapitre I."
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#les-trois-fonctions-de-letat",
    "href": "enseignements/eco_co_chapitre_1.html#les-trois-fonctions-de-letat",
    "title": "Economie Contemporaine",
    "section": "Les trois fonctions de l’Etat:",
    "text": "Les trois fonctions de l’Etat:\n\nAllocation des ressources: l’Etat réalise des dépenses pour entretenir son administration et financer les biens collectifs (défense, infrastructures …)\nRedistribution: Vers l’égalité d’accès des citoyens à certaines ressources\nRégulation: Soutenir l’activité économique"
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#les-objectifs-de-la-politique-économique-de-letat",
    "href": "enseignements/eco_co_chapitre_1.html#les-objectifs-de-la-politique-économique-de-letat",
    "title": "Economie Contemporaine",
    "section": "Les objectifs de la politique économique de l’Etat:",
    "text": "Les objectifs de la politique économique de l’Etat:\n\n\nShow the code\n# Étape 1 : Préparer les données\ndata_france &lt;- data.frame(\n  periode = c(\"2000\", \"2005\", \"2010\", \"2015\", \"2020\"),\n  croissance = c(3.0, 2.5, 1.2, 1.8, -0.5),  # Croissance économique (%)\n  emploi = c(93, 91, 89, 87, 85),           # Taux d'emploi (%)\n  prix = c(1.5, 2.0, 1.8, 1.6, 0.5),        # Inflation (%)\n  commerce = c(0.2, -0.5, -1.0, -1.5, -2.0) # Balance commerciale (% du PIB)\n)\n\n# Étape 2 : Normaliser les données\nnormalize &lt;- function(x) {\n  (x - min(x)) / (max(x) - min(x))\n}\n\ndata_normalized &lt;- data_france\ndata_normalized[, -1] &lt;- as.data.frame(lapply(data_france[, -1], normalize))\n\n# Étape 3 : Préparer les données pour le graphique radar\n# Installer et charger le package fmsb si nécessaire\n\nlibrary(fmsb)\n\n# Ajouter les lignes pour les max et min (requis pour le package fmsb)\nradar_data &lt;- rbind(\n  rep(1, 4),  # Valeurs maximales après normalisation\n  rep(0, 4),  # Valeurs minimales après normalisation\n  data_normalized[, -1]  # Données normalisées\n)\n\n# Nommer les colonnes pour le graphique radar\ncolnames(radar_data) &lt;- c(\"Croissance\", \"Emploi\", \"Prix\", \"Commerce\")\nrownames(radar_data) &lt;- c(\"Max\", \"Min\", data_france$periode)\n\n# Étape 4 : Tracer le carré magique\nradarchart(\n  radar_data,\n  axistype = 1,\n  pcol = rainbow(nrow(data_france)),  # Couleurs pour chaque période\n  pfcol = rainbow(nrow(data_france), alpha = 0.4),  # Couleurs remplies\n  plwd = 2,  # Épaisseur des lignes\n  cglcol = \"grey\", cglty = 1, axislabcol = \"black\", caxislabels = seq(0, 1, 0.2),\n  title = \"Carré magique de Kaldor - France à différentes périodes\"\n)\n\n# Ajouter une légende\nlegend(\n  \"topright\",\n  legend = data_france$periode,\n  col = rainbow(nrow(data_france)),\n  lty = 1, lwd = 2\n)"
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#remédier-aux-défaillances-de-marché",
    "href": "enseignements/eco_co_chapitre_1.html#remédier-aux-défaillances-de-marché",
    "title": "Economie Contemporaine",
    "section": "Remédier aux défaillances de marché",
    "text": "Remédier aux défaillances de marché\n\nLes Externalités\nDéfinition: Situation dans laquelle la consommation ou la production d’un agent influe positivement ou négativement sur l’utilité d’un autre agent, sans que cette intéraction ne transite par le marché, c’est à dire par le mécanisme des prix.\nL’origine des externalités réside dans l’imperfection des droits de propriété.\nDans le cas d’une externalité négative, le coût marginal privé est inférier au coût marginal social ."
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#les-biens-publics",
    "href": "enseignements/eco_co_chapitre_1.html#les-biens-publics",
    "title": "Economie Contemporaine",
    "section": "Les Biens Publics",
    "text": "Les Biens Publics\n\n\n\n\n\n\n\n\n\nExcluabilité\nNon Excluabilité\n\n\n\n\nRivalité\nBiens Privatifs (ex: aliments, vêtements …)\nBiens Communs (ex: Ressources marines…)\n\n\nNon Rivalité\nBiens de Club (ex: autoroute)\nBiens Collectifs (ex: Radio, défense nationale …)"
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#biens-collectifs-et-comportements-de-free-rider",
    "href": "enseignements/eco_co_chapitre_1.html#biens-collectifs-et-comportements-de-free-rider",
    "title": "Economie Contemporaine",
    "section": "Biens collectifs et comportements de Free Rider",
    "text": "Biens collectifs et comportements de Free Rider\nUn des problèmes des biens collectifs est que le libre jeu du marché peut conduire à une situation non-optimale car les individus sont tentés de se comporter en Free Rider.\n\nBien collectif et dilemme du prisonnier\n\n\n\npayer\nne pas payer\n\n\npayer\n(10, 10)\n(2,15)\n\n\nne pas payer\n(15,2)\n(5,5)"
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#veiller-au-fonctionnement-concurrentiel-des-marchés",
    "href": "enseignements/eco_co_chapitre_1.html#veiller-au-fonctionnement-concurrentiel-des-marchés",
    "title": "Economie Contemporaine",
    "section": "Veiller au fonctionnement concurrentiel des marchés",
    "text": "Veiller au fonctionnement concurrentiel des marchés\n\nLes lois anti-trust:\npolitique de concurrence: contrôle des concentrations d’entreprises, abus de position dominante, ententes anti-concurrentielles .\n\n\nRégulation des monopoles\nLorsque le monopole est justifié, l’Etat doit en surveiller le fonctionnement:\n\nTaxation du monopole naturel\nObligation de tarification au coût moyen\nPrix plafond"
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#le-modèle-is-lm",
    "href": "enseignements/eco_co_chapitre_1.html#le-modèle-is-lm",
    "title": "Economie Contemporaine",
    "section": "Le modèle IS-LM",
    "text": "Le modèle IS-LM\nIl s’agit d’un modèle d’inspiration keynésienne qui met en lumière le rôle des politiques budgétaires et monétaires.\nLe modèle IS-LM décrit les équilibres sur deux marchés: le marché des biens et services et le marché de la monnaie, et comment ensemble ils déterminent l’équilibre général dans une économie.\nL’équilibre général est atteint lorsque le marché des biens et services ainsi que le marché de la monnaie sont à l’équilibre pour un niveau particulier de taux d’intéret (i) et de revenu (Y)."
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#le-marché-de-la-monnaie",
    "href": "enseignements/eco_co_chapitre_1.html#le-marché-de-la-monnaie",
    "title": "Economie Contemporaine",
    "section": "Le marché de la monnaie",
    "text": "Le marché de la monnaie"
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#la-demande-de-monnaie",
    "href": "enseignements/eco_co_chapitre_1.html#la-demande-de-monnaie",
    "title": "Economie Contemporaine",
    "section": "La demande de monnaie:",
    "text": "La demande de monnaie:\nPlusieurs facteurs déterminent la quantité de monnaie que je souhaite détenir :\n\nRevenu : Plus mon revenu est élevé, plus mes dépenses augmentent, ce qui accroît ma nécessité de disposer de liquidités ou d’argent sur mon compte courant.\nPrix : Si les biens et services deviennent plus chers, j’ai besoin d’une quantité d’argent plus importante pour les acheter."
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#le-marché-des-biens",
    "href": "enseignements/eco_co_chapitre_1.html#le-marché-des-biens",
    "title": "Economie Contemporaine",
    "section": "Le marché des biens",
    "text": "Le marché des biens\nEn économie fermée, la demande totale de biens est la somme de la consommation des ménages, de l’investissement des ménages et des entreprises, et des dépenses publiques. Soit:\n\\(Z = C+I+G\\)"
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#les-déterminants-de-la-consommation",
    "href": "enseignements/eco_co_chapitre_1.html#les-déterminants-de-la-consommation",
    "title": "Economie Contemporaine",
    "section": "Les déterminants de la consommation:",
    "text": "Les déterminants de la consommation:\nLe ménage doit arbitrer entre la consommation du bien agrégé aujourd’hui et la consommation du bien dans le futur. Il choisit entre la consommation et l’épargne.\nLa fonction de consommation peut s’écrire : \\(C = C (Y_D, i)\\)\n\\(Y_{D}\\) est le revenu disponible des ménages, c’est-à-dire le revenu qui leur reste après qu’ils aient payé les impôts et perçu les transferts publics."
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#les-déterminants-de-linvestissement",
    "href": "enseignements/eco_co_chapitre_1.html#les-déterminants-de-linvestissement",
    "title": "Economie Contemporaine",
    "section": "Les déterminants de l’Investissement :",
    "text": "Les déterminants de l’Investissement :\nLorsque la demande augmente, alors les entreprises investissent pour répondre à cette demande. Lorsque le taux d’intérêt augmente, le coût pour investir augmente (coût du crédit et/ou coût d’opportunité).\n\\(I = I (Y, i)\\)"
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#les-dépenses-publiques",
    "href": "enseignements/eco_co_chapitre_1.html#les-dépenses-publiques",
    "title": "Economie Contemporaine",
    "section": "Les dépenses publiques:",
    "text": "Les dépenses publiques:\nLes dépenses gouvernementales, G, sont la troisième composante de la demande globale. Avec les impôts, T, elles représentent les variables de la politique budgétaire (les choix d’impôts et de dépenses du gouvernement). Elles sont considérées comme exogènes (elles ne dépendent pas du modèle.)"
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#application",
    "href": "enseignements/eco_co_chapitre_1.html#application",
    "title": "Economie Contemporaine",
    "section": "Application",
    "text": "Application\nA ce cours est associée une application de simulation de politiques économiques:\nhttps://pascalinev.shinyapps.io/eco_generale/\nA vous de jouer …"
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#mais-également",
    "href": "enseignements/eco_co_chapitre_1.html#mais-également",
    "title": "Economie Contemporaine",
    "section": "Mais également …",
    "text": "Mais également …\n\nTaux d’intérêt : Si le taux d’intérêt est élevé, j’ai tendance à préférer mettre davantage d’argent de côté en le plaçant dans des investissements, car cela peut me rapporter des intérêts. Cela réduit donc la quantité de monnaie que je souhaite détenir immédiatement.\nArbitrage entre titres et monnaie : Le taux d’intérêt influence ma décision quant à la répartition de mes actifs entre les titres financiers (investissements) et la monnaie. Si les taux d’intérêt augmentent, j’ai davantage d’incitation à investir dans des titres qui génèrent des intérêts, ce qui diminue ma demande de monnaie."
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#résumé",
    "href": "enseignements/eco_co_chapitre_1.html#résumé",
    "title": "Economie Contemporaine",
    "section": "Résumé",
    "text": "Résumé\nEn résumé, mon niveau de revenu, les prix des biens, le taux d’intérêt et la possibilité de réaliser un arbitrage entre les investissements et la détention de monnaie sont des déterminants importants de la quantité de monnaie que je souhaite détenir.\nSoit formellement :\n\\(Md=PY*L(i)\\)\nGraphiquement, la fonction de demande de monnaie est décroissante, la fonction d’offre est une droite verticale. On considère que l’offre de monnaie est exogène, fixée par la banque centrale."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Présentation",
    "section": "",
    "text": "[Pascaline VINCENT]\nEnseignante en économie · IAE-Nantes Economie et Management\n📍 Nantes – France\n✉️ Pascaline.Vincent@univ-nantes.fr\nJe publie ici mes cours et supports de présentation."
  },
  {
    "objectID": "enseignements/micro.html",
    "href": "enseignements/micro.html",
    "title": "micro",
    "section": "",
    "text": "Offre et Demande\n\n\ncode R\nlibrary(ggplot2)\n\n# Paramètres (linéaires)\na &lt;- 100; b &lt;- 2    # demande : P_d(Q) = (a - Q)/b\nc &lt;- 10;  d &lt;- 2    # offre   : P_s(Q) = (Q - c)/d\n\n# Fonctions prix en fonction de la quantité Q\nP_d &lt;- function(Q) (a - Q) / b\nP_s &lt;- function(Q) (Q - c) / d\n\n# Équilibre initial\nP_eq &lt;- (a - c) / (b + d)\nQ_eq &lt;- a - b * P_eq\n\n# Grille en Q (suffisamment fine pour l'approx intégrale)\nQ_max &lt;- max(Q_eq * 1.5, 100)\nQ_all &lt;- seq(0, Q_max, length.out = 2000)\ndf_all &lt;- data.frame(Q = Q_all,\n                     P_dem = P_d(Q_all),\n                     P_off = P_s(Q_all))\n\n# Partie utile pour les aires : de 0 à Q_eq\nQ_shade &lt;- seq(0, Q_eq, length.out = 1000)\ndf_shade &lt;- data.frame(Q = Q_shade,\n                       P_dem = P_d(Q_shade),\n                       P_off = P_s(Q_shade))\n\n# Calcul numérique (trapèze) du surplus consommateur : ∫_0^{Q*} (P_d(Q) - P_eq) dQ\ndq &lt;- diff(df_shade$Q)\ny_cs &lt;- df_shade$P_dem - P_eq\nCS &lt;- sum( (y_cs[-length(y_cs)] + y_cs[-1]) / 2 * dq )\n\n# Surplus producteur : ∫_0^{Q*} (P_eq - P_s(Q)) dQ\ny_ps &lt;- P_eq - df_shade$P_off\nPS &lt;- sum( (y_ps[-length(y_ps)] + y_ps[-1]) / 2 * dq )\n\n# Tracé\nggplot(df_all, aes(x = Q)) +\n  geom_line(aes(y = P_dem), size = 1.1) +\n  geom_line(aes(y = P_off), size = 1.1) +\n  # Surplus consommateur : zone entre P_eq (ymin) et P_dem (ymax), pour Q∈[0,Q_eq]\n  geom_ribbon(data = df_shade, aes(x = Q, ymin = P_eq, ymax = P_dem),\n              fill = \"blue\", alpha = 0.25) +\n  # Surplus producteur : zone entre P_off (ymin) et P_eq (ymax), pour Q∈[0,Q_eq]\n  geom_ribbon(data = df_shade, aes(x = Q, ymin = P_off, ymax = P_eq),\n              fill = \"red\", alpha = 0.25) +\n  geom_hline(yintercept = P_eq, linetype = \"dashed\") +\n  geom_point(aes(x = Q_eq, y = P_eq), size = 3) +\n  annotate(\"text\", x = Q_eq * 0.45, y = max(df_all$P_dem) * 0.9,\n           label = paste0(\"Surplus consommateur (SC) ≈ \", round(CS, 2))) +\n  annotate(\"text\", x = Q_eq * 0.45, y = min(df_all$P_off) + (P_eq - min(df_all$P_off)) * 0.6,\n           label = paste0(\"Surplus producteur (SP) ≈ \", round(PS, 2))) +\n  labs(title = \"Offre et Demande — Surplus\",\n       x = \"Quantité (Q)\", y = \"Prix (P)\") +\n  coord_cartesian(xlim = c(0, Q_max),\n                  ylim = c(min(df_all$P_off, na.rm = TRUE), max(df_all$P_dem, na.rm = TRUE))) +\n  theme_minimal(base_size = 13)\n\n\n\n\n\nSurplus : aire sous la demande au-dessus de P*"
  },
  {
    "objectID": "enseignements/micro.html#la-demande",
    "href": "enseignements/micro.html#la-demande",
    "title": "Introduction à la microéconomie",
    "section": "La demande",
    "text": "La demande\nElle représente la relation entre la quantité de biens qu’un consommateur est disposé à acheter pour un certain prix \\(Q_d=Q_d(P)\\)\n\n\nShow the code\n# Paramètres\na_initial &lt;- 100\nb &lt;- 2\na_income_rise &lt;- 130\n\n# Plage de quantités Q\nQ &lt;- seq(0, a_income_rise, by = 1)\n\n# Inversion de la fonction de demande pour P = f(Q)\nP_initial &lt;- (a_initial - Q) / b\nP_shifted &lt;- (a_income_rise - Q) / b\n\n# Tracé dans le plan (Q,P)\nplot(\n  Q, P_initial,\n  type = \"l\", lwd = 2,\n  xlab = \"Quantité demandée (Q)\",\n  ylab = \"Prix (P)\",\n  main = \"Demande dans le plan (Q,P) et déplacement après hausse de revenu\",\n  ylim = c(0, max(P_initial, P_shifted))\n)\n\nlines(Q, P_shifted, col = \"blue\", lwd = 2)\n\ntext(30, (a_initial - 30)/b, \"Demande initiale\", pos = 3)\ntext(30, (a_income_rise - 30)/b, \"Après hausse de revenu\", pos = 1, col = \"blue\")\n\n# Mention explicite de la pente négative\nmtext(\"La pente est négative : dP/dQ &lt; 0\", side = 3, line = 0.5)\n\nlegend(\n  \"topright\",\n  legend = c(\"Demande initiale\", \"Après hausse de revenu\"),\n  col = c(\"black\", \"blue\"),\n  lwd = 2\n)"
  },
  {
    "objectID": "enseignements/micro.html#loffre",
    "href": "enseignements/micro.html#loffre",
    "title": "Introduction à la microéconomie",
    "section": "L’offre",
    "text": "L’offre\n\\(Q_s=Q_s(P)\\)"
  },
  {
    "objectID": "enseignements/micro.html#surplus",
    "href": "enseignements/micro.html#surplus",
    "title": "Introduction à la microéconomie",
    "section": "Surplus",
    "text": "Surplus\n\n\nShow the code\nlibrary(ggplot2)\n\n# Paramètres (linéaires)\na &lt;- 100; b &lt;- 2    # demande : P_d(Q) = (a - Q)/b\nc &lt;- 10;  d &lt;- 2    # offre   : P_s(Q) = (Q - c)/d\n\n# Fonctions prix en fonction de la quantité Q\nP_d &lt;- function(Q) (a - Q) / b\nP_s &lt;- function(Q) (Q - c) / d\n\n# Équilibre initial\nP_eq &lt;- (a - c) / (b + d)\nQ_eq &lt;- a - b * P_eq\n\n# Grille en Q (suffisamment fine pour l'approx intégrale)\nQ_max &lt;- max(Q_eq * 1.5, 100)\nQ_all &lt;- seq(0, Q_max, length.out = 2000)\ndf_all &lt;- data.frame(Q = Q_all,\n                     P_dem = P_d(Q_all),\n                     P_off = P_s(Q_all))\n\n# Partie utile pour les aires : de 0 à Q_eq\nQ_shade &lt;- seq(0, Q_eq, length.out = 1000)\ndf_shade &lt;- data.frame(Q = Q_shade,\n                       P_dem = P_d(Q_shade),\n                       P_off = P_s(Q_shade))\n\n# Calcul numérique (trapèze) du surplus consommateur : ∫_0^{Q*} (P_d(Q) - P_eq) dQ\ndq &lt;- diff(df_shade$Q)\ny_cs &lt;- df_shade$P_dem - P_eq\nCS &lt;- sum( (y_cs[-length(y_cs)] + y_cs[-1]) / 2 * dq )\n\n# Surplus producteur : ∫_0^{Q*} (P_eq - P_s(Q)) dQ\ny_ps &lt;- P_eq - df_shade$P_off\nPS &lt;- sum( (y_ps[-length(y_ps)] + y_ps[-1]) / 2 * dq )\n\n# Tracé\nggplot(df_all, aes(x = Q)) +\n  geom_line(aes(y = P_dem), size = 1.1) +\n  geom_line(aes(y = P_off), size = 1.1) +\n  # Surplus consommateur : zone entre P_eq (ymin) et P_dem (ymax), pour Q∈[0,Q_eq]\n  geom_ribbon(data = df_shade, aes(x = Q, ymin = P_eq, ymax = P_dem),\n              fill = \"blue\", alpha = 0.25) +\n  # Surplus producteur : zone entre P_off (ymin) et P_eq (ymax), pour Q∈[0,Q_eq]\n  geom_ribbon(data = df_shade, aes(x = Q, ymin = P_off, ymax = P_eq),\n              fill = \"red\", alpha = 0.25) +\n  geom_hline(yintercept = P_eq, linetype = \"dashed\") +\n  geom_point(aes(x = Q_eq, y = P_eq), size = 3) +\n  annotate(\"text\", x = Q_eq * 0.45, y = max(df_all$P_dem) * 0.9,\n           label = paste0(\"Surplus consommateur (SC) ≈ \", round(CS, 2))) +\n  annotate(\"text\", x = Q_eq * 0.45, y = min(df_all$P_off) + (P_eq - min(df_all$P_off)) * 0.6,\n           label = paste0(\"Surplus producteur (SP) ≈ \", round(PS, 2))) +\n  labs(title = \"Offre et Demande — Surplus\",\n       x = \"Quantité (Q)\", y = \"Prix (P)\") +\n  coord_cartesian(xlim = c(0, Q_max),\n                  ylim = c(min(df_all$P_off, na.rm = TRUE), max(df_all$P_dem, na.rm = TRUE))) +\n  theme_minimal(base_size = 13)\n\n\n\n\n\nSurplus : aire sous la demande au-dessus de P*"
  },
  {
    "objectID": "enseignements/micro.html#la-contrainte-budgétaire",
    "href": "enseignements/micro.html#la-contrainte-budgétaire",
    "title": "Introduction à la microéconomie",
    "section": "La contrainte budgétaire",
    "text": "La contrainte budgétaire\nLa droite de budget correspond à l’ensemble des paniers de biens \\((x,y)\\) qui coûtent exatement \\(R\\), le budget du consommateur. Soit:\n\\(R=p_x*x+p_y*y\\) \\(&lt;=&gt; y= R/p_y-p_x/p_y*x\\)\nc’est l’équation d’une droite de pente \\(-p_x/p_y\\), avec une ordonnée à l’origine égale à \\(R/p_y\\)\nExemple:\n\\(R=100\\); \\(p_x=10\\); \\(p_y=20\\)\n\n\nShow the code\nlibrary(ggplot2)\n\n# Paramètres\nR  &lt;- 100   # revenu\npx &lt;- 10\npy &lt;- 20\n\n# Intersections\nx_max &lt;- R / px\ny_max &lt;- R / py\n\n# Points pour tracer la droite budgétaire\ndf_bc &lt;- data.frame(\n  x = c(0, x_max),\n  y = c(y_max, 0)\n)\n\nggplot(df_bc, aes(x = x, y = y)) +\n  geom_line(linewidth = 1.2) +\n  geom_point(aes(x = 0, y = y_max), size = 3) +\n  geom_point(aes(x = x_max, y = 0), size = 3) +\n  annotate(\"text\", x = x_max, y = -0.5,\n           label = paste0(\"x_max = \", x_max)) +\n  annotate(\"text\", x = -0.5, y = y_max,\n           label = paste0(\"y_max = \", y_max)) +\n  labs(\n    title = \"Contrainte budgétaire :  px·x + py·y = R\",\n    subtitle = paste0(px, \"·x + \", py, \"·y = \", R),\n    x = \"Bien x\",\n    y = \"Bien y\"\n  ) +\n  coord_cartesian(xlim = c(0, x_max), ylim = c(0, y_max)) +\n  theme_minimal(base_size = 13)\n\n\n\n\n\nContrainte budgétaire dans le plan (x,y)"
  },
  {
    "objectID": "enseignements/micro.html#des-préférences-du-consommateur-à-la-fonction-dutilité",
    "href": "enseignements/micro.html#des-préférences-du-consommateur-à-la-fonction-dutilité",
    "title": "Introduction à la microéconomie",
    "section": "Des préférences du consommateur à la fonction d’utilité",
    "text": "Des préférences du consommateur à la fonction d’utilité"
  },
  {
    "objectID": "enseignements/micro.html#le-panier-optimal",
    "href": "enseignements/micro.html#le-panier-optimal",
    "title": "Introduction à la microéconomie",
    "section": "Le panier Optimal",
    "text": "Le panier Optimal\n\n\nShow the code\nlibrary(ggplot2)\n\n# Fonction d'utilité Cobb-Douglas U(x,y)=sqrt(xy)\nU  &lt;- function(x, y) sqrt(x*y)\n\n# Niveau d'utilité de la courbe (modifiable)\nU0 &lt;- 6   # alors xy = U0^2 = 36  =&gt; y = 36/x\n\n# Point illustratif sur la courbe (modifiable, doit vérifier x0*y0=36)\nx0 &lt;- 4\ny0 &lt;- (U0^2)/x0  # 9\n\n# TMS au point (x0,y0) : -MUx/MUy = -y/x\nTMS &lt;- - y0/x0   # -2.25\n\n# Données pour la courbe d'indifférence U=U0  (hyperbole y=36/x)\nxs  &lt;- seq(1.5, 20, length.out = 400)\nys  &lt;- (U0^2) / xs\nindif &lt;- data.frame(x = xs, y = ys)\n\n# Droite tangente en (x0,y0): y = y0 + TMS*(x - x0)\nxt  &lt;- seq(1.5, 20, length.out = 200)\nyt  &lt;- y0 + TMS * (xt - x0)\ntangent &lt;- data.frame(x = xt, y = yt)\n\n# Petite flèche montrant la pente (TMS)\n# On prend un court segment autour de x0\nseg_dx &lt;- 1\nseg &lt;- data.frame(\n  x  = c(x0, x0 + seg_dx),\n  y  = c(y0, y0 + TMS*seg_dx)\n)\n\nggplot() +\n  # Courbe d'indifférence\n  geom_line(data = indif, aes(x, y), linewidth = 1.1) +\n  # Tangente au point choisi\n  geom_line(data = tangent, aes(x, y), linetype = \"dashed\") +\n  # Point (x0,y0)\n  geom_point(aes(x0, y0), size = 3) +\n  # Segment/flèche pour la pente (TMS)\n  geom_segment(data = seg, aes(x = x[1], y = y[1], xend = x[2], yend = y[2]),\n               arrow = arrow(length = unit(6, \"pt\"))) +\n  # Annotations\n  annotate(\"label\", x = x0, y = y0 + 2,\n           label = paste0(\"Point (x0=\", x0, \", y0=\", round(y0,2), \")\")) +\n  annotate(\"label\", x = x0 + 4, y = y0 - 2,\n           label = paste0(\"Tangente : pente = TMS = -y0/x0 = \", round(TMS, 2))) +\n  labs(x = \"Bien x\", y = \"Bien y\",\n       title = \"Taux marginal de substitution (TMS)\",\n       subtitle = expression(paste(\"Courbe d'indifférence  \", U(x,y)==sqrt(xy),\n                                   \"  avec  \", U==U[0], \"  et  TMS== -y/x\"))) +\n  coord_cartesian(ylim = c(0, max(ys, yt, na.rm = TRUE))) +\n  theme_minimal(base_size = 13)\n\n\n\n\n\nTMS = pente de la tangente à la courbe d’indifférence"
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#le-budget-de-letat",
    "href": "enseignements/eco_co_chapitre_1.html#le-budget-de-letat",
    "title": "Economie Contemporaine",
    "section": "Le budget de l’Etat",
    "text": "Le budget de l’Etat\nPour présenter le budget de l’Etat, nous nous référons au site suivant\n\nLes recettes\nLes impôts et les taxes (dont TVA)\n\n\nShow the code\n# Charger les bibliothèques \nlibrary(readxl)  \nlibrary(ggplot2)\nlibrary(plotly) \n \ndonnees &lt;- read_excel(\"donnees.xls\") \n\ndonnees &lt;- donnees[-1,] \ndonnees$Valeur&lt;- donnees$`Évaluations 2024 révisées`  # Ajouter une colonne pour le pourcentage \ndonnees$Pourcentage &lt;- round(donnees$Valeur / sum(donnees$Valeur) * 100, 1) \n\np_interactif &lt;- plot_ly(donnees, labels = ~Recette, values = ~Valeur, type = \"pie\",                         textinfo = \"label+percent\", hoverinfo = \"label+percent+value\",                         marker = list(line = list(color = \"#FFFFFF\", width = 1))) %&gt;%   layout(title = \"Répartition des Recettes\")  \n\np_interactif\n\n\n\n\n\n\nSource: Ministère de l’Economie, des Finances et de l’Industrie, projet de loi de finances 2025\n\n\nLes Dépenses\n\n\nShow the code\nlibrary(readxl)\nlibrary(plotly)\ndepenses &lt;- read_excel(\"depenses.xlsx\") \ndepenses$depenses&lt;-depenses$`Dépenses publiques`  \n# Création du camembert interactif avec plotly \np_interactif2 &lt;- plot_ly(depenses, labels = ~Structure, values = ~depenses, type = \"pie\",textinfo = \"label+percent\", hoverinfo = \"label+percent+value\",  marker = list(line = list(color = \"#FFFFFF\", width = 1))) %&gt;%  \n  layout(title = \"Répartition des Dépenses\")  # Afficher le graphique interactif p_interactif2  \n\np_interactif2\n\n\n\n\n\n\n\n\nEvolution du solde budgétaire\n\n\nShow the code\ndette &lt;- read_excel(\"dette.xls\") \ndette$year&lt;-dette$Année\ndette$deficit&lt;-dette$`Déficit public notifié`\nggplot(dette, aes(x =year, y = deficit)) +   geom_line(color = \"blue\", size = 1) +  geom_hline(yintercept = -3, linetype = \"dashed\", color = \"orange\", size = 1) +     scale_y_continuous(limits = c(-10, 2), name = \"en % du PIB\") +    labs(title = \"Solde des finances Publiques\",        x = \"Année\") +   theme_minimal()  \n\n\n\n\n\n\n\n\n\n\n\nEvolution des dépenses et recettes\n\n\nShow the code\nrecettes &lt;- read_excel(\"recettes.xls\") # Création du graphique avec ggplot2 \nggplot(recettes, aes(x = year)) +    geom_line(aes(y = Depenses, color = \"Dépenses Publiques\"), size = 1.2) +    geom_line(aes(y = Recettes, color = \"Recettes\"), size = 1.2) +     scale_color_manual(values = c(\"Dépenses Publiques\" = \"blue\", \"Recettes\" = \"orange\")) +   labs(title = \"Évolution des Dépenses et Recettes Publiques\",        x = \"Année\",        y = \"Valeurs (% du PIB)\",        color = \"Légende\") +   theme_minimal() +    theme(text = element_text(size = 12))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nlibrary(readxl)\ndeficit_europe &lt;- read_excel(\"deficit_europe.xls\")\n\ndeficit_europe$deficit &lt;- deficit_europe$`Solde des finances publiques\n(en % du PIB)`\n\nggplot(deficit_europe, aes(x = reorder(Pays, deficit), y = deficit)) +  \n  geom_bar(stat = \"identity\", fill = \"steelblue\") + \n  coord_flip() +   \n  labs(title = \"Déficit par pays\", x = \"Pays\", y = \"Déficit (%)\") + \n  theme_minimal()"
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#les-règles-qui-régissent-le-budget-de-letat",
    "href": "enseignements/eco_co_chapitre_1.html#les-règles-qui-régissent-le-budget-de-letat",
    "title": "Economie Contemporaine",
    "section": "Les règles qui régissent le budget de l’Etat",
    "text": "Les règles qui régissent le budget de l’Etat\n\nLes principes budgétaires"
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#citation-1",
    "href": "enseignements/eco_co_chapitre_1.html#citation-1",
    "title": "Economie Contemporaine",
    "section": "Citation",
    "text": "Citation\nle budget doit répondre à plusieurs principes budgétaires comme l’universalité, l’unité, la spécialité et l’annualité.\n\nL’universalité budgétaire de l’État, signifie que, normalement — sauf pour quelques exceptions —, toutes les recettes doivent alimenter le budget de l’État sans être affectées à une dépense précise. C’est un grand pot commun qui permet d’alimenter toutes les politiques publiques sans distinction.\nLe budget de l’État doit aussi être présenté dans un document unique avec toutes les dépenses et toutes les recettes. Ce document doit être le plus exhaustif possible. C’est un enjeu de lisibilité et de transparence pour les citoyens et pour permettre au Parlement, qui va ensuite voter ce texte, de travailler efficacement.\nLe budget doit également détailler l’autorisation des crédits par destination, c’est-à-dire qu’une dépense va être prévue dans un but défini, c’est le principe de spécialité.\nLe dernier principe, c’est l’annualité. Chaque année, on détermine les recettes et les dépenses pour une année. Le budget tient compte, bien sûr, du fait que certaines politiques publiques sont pluriannuelles. Mais on fait en sorte que chaque année, on puisse faire de la justification au premier euro, c’est-à-dire que chaque dépense puisse être justifiée annuellement.\n\n\nLes règles européennes\nLe traité de Maastricht prévoit deux critères de convergence:\n\nUne limitation du déficit public &lt; 3% du PIB\nUn plafonnement de la dette publique, qui ne doit pas excéder 60% du PIB"
  },
  {
    "objectID": "enseignements/eco_co_chapitre_1.html#débat",
    "href": "enseignements/eco_co_chapitre_1.html#débat",
    "title": "Economie Contemporaine",
    "section": "Débat",
    "text": "Débat\nDonnez des arguments Pour et Contre une discipline budgétaire suivant ces critères définis."
  },
  {
    "objectID": "normes_identite/CGNI.html#utilité-et-identité",
    "href": "normes_identite/CGNI.html#utilité-et-identité",
    "title": "Vers une Mesure Continue de l’identité de Genre",
    "section": "",
    "text": "Pour un économiste, le concept d’utilité est central. Il s’agit d’une mesure de la satisfaction individuelle.\nUn individu, par exemple un consommateur, réalise ses choix en fonction du niveau de satisfaction qu’il peut retirer. C’est son objectif, modélisé sous forme de fonction.\nDans les modèles traditionnels, l’utilité dépend de quelques variables objectives, qui ont l’intérêt d’être mesurables.\nPar exemple, pour un consommateur, \\(U=F(x,y)\\) , où \\(x\\) et \\(y\\) sont les quantités de biens consommées.\nL’apport d’Akerlof et Kranton, est d’indiquer que les choix des individus sont influencés par le sentiment qu’ils ont d’eux même, leur identité.\nEnrichir les modèles traditionnels de cette nouvelle variable permettrait de mieux comprendre ce qui parfois échappe à la théorie classique."
  },
  {
    "objectID": "normes_identite/CGNI.html#modèle-avec-identité",
    "href": "normes_identite/CGNI.html#modèle-avec-identité",
    "title": "Vers une Mesure Continue de l’identité de Genre",
    "section": "",
    "text": "Reprenons ici le modèle proposé par Akerlof et Kranton,\nla fonction d’utilité d’un individu est la suivante:\n\\(U_j = U_j(a_j, a_j I_j)\\)\noù :\n\n\\(a_j\\) représente les actions de l’individu \\(j\\)\n\\(a_j\\) \\(I_j\\) capture les intéractions entre les actions de \\(j\\) et son identité \\(I_j\\)\n\nCette fonction d’identite \\(I_j\\) dépend elle même de plusieurs facteurs:\n\\(I_j = I_j(a_j, a_{-j}, c_j, E_j, P)\\)\noù :\n\n\\(a_j\\) représente les actions de l’individu \\(j\\),\n\\(a_{-j}\\) repésente les actions des autres individus,\n\\(c_j\\) est la catégorie sociale à laquelle appartien \\(j\\),\n\\(E_j\\) sont les caractéristiques données de \\(j\\),\n\\(P\\) sont les prescriptions (ou normes sociales) associées à la catégorie \\(c_j\\).\n\nCe modèle formalise cette tension qui peut exister pour les individus entre se conformer ou non aux normes de sa catégorie sociale assignée, en fonction de la distance qui peut exister entre ses propres caractéristiques et les prescriptions assignées.\nIl suppose aussi l’existence possible de sanctions de la part des pairs si les normes ne sont pas suivies (moqueries, mise à l’écart ou même violence)\nPar exemple, dans leur papier (George A. Akerlof and Kranton, n.d.) complètent les théories traditionnelles de l’économie de l’éducation en expliquant le plus ou moins grand investissement scolaire des étudiants en fonction de leurs caractéristiques identitaires (les sportifs, les intellos et les rebelles)"
  },
  {
    "objectID": "normes_identite/CGNI.html#identité-et-choix-des-individus",
    "href": "normes_identite/CGNI.html#identité-et-choix-des-individus",
    "title": "Vers une Mesure Continue de l’identité de Genre",
    "section": "",
    "text": "L’économie étudie comment les agents font leur choix (de consommation, de production…), ces choix dépendent de l’identité des individus.\nEn effet, le sens que l’on a de soi, influence nos décisions, et ces décisions influencent notre identité en retour.\nDans un premier temps, la catégorie sociale à laquelle j’appartiens peut influencer mes préférences (Chen and Li (2009)) ,mes comportements pro-sociaux (Charness, Cobo-Reyes, and Jiménez (2014)) et donc mes décisions.\nDans un second temps, l’individu arbitre entre ses propres caractéristiques et les prescriptions de sa catégorie sociale (ou les prescriptions supposées).\nVais-je me conformer à ce qui est attendu? Mes propres caractéristiques sont-elles plus ou moins proches des normes en vigueur? Si je ne me conforme pas, quelle sera la réaction de mes pairs?\nCet arbitrage et cette possibilité pour autrui de répondre à mes actions a été représenté sous forme d’arbre de décision par George A. Akerlof and Kranton (2000a)\n\n\n\n\n\nCette friction entre adhérer ou non aux normes de ma catégorie sociale a conduit la recherche des économistes de l’identité vers les questions de conflits inter-groupes (Austen-Smith and Fryer (2005), Chakravarty et al. (2015), Fryer, Fryer, and Torelli (2010), Bénabou and Tirole (2004).)\nOn s’interroge sur les normes, l’adhésion ou non à ces dernières et le rôle que peuvent jouer les politiques publiques sur ces prescriptions.\nMais l’identité joue également un rôle fondamental sur les performances individuelles."
  },
  {
    "objectID": "normes_identite/CGNI.html#identité-et-performances",
    "href": "normes_identite/CGNI.html#identité-et-performances",
    "title": "Vers une Mesure Continue de l’identité de Genre",
    "section": "",
    "text": "Dans une étude particulièrement intéressante, Shih, Pittinsky, and Trahan (2006) ont montré comment l’activation d’une identité particulière, ou tout du moins comment les stéréotypes associés à cette identité, pouvaient avoir un impact sur les performances individuelles.\nEn réalisant une étude auprès d’étudiantes asiatiques aux Etats Unis, les chercheurs ont proposé l’expérience suivante:\nUn questionnaire était fourni aux participantes avant de réaliser un test de mathématiques.\nUne partie des participantes répondaient à un questionnaire dont les questions portaient sur leur identité asiatique, pour les autres participantes le questionnaire activait leur identité féminine, un groupe de contrôle était également implémanté.\nCe simple questionnaire en préambule a eu des effets notables sur les performances aux tests de mathématiques réalisés ensuite, puisque en moyenne, les étudiantes dont l’identité asiatique avait été mise en évidence performaient significativement mieux aux tests de mathématiques que leurs homologues dont l’identité féminine avait été activée.\nCette étude plaide donc pour la nécessité de s’interroger sur la notion d’identité, dès lors que cette variable peut significativement avoir des répercussions sur les résultats socio-économiques des individus.\nCependant, les critiques apportées à ce nouveau courant sont notamment que ce concept fondamental d’identité est trop flou, comment intégrer dans les modèles ou bien encore dans les études empiriques cette dimension si polymorphe?\nLa question de la mesure de l’identité se pose alors… ## Construction de l’indice\nL’indice que nous proposons repose donc sur la dernière approche présentée:\nUn indice de mesure continue de l’identité de genre, construit comme un indice composite à partir de dimensions non définies a priori comme genrées.\nMais alors, quelles variables choisir pour représenter ces dimensions du genre?\nNotre choix s’est porté sur les pratiques culturelles des français (leurs loisirs culturels) car ces pratiques sont en effet particulièrement genrées (différenciées selon les sexes biologiques), il nous paraissait pertinent de s’appuyer sur ces dernières pour construire notre indice.\n\n\nEn sociologie, la question de la culture et du Genre fait l’objet de travaux ayant montré combien les pratiques culturelles sont différenciées chez les hommes et les femmes (Octobre (2008)) , et ce, dès l’enfance.\nCette différenciation nous permet d’envisager qu’il y ait des pratiques plus ou moins féminines ou masculines, dans la mesure où en moyenne elles sont plus pratiquées par des hommes ou par des femmes.\nCela signifie qu’il existe des normes genrées dans la pratique ou non d’une activité culturelle: le tricot est essentiellement féminin, la chasse est une activité plutôt pratiquée par les hommes.\nCes exemples sont tirés de l’analyse de nos données, en effet, nous avons utilisé la base de données Enquête sur les pratiques culturelles des Français, 2018.\nCette base de données comprend des informations sur les pratiques culturelles des français (9234 individus interrogés) , ainsi que des données socio-démographiques et porte également une question qui va nous intéresser sur le degré de satisfaction en termes de temps libre.\nCette dernière variable (“Vous arrive-t-il d’avoir le sentiment de manquer de temps libre pour faire tout ce dont vous avez envie?”) a retenu notre attention car elle pourrait être une mesure de l’utilité (satisfaction) de l’individu.\n\n\n\n\nShow the code\nlibrary(foreign)\nlibrary(questionr) \nlibrary(ggplot2) \nlibrary(tidyverse) \nlibrary(ggmosaic)\nlibrary(GGally) \nlibrary(dataMaid)\nlibrary(dplyr) \nlibrary(GDAtools)\nlibrary(FactoMineR)\nlibrary(gtsummary) \nlibrary(factoextra)\nlibrary(gtsummary) \nlibrary(kableExtra)\nlibrary(RColorBrewer) \nlibrary(FactoMineR) \nlibrary(xtable) \nlibrary(explor)\n\n\n\n\nShow the code\ndata&lt;-read.csv2(\"pc18_quetelet_octobre2023.csv\")\n\n\n\n\nShow the code\ndata$Sex &lt;- factor(data$SEXE, \n                            levels = c(1, 2), \n                            labels = c(\"Men\", \"Women\"))\nmy_data_frame &lt;- data |&gt; dplyr::rename( \n  Knitting = A1001 , \n  Cards_games = A1002,  \n  Gambling = A1003 , \n  Cooking = A1004 , \n  DIY = A1005  ,\n  Vegetable_garden = A1006 , \n  Ornamental_garden = A1007,  \n  Fishing_hunting = A1008 , \n  Collection = A1009  ,\n  Vehicle_custom = A1010 , \n  No_Amateur=A1011,\n  Making_music = A1901  ,\n  Diary = A1902  ,\n  Writing = A1903,  \n  Painting = A1904,  \n  Montage = A1905 , \n  Circus = A1906  ,\n  Pottery = A1907 , \n  Theater = A1908 , \n  Drawing = A1909 , \n  Dancing = A1910,  \n  Photography = A1911  ,\n  Genealogy = A1912 , \n  Science = A1913  ,\n  None = A1914  ,\n  Video_games = B1  ,\n  TV = C1  ,\n  Radio = E1  ,\n  Library = F1  ,\n  Museums = H112,  \n  Internet = I4 , \n  Concert = G2413 )\n\n\nmy_data_frame$Video_games &lt;- ifelse(my_data_frame$Video_games == 1, 1, 0)\nmy_data_frame$TV &lt;- ifelse(my_data_frame$TV == 5, 0, 1)\nmy_data_frame$Radio &lt;- ifelse(my_data_frame$Radio == 5, 0, 1)\nmy_data_frame$Library&lt;- ifelse(my_data_frame$Radio == 1, 1, 0)\nmy_data_frame$Museums&lt;- ifelse(my_data_frame$Museums == 1, 0, 1)\nmy_data_frame$Internet&lt;- ifelse(my_data_frame$Internet == 5, 0, 1)\nmy_data_frame$Concert&lt;- ifelse(my_data_frame$Concert == 1, 0, 1)\n\n\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(satisfaction = case_when(\n    A2 %in% 1 ~ \"Low\",      # 1 à 4 -&gt; Low\n    A2 %in% 2 ~ \"Medium\",   # 5 à 7 -&gt; Medium\n    A2 %in% 3 ~ \"High\",    # 8 à 10 -&gt; High\n    TRUE ~ NA_character_              \n  ))  \nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(Income = case_when(\n    CRITREVENU %in% 1:4 ~ \"Low\",      # 1 à 4 -&gt; Low\n    CRITREVENU %in% 5:7 ~ \"Medium\",   # 5 à 7 -&gt; Medium\n    CRITREVENU %in% 8:10 ~ \"High\",    # 8 à 10 -&gt; High\n    TRUE ~ NA_character_              \n  ))\n\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(Health = case_when(\n    A15 %in% 1:2 ~ \"Good\",      # 1 à 4 -&gt; Low\n    A15 %in% 3 ~ \"Medium\",   # 5 à 7 -&gt; Medium\n    A15 %in% 4:5 ~ \"Bad\",    # 8 à 10 -&gt; High\n    TRUE ~ NA_character_              \n  ))\n\n\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(Couple = case_when(\n    VITENCOUPLE %in% 1:2 ~ \"Yes\",     \n    VITENCOUPLE %in% 3~ \"No\",  \n    \n    TRUE ~ NA_character_              \n  ))\n\nquartiles &lt;- quantile(data$AGE, probs = c(0.25, 0.5, 0.75), na.rm = TRUE)\n\nmy_data_frame$age_group &lt;- cut(\n  my_data_frame$AGE,\n  breaks = 4,  # Automatically divide into 4 slices\n  labels = c(\"[15-38[\", \"[38-54[\", \"[54-67[\", \"[67-97[\"),  # Labels optionnels\n  include.lowest = TRUE \n)\n\n\n\n\nShow the code\nstat_des_1 &lt;- my_data_frame |&gt;\n    tbl_summary(\n        include = c(\"AGE\", \"Income\", \"Couple\", \"CLASSIF\", \"satisfaction\", \"Health\"),\n        by = \"Sex\",\n        statistic = list(\n            all_continuous() ~ \"{min} - {max}\"\n        )\n    ) |&gt;\n    add_overall(last = TRUE) |&gt;\n    add_p(\n        test.args = list(\n            all_continuous() ~ list(simulate.p.value = TRUE),\n            all_categorical() ~ list(simulate.p.value = TRUE)\n        )\n    )\n\nstat_des_1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\nOverall N = 9,2341\np-value2\n\n\n\n\nAGE\n15 - 95\n15 - 97\n15 - 97\n0.042\n\n\nIncome\n\n\n\n\n\n\n&lt;0.001\n\n\n    High\n1,432 (39%)\n1,464 (33%)\n2,896 (36%)\n\n\n\n\n    Low\n762 (21%)\n1,284 (29%)\n2,046 (25%)\n\n\n\n\n    Medium\n1,476 (40%)\n1,644 (37%)\n3,120 (39%)\n\n\n\n\n    Unknown\n492\n680\n1,172\n\n\n\n\nCouple\n2,444 (59%)\n2,567 (51%)\n5,011 (54%)\n&lt;0.001\n\n\n    Unknown\n4\n9\n13\n\n\n\n\nCLASSIF\n\n\n\n\n\n\n&lt;0.001\n\n\n    1\n123 (8.7%)\n63 (4.5%)\n186 (6.6%)\n\n\n\n\n    2\n454 (32%)\n143 (10%)\n597 (21%)\n\n\n\n\n    3\n190 (13%)\n92 (6.6%)\n282 (10%)\n\n\n\n\n    4\n157 (11%)\n126 (9.1%)\n283 (10%)\n\n\n\n\n    5\n278 (20%)\n236 (17%)\n514 (18%)\n\n\n\n\n    6\n194 (14%)\n703 (51%)\n897 (32%)\n\n\n\n\n    7\n13 (0.9%)\n7 (0.5%)\n20 (0.7%)\n\n\n\n\n    8\n11 (0.8%)\n18 (1.3%)\n29 (1.0%)\n\n\n\n\n    9\n1 (&lt;0.1%)\n1 (&lt;0.1%)\n2 (&lt;0.1%)\n\n\n\n\n    Unknown\n2,741\n3,683\n6,424\n\n\n\n\nsatisfaction\n\n\n\n\n\n\n&lt;0.001\n\n\n    High\n1,461 (35%)\n1,656 (33%)\n3,117 (34%)\n\n\n\n\n    Low\n1,488 (36%)\n2,015 (40%)\n3,503 (38%)\n\n\n\n\n    Medium\n1,207 (29%)\n1,398 (28%)\n2,605 (28%)\n\n\n\n\n    Unknown\n6\n3\n9\n\n\n\n\nHealth\n\n\n\n\n\n\n&lt;0.001\n\n\n    Bad\n322 (7.8%)\n461 (9.1%)\n783 (8.5%)\n\n\n\n\n    Good\n2,984 (72%)\n3,426 (68%)\n6,410 (70%)\n\n\n\n\n    Medium\n841 (20%)\n1,157 (23%)\n1,998 (22%)\n\n\n\n\n    Unknown\n15\n28\n43\n\n\n\n\n\n1 Min - Max; n (%)\n\n\n2 Wilcoxon rank sum test; Pearson’s Chi-squared test with simulated p-value (based on 2000 replicates); Fisher’s Exact Test for Count Data with simulated p-value (based on 2000 replicates)\n\n\n\n\n\n\n\n\nLecture: Parmi les individus de sexe masculin, 59% sont en couple. La différence avec les femmes est significative (p&lt;0,001)\n\n\nShow the code\ntable &lt;- my_data_frame |&gt;\n  tbl_summary(\n    include = c(  \"Knitting\" , \n                  \"Cards_games\",  \n                  \"Gambling\" , \n                  \"Cooking\" , \n                  \"DIY\"  ,\n                  \"Vegetable_garden\" , \n                  \"Ornamental_garden\",  \n                  \"Fishing_hunting\" , \n                  \"Collection\"  ,\n                  \"Vehicle_custom\", \n                  \"Making_music\"   ,\n                  \"Diary\" ,\n                  \"Writing\" ,  \n                  \"Painting\",  \n                  \"Montage\"  , \n                  \"Circus\"   ,\n                  \"Pottery\" , \n                  \"Theater\" , \n                  \"Drawing\" , \n                  \"Dancing\",  \n                  \"Photography\"  ,\n                  \"Genealogy\" , \n                  \"Science\"  ,\n                  \"None\"  ,\n                  \"No_Amateur\",\n                  \"Video_games\"  ,\n                  \"TV\" ,\n                  \"Radio\"  ,\n                  \"Library\"  ,\n                  \"Museums\",  \n                  \"Internet\", \n                  \"Concert\"),\n    by = \"Sex\"\n  ) |&gt;\n  add_overall(last = TRUE) |&gt;\n  add_p()\n\ntable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\nOverall N = 9,2341\np-value2\n\n\n\n\nKnitting\n73 (1.8%)\n1,370 (27%)\n1,443 (16%)\n&lt;0.001\n\n\nCards_games\n1,899 (46%)\n2,764 (54%)\n4,663 (50%)\n&lt;0.001\n\n\nGambling\n990 (24%)\n970 (19%)\n1,960 (21%)\n&lt;0.001\n\n\nCooking\n1,685 (40%)\n3,473 (68%)\n5,158 (56%)\n&lt;0.001\n\n\nDIY\n2,667 (64%)\n2,283 (45%)\n4,950 (54%)\n&lt;0.001\n\n\nVegetable_garden\n1,335 (32%)\n1,245 (25%)\n2,580 (28%)\n&lt;0.001\n\n\nOrnamental_garden\n1,793 (43%)\n2,198 (43%)\n3,991 (43%)\n0.8\n\n\nFishing_hunting\n722 (17%)\n212 (4.2%)\n934 (10%)\n&lt;0.001\n\n\nCollection\n395 (9.5%)\n281 (5.5%)\n676 (7.3%)\n&lt;0.001\n\n\nVehicle_custom\n264 (6.3%)\n60 (1.2%)\n324 (3.5%)\n&lt;0.001\n\n\nMaking_music\n1,312 (32%)\n1,830 (36%)\n3,142 (34%)\n&lt;0.001\n\n\nDiary\n285 (6.8%)\n1,206 (24%)\n1,491 (16%)\n&lt;0.001\n\n\nWriting\n410 (9.9%)\n746 (15%)\n1,156 (13%)\n&lt;0.001\n\n\nPainting\n667 (16%)\n1,303 (26%)\n1,970 (21%)\n&lt;0.001\n\n\nMontage\n843 (20%)\n586 (12%)\n1,429 (15%)\n&lt;0.001\n\n\nCircus\n116 (2.8%)\n179 (3.5%)\n295 (3.2%)\n0.044\n\n\nPottery\n264 (6.3%)\n705 (14%)\n969 (10%)\n&lt;0.001\n\n\nTheater\n483 (12%)\n800 (16%)\n1,283 (14%)\n&lt;0.001\n\n\nDrawing\n864 (21%)\n1,285 (25%)\n2,149 (23%)\n&lt;0.001\n\n\nDancing\n410 (9.9%)\n1,782 (35%)\n2,192 (24%)\n&lt;0.001\n\n\nPhotography\n1,175 (28%)\n1,176 (23%)\n2,351 (25%)\n&lt;0.001\n\n\nGenealogy\n513 (12%)\n575 (11%)\n1,088 (12%)\n0.14\n\n\nScience\n611 (15%)\n469 (9.2%)\n1,080 (12%)\n&lt;0.001\n\n\nNone\n1,394 (33%)\n1,261 (25%)\n2,655 (29%)\n&lt;0.001\n\n\nNo_Amateur\n276 (6.6%)\n359 (7.1%)\n635 (6.9%)\n0.4\n\n\nVideo_games\n1,760 (42%)\n1,827 (36%)\n3,587 (39%)\n&lt;0.001\n\n\nTV\n3,878 (93%)\n4,806 (95%)\n8,684 (94%)\n0.001\n\n\nRadio\n3,522 (85%)\n4,186 (83%)\n7,708 (83%)\n0.007\n\n\nLibrary\n3,522 (85%)\n4,186 (83%)\n7,708 (83%)\n0.007\n\n\nMuseums\n4,101 (99%)\n5,009 (99%)\n9,110 (99%)\n0.4\n\n\nInternet\n3,459 (83%)\n4,185 (83%)\n7,644 (83%)\n0.4\n\n\nConcert\n3,344 (80%)\n4,234 (83%)\n7,578 (82%)\n&lt;0.001\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\nLecture: Parmi les hommes, 1.8% déclarent pratiquer le tricot, contre 27% des femmes. Cette activité est pratiquée par 16% des répondants.\nLes p-value &lt;10% indiquent que les différences de participation aux pratiques culturelles sont significativement différentes selon le sexe biologique du répondant.\n\n\n\n\n\n\nNote\n\n\n\nNous retiendrons pour la construction de notre indice les pratiques culturelles suivantes:\n“Knitting” , “Cards_games”,“Gambling” , “Cooking” , “DIY” , “Vegetable_garden” , “Fishing_hunting” , “Collection” , “Vehicle_custom”, “Making_music” , “Diary” , “Writing” ,“Painting”,“Montage” , “Pottery” , “Theater” , “Drawing” , “Dancing”,\n“Photography” , “Genealogy” , “Science” , “None” , “Video_games” , “Library” , “Concert”\n\n\n\n\n\n\nAfin de construire notre indice d’identité de genre, nous suivons la méthodologie proposée par Cipriani et al. (n.d.) et réalisons une Analyse des Correspondances Multiples (ACM) sur nos variables “pratiques culturelles”.\n\n\n\n\n\n\nEncadré Technique 1: Détails de la méthode ACM\n\n\n\nL’**ACM** est une extension de l’**Analyse des Correspondances Simples (ACS)** qui permet d’explorer les relations entre plusieurs variables qualitatives en projetant les individus et les modalités dans un espace de faible dimension. Elle est souvent utilisée pour analyser des **questionnaires** et des **tableaux de contingence** complexes.\n### Principaux résultats d’une ACM\n1. **Inertie totale**\nMesure la dispersion des données et est donnée par :\n\\(I_{\\text{total}} = \\frac{q}{q-1} \\sum_{k} \\lambda_k\\)\noù \\(\\lambda_k\\) sont les valeurs propres et \\(q\\) est le nombre total de modalités.\n2. **Valeurs propres \\(\\lambda_k\\)**\nElles indiquent la variance expliquée par chaque axe factoriel. Plus une valeur propre est élevée, plus l’axe correspondant est important dans l’analyse.\n3. **Rapports de corrélation \\(\\eta^2\\)**\nLe **rapport de corrélation** \\(\\eta^2\\) mesure la liaison entre une variable et un axe factoriel :\n\\(\\eta^2 = \\frac{\\sum_{i} f_i d_{i,k}^2}{\\sum_{i} f_i d_{i}^2}\\)\noù $ f_i $ est la fréquence de l’individu/modalité $i $, et $d_{i,k} $ est sa distance à l’axe \\(k\\) .\n4. **Coordonnées des individus et modalités**\nElles sont obtenues à partir des vecteurs propres et permettent la représentation graphique des données :\n\\(C_{i,k} = \\frac{v_{i,k}}{\\sqrt{\\lambda_k}}\\)\noù \\(v_{i,k}\\) est le vecteur propre associé à l’axe \\(k\\).\n5. **Cos² (Qualité de représentation)**\nIndique dans quelle mesure un point est bien représenté sur un axe donné. Une valeur proche de **1** signifie que la projection sur cet axe est pertinente.\n6. **Contributions **\nElles mesurent l’importance d’une modalité ou d’un individu dans la construction d’un axe. Plus une contribution est élevée, plus l’élément joue un rôle important dans l’interprétation de l’axe.\n\n\n\n\nShow the code\npratiques_cols_1 &lt;- c( \"Knitting\" , \n                     \"Cards_games\",  \n                     \"Gambling\" , \n                     \"Cooking\" , \n                     \"DIY\"  ,\n                     \"Vegetable_garden\" , \n                     \"Fishing_hunting\" , \n                     \"Collection\"  ,\n                     \"Vehicle_custom\",\n                     \"Making_music\"   ,\n                     \"Diary\" ,\n                     \"Writing\" ,  \n                     \"Painting\",  \n                     \"Montage\"  , \n                     \"Pottery\" , \n                     \"Theater\" , \n                     \"Drawing\" , \n                     \"Dancing\",  \n                     \"Photography\"  ,\n                     \"Genealogy\" , \n                     \"Science\"  ,\n                     \"None\" ,\n                     \"Video_games\"  ,\n                     \"Library\"  ,\n                     \"Concert\"\n                            )\n\n\n#MCA\n\n# Add Sex Column to the selection\ncols_of_interest_1 &lt;- c(\"Sex\", \"AGE\", pratiques_cols_1)\n\n# Build a new dataframe with these columns\ndata_pratiques &lt;- my_data_frame[, cols_of_interest_1]\ndata_pratiques$AGE &lt;- cut(data_pratiques$AGE, \n                          breaks = quantile(data_pratiques$AGE, probs = seq(0, 1, 0.25), na.rm = TRUE), \n                          include.lowest = TRUE)\nra_data &lt;- na.omit(data_pratiques)\n\ncols_to_factor &lt;- c(  \"Knitting\" , \n                      \"Cards_games\",  \n                      \"Gambling\" , \n                      \"Cooking\" , \n                      \"DIY\"  ,\n                      \"Vegetable_garden\" , \n                      \"Fishing_hunting\" , \n                      \"Collection\"  ,\n                      \"Vehicle_custom\",\n                      \"Making_music\"   ,\n                      \"Diary\" ,\n                      \"Writing\" ,  \n                      \"Painting\",  \n                      \"Montage\"  , \n                      \"Pottery\" , \n                      \"Theater\" , \n                      \"Drawing\" , \n                      \"Dancing\",  \n                      \"Photography\"  ,\n                      \"Genealogy\" , \n                      \"Science\"  ,\n                      \"None\"  ,\n                      \"Video_games\"  ,\n                      \"Library\"  ,\n                      \"Concert\")\n\n# apply as.factor to these columnns\nra_data[cols_to_factor] &lt;- lapply(ra_data[cols_to_factor], as.factor)\n\n# running MCA with FactoMiner\nacm2_fm &lt;- ra_data |&gt; \n  FactoMineR::MCA(\n    ncp = Inf,\n    graph = TRUE,\n    quali.sup = 1:2\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn remarque que la variable supplémentaire “Sexe” correspond à la dimension 2 de notre ACM. Cette dimension explique 6,06% de la variance totale.\nUne analyse plus poussée avec le package Explor nous permet de mesurer l’association de la variable supplémentaire Sexe avec cette dimension (dim2), en effet, l’ \\(𝞰^2\\) est de 0,14 , ce qui peut sembler peu mais indique bien que notre variable supplémentaire est liée à cet axe.\nPour construire notre indice, nous utiliserons donc les coordonnées des variables pratiques culturelles le long de cet axe 2.\n\n\nShow the code\n# Extract modality names\nmodalites_names &lt;- rownames(acm2_fm$var$coord)\n\n# Check modality names\nhead(modalites_names)\n\n\n[1] \"Knitting_0\"    \"Knitting_1\"    \"Cards_games_0\" \"Cards_games_1\"\n[5] \"Gambling_0\"    \"Gambling_1\"   \n\n\nShow the code\n# Extract coordinates for dimension 2\ncoord_dim2_modalites &lt;- acm2_fm$var$coord[, 2]\n\n# Create a table associating the modalities and their coordinates in dimension 2\nmodalites_coord &lt;- data.frame(Modalite = modalites_names, Coord_Dim2 = coord_dim2_modalites)\n\n\n\n# Keep only the two necessary columns\nmodalites_coord_selected &lt;- modalites_coord[, c(\"Modalite\", \"Coord_Dim2\")]\n\nprint(modalites_coord_selected)\n\n\n                             Modalite  Coord_Dim2\nKnitting_0                 Knitting_0  0.04314603\nKnitting_1                 Knitting_1 -0.23295268\nCards_games_0           Cards_games_0 -0.21072530\nCards_games_1           Cards_games_1  0.20656774\nGambling_0                 Gambling_0 -0.17433328\nGambling_1                 Gambling_1  0.64698995\nCooking_0                   Cooking_0 -0.06432635\nCooking_1                   Cooking_1  0.05083253\nDIY_0                           DIY_0 -0.59097111\nDIY_1                           DIY_1  0.51145863\nVegetable_garden_0 Vegetable_garden_0 -0.29999865\nVegetable_garden_1 Vegetable_garden_1  0.77371744\nFishing_hunting_0   Fishing_hunting_0 -0.16671349\nFishing_hunting_1   Fishing_hunting_1  1.48150102\nCollection_0             Collection_0 -0.05539977\nCollection_1             Collection_1  0.70134797\nVehicle_custom_0     Vehicle_custom_0 -0.05128080\nVehicle_custom_1     Vehicle_custom_1  1.41022187\nMaking_music_0         Making_music_0  0.09403755\nMaking_music_1         Making_music_1 -0.18232870\nDiary_0                       Diary_0  0.09378209\nDiary_1                       Diary_1 -0.48702531\nWriting_0                   Writing_0  0.06770001\nWriting_1                   Writing_1 -0.47308017\nPainting_0                 Painting_0  0.04361213\nPainting_1                 Painting_1 -0.16081142\nMontage_0                   Montage_0 -0.07125251\nMontage_1                   Montage_1  0.38917132\nPottery_0                   Pottery_0  0.01201096\nPottery_1                   Pottery_1 -0.10244644\nTheater_0                   Theater_0  0.07187594\nTheater_1                   Theater_1 -0.44542916\nDrawing_0                   Drawing_0  0.04570585\nDrawing_1                   Drawing_1 -0.15068681\nDancing_0                   Dancing_0  0.14396501\nDancing_1                   Dancing_1 -0.46250072\nPhotography_0           Photography_0 -0.07539973\nPhotography_1           Photography_1  0.22074706\nGenealogy_0               Genealogy_0 -0.01967874\nGenealogy_1               Genealogy_1  0.14733732\nScience_0                   Science_0 -0.04008198\nScience_1                   Science_1  0.30261895\nNone_0                         None_0 -0.06572453\nNone_1                         None_1  0.16286315\nVideo_games_0           Video_games_0 -0.22185919\nVideo_games_1           Video_games_1  0.34927205\nLibrary_0                   Library_0 -0.65936864\nLibrary_1                   Library_1  0.13053925\nConcert_0                   Concert_0 -0.23244943\nConcert_1                   Concert_1  0.05079655\n\n\nCe tableau indique les poids utilisés pour la construction de notre indice.\n\n\nShow the code\n# Initialize a vector to store the index of each individual\nra_data$indice_culturel &lt;- 0\n\n# Browse each individual\nfor (i in 1:nrow(ra_data)) {\n  \n  # Initialize individual's index to 0\n  indice_individu &lt;- 0\n  \n  # Browse each practice column (columns 3 to 27)\n  for (pratique in 3:27) {\n    \n    # Retrieve the individual's response for this practice (0 or 1)\n    reponse &lt;- ra_data[i, pratique]\n    \n    # If the answer is 1, add the coordinate of the corresponding modality to the index.\n    if (reponse == 1) {\n      \n      # Create the modality name (e.g. “knitting_1” or “knitting_0”)\n      nom_modalite_1 &lt;- paste0(names(ra_data)[pratique], \"_1\")\n      nom_modalite_0 &lt;- paste0(names(ra_data)[pratique], \"_0\")\n      \n      # Find the coordinate associated with the corresponding modality\n      if (nom_modalite_1 %in% modalites_coord$Modalite) {\n        indice_individu &lt;- indice_individu + modalites_coord$Coord_Dim2[modalites_coord$Modalite == nom_modalite_1]\n      }\n      if (nom_modalite_0 %in% modalites_coord$Modalite) {\n        indice_individu &lt;- indice_individu + modalites_coord$Coord_Dim2[modalites_coord$Modalite == nom_modalite_0]\n      }\n    }\n  }\n  \n  # Assign the calculated index to the individual\n  ra_data$indice_culturel[i] &lt;- indice_individu\n}\n####Normalisation\n\n# Calculate minimum and maximum index values\nmin_indice &lt;- min(ra_data$indice_culturel, na.rm = TRUE)\nmax_indice &lt;- max(ra_data$indice_culturel, na.rm = TRUE)\n\n# Normalize index\nra_data$indice_culturel_normalise &lt;- (ra_data$indice_culturel - min_indice) / (max_indice - min_indice)\n\n# Check results\n\nhead(ra_data[, c(\"indice_culturel\", \"indice_culturel_normalise\")])\n\n\n  indice_culturel indice_culturel_normalise\n1       2.8024423                 0.8624142\n2       0.5427446                 0.5073268\n3      -0.4557477                 0.3504244\n4      -0.3429253                 0.3681533\n5       0.0409659                 0.4284777\n6      -0.2367887                 0.3848315\n\n\nNotre indice est donc construit de la façon suivante:\n\\[I_{1j} = \\sum_{k=1}^{Z} w_{1k} \\cdot X_{k j}\\]\nDans cette expression, \\(I_{1j}\\) désigne l’indice de l’individu \\(j\\), tandis que \\(w_{1k}\\) représente le poids associé à chaque variable culturelle \\(X_{kj}\\). La somme englobe toutes les variables culturelles \\(Z\\), ce qui nous permet de saisir l’engagement culturel global de l’individu.\n\n\n\n\n\nShow the code\nmy_data_frame$identity&lt;-ra_data$indice_culturel_normalise\nmy_data_frame$indice&lt;-ra_data$indice_culturel\nggplot(my_data_frame, aes(x = identity, fill = Sex)) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) + \n  labs(title = \"Density of The Normalized Cultural Index by Sexe\",\n       x = \"Normalized Cultural Index\",\n       y = \"Density\",\n       fill = \"Sexe\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\nstat_des_indice&lt;-my_data_frame%&gt;%\n  tbl_summary(include=c(\"identity\"),by = \"Sex\",\n              statistic = list(\n            all_continuous() ~ \"{min} - {max}\"\n        )) %&gt;%\n  add_overall(last = TRUE) %&gt;%\n  add_p()\nstat_des_indice\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\nOverall N = 9,2341\np-value2\n\n\n\n\nidentity\n0.01 - 1.00\n0.00 - 0.91\n0.00 - 1.00\n&lt;0.001\n\n\n\n1 Min - Max\n\n\n2 Wilcoxon rank sum test\n\n\n\n\n\n\n\n\nL’indice normalisé est compris entre 0 et 1. Plus il est proche de zéro plus les individus sont proches de la norme féminine (en termes de pratiques culturelles).\nL’indice est significativement différent selon le sexe biologique des interrogés.\n\n\nShow the code\nreg&lt;- lm(identity~Sex, my_data_frame)\nsummary(reg)\n\n\n\nCall:\nlm(formula = identity ~ Sex, data = my_data_frame)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.41933 -0.07875 -0.01093  0.06694  0.58782 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.424436   0.001815  233.79   &lt;2e-16 ***\nSexWomen    -0.099669   0.002450  -40.69   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1171 on 9232 degrees of freedom\nMultiple R-squared:  0.1521,    Adjusted R-squared:  0.152 \nF-statistic:  1656 on 1 and 9232 DF,  p-value: &lt; 2.2e-16\n\n\nLe sexe biologique est très significatif, les valeurs plus faibles de l’indice sont associées au sexe féminin.\n\n\n\n\n\nShow the code\ndata$identity&lt;- my_data_frame$identity\nmy_data_frame$identity&lt;-data$identity\n# List of cultural activities\ncultural_activities &lt;- c(\n   \"Knitting\" , \n                      \"Cards_games\",  \n                      \"Gambling\" , \n                      \"Cooking\" , \n                      \"DIY\"  ,\n                      \"Vegetable_garden\" , \n                      \"Fishing_hunting\" , \n                      \"Collection\"  ,\n                      \"Vehicle_custom\",\n                      \"Making_music\"   ,\n                      \"Diary\" ,\n                      \"Writing\" ,  \n                      \"Painting\",  \n                      \"Montage\"  , \n                      \"Pottery\" , \n                      \"Theater\" , \n                      \"Drawing\" , \n                      \"Dancing\",  \n                      \"Photography\"  ,\n                      \"Genealogy\" , \n                      \"Science\"  ,\n                      \"None\"  ,\n                      \"Video_games\"  ,\n                      \"Library\"  ,\n                      \"Concert\"\n)\n\n# Create a data frame to store the results\nresult_table &lt;- data.frame(Activity = character(0), Accuracy = numeric(0))\n\nfor (activity in cultural_activities) {\n  # Perform a Probit regression for the current cultural activity\n  model_formula &lt;- as.formula(paste(activity, \"~ identity\"))\n  model &lt;- glm(model_formula, data = my_data_frame, family = binomial(link = \"probit\"))\n \n  # Calculate predictions\n  predicted &lt;- ifelse(predict(model, type = \"response\") &gt;= 0.5, 1, 0)\n \n  # Calculate the accuracy\n  correct_predictions &lt;- sum(predicted == my_data_frame[[activity]])\n  total_predictions &lt;- nrow(my_data_frame)\n  accuracy &lt;- (correct_predictions / total_predictions) * 100\n \n  # Add the result to the data frame\n  result_table &lt;- rbind(result_table, data.frame(Activity = activity, Accuracy = accuracy))\n}\nresult_table\n\n\n           Activity Accuracy\n1          Knitting 84.37297\n2       Cards_games 51.00715\n3          Gambling 79.18562\n4           Cooking 56.55187\n5               DIY 51.25623\n6  Vegetable_garden 72.89365\n7   Fishing_hunting 93.95712\n8        Collection 92.54927\n9    Vehicle_custom 96.85943\n10     Making_music 68.16114\n11            Diary 85.85662\n12          Writing 88.16331\n13         Painting 78.76327\n14          Montage 84.52458\n15          Pottery 89.50617\n16          Theater 86.53888\n17          Drawing 76.73814\n18          Dancing 79.66212\n19      Photography 74.53974\n20        Genealogy 88.21746\n21          Science 88.30409\n22             None 70.19710\n23      Video_games 62.06411\n24          Library 83.20338\n25          Concert 81.92549\n\n\nNous réalisons une série de régressions Probit sur les différentes pratiques culturelles, avec pour unique régresseur notre indice d’identité, afin de mesurer le pouvoir prédictif (ou accuracy) de ce dernier.\n\n\n\nComparons l’indice obtenu avec d’autres mesures, et plus particulièrement avec les indices échelle d’identité.\nPour cela, nous allons diviser notre indice en 7 catégories, allant du plus féminin au plus masculin.\n\n\nShow the code\nmy_data_frame$identity_scale &lt;- cut(\n  my_data_frame$identity,\n  breaks = 7,  # Automatically divide into 7 slices\n  labels = c(\"Very Feminine\", \"1\", \"2\", \"3\", \"4\", \"5\", \"Very Masculine\"), \n  include.lowest = TRUE  \n)\ntable1 &lt;-\n  my_data_frame |&gt; \n  tbl_summary(include = c(identity_scale),\n  by=Sex ,)|&gt; \n    add_p()\ntable1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\np-value2\n\n\n\n\nidentity_scale\n\n\n\n\n&lt;0.001\n\n\n    Very Feminine\n9 (0.2%)\n218 (4.3%)\n\n\n\n\n    1\n403 (9.7%)\n1,506 (30%)\n\n\n\n\n    2\n2,139 (51%)\n2,669 (53%)\n\n\n\n\n    3\n985 (24%)\n576 (11%)\n\n\n\n\n    4\n509 (12%)\n90 (1.8%)\n\n\n\n\n    5\n96 (2.3%)\n10 (0.2%)\n\n\n\n\n    Very Masculine\n21 (0.5%)\n3 (&lt;0.1%)\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\nCe tableau est à mettre en perspective avec les données de Trachman (2022a).\nTout d’abord non remarquons que, comme dans l’enquête de Trachman (2022a), les individus “hors norme” sont peu nombreux (d’après notre indice, moins de 0,1% des femmes ont des pratiques culturelles très masculines; 0,2% des hommes ont des pratiques très féminines) , de même que les individus dont les pratiques culturelles seraient complètement conformes à leur sexe biologique ne sont pas la majorité (4,3% des femmes sont classées comme très féminines, 0,5% des hommes comme très masculins.)\nCela plaide encore une fois pour l’intérêt d’une mesure continue.\nNous allons ensuite explorer plus en détails les variables socio-démographiques qui peuvent influencer notre indice (revenu, âge, catégorie socio-professionnelle …)"
  },
  {
    "objectID": "recherche/recherche_presentation.html",
    "href": "recherche/recherche_presentation.html",
    "title": "Thèmes de Recherche",
    "section": "",
    "text": "Thèmes de Recherche\nEconomie et identité; Genre; Distances aux normes\n\n\nTravail en cours\nVers une mesure continue de l’identité de Genre: enjeux pour l’analyse économique\n\n\nThèse\nThèse soutenue en 2015\n“Essais sur la ségrégation et l’identité en France”\nSous la direction de Benoît Tarroux\nMention très honorable\nJury :\nProf. Catherine Baumont, Université de Bourgogne (Rapporteur)\nProf. Isabelle Lebon, Université de Caen (Présidente)\nProf. Yannick L’Horty, Université Paris-Est Marne la vallée (Rapporteur)\nProf. Fabien Moizeau, Université de Rennes 1 (Examinateur)\nBenoît Tarroux, Université de Rennes 1 (Directeur)\n\n\nEncadrements :\nMémoire APEME : Femmes économistes: Oubliées de l’Histoire, Anaïs Bidau\n\n\nCommunications\n2024, Conférence AFEPOP, Aubervilliers, “Beyond Binary: Continuous Measurement of Gender through Cultural Practices”\n2014 ESA, Experimental economics, european meeting, Prague\n2012 Conférence Territoires, Emploi et Politiques Publiques (TEPP), Caen Séminaire doctoral de l’association PROJECT et du CREM (Centre de Recherche en Economie et Management), Rennes\n2011 Journées Louis-André Gérard-Varet (LAGV), Marseille"
  }
]